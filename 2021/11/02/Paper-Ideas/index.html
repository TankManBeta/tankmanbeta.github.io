<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//unpkg.com/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//unpkg.com/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","version":"8.2.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="前言记录一下读过论文的idea">
<meta property="og:type" content="article">
<meta property="og:title" content="Paper Ideas">
<meta property="og:url" content="http://example.com/2021/11/02/Paper-Ideas/index.html">
<meta property="og:site_name" content="木霈玖的博客">
<meta property="og:description" content="前言记录一下读过论文的idea">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104195000.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104195040.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104203300.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/swin_1.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/swin_2.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201617035.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201619762.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201620069.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201624545.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/image-20211128164821263.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/image-20211128222044474.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222142.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222208.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222342.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222510.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222753.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_1.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_2.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_3.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_4.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_5.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309201020.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309201330.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309202447.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309202721.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309204135.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309204238.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309210508.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310155509.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310165322.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310170640.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310171021.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310171036.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180129.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180331.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180732.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310182117.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310182545.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311161000.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163413.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163508.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163540.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311164311.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311164651.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311170307.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317183104.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317184032.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317184906.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317185502.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317192154.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409163226.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409163632.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409170339.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409190020.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409191356.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192717.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192809.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192845.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192956.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193039.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193200.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193248.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418100747.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418101053.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418102832.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418103015.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418103050.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418104326.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418104941.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418105440.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418112136.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418171923.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418172009.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418172045.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419144543.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419144750.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210104.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210302.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210602.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419212746.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419213250.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419213846.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419214445.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419214930.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419215013.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506153709.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506161343.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506163025.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506185405.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506190851.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506191803.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506193734.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506195407.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922185741.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922190052.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922182417.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183152.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183302.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183445.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183525.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183605.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922184617.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922184701.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018145545.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018154155.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018154550.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115190422.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115191221.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115191016.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115191607.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116200121.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116200232.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116205653.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116213608.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116213714.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221118212130.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122154217.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122160053.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122193732.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122193746.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306281141887.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122213846.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122214437.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123152103.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123170343.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123170408.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123183426.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123184335.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202307272018331.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123184435.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123203344.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123203431.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123204243.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123210401.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123210533.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123210855.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123211556.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123211716.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205170739.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205203028.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205214837.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205215023.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205214955.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217220123.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217220133.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217220736.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217221314.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217223920.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217232831.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218200105.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218202953.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218205354.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218210144.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218212706.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218212838.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219220719.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219221457.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219222626.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219222817.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219225014.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219230838.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219232152.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219235252.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219235653.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221220000003.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221220001036.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230211153611.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230211155200.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212144228.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212153208.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212155919.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212163209.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212201155.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212202332.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230213101414.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302131715182.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230213161638.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230213161939.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302131656136.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302131924672.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302132056756.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302212130293.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221930860.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221935195.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221938520.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221943064.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221945395.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032014921.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032028309.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032029896.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032100151.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032100790.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032101711.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132019570.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132057323.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132101706.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132119440.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132153659.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305241731730.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305241749960.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305241755648.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291451457.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291457474.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291556942.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291556510.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291616203.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291619802.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292133138.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292200111.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292201794.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292208610.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292208510.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151113163.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151156212.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151134329.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151152897.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151155277.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202307271409187.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101600250.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101633201.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101641619.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101644169.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101707037.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101725583.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101735864.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101735384.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308111724017.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308111728085.png">
<meta property="article:published_time" content="2021-11-02T13:40:57.000Z">
<meta property="article:modified_time" content="2023-09-07T01:24:44.047Z">
<meta property="article:author" content="木霈玖">
<meta property="article:tag" content="总结">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104195000.png">


<link rel="canonical" href="http://example.com/2021/11/02/Paper-Ideas/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>
<title>Paper Ideas | 木霈玖的博客</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">木霈玖的博客</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Physics-Coupled-Spatio-Temporal-Active-Learning-for-Dynamical-Systems"><span class="nav-number">2.</span> <span class="nav-text">Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ACTIVE-LEARNING-OF-DEEP-SURROGATES-FOR-PDES"><span class="nav-number">3.</span> <span class="nav-text">ACTIVE LEARNING OF DEEP SURROGATES FOR PDES</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows"><span class="nav-number">4.</span> <span class="nav-text">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">4.1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Architecture"><span class="nav-number">4.2.</span> <span class="nav-text">Architecture</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adversarial-Sampling-for-Solving-Differential-Equations-with-Neural-Networks"><span class="nav-number">5.</span> <span class="nav-text">Adversarial Sampling for Solving Differential Equations with Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-1"><span class="nav-number">5.1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Key-Idea"><span class="nav-number">5.2.</span> <span class="nav-text">Key Idea</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Architecture-1"><span class="nav-number">5.3.</span> <span class="nav-text">Architecture</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Problem"><span class="nav-number">5.4.</span> <span class="nav-text">Problem</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Solution"><span class="nav-number">5.5.</span> <span class="nav-text">Solution</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Machine-Learning-of-Linear-Differential-Equations-using-Gaussian-Processes"><span class="nav-number">6.</span> <span class="nav-text">Machine Learning of Linear Differential Equations using Gaussian Processes</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Priors"><span class="nav-number">6.1.</span> <span class="nav-text">Priors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kernels"><span class="nav-number">6.2.</span> <span class="nav-text">Kernels</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Training"><span class="nav-number">6.3.</span> <span class="nav-text">Training</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Predictions"><span class="nav-number">6.4.</span> <span class="nav-text">Predictions</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Learning-Physics-Informed-Neural-Networks-without-Stacked-Back-propagation"><span class="nav-number">7.</span> <span class="nav-text">Learning Physics-Informed Neural Networks without Stacked Back-propagation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Problems"><span class="nav-number">7.1.</span> <span class="nav-text">Problems</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Contribution"><span class="nav-number">7.2.</span> <span class="nav-text">Contribution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Advantages"><span class="nav-number">7.3.</span> <span class="nav-text">Advantages</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Notice"><span class="nav-number">7.4.</span> <span class="nav-text">Notice</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Two-Sources-of-Inefficiency-In-Computing-the-PINN-Loss"><span class="nav-number">7.5.</span> <span class="nav-text">Two Sources of Inefficiency In Computing the PINN Loss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Method"><span class="nav-number">7.6.</span> <span class="nav-text">Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-Back-propagation-free-Derivative-Estimators"><span class="nav-number">7.6.1.</span> <span class="nav-text">4.1 Back-propagation-free Derivative Estimators</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Proof"><span class="nav-number">7.6.1.1.</span> <span class="nav-text">Proof</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-Model-Capacity"><span class="nav-number">7.6.2.</span> <span class="nav-text">4.2 Model Capacity</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Proof-1"><span class="nav-number">7.6.2.1.</span> <span class="nav-text">Proof</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-Variance-Reduced-Stein%E2%80%99s-Derivative-Estimators"><span class="nav-number">7.6.3.</span> <span class="nav-text">4.3 Variance-Reduced Stein’s Derivative Estimators</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#The-control-variate-method"><span class="nav-number">7.6.3.1.</span> <span class="nav-text">The control variate method</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Further-improvement-using-the-antithetic-variable-method"><span class="nav-number">7.6.3.2.</span> <span class="nav-text">Further improvement using the antithetic variable method</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Neural-Galerkin-Scheme-with-Active-Learning-for-High-Dimensional-Evolution-Equations"><span class="nav-number">8.</span> <span class="nav-text">Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract"><span class="nav-number">8.1.</span> <span class="nav-text">Abstract</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#problems"><span class="nav-number">8.1.1.</span> <span class="nav-text">problems</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-2"><span class="nav-number">8.2.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Main-contributions"><span class="nav-number">8.2.1.</span> <span class="nav-text">Main contributions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Related-works"><span class="nav-number">8.2.2.</span> <span class="nav-text">Related works</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Neural-Galerkin-schemes"><span class="nav-number">8.3.</span> <span class="nav-text">Neural Galerkin schemes</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Galerkin"><span class="nav-number">8.3.1.</span> <span class="nav-text">Neural Galerkin</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Parametrizing-the-solution"><span class="nav-number">8.3.1.1.</span> <span class="nav-text">Parametrizing the solution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Controlling-the-residual"><span class="nav-number">8.3.1.2.</span> <span class="nav-text">Controlling the residual</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Neural-Galerkin-equations"><span class="nav-number">8.3.1.3.</span> <span class="nav-text">Neural Galerkin equations</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Estimating-M-theta-and-F-t-theta"><span class="nav-number">8.3.2.</span> <span class="nav-text">Estimating $M(\theta)$ and $F(t, \theta)$</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Importance-sampling-with-a-fixed-measure"><span class="nav-number">8.3.2.1.</span> <span class="nav-text">Importance sampling with a fixed measure</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Direct-sampling-with-an-adaptive-measure"><span class="nav-number">8.3.2.2.</span> <span class="nav-text">Direct sampling with an adaptive measure</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Discretization-in-time"><span class="nav-number">8.3.3.</span> <span class="nav-text">Discretization in time</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Explicit-integrators"><span class="nav-number">8.3.3.1.</span> <span class="nav-text">Explicit integrators</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Implicit-integrators"><span class="nav-number">8.3.3.2.</span> <span class="nav-text">Implicit integrators</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-architectures"><span class="nav-number">8.3.4.</span> <span class="nav-text">Neural architectures</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#AUTOIP-A-UNITED-FRAMEWORK-TO-INTEGRATE-PHYSICS-INTO-GAUSSIAN-PROCESSES"><span class="nav-number">9.</span> <span class="nav-text">AUTOIP: A UNITED FRAMEWORK TO INTEGRATE PHYSICS INTO GAUSSIAN PROCESSES</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-3"><span class="nav-number">9.1.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Contribution-1"><span class="nav-number">9.1.1.</span> <span class="nav-text">Contribution</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gaussian-Process-Regression"><span class="nav-number">9.2.</span> <span class="nav-text">Gaussian Process Regression</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Model"><span class="nav-number">9.3.</span> <span class="nav-text">Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Algorithm"><span class="nav-number">9.4.</span> <span class="nav-text">Algorithm</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RESPECTING-CAUSALITY-IS-ALL-YOU-NEED-FOR-TRAINING-PHYSICS-INFORMED-NEURAL-NETWORKS"><span class="nav-number">10.</span> <span class="nav-text">RESPECTING CAUSALITY IS ALL YOU NEED FOR TRAINING PHYSICS-INFORMED NEURAL NETWORKS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-4"><span class="nav-number">10.1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Causal-training-for-physics-informed-neural-networks"><span class="nav-number">10.2.</span> <span class="nav-text">Causal training for physics-informed neural networks</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Deep-Implicit-Moving-Least-Squares-Functions-for-3D-Reconstruction"><span class="nav-number">11.</span> <span class="nav-text">Deep Implicit Moving Least-Squares Functions for 3D Reconstruction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-1"><span class="nav-number">11.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-5"><span class="nav-number">11.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-Work"><span class="nav-number">11.3.</span> <span class="nav-text">Related Work</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-representations-for-3D-generation"><span class="nav-number">11.3.1.</span> <span class="nav-text">Deep representations for 3D generation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Surface-reconstruction-from-point-clouds"><span class="nav-number">11.3.2.</span> <span class="nav-text">Surface reconstruction from point clouds</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Method-1"><span class="nav-number">11.4.</span> <span class="nav-text">Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#IMLS-surface"><span class="nav-number">11.4.1.</span> <span class="nav-text">IMLS surface</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-IMLS-surface"><span class="nav-number">11.4.2.</span> <span class="nav-text">Deep IMLS surface</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Scaffold-prediction"><span class="nav-number">11.4.2.1.</span> <span class="nav-text">Scaffold prediction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MLS-point-prediction"><span class="nav-number">11.4.2.2.</span> <span class="nav-text">MLS point prediction</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Network-structure"><span class="nav-number">11.4.3.</span> <span class="nav-text">Network structure</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Loss-function-design"><span class="nav-number">11.4.4.</span> <span class="nav-text">Loss function design</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Octree-structure-loss"><span class="nav-number">11.4.4.1.</span> <span class="nav-text">Octree structure loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SDF-loss"><span class="nav-number">11.4.4.2.</span> <span class="nav-text">SDF loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MLS-point-repulsion-loss"><span class="nav-number">11.4.4.3.</span> <span class="nav-text">MLS point repulsion loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Projection-smoothness-loss"><span class="nav-number">11.4.4.4.</span> <span class="nav-text">Projection smoothness loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Radius-smoothness-loss"><span class="nav-number">11.4.4.5.</span> <span class="nav-text">Radius smoothness loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Weight-decay"><span class="nav-number">11.4.4.6.</span> <span class="nav-text">Weight decay</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Efficient-Training-of-Physics-Informed-Neural-Networks-via-Importance-Sampling"><span class="nav-number">12.</span> <span class="nav-text">Efficient Training of Physics-Informed Neural Networks via Importance Sampling</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-2"><span class="nav-number">12.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-6"><span class="nav-number">12.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-Learning-of-Differential-Equations"><span class="nav-number">12.3.</span> <span class="nav-text">Deep Learning of Differential Equations</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Importance-Sampling-for-Training-of-PINNs"><span class="nav-number">12.4.</span> <span class="nav-text">Importance Sampling for Training of PINNs</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PAGP-A-physics-assisted-Gaussian-process-framework-with-active-learning-for-forward-and-inverse-problems-of-partial-differential-equations"><span class="nav-number">13.</span> <span class="nav-text">PAGP: A physics-assisted Gaussian process framework with active learning for forward and inverse problems of partial differential equations</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-3"><span class="nav-number">13.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-7"><span class="nav-number">13.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology"><span class="nav-number">13.3.</span> <span class="nav-text">Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Gaussian-process-regression"><span class="nav-number">13.3.1.</span> <span class="nav-text">Gaussian process regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Derivatives-of-Gaussian-process-regression"><span class="nav-number">13.3.2.</span> <span class="nav-text">Derivatives of Gaussian process regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Models"><span class="nav-number">13.3.3.</span> <span class="nav-text">Models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Active-Learning"><span class="nav-number">13.3.4.</span> <span class="nav-text">Active Learning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion"><span class="nav-number">13.4.</span> <span class="nav-text">Conclusion</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Breaking-the-Dilemma-of-Medical-Image-to-image-Translation"><span class="nav-number">14.</span> <span class="nav-text">Breaking the Dilemma of Medical Image-to-image Translation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-4"><span class="nav-number">14.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-8"><span class="nav-number">14.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology-1"><span class="nav-number">14.3.</span> <span class="nav-text">Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Theoretical-Motivation"><span class="nav-number">14.3.1.</span> <span class="nav-text">Theoretical Motivation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RegGAN"><span class="nav-number">14.3.2.</span> <span class="nav-text">RegGAN</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Characterizing-possible-failure-modes-in-physics-informed-neural-networks"><span class="nav-number">15.</span> <span class="nav-text">Characterizing possible failure modes in physics-informed neural networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-5"><span class="nav-number">15.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-9"><span class="nav-number">15.2.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-overview"><span class="nav-number">15.2.1.</span> <span class="nav-text">Problem overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Main-contributions-1"><span class="nav-number">15.2.2.</span> <span class="nav-text">Main contributions</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-work"><span class="nav-number">15.3.</span> <span class="nav-text">Related work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Possible-failure-modes-for-physics-informed-neural-networks"><span class="nav-number">15.4.</span> <span class="nav-text">Possible failure modes for physics-informed neural networks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Experiment-setup"><span class="nav-number">15.4.1.</span> <span class="nav-text">Experiment setup.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#convection%E3%80%81reaction-diffusion"><span class="nav-number">15.4.2.</span> <span class="nav-text">convection、reaction-diffusion</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Diagnosing-possible-failure-modes-for-physics-informed-NNs"><span class="nav-number">15.5.</span> <span class="nav-text">Diagnosing possible failure modes for physics-informed NNs</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Soft-PDE-regularization-and-optimization-difficulties"><span class="nav-number">15.5.1.</span> <span class="nav-text">Soft PDE regularization and optimization difficulties</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Expressivity-versus-optimization-difficulty"><span class="nav-number">15.6.</span> <span class="nav-text">Expressivity versus optimization difficulty</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Curriculum-PINN-Regularization"><span class="nav-number">15.6.1.</span> <span class="nav-text">Curriculum PINN Regularization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sequence-to-sequence-learning-vs-learning-the-entire-space-time-solution"><span class="nav-number">15.6.2.</span> <span class="nav-text">Sequence-to-sequence learning vs learning the entire space-time solution</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Uncertainty-Quantification-in-Scientific-Machine-Learning-Methods-Metrics-and-Comparisons"><span class="nav-number">16.</span> <span class="nav-text">Uncertainty Quantification in Scientific Machine Learning:Methods, Metrics, and Comparisons</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-6"><span class="nav-number">16.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-10"><span class="nav-number">16.2.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Novel-contributions-of-this-work"><span class="nav-number">16.2.1.</span> <span class="nav-text">Novel contributions of this work</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Neural-PDEs-and-neural-operators"><span class="nav-number">16.3.</span> <span class="nav-text">Neural PDEs and neural operators</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Solving-forward-and-mixed-PDE-problems-Overview-of-PINN-method"><span class="nav-number">16.3.1.</span> <span class="nav-text">Solving forward and mixed PDE problems: Overview of PINN method</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Learning-operator-mappings-Overview-of-DeepONet-method"><span class="nav-number">16.3.2.</span> <span class="nav-text">Learning operator mappings: Overview of DeepONet method</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Modeling-total-uncertainty"><span class="nav-number">16.4.</span> <span class="nav-text">Modeling total uncertainty</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Uncertainty-in-function-approximation"><span class="nav-number">16.4.1.</span> <span class="nav-text">Uncertainty in function approximation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Uncertainty-in-PINNs"><span class="nav-number">16.4.2.</span> <span class="nav-text">Uncertainty in PINNs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Uncertainty-in-DeepONets"><span class="nav-number">16.4.3.</span> <span class="nav-text">Uncertainty in DeepONets</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methods-for-uncertainty-quantification"><span class="nav-number">16.5.</span> <span class="nav-text">Methods for uncertainty quantification</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Multi-Objective-Loss-Balancing-for-Physics-Informed-Deep-Learning"><span class="nav-number">17.</span> <span class="nav-text">Multi-Objective Loss Balancing for Physics-Informed Deep Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-7"><span class="nav-number">17.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-11"><span class="nav-number">17.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Physics-Informed-Neural-Networks-PINNs"><span class="nav-number">17.3.</span> <span class="nav-text">Physics-Informed Neural Networks (PINNs)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology-2"><span class="nav-number">17.4.</span> <span class="nav-text">Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Multi-Objective-Optimisation"><span class="nav-number">17.4.1.</span> <span class="nav-text">Multi-Objective Optimisation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adaptive-Loss-Balancing-Methods"><span class="nav-number">17.4.2.</span> <span class="nav-text">Adaptive Loss Balancing Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Learning-Rate-Annealing"><span class="nav-number">17.4.2.1.</span> <span class="nav-text">Learning Rate Annealing</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#GradNorm"><span class="nav-number">17.4.2.2.</span> <span class="nav-text">GradNorm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SoftAdapt"><span class="nav-number">17.4.2.3.</span> <span class="nav-text">SoftAdapt</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Relative-Loss-Balancing-with-Random-Lookback-ReLoBRaLo"><span class="nav-number">17.5.</span> <span class="nav-text">Relative Loss Balancing with Random Lookback (ReLoBRaLo)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hyperparameter-Tuning-and-Meta-Learning"><span class="nav-number">17.6.</span> <span class="nav-text">Hyperparameter Tuning and Meta Learning</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#A-Unified-Hard-Constraint-Framework-for-Solving-Geometrically-Complex-PDEs"><span class="nav-number">18.</span> <span class="nav-text">A Unified Hard-Constraint Framework for Solving Geometrically Complex PDEs</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-8"><span class="nav-number">18.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-12"><span class="nav-number">18.2.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#contribution"><span class="nav-number">18.2.1.</span> <span class="nav-text">contribution</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Background"><span class="nav-number">18.3.</span> <span class="nav-text">Background</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Physics-Informed-Neural-Networks"><span class="nav-number">18.3.1.</span> <span class="nav-text">Physics-Informed Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hard-Constraint-Methods"><span class="nav-number">18.3.2.</span> <span class="nav-text">Hard-Constraint Methods</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology-3"><span class="nav-number">18.4.</span> <span class="nav-text">Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-Setup"><span class="nav-number">18.4.1.</span> <span class="nav-text">Problem Setup</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reformulating-PDEs-via-Extra-Fields"><span class="nav-number">18.4.2.</span> <span class="nav-text">Reformulating PDEs via Extra Fields</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Unified-Hard-Constraint-Framework"><span class="nav-number">18.4.3.</span> <span class="nav-text">A Unified Hard-Constraint Framework</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DeepONet-Learning-nonlinear-operators-for-identifying-differential-equations-based-on-the-universal-approximation-theorem-of-operators"><span class="nav-number">19.</span> <span class="nav-text">DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-9"><span class="nav-number">19.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-13"><span class="nav-number">19.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology-4"><span class="nav-number">19.3.</span> <span class="nav-text">Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-operator-networks-DeepONets"><span class="nav-number">19.3.1.</span> <span class="nav-text">Deep operator networks (DeepONets)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-generation"><span class="nav-number">19.3.2.</span> <span class="nav-text">Data generation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion-1"><span class="nav-number">19.4.</span> <span class="nav-text">Conclusion</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#FOURIER-NEURAL-OPERATOR-FOR-PARAMETRIC-PARTIAL-DIFFERENTIAL-EQUATIONS"><span class="nav-number">20.</span> <span class="nav-text">FOURIER NEURAL OPERATOR FOR PARAMETRIC PARTIAL DIFFERENTIAL EQUATIONS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-10"><span class="nav-number">20.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-14"><span class="nav-number">20.2.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Conventional-solvers-vs-Data-driven-methods"><span class="nav-number">20.2.1.</span> <span class="nav-text">Conventional solvers vs. Data-driven methods.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Finite-dimensional-operators"><span class="nav-number">20.2.2.</span> <span class="nav-text">Finite-dimensional operators.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-FEM"><span class="nav-number">20.2.3.</span> <span class="nav-text">Neural-FEM.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Operators"><span class="nav-number">20.2.4.</span> <span class="nav-text">Neural Operators.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fourier-Transform"><span class="nav-number">20.2.5.</span> <span class="nav-text">Fourier Transform.</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LEARNING-OPERATORS"><span class="nav-number">20.3.</span> <span class="nav-text">LEARNING OPERATORS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Learning-the-Operator"><span class="nav-number">20.3.1.</span> <span class="nav-text">Learning the Operator.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Discretization"><span class="nav-number">20.3.2.</span> <span class="nav-text">Discretization.</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NEURAL-OPERATOR"><span class="nav-number">20.4.</span> <span class="nav-text">NEURAL OPERATOR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FOURIER-NEURAL-OPERATOR"><span class="nav-number">20.5.</span> <span class="nav-text">FOURIER NEURAL OPERATOR</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#The-discrete-case-and-the-FFT"><span class="nav-number">20.5.1.</span> <span class="nav-text">The discrete case and the FFT.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Parameterizations-of-R"><span class="nav-number">20.5.2.</span> <span class="nav-text">Parameterizations of R.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Invariance-to-discretization"><span class="nav-number">20.5.3.</span> <span class="nav-text">Invariance to discretization.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Quasi-linear-complexity"><span class="nav-number">20.5.4.</span> <span class="nav-text">Quasi-linear complexity.</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86"><span class="nav-number">20.6.</span> <span class="nav-text">补充知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#FFT"><span class="nav-number">20.6.1.</span> <span class="nav-text">FFT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B"><span class="nav-number">20.6.2.</span> <span class="nav-text">代码流程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#A-composite-neural-network-that-learns-from-multi-fidelity-data-Application-to-function-approximation-and-inverse-PDE-problems"><span class="nav-number">21.</span> <span class="nav-text">A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">21.1.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NSFnets-Navier-Stokes-flow-nets-Physics-informed-neural-networks-for-the-incompressible-Navier-Stokes-equations"><span class="nav-number">22.</span> <span class="nav-text">NSFnets (Navier-Stokes flow nets): Physics-informed neural networks for the incompressible Navier-Stokes equations</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-11"><span class="nav-number">22.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-15"><span class="nav-number">22.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology-5"><span class="nav-number">22.3.</span> <span class="nav-text">Methodology</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Spatio-Temporal-Super-Resolution-of-Dynamical-Systems-using-Physics-Informed-Deep-Learning"><span class="nav-number">23.</span> <span class="nav-text">Spatio-Temporal Super-Resolution of Dynamical Systems using Physics-Informed Deep-Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-12"><span class="nav-number">23.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-16"><span class="nav-number">23.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Background-1"><span class="nav-number">23.3.</span> <span class="nav-text">Background</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Governing-equations"><span class="nav-number">23.3.1.</span> <span class="nav-text">Governing equations</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology-6"><span class="nav-number">23.4.</span> <span class="nav-text">Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Objective-function"><span class="nav-number">23.4.1.</span> <span class="nav-text">Objective function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Input-and-output-for-the-framework"><span class="nav-number">23.4.2.</span> <span class="nav-text">Input and output for the framework</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Framework-Architecture"><span class="nav-number">23.4.3.</span> <span class="nav-text">Framework Architecture</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Spatial-resolution-enhancement-module"><span class="nav-number">23.4.3.1.</span> <span class="nav-text">Spatial resolution enhancement module</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Temporal-resolution-enhancement-module"><span class="nav-number">23.4.3.2.</span> <span class="nav-text">Temporal resolution enhancement module</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Error-Aware-B-PINNs-Improving-Uncertainty-Quantification-in-Bayesian-Physics-Informed-Neural-Networks"><span class="nav-number">24.</span> <span class="nav-text">Error-Aware B-PINNs: Improving Uncertainty Quantification in Bayesian Physics-Informed Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-13"><span class="nav-number">24.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-17"><span class="nav-number">24.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Background-2"><span class="nav-number">24.3.</span> <span class="nav-text">Background</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-Formulation"><span class="nav-number">24.3.1.</span> <span class="nav-text">Problem Formulation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Physics-Informed-Neural-Networks-1"><span class="nav-number">24.3.2.</span> <span class="nav-text">Physics-Informed Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Uncertainty-Quantification-in-Bayesian-Neural-Networks"><span class="nav-number">24.3.3.</span> <span class="nav-text">Uncertainty Quantification in Bayesian Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Methods-for-Finding-the-Posterior-Distribution"><span class="nav-number">24.3.3.1.</span> <span class="nav-text">Methods for Finding the Posterior Distribution</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Uncertainty-Quantification-in-B-PINNs"><span class="nav-number">24.4.</span> <span class="nav-text">Uncertainty Quantification in B-PINNs</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Existing-Approach"><span class="nav-number">24.4.1.</span> <span class="nav-text">Existing Approach</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Error-Aware-B-PINNs"><span class="nav-number">24.4.2.</span> <span class="nav-text">Error-Aware B-PINNs</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#My-Summary"><span class="nav-number">24.5.</span> <span class="nav-text">My Summary</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#A-Dimension-Augmented-Physics-Informed-Neural-Network-DaPINN-with-High-Level-Accuracy-and-Efficiency"><span class="nav-number">25.</span> <span class="nav-text">A Dimension-Augmented Physics-Informed Neural Network(DaPINN) with High Level Accuracy and Efficiency</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-14"><span class="nav-number">25.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-18"><span class="nav-number">25.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methods"><span class="nav-number">25.3.</span> <span class="nav-text">Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Physics-informed-neural-networks-PINN"><span class="nav-number">25.3.1.</span> <span class="nav-text">Physics-informed neural networks (PINN)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dimension-augmentated-PINN"><span class="nav-number">25.3.2.</span> <span class="nav-text">Dimension-augmentated PINN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Several-input-dimension-augmentation-methods"><span class="nav-number">25.3.3.</span> <span class="nav-text">Several input dimension augmentation methods</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#L-HYDRA-MULTI-HEAD-PHYSICS-INFORMED-NEURAL-NETWORKS"><span class="nav-number">26.</span> <span class="nav-text">L-HYDRA: MULTI-HEAD PHYSICS-INFORMED NEURAL NETWORKS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-15"><span class="nav-number">26.1.</span> <span class="nav-text">Abstract.</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-19"><span class="nav-number">26.2.</span> <span class="nav-text">Introduction.</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology-7"><span class="nav-number">26.3.</span> <span class="nav-text">Methodology.</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Multi-head-physics-informed-neural-networks-MH-PINNs"><span class="nav-number">26.3.1.</span> <span class="nav-text">Multi-head physics-informed neural networks (MH-PINNs).</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Generative-modeling-and-normalizing-flows-NFs"><span class="nav-number">26.3.2.</span> <span class="nav-text">Generative modeling and normalizing flows (NFs).</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prior-knowledge-utilized-in-the-downstream-tasks"><span class="nav-number">26.3.3.</span> <span class="nav-text">Prior knowledge utilized in the downstream tasks.</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Regularization-in-optimization"><span class="nav-number">26.3.3.1.</span> <span class="nav-text">Regularization in optimization.</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Prior-distribution-in-Bayesian-inference"><span class="nav-number">26.3.3.2.</span> <span class="nav-text">Prior distribution in Bayesian inference.</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#My-Summary-1"><span class="nav-number">26.4.</span> <span class="nav-text">My Summary</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LSA-PINN-Linear-Boundary-Connectivity-Loss-for-Solving-PDEs-on-Complex-Geometry"><span class="nav-number">27.</span> <span class="nav-text">LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex Geometry</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-16"><span class="nav-number">27.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-20"><span class="nav-number">27.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-Work-1"><span class="nav-number">27.3.</span> <span class="nav-text">Related Work</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Efficient-sampling-in-PINNs"><span class="nav-number">27.3.1.</span> <span class="nav-text">Efficient sampling in PINNs.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN-architecture-and-numerical-differentiation-ND-type-loss-for-PINNs"><span class="nav-number">27.3.2.</span> <span class="nav-text">CNN architecture and numerical differentiation (ND)-type loss for PINNs.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Enforcing-BC-constraint-in-PINN-loss"><span class="nav-number">27.3.3.</span> <span class="nav-text">Enforcing BC constraint in PINN loss.</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Preliminary"><span class="nav-number">27.4.</span> <span class="nav-text">Preliminary</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Method-2"><span class="nav-number">27.5.</span> <span class="nav-text">Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Enforcing-linear-constraint-at-near-boundary-samples"><span class="nav-number">27.5.1.</span> <span class="nav-text">Enforcing linear constraint at near-boundary samples</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Boundary-connectivity-BCXN-loss-with-direct-forcing"><span class="nav-number">27.5.2.</span> <span class="nav-text">Boundary connectivity (BCXN)-loss with direct forcing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Procedure-to-evaluate-the-field-value-vec-u-MI-at-mirror-point"><span class="nav-number">27.5.3.</span> <span class="nav-text">Procedure to evaluate the field value $\vec{u}_{MI}$ at mirror point</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DMIS-Dynamic-Mesh-based-Importance-Sampling-for-Training-Physics-Informed-Neural-Networks"><span class="nav-number">28.</span> <span class="nav-text">DMIS: Dynamic Mesh-based Importance Sampling for Training Physics-Informed Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-17"><span class="nav-number">28.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-21"><span class="nav-number">28.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-Work-2"><span class="nav-number">28.3.</span> <span class="nav-text">Related Work</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Physics-Informed-Neural-Networks-2"><span class="nav-number">28.3.1.</span> <span class="nav-text">Physics-Informed Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Importance-Sampling"><span class="nav-number">28.3.2.</span> <span class="nav-text">Importance Sampling</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Optimization-Problem-of-PINNs"><span class="nav-number">28.4.</span> <span class="nav-text">Optimization Problem of PINNs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Method-3"><span class="nav-number">28.5.</span> <span class="nav-text">Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Importance-Sampling-for-PINNs"><span class="nav-number">28.5.1.</span> <span class="nav-text">Importance Sampling for PINNs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Simplified-Calculation-amp-Reweighting"><span class="nav-number">28.5.2.</span> <span class="nav-text">Simplified Calculation &amp; Reweighting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DMWE"><span class="nav-number">28.5.3.</span> <span class="nav-text">DMWE</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Transfer-Learning-Enhanced-DeepONet-for-Long-Time-Prediction-of-Evolution-Equations"><span class="nav-number">29.</span> <span class="nav-text">Transfer Learning Enhanced DeepONet for Long-Time Prediction of Evolution Equations</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-18"><span class="nav-number">29.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-22"><span class="nav-number">29.2.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Related-works-1"><span class="nav-number">29.2.1.</span> <span class="nav-text">Related works</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Numerical-method"><span class="nav-number">29.3.</span> <span class="nav-text">Numerical method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Physics-informed-DeepONet"><span class="nav-number">29.3.1.</span> <span class="nav-text">Physics-informed DeepONet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepONet-with-transfer-learning"><span class="nav-number">29.3.2.</span> <span class="nav-text">DeepONet with transfer learning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Theoretical-result"><span class="nav-number">29.4.</span> <span class="nav-text">Theoretical result</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Numerical-experiments"><span class="nav-number">29.5.</span> <span class="nav-text">Numerical experiments</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Theory-guided-physics-informed-neural-networks-for-boundary-layer-problems-with-singular-perturbation"><span class="nav-number">30.</span> <span class="nav-text">Theory-guided physics-informed neural networks for boundary layer problems with singular perturbation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-19"><span class="nav-number">30.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-23"><span class="nav-number">30.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methods-1"><span class="nav-number">30.3.</span> <span class="nav-text">Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-statement-singularly-perturbed-differential-equations"><span class="nav-number">30.3.1.</span> <span class="nav-text">Problem statement: singularly perturbed differential equations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Boundary-layer-physics-informed-neural-networks-BL-PINN"><span class="nav-number">30.3.2.</span> <span class="nav-text">Boundary layer physics-informed neural networks (BL-PINN)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Is-L2-Physics-Informed-Loss-Always-Suitable-for-Training-Physics-Informed-Neural-Network"><span class="nav-number">31.</span> <span class="nav-text">Is L2 Physics-Informed Loss Always Suitable for Training Physics-Informed Neural Network?</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-20"><span class="nav-number">31.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-24"><span class="nav-number">31.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-Works"><span class="nav-number">31.3.</span> <span class="nav-text">Related Works</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Preliminary-1"><span class="nav-number">31.4.</span> <span class="nav-text">Preliminary</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Failure-Mode-of-PINN-on-High-Dimensional-Stochastic-Optimal-Control"><span class="nav-number">31.5.</span> <span class="nav-text">Failure Mode of PINN on High-Dimensional Stochastic Optimal Control</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Solving-HJB-Equations-with-Adversarial-Training"><span class="nav-number">31.6.</span> <span class="nav-text">Solving HJB Equations with Adversarial Training</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Extended-physics-informed-neural-networks-XPINNs-A-generalized-space-time-domain-decomposition-based-deep-learning-framework-for-nonlinear-partial"><span class="nav-number">32.</span> <span class="nav-text">Extended physics-informed neural networks (XPINNs) : A generalized space-time domain decomposition based deep learning framework for nonlinear partial</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-21"><span class="nav-number">32.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-25"><span class="nav-number">32.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Problem-Formulation-1"><span class="nav-number">32.3.</span> <span class="nav-text">Problem Formulation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology-8"><span class="nav-number">32.4.</span> <span class="nav-text">Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Mathematical-setup-for-fully-connected-neural-networks"><span class="nav-number">32.4.1.</span> <span class="nav-text">Mathematical setup for fully connected neural networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Extended-Physics-Informed-Neural-Networks"><span class="nav-number">32.4.2.</span> <span class="nav-text">Extended Physics-Informed Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Subdomain-loss-function"><span class="nav-number">32.4.2.1.</span> <span class="nav-text">Subdomain loss function</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Conservative-physics-informed-neural-networks-on-discrete-domains-for-conservation-laws-Applications-to-forward-and-inverse-problems"><span class="nav-number">33.</span> <span class="nav-text">Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-22"><span class="nav-number">33.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-26"><span class="nav-number">33.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Problem-setup"><span class="nav-number">33.3.</span> <span class="nav-text">Problem setup</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methodology-9"><span class="nav-number">33.4.</span> <span class="nav-text">Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Sub-domain-loss-function-and-optimization-algorithm"><span class="nav-number">33.4.1.</span> <span class="nav-text">Sub-domain loss function and optimization algorithm</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Error-analysis-for-cPINN"><span class="nav-number">33.4.2.</span> <span class="nav-text">Error analysis for cPINN</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ADAPTIVE-FOURIER-NEURAL-OPERATORS-EFFICIENT-TOKEN-MIXERS-FOR-TRANSFORMERS"><span class="nav-number">34.</span> <span class="nav-text">ADAPTIVE FOURIER NEURAL OPERATORS: EFFICIENT TOKEN MIXERS FOR TRANSFORMERS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ABSTRACT"><span class="nav-number">34.1.</span> <span class="nav-text">ABSTRACT</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#INTRODUCTION"><span class="nav-number">34.2.</span> <span class="nav-text">INTRODUCTION</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RELATED-WORKS"><span class="nav-number">34.3.</span> <span class="nav-text">RELATED WORKS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PRELIMINARIES-AND-PROBLEM-STATEMENT"><span class="nav-number">34.4.</span> <span class="nav-text">PRELIMINARIES AND PROBLEM STATEMENT</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Discrete-FNO"><span class="nav-number">34.4.1.</span> <span class="nav-text">Discrete FNO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Local-Features"><span class="nav-number">34.4.2.</span> <span class="nav-text">Local Features</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Resolution-Invariance"><span class="nav-number">34.4.3.</span> <span class="nav-text">Resolution Invariance</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ADAPTIVE-FOURIER-NEURAL-OPERATORS-FOR-TRANSFORMERS"><span class="nav-number">34.5.</span> <span class="nav-text">ADAPTIVE FOURIER NEURAL OPERATORS FOR TRANSFORMERS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Block-Diagonal-Structure-on-W"><span class="nav-number">34.5.1.</span> <span class="nav-text">Block-Diagonal Structure on W</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Weight-Sharing"><span class="nav-number">34.5.2.</span> <span class="nav-text">Weight Sharing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Soft-Thresholding-and-Shrinkage"><span class="nav-number">34.5.3.</span> <span class="nav-text">Soft-Thresholding and Shrinkage</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#FOURCASTNET-A-GLOBAL-DATA-DRIVEN-HIGH-RESOLUTION-WEATHER-MODEL-USING-ADAPTIVE-FOURIER-NEURAL-OPERATORS"><span class="nav-number">35.</span> <span class="nav-text">FOURCASTNET: A GLOBAL DATA-DRIVEN HIGH-RESOLUTION WEATHER MODEL USING ADAPTIVE FOURIER NEURAL OPERATORS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-23"><span class="nav-number">35.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-27"><span class="nav-number">35.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Training-Methods"><span class="nav-number">35.3.</span> <span class="nav-text">Training Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#FourCastNet-Model-Description"><span class="nav-number">35.3.1.</span> <span class="nav-text">FourCastNet: Model Description</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-structure"><span class="nav-number">35.3.2.</span> <span class="nav-text">Model structure</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Training-methods"><span class="nav-number">35.3.3.</span> <span class="nav-text">Training methods</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Inference"><span class="nav-number">35.3.4.</span> <span class="nav-text">Inference</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Prediction-of-transonic-flow-over-supercritical-airfoils-using-geometric-encoding-and-deep-learning-strategies"><span class="nav-number">36.</span> <span class="nav-text">Prediction of transonic flow over supercritical airfoils using geometric-encoding and deep-learning strategies</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Methods-2"><span class="nav-number">36.1.</span> <span class="nav-text">Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Encoding-of-geometric-information"><span class="nav-number">36.1.1.</span> <span class="nav-text">Encoding of geometric information</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-network-architecture"><span class="nav-number">36.1.2.</span> <span class="nav-text">Neural network architecture</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Loss-functions"><span class="nav-number">36.1.3.</span> <span class="nav-text">Loss functions</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Multilevel-wavelet-transformation"><span class="nav-number">36.1.3.1.</span> <span class="nav-text">Multilevel wavelet transformation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gradient-distribution"><span class="nav-number">36.1.3.2.</span> <span class="nav-text">Gradient distribution</span></a></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">木霈玖</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/02/Paper-Ideas/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="木霈玖">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="木霈玖的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Paper Ideas
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-11-02 21:40:57" itemprop="dateCreated datePublished" datetime="2021-11-02T21:40:57+08:00">2021-11-02</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2023-09-07 09:24:44" itemprop="dateModified" datetime="2023-09-07T09:24:44+08:00">2023-09-07</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%80%BB%E7%BB%93/" itemprop="url" rel="index"><span itemprop="name">总结</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>80k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1:13</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下读过论文的idea</p>
<a id="more"></a>
<h1 id="Physics-Coupled-Spatio-Temporal-Active-Learning-for-Dynamical-Systems"><a href="#Physics-Coupled-Spatio-Temporal-Active-Learning-for-Dynamical-Systems" class="headerlink" title="Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems"></a>Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems</h1><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104195000.png" alt="framework"></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104195040.png" alt="FN-PN"></p>
<ul>
<li>初始化<ul>
<li>选定 $n$ 个点 $\longrightarrow$ $\Omega^{n}_{temp}$</li>
<li>创建训练数据 $\longrightarrow$ $D_{temp}$ （选定 $n$ 个点都取 $T_{\omega}$ 时长的数据）</li>
</ul>
</li>
<li>训练<ul>
<li>learn $\lambda$ $\longleftarrow$ 最小化 $E_{q}$ ，偏微分方程</li>
<li>train ST-PCNN $\longleftarrow$ $\lambda$</li>
<li>predict $[\hat{s}]$ $\longleftarrow$ at all locations</li>
<li>$\Omega_{Kriging}^{n}$ $\longleftarrow$ $n$ 个：largest estimate error</li>
<li>$D_{Kriging}$ $\longleftarrow$ 上一步新选出的 $n$ 个，选取 $T_{\omega}$ 时长数据</li>
<li>更新 $D$</li>
</ul>
</li>
</ul>
<h1 id="ACTIVE-LEARNING-OF-DEEP-SURROGATES-FOR-PDES"><a href="#ACTIVE-LEARNING-OF-DEEP-SURROGATES-FOR-PDES" class="headerlink" title="ACTIVE LEARNING OF DEEP SURROGATES FOR PDES"></a>ACTIVE LEARNING OF DEEP SURROGATES FOR PDES</h1><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104203300.png" alt="model"></p>
<p>algorithm: reduce number of training points(selected based on error measure)</p>
<p>AL: adding the most uncertain points</p>
<ul>
<li><p>Initialize:</p>
<p>random choose $n_{init}$ train 50 epochs $\longrightarrow$ $\widetilde{t^{0}}(p)$</p>
</li>
<li><p>Do T times:</p>
<ul>
<li>evaluate $\widetilde{t^{i}}(p)$ at $M×K$ points</li>
<li>choose $K$ points(largest $\sigma_{*}^{2}$ )</li>
<li>put the $K$ points into training set</li>
</ul>
</li>
</ul>
<h1 id="Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows"><a href="#Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows" class="headerlink" title="Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"></a>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</h1><p>Application：language $\longrightarrow$ vision</p>
<p>Challenges:</p>
<ul>
<li>scale（视觉实体的区别尺度区别很大，例如车辆和人）</li>
<li>high resolution of pixels(计算复杂度： $n^{2}$ )</li>
</ul>
<p>Advantages：</p>
<ul>
<li>通过限制在局部窗口内使用自注意力，带来了更高的效率</li>
<li>通过移动，使得相邻两个窗口之间有了交互，上下层之间也有了跨窗口连接，从而变相达到了一种全局建模的效果</li>
<li>层级式的结构不仅非常灵活地去建模各个尺度的信息并且计算复杂度随着图像大小线性增长</li>
</ul>
<p>Key point:</p>
<ul>
<li>小批量开始 $\longrightarrow$ 逐渐合并邻居</li>
<li>如何实现线性复杂度：在无重叠窗口计算自注意力<ul>
<li>standard transformer architecture: global self-attention $\longrightarrow$ quadratic complexity</li>
<li>Swin Transformer: local self-attention $\longrightarrow$ linear complexity</li>
</ul>
</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>CNNs在计算机视觉中发挥了重要作用；在NLP领域，Transformer已经成为了主流模型，得益于注意力机制的使用，Transformer对长期依赖建模非常有效。</p>
<ul>
<li>为了解决多尺度问题，Swin-Transformer采用了层级式的结构，从小patch开始逐渐合并邻居patch。</li>
<li>为了实现线性计算复杂度，Swin-Transformer在不重叠的局部窗口计算自注意力。</li>
<li>移动窗口，新窗口中的注意力计算跨越先前窗口的边界，提供它们之间的连接。</li>
</ul>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><ul>
<li><p>Overall Framework：具体地，我们一开始的patch大小为 $4 \times 4$ ，原始的图像大小为 $224 \times 224$ ，窗口大小为 $7 \times 7$ ，这里的窗口大小指的是patch的数目，也就是说我们可以得到 $\frac{224}{4} \times \frac{224}{4} = 56 \times 56$ 个patch，又因为一个窗口的大小为 $7 \times 7$ ，因此我们的窗口数目为 $\frac{56}{7} \times \frac{56}{7} = 8 \times 8$ 个窗口。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/swin_1.png" alt=""></p>
</li>
<li><p>Two Successive Swin Transformer Blocks：这些block都是两个两个出现的，因为第二个block是在第一个block的基础之上做一个窗口的移动。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/swin_2.png" alt=""></p>
</li>
<li><p>Shifted window partitioning：SW-MSA紧接在W-MSA后面就是想让不同window之间也有信息传递。因此，最直接的想法就是将图片平移，但不是平移<code>window_size</code>，比如平移一半，再以跟之前相同的划分来切割，这样就会有上一轮本来不在同一个window里面的patch，现在出现在同一个window。但是，最简单的处理，比如像第一个图，会出现更多的window，有些window尺寸还不一样。一种修补方法是做padding补上一些块，但是会增大计算量。为此，这里采用cycling（rolling）的方法，即滚动，将图片向左、向上平移window一半的尺寸，比如window是7，这里就平移三个patch，左边的那些块移到右边，上边的那些块移到下边。然后采用mask的方式来计算每一块的自注意力。</p>
<ul>
<li><p>情况1，一左一右。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201617035.png" alt=""></p>
</li>
<li><p>情况2，一上一下。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201619762.png" alt=""></p>
</li>
<li><p>情况3，一个window内4个part。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201620069.png" alt=""></p>
</li>
</ul>
<p>首先将一个大特征图（图中为 $16 \times 16$ ）分为4个window，然后给每个区域打上编号。之后，对于每个window，就可以按之前的方式生成mask矩阵：1. 先展平；2. 如果x坐标，y坐标编号相同，那么就赋 $0$ （表示起作用的位置）；如果编号不同，就赋值$-100$，表示mask掉。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201624545.png" alt=""></p>
</li>
</ul>
<h1 id="Adversarial-Sampling-for-Solving-Differential-Equations-with-Neural-Networks"><a href="#Adversarial-Sampling-for-Solving-Differential-Equations-with-Neural-Networks" class="headerlink" title="Adversarial Sampling for Solving Differential Equations with Neural Networks"></a>Adversarial Sampling for Solving Differential Equations with Neural Networks</h1><h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p>sample points adversarially to maximize the loss of the current solution estimate  </p>
<p>Advantages on using neural networks:</p>
<ul>
<li>instead of obtaining solution values at discretized points, we get a closed and differentiable solution function</li>
<li>it is more effective in solving high dimensional PDEs by faring better against the “curse of dimensionality” </li>
<li>numerical errors are not accumulated in each iteration</li>
<li>initial and boundary conditions are satisfied by construction</li>
</ul>
<p>Drawbacks  of using a predefined sampling scheme: agnostic to the equation being solved as well as our current estimate $\hat{y}$</p>
<h2 id="Key-Idea"><a href="#Key-Idea" class="headerlink" title="Key Idea"></a>Key Idea</h2><p>present a sampling scheme that is dependent on the current estimate $\hat{y}$, using a neural network to represent a variable sampling distribution.</p>
<p>In each iteration, the sampler is trained to <strong>produce points which maximize the loss of the solver (and a secondary loss). </strong></p>
<p>Thus, it competes with the solver whose weights are updated to minimize the loss at these very points.  </p>
<h2 id="Architecture-1"><a href="#Architecture-1" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/image-20211128164821263.png" alt=""></p>
<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>It is observed that if the sampler is purely optimized with the objective of maximizing $\hat{L}(\hat{y}; x)$(residual loss corresponding to the $DE$ at samples $x$), it tends to collapse all samples to one single point of high loss. </p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>Therefore, use <strong>an additional loss term $D_{k}$,</strong>Given points$\begin{Bmatrix}x_{1},x_{2},\dots,x_{n}\end{Bmatrix}$, we define $d_{k}(x_{i})$ to be the sum of distances of $x_{i}$ from its $k$ nearest neighbors.</p>
<h1 id="Machine-Learning-of-Linear-Differential-Equations-using-Gaussian-Processes"><a href="#Machine-Learning-of-Linear-Differential-Equations-using-Gaussian-Processes" class="headerlink" title="Machine Learning of Linear Differential Equations using Gaussian Processes"></a>Machine Learning of Linear Differential Equations using Gaussian Processes</h1><p>Gaussian process priors are modified according to the particular form of such operators and are employed to infer parameters of the linear equations from scarce and possibly noisy observations.  </p>
<p>optimal model parameters and hyper-parameters are all learned directly from the data by maximizing the joint marginal log-likelihood of the probabilistic model instead of being guessed or tuned manually by the user.  </p>
<h2 id="Priors"><a href="#Priors" class="headerlink" title="Priors"></a>Priors</h2><p>place the $GP$ prior on $u(x)$ instead of $f(x)$ </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/image-20211128222044474.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222142.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222208.png" alt=""></p>
<h2 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222342.png" alt=""></p>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>employing a $Quasi-Newton$ optimizer $L-BFGS$ to minimize the negative log marginal likelihood</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222510.png" alt=""></p>
<h2 id="Predictions"><a href="#Predictions" class="headerlink" title="Predictions"></a>Predictions</h2><p>one can predict the values $u(x)$ and $f(x)$ at a new test point $x$ by writing the posterior distributions</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222753.png" alt=""></p>
<h1 id="Learning-Physics-Informed-Neural-Networks-without-Stacked-Back-propagation"><a href="#Learning-Physics-Informed-Neural-Networks-without-Stacked-Back-propagation" class="headerlink" title="Learning Physics-Informed Neural Networks without Stacked Back-propagation"></a>Learning Physics-Informed Neural Networks without Stacked Back-propagation</h1><h2 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h2><p>PINN training suffers from a significant scalability issue</p>
<h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ul>
<li>developing a novel approach to train the model without stacked back-propagation</li>
<li>parameterize the PDE solution $u(x; θ)$ as a Gaussian smoothed model, $u(x;\theta)=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}f(x+\delta,\theta)$, where $u$ transforms arbitrary base network $f$ by injecting Gaussian noise into input $x$. This transformation gives rise to a key property for $u$ where its derivatives to the input can be efficiently calculated <em>without back-propagation</em>.<ul>
<li>Such property is derived from the well-known Stein’s Identity that essentially tells that the derivatives of any Gaussian smoothed function $u$ can be reformulated as some expectation terms of the output of its base $f$, which can be estimated using Monte Carlo methods. </li>
</ul>
</li>
<li>given any PDE problem, we can replace the derivative terms in the PDE with Stein’s<br>derivative estimators.</li>
</ul>
<h2 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h2><ol>
<li>no longer need stacked back-propagation to compute the loss</li>
<li>parallelize the computation into distributed machines to further accelerate the training </li>
</ol>
<h2 id="Notice"><a href="#Notice" class="headerlink" title="Notice"></a>Notice</h2><p>for large $\sigma$, the induced Gaussian smoothed models may not be expressive enough to approximate functions (i.e., learn solutions) with a large Lipschitz constant. Therefore, using a small value of $\sigma$ is usually a better choice in practice. However, a small $\sigma$ will lead to high-variance Stein’s derivative estimation, which inevitably causes unstable training.  </p>
<h2 id="Two-Sources-of-Inefficiency-In-Computing-the-PINN-Loss"><a href="#Two-Sources-of-Inefficiency-In-Computing-the-PINN-Loss" class="headerlink" title="Two Sources of Inefficiency In Computing the PINN Loss"></a>Two Sources of Inefficiency In Computing the PINN Loss</h2><ol>
<li>different orders of derivatives can only be calculated sequentially  </li>
<li>the dimension-level inefficiency </li>
</ol>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="4-1-Back-propagation-free-Derivative-Estimators"><a href="#4-1-Back-propagation-free-Derivative-Estimators" class="headerlink" title="4.1 Back-propagation-free Derivative Estimators"></a>4.1 Back-propagation-free Derivative Estimators</h3><p>define $u(x)=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}f(x+\delta,\theta)$, then we have $\bigtriangledown_{x}u=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}[\frac{\delta}{\sigma^{2}}f(x+\delta)]$</p>
<h4 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_1.png" alt=""></p>
<p>From the above theorem, we can see that the first-order derivative rxu can be reformulated as an expectation term $E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}[\frac{\delta}{\sigma^{2}}f(x+\delta)]$, To calculate the value of the expectation, we can use Monte Carlo method to obtain an unbiased estimation from K.  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_2.png" alt=""></p>
<h3 id="4-2-Model-Capacity"><a href="#4-2-Model-Capacity" class="headerlink" title="4.2 Model Capacity"></a>4.2 Model Capacity</h3><p>For any measurable function $f : R^{d}\rightarrow R$, define $u(x)=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}f(x+\delta,\theta)$, then<br>$u(x) $is $\frac{F}{\sigma}\sqrt{\frac{2}{\pi}}$-Lipschitz with respect to $l_{2}$-norm, where $F=sup_{x\in R^{d}}|f(x)|$.  </p>
<h4 id="Proof-1"><a href="#Proof-1" class="headerlink" title="Proof"></a>Proof</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_3.png" alt=""></p>
<h3 id="4-3-Variance-Reduced-Stein’s-Derivative-Estimators"><a href="#4-3-Variance-Reduced-Stein’s-Derivative-Estimators" class="headerlink" title="4.3 Variance-Reduced Stein’s Derivative Estimators"></a>4.3 Variance-Reduced Stein’s Derivative Estimators</h3><h4 id="The-control-variate-method"><a href="#The-control-variate-method" class="headerlink" title="The control variate method"></a>The control variate method</h4><p>One generic approach to reducing the variance of Monte Carlo estimates of integrals is to use an additive control variate, which is known as baseline.  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_4.png" alt=""></p>
<h4 id="Further-improvement-using-the-antithetic-variable-method"><a href="#Further-improvement-using-the-antithetic-variable-method" class="headerlink" title="Further improvement using the antithetic variable method"></a>Further improvement using the antithetic variable method</h4><p>The antithetic variable method is yet another powerful technique for variance reduction.  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_5.png" alt=""></p>
<h1 id="Neural-Galerkin-Scheme-with-Active-Learning-for-High-Dimensional-Evolution-Equations"><a href="#Neural-Galerkin-Scheme-with-Active-Learning-for-High-Dimensional-Evolution-Equations" class="headerlink" title="Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations"></a>Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><h3 id="problems"><a href="#problems" class="headerlink" title="problems"></a>problems</h3><ol>
<li>no data are available  </li>
<li>the principal aim is to gather insights from a known model  </li>
</ol>
<p>高维逼近问题需要一个完全不同的“离线”自适应概念来规避维数的诅咒。</p>
<h2 id="Introduction-2"><a href="#Introduction-2" class="headerlink" title="Introduction"></a>Introduction</h2><p>develop time-integrators for PDEs that use DNNs to represent the solution but update the parameters sequentially from one time slice to another rather than globally over the whole time-space domain.  </p>
<p>use the structural form of the PDEs, but no a priori data about their solution.</p>
<p>leverage adaptivity in both function approximation and data acquisition.   </p>
<h3 id="Main-contributions"><a href="#Main-contributions" class="headerlink" title="Main contributions"></a>Main contributions</h3><ol>
<li><p>derive a nonlinear evolution equation for the parameters. </p>
<p>This equation can then be integrated using standard solvers with different level of sophistication.   </p>
<p>the proposed approach takes larger time steps when possible and corrects to smaller time-step sizes if the dynamics of the solution require it.  </p>
</li>
<li><p>The evolution equations that we derive for the DNN parameters involve operators that require estimation via sampling in space.  propose a dynamical estimation of the loss.   </p>
</li>
<li><p>We illustrate the viability and usefulness of our approach on a series of test cases.  </p>
</li>
</ol>
<h3 id="Related-works"><a href="#Related-works" class="headerlink" title="Related works"></a>Related works</h3><ol>
<li>The need for adaptive data acquisition in the context of machine learning for problems<br>in science and engineering has been emphasized in previous works.</li>
<li>There also is a large body of work on numerically solving PDEs with DNN parametrization based on collocation over the spatio-temporal domain.   </li>
<li>There also is a range of surrogate-modeling methods based on nonlinear parametrizations.  </li>
</ol>
<h2 id="Neural-Galerkin-schemes"><a href="#Neural-Galerkin-schemes" class="headerlink" title="Neural Galerkin schemes"></a>Neural Galerkin schemes</h2><h3 id="Neural-Galerkin"><a href="#Neural-Galerkin" class="headerlink" title="Neural Galerkin"></a>Neural Galerkin</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309201020.png" alt=""></p>
<h4 id="Parametrizing-the-solution"><a href="#Parametrizing-the-solution" class="headerlink" title="Parametrizing the solution"></a>Parametrizing the solution</h4><p>use ansatz $u(t,x)=U(\theta(t),x)$ , It is important to emphasize that U may depend nonlinearly on $\theta (t)$ , which is in stark contrast to the majority of classical approximations in scientific computing that have a linear dependence on the parameter.</p>
<h4 id="Controlling-the-residual"><a href="#Controlling-the-residual" class="headerlink" title="Controlling the residual"></a>Controlling the residual</h4><p>Since we do not have access to the solution $u(t)$ , we will use the structure of the governing equation to control the approximation error. To this end, note that inserting the ansatz solution $U(\theta(t))$ in Eq. (1). assuming differentiability of $\theta(t)$ and using $\partial_{t}U(\theta(t))=\triangledown_{\theta}U(\theta)\cdot \dot{\theta}(t)$ , leads to the residual function r:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309201330.png" alt=""></p>
<p>we will opt for controlling the residual locally in time, which leads to an initial value problem that can be solved over arbitrary long times. Specifically, we will seek $\theta(t)$ such that for all $t &gt; 0$ it holds</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309202447.png" alt=""></p>
<p>where we define the objective function $J_{t}:\Theta \times \dot{\Theta} \rightarrow \mathbb{R}$</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309202721.png" alt=""></p>
<h4 id="Neural-Galerkin-equations"><a href="#Neural-Galerkin-equations" class="headerlink" title="Neural Galerkin equations"></a>Neural Galerkin equations</h4><p>Since $J_{t}(\theta(t); \eta)$ is quadratic in $\eta$ and positive semi-definite, its minimum is unique and its minimizers solve the Euler-Lagrange equation</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309204135.png" alt=""></p>
<p>Written explicitly, Eq. (6) is a system of ODEs for $\theta(t)$:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309204238.png" alt=""></p>
<p>where we defined</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309210508.png" alt=""></p>
<p>in which $\bigotimes$ denotes the outer product.  The initial condition $\theta_{0}$ can be obtained via e.g. minimization of the least-squares loss between $u_{0}$ and $U(\theta_{0})$:  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310155509.png" alt=""></p>
<p>where ν is some user-prescribed measure with full support on $\mathcal{X}$ .  </p>
<h3 id="Estimating-M-theta-and-F-t-theta"><a href="#Estimating-M-theta-and-F-t-theta" class="headerlink" title="Estimating $M(\theta)$ and $F(t, \theta)$"></a>Estimating $M(\theta)$ and $F(t, \theta)$</h3><p>integrals in Eq. (8) do not admit a closed-form solution and so will need to be numerically estimated. In low dimensions,  we perform quadrature on a grid; in high dimensions, If $ν_{\theta}$<br>is a probability measure, we can consider using a vanilla Monte-Carlo estimator for each term,     </p>
<p>by drawing $n$ samples $\{x_{i}\}_{i=1}^{n}$ from $ν_{\theta}$ and replacing the expectations by empirical averages over these samples.  This estimator is efficient to approximate certain kernels uniformly over high-dimensional spaces, but not necessarily if the solution to the PDE develops spatially localized structures. Here are two options:</p>
<h4 id="Importance-sampling-with-a-fixed-measure"><a href="#Importance-sampling-with-a-fixed-measure" class="headerlink" title="Importance sampling with a fixed measure"></a>Importance sampling with a fixed measure</h4><p>importance sampling: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/41217212">重要性采样</a></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310165322.png" alt=""></p>
<h4 id="Direct-sampling-with-an-adaptive-measure"><a href="#Direct-sampling-with-an-adaptive-measure" class="headerlink" title="Direct sampling with an adaptive measure"></a>Direct sampling with an adaptive measure</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310170640.png" alt=""></p>
<h3 id="Discretization-in-time"><a href="#Discretization-in-time" class="headerlink" title="Discretization in time"></a>Discretization in time</h3><p>To update $\theta^{k}$, we can either use:  </p>
<h4 id="Explicit-integrators"><a href="#Explicit-integrators" class="headerlink" title="Explicit integrators"></a>Explicit integrators</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310171021.png" alt=""></p>
<h4 id="Implicit-integrators"><a href="#Implicit-integrators" class="headerlink" title="Implicit integrators"></a>Implicit integrators</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310171036.png" alt=""></p>
<h3 id="Neural-architectures"><a href="#Neural-architectures" class="headerlink" title="Neural architectures"></a>Neural architectures</h3><p>The first is a shallow (one-hidden-layer) network with m nodes given by</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180129.png" alt=""></p>
<p> The first is the Gaussian kernel, which we use when $\mathcal{X} = \mathbb{R}^{d}$</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180331.png" alt=""></p>
<p>the second is we use when $\mathcal{X} = L\mathbb{T}^{d}$ with L &gt; 0 and we need to enforce periodicity.</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180732.png" alt=""></p>
<p>The other neural architecture that we use is a feedforward neural network with $l\in \mathbb{N}$ hidden layers and m nodes per layer:  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310182117.png" alt=""></p>
<p>$\varphi_{tanh}^{L}$ is the nonlinear unit</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310182545.png" alt=""></p>
<h1 id="AUTOIP-A-UNITED-FRAMEWORK-TO-INTEGRATE-PHYSICS-INTO-GAUSSIAN-PROCESSES"><a href="#AUTOIP-A-UNITED-FRAMEWORK-TO-INTEGRATE-PHYSICS-INTO-GAUSSIAN-PROCESSES" class="headerlink" title="AUTOIP: A UNITED FRAMEWORK TO INTEGRATE PHYSICS INTO GAUSSIAN PROCESSES"></a>AUTOIP: A UNITED FRAMEWORK TO INTEGRATE PHYSICS INTO GAUSSIAN PROCESSES</h1><h2 id="Introduction-3"><a href="#Introduction-3" class="headerlink" title="Introduction"></a>Introduction</h2><p>To model a system, one usually writes down a set of partial differential equations (PDEs) and/or ordinary differential equations (ODEs) that characterize how the system runs according to physical laws.  Then, one identifies the boundary and/or initial conditions and solves the equations.</p>
<p>Machine learning and data science use a completely different paradigm. They estimate or reconstruct target functions from observed data rather than from solving the equations.</p>
<h3 id="Contribution-1"><a href="#Contribution-1" class="headerlink" title="Contribution"></a>Contribution</h3><p>consider incorporating physics knowledge into Gaussian processes (GPs). Not only flexible enough to learn various, complex functions from data, but also convenient to quantify the uncertainty due to their closed-form posterior distribution. </p>
<ol>
<li>联合采样目标函数在input的值，方程有关的微分的值，多元高斯分布在配点的潜在源. we couple the target function and its derivatives in a probabilistic framework, without the need for conducting differential operations on a nonlinear surrogate (like NNs).  </li>
<li>Next, we feed these samples to two likelihoods. One is to fit the training data. The other is a virtual Gaussian likelihood that encourages the conformity to the equation.</li>
<li>we use the whitening trick to parameterize the latent random variables with a standard Gaussian noise.       </li>
</ol>
<h2 id="Gaussian-Process-Regression"><a href="#Gaussian-Process-Regression" class="headerlink" title="Gaussian Process Regression"></a>Gaussian Process Regression</h2><p>Consider a training dataset $\mathcal{D}=(X,y)$, where $X = [x_{1},\dots,x_{N}]$, $y = [y_{1},\dots, y_{N}]$, each $x_{n}$ is an input, and $y_{n}$ is a noisy observation of $f(x_{n})$.  Then the function values at the training inputs, $f = [f(x_{1}),\dots,f(x_{N})]$, follow a multivariate Gaussian distribution, $p(f|X) = N(f|0,K)$ where each $[K]_{i,j} = κ(x_{i}, x_{j})$  </p>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>Specifically, we first construct a GP prior over $u$, $g$ and the equation-related derivatives, i.e., $\partial_{t}u$ and $\partial_{x}^{2}u$  , The covariance and cross-covariance among $u$ and its derivatives can be obtained outright from $κ_{u}$ via kernel differentiation   </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311161000.png" alt=""></p>
<p>Now, we can leverage the covariance functions in (4) and $k_{g}$ to construct a joint Gaussian prior over $f = [u; \hat{u}; \hat{u}_{t}; \hat{u}_{xx}; g]$ ,</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163413.png" alt=""></p>
<p>Given $f$ , we feed them to two data likelihoods. One is to fit the actual observations from a Gaussian noise model,  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163508.png" alt=""></p>
<p>The other is a virtual Gaussian likelihood that integrates the physics knowledge in the differential equation</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163540.png" alt=""></p>
<h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><p> the virtual likelihood (7) couples the components of $f$ to reflect the equation. Hence, we develop a general variational inference algorithm to jointly estimate the posterior<br>of $f$ and kernel parameters, inverse noise variance $\beta$, $v$, etc. However, we found that a straightforward implementation to optimize the variational posterior $q(f)$ is often stuck at an inferior estimate.  </p>
<p>That is, we parameterize $f$ with a Gaussian noise,</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311164311.png" alt=""></p>
<p>where $\eta \thicksim N(0, I)$, and $A$ is the Cholesky decomposition of the covariance matrix $\Sigma$  i.e., $\Sigma = AA^{T}$ . Therefore, the joint probability of the model can be rewritten as</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311164651.png" alt=""></p>
<p>We then introduce a Gaussian variational posterior for the noise,  $q(\eta) = \mathcal{N}(\eta|\mu,LL^{T})$ where $L$ is a lower-triangular matrix to ensure the positive definiteness of the covariance matrix.   </p>
<p>We then construct a variational evidence lower bound,</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311170307.png" alt=""></p>
<h1 id="RESPECTING-CAUSALITY-IS-ALL-YOU-NEED-FOR-TRAINING-PHYSICS-INFORMED-NEURAL-NETWORKS"><a href="#RESPECTING-CAUSALITY-IS-ALL-YOU-NEED-FOR-TRAINING-PHYSICS-INFORMED-NEURAL-NETWORKS" class="headerlink" title="RESPECTING CAUSALITY IS ALL YOU NEED FOR TRAINING PHYSICS-INFORMED NEURAL NETWORKS"></a>RESPECTING CAUSALITY IS ALL YOU NEED FOR TRAINING PHYSICS-INFORMED NEURAL NETWORKS</h1><h2 id="Introduction-4"><a href="#Introduction-4" class="headerlink" title="Introduction"></a>Introduction</h2><p>Extensions to enhance the accuracy and robustness of PINNs: novel optimization algorithms for adaptive training;  adaptive algorithms for selecting batches of training data; novel network architectures; domain decomposition strategies; new types of activation functions; sequential learning strategies.</p>
<p>notion of temporal dependence is absent in most continuous-time PINNs formulations   </p>
<p>Specific contributions can be summarized as:  </p>
<ul>
<li>We reveal an implicit bias suggesting that continuous-time PINNs models can violate causality, and hence are susceptible to converge towards erroneous solutions.  </li>
<li>We put forth a simple re-formulation of PINNs loss functions that allows us to explicitly respect the causal structure that characterizes the solution of general nonlinear PDEs. </li>
<li>Strikingly, we demonstrate that this simple modification alone is enough to introduce significant accuracy improvements, allowing us to tackle problems that have remained elusive to PINNs.  </li>
<li>We provide a practical quantitative criterion for assessing the training convergence of a PINNs model.  </li>
<li>We examine a collection of challenging benchmarks for which existing PINNs formulations fail, and demonstrate that the proposed causal training strategy leads to state-of-the-art results.  </li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317183104.png" alt=""></p>
<h2 id="Causal-training-for-physics-informed-neural-networks"><a href="#Causal-training-for-physics-informed-neural-networks" class="headerlink" title="Causal training for physics-informed neural networks"></a>Causal training for physics-informed neural networks</h2><p>To this end, we define a weighted residual loss as</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317184032.png" alt=""></p>
<p>We recognize that the weights $w_{i}$ should be large – and therefore allow the minimization of $\mathcal{L}_{r}(t_{i}, \theta)$ – only if all residuals $\{\mathcal{L}_{r}(t_{k}, \theta)\}^{i}_{k=1}$ before $t_{i}$ are minimized properly, and vice versa.   </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317184906.png" alt=""></p>
<p>As such, the weighted residual loss can be written as  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317185502.png" alt=""></p>
<p>$\mathcal{L}_{r}(t_{i}, \theta)$ will not be minimized unless all previous residuals $\{ \mathcal{L}_{r}(t_{k}, \theta) \}_{k=1}^{i-1}$ decrease to<br>some small value such that $w_{i}$ is large enough.</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317192154.png" alt=""></p>
<h1 id="Deep-Implicit-Moving-Least-Squares-Functions-for-3D-Reconstruction"><a href="#Deep-Implicit-Moving-Least-Squares-Functions-for-3D-Reconstruction" class="headerlink" title="Deep Implicit Moving Least-Squares Functions for 3D Reconstruction"></a>Deep Implicit Moving Least-Squares Functions for 3D Reconstruction</h1><h2 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h2><p>点集因为其灵活和轻量级的表示被广泛应用于3D深度学习，但是它的离散特性限制了对连续和精细的几何图形的表示。这篇文章通过引入隐式最小二乘（IMLS）曲面公式，将离散的点集转化成光滑的曲面，定义了点集上的局部隐式函数。IMLSNet预测一个八叉树结构，作为再需要时生成MLS点的支架，并且用学到的先验知识来表征形状几何。同时，一旦MLS点被预测，隐式函数的评估将独立于神经网络，从而实现了快速运行时评估。</p>
<h2 id="Introduction-5"><a href="#Introduction-5" class="headerlink" title="Introduction"></a>Introduction</h2><p>与多边形网格和体积网格等其他3D表示相比，点集作为神经元被自然地嵌入DNN中，易于获取，拥有最小的额外结构，动态捕捉复杂的几何和拓扑，并且不会浪费自由空间区域的计算。事实上，点集已经被用于基于深度学习的不同任务的3D分析。在使用点集进行深度学习生成三维数据时，一方面可以灵活地建模变化的拓扑和复杂的表面，另一方面也会受到离散和粗糙几何的影响。</p>
<p>近年来的研究主要集中在以网格和多边形块的形式生成形状，但由于其离散性和非光滑性，其形状表达能力仍然受到限制。而深度隐式函数方法则在整个三维域上定义光滑函数，以保证结果的连续性，在高质量的三维重建中具有很好的应用前景。然而，隐式曲面生成是低效的，因为对于三维域中的每个点，在提取曲面之前，网络都必须单独评估。在本文中，我们结合了隐函数方法和点集方法的优点，在保留显式点集固有的灵活性和计算效率的同时，将点集表示方法扩展到隐式曲面模型中，以实现高质量的三维生成。</p>
<p>对于通过点集建模光滑曲面，我们采用点集曲面，并使用点的移动最小二乘插值来定义在点集的窄带区域内的局部隐函数。特别是对于本文使用的隐式MLS公式，对于狭窄区域内的任意空间点，采用隐式MLS函数将其映射到零水平集表面的有符号距离值，定义为附近点支持的有符号距离的定向平面的加权混合；然后将零水平集曲面提取为光滑连续的曲面，用于形状表示。</p>
<p>虽然MLS曲面在三维重建和绘制方面已经得到了很好的研究，但将其表示整合到深度学习框架中带来了新的挑战和机遇，这在现有的基于点集或隐式表示的方法中是看不到的。首先，当点足够密集且均匀分布于重构形状上时，才能最有效地定义隐式MLS曲面。然而大多数点生成方法固定点的数量并且消耗大量资源用于难以概括的密集点的预测,我们引入一个octree-based脚手架，只在需要时根据目标形状生成可变数量的MLS点，通过定制损失函数进一步调整点的分布。第二，为了度量训练监督和测试评估的预测隐函数，而现有的隐式方法必须在整个3D域上使用密集抽样，MLS表面自然地定位在生成点的窄带区域内，这促使我们只在八叉树节点上使用更简洁的抽样来进行监督和评估。此外，一旦所有的MLS点都嵌入到三维域中，评估就独立于网络，从而避免了其他隐式方法典型的点网络评估的代价。</p>
<p>我们使用广泛的消融试验来验证设计的选择。我们也通过三维物体的重建任务证明了我们的深度隐式MLS曲面方法比点集生成方法和其他全局或局部隐式函数方法都有更好的性能。</p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Deep-representations-for-3D-generation"><a href="#Deep-representations-for-3D-generation" class="headerlink" title="Deep representations for 3D generation"></a>Deep representations for 3D generation</h3><p>点集是许多著作中常用的表示方法。但由于通常指定了点的个数，其表示细节几何的能力受到限制，需要进一步的点上采样来提高点密度和形状质量。</p>
<p>密集的体素很好地表征了形状占用率，但其高昂的内存成本妨碍了其用于表示高分辨率3D内容。稀疏体素包括八叉树克服了这些问题，在内存和计算方面都有很大的效率。</p>
<p>网格表示和基于patch的表示是提高形状质量的方便的3D表示。然而，它们的能力受到预定义的网格拓扑和分辨率，或多个补丁的断开连接的限制。中间3D表示，如粗体素或形状骨架是进一步提高其质量的可能方法。中间3D表示，如粗体素或形状骨架是进一步提高其质量的可能方法。</p>
<p>基于基元的表示使用一组简单的几何对象，如平面和立方体来近似3D形状。基于结构的表示明确地将语义部件结构编码为长方体，并使用体素表示在每个长方体内重构部件。虽然它们适用于表征形状结构，但由于基元的简单性，它们的近似质量也受到限制。</p>
<p>最近出现了基于隐式表面的深度学习方法提供了一种平滑连续的3D表示，并在连续空间中实现函数评价。对于一个给定的点，网络预测它的占用率或从它到表面的符号距离。这些技术最近得到了进一步的改进，通过整合局部特征来建模更详细的形状几何。</p>
<p>我们的方法属于深度隐式类，通过对光滑、连续的隐式MLS曲面进行建模，同时具有显式点集生成的灵活性和效率；它是一种混合的3D深度学习表示，结合了点集和隐函数的优点。</p>
<h3 id="Surface-reconstruction-from-point-clouds"><a href="#Surface-reconstruction-from-point-clouds" class="headerlink" title="Surface reconstruction from point clouds"></a>Surface reconstruction from point clouds</h3><p>表面重建技术已经研究了几十年。其中，利用全局或局部平滑先验对点云进行高质量重建的方法包括：多层分割的单位云(MPU)、泊松重建、径向基函数和移动最小二乘曲面(MLS) 广泛用于点集曲面建模和绘制。</p>
<p>由于MLS的快速和局部评价特性，我们选择MLS表面作为我们的深层3D表示。MLS曲面可以分为两种类型：投影MLS曲面和隐式MLS曲面(IMLS)。前者通过迭代投影定义一组平稳点，后者直接定义隐函数。我们使用基于IMLS的带符号的距离监控，实现了快速的功能评估。</p>
<h2 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h2><h3 id="IMLS-surface"><a href="#IMLS-surface" class="headerlink" title="IMLS surface"></a>IMLS surface</h3><p>隐式MLS曲面定义如下: 表示 $\mathcal{P}=\{p_{i} \in \mathbb{R}^{3} \}_{i=1}^{N}$ 为三维点集，每个点都具有单位法向 $n_{i} \in \mathbb{R}^{3}$，控制半径 $r_{i} \in \mathbb{R}^{+}$ 。为了方便起见，我们称这些点为MLS点。</p>
<p>对于每个MLS点 $p_{i}$ 到其切平面的有符号距离函数定义为 $＜x-p_{i},n_{i}＞$ ，其中 $＜\cdot,\cdot＞$ 是内积。通过加权平均所有逐点带符号的距离函数，我们得到了一个隐函数 $F(x)$ 的零水平集定义了隐式曲面 $\mathcal{S}$ :</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409163226.png" alt=""></p>
<p>这里我们设权函数 $\theta(d,r)=exp(-d^{2}/r^{2})$ 。Kolluri证明了在均匀采样条件下IMLS曲面 $\mathcal{S}$ 是对 $\mathcal{P}$ 进行采样的原始曲面的几何和拓扑正确的近似，而IMLS函数 $F$ 是对原始曲面的有符号距离函数的紧密近似。</p>
<p>由于当 $x$ 远离 $p_{i}$ 时，权函数衰减，因此只考虑附近的MLS点可以加速 $F(x)$ 的求值。Eq.(1)可以修改为:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409163632.png" alt=""></p>
<p>其中 $\Omega(x)$ 表示以 $x$ 为中心，半径为 $r_{b}$ 的球内的MLS点集合。 $r_{b}$ 可由用户设置为截断点距离值。</p>
<p>由于上述公式，函数值为零 $F(x)$ 存在于IMLS点的窄带区域。通过对边界区域内的规则网格进行函数求值，通过移动立方体可以有效地将 $\mathcal{S}$ 显式地提取为三角形网格。</p>
<h3 id="Deep-IMLS-surface"><a href="#Deep-IMLS-surface" class="headerlink" title="Deep IMLS surface"></a>Deep IMLS surface</h3><p>在实际三维重建中，稀疏的、无方向的点云可能带有噪声和缺失区域，这是典型的输入，但传统方法无法很好地处理这些输入三维重建方法，比如泊松重建。为了处理这种不完美的数据，我们的目标是设计一个自编码的神经网络来生成IMLS曲面。</p>
<p>定义网络输出的一种简单方法是设置固定数量的IMLS点元组 $\{ p_{i},n_{i},r_{i} \}_{i=1}^{N}$ 。但是，它会限制IMLS的表示能力，不能很好地从数据中学习局部几何先验。我们引入了一个中间网络输出：基于八叉树的脚手架，以帮助生成需要的MLS点。基于八叉树的支架是一个 $d$ 深度的八叉树 $\mathcal{O}$ ，它在多分辨率下大致近似3D表面。对于每一个最细的非空八分位数 $o_{k}$ ，也就是八叉树中最小的非空体素，我们关联一个小集合的MLS点，这些点的位置靠近八分位数中心 $c_{k}$ 。具体来说与 $o_{k}$ 关联的MLS点定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409170339.png" alt=""></p>
<p>其中 $t_{k,l}\in \mathbb{R}^{3}$ 是 $p_{k,l}$ 到 $c_{k}$ 的偏移向量， $s$ 是一个预定义的点的数目。由于基于八叉树的支架的结构依赖于目标表面，因此需要自适应地确定MLS点的总数及其位置。</p>
<p>有了上面的设置，一个适合IMLS生成的网络应该输出：</p>
<p>（1）一个基于八叉树的脚手架 $\mathcal{O}$ </p>
<p>（2）一个最细的非空八分圆 $o_{k}$ 的MLS点偏移量、MLS点法线和控制半径</p>
<p>这里我们注意到，由输入噪声和稀疏点云创建的八叉树不能用作脚手架，因为它可能是不完整和不准确的，并且不同于目标形状。</p>
<h4 id="Scaffold-prediction"><a href="#Scaffold-prediction" class="headerlink" title="Scaffold prediction"></a>Scaffold prediction</h4><p>使用基于八叉树的卷积神经网络(O-CNN)自动编码器来生成支架。其编码器采用输入点云构建的深度 $d_{in}$ 八叉树作为输入，并仅在八叉树内进行CNN计算。它的解码器以4 × 4 × 4的单元格开始，预测每个单元格是否空，如果单元格不空，则将其细分为8个八边形。这个过程递归地对每个非空的八进制执行，直到达到最大输出八叉树深度 $d_{out}$ 。</p>
<h4 id="MLS-point-prediction"><a href="#MLS-point-prediction" class="headerlink" title="MLS point prediction"></a>MLS point prediction</h4><p>与之前工作不同，解码器在每个最细的非空八分圆处回归定向点或平面补丁以实现亚体素精度，我们通过一个具有如下隐含层的多层感知器(MLP)来预测MLS点元组，该元组的特征向量用 $f(o_{k})$ 表示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409190020.png" alt=""></p>
<p>注意，MLP预测了 $p_{k,l}$ 的局部坐标，即 $t_{k,l}$ ，因此它可以从数据中学习局部先验。为了保证 $p_{k,l}$ 接近 $c_{k}$ ， $t_{k,l}$ 的每个坐标分量的取值范围限制在 $[−\beta h， \beta h]$ ，这里 $h$ 为最细的八分区的大小， $\beta$ 默认设置为1.5。我们还将 $r_{k,s}$ 限制在 $[l_{r}/ 2,2l_{r}]$ 内，其中 $l_{r} = \frac{h}{\sqrt{s}}$ 。这些约束是通过使用tanh激活网络输出来实现的，并通过其范围缩放值。</p>
<h3 id="Network-structure"><a href="#Network-structure" class="headerlink" title="Network structure"></a>Network structure</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409191356.png" alt=""></p>
<p>论文使用类似 U-Net 的 O-CNN 自动编码器，其中包含 O-CNN ResNet 块和输出引导的跳过连接。对于给定的无方向点云，论文提出为其构建一个深度八叉树。在每个最细的八分圆中，通过将八分圆内输入点的平均位置的偏移量与带有二进制标量的八分圆中心的偏移量与=连接来设置输入 4 维信号，该二进制标量指示八分圆是否为空。</p>
<p>Resblock(n, c) 表示一个 n 层基于 O-CNN 的残差块，通道编号为 c。Downsample(c) 和 Upsample(c) 是基于八叉树的卷积和反卷积算子 [49]，然后是批量归一化和 ReLU。对于第一个 Resblock，c 设置为 64，并且在每个 Downsample 算子之后增加 2 倍，并且在每个 Upsample 算子之后除以 2。在论文的实验中，论文设置 n = 3。隐藏层 MLP 用于预测八分圆是否为空。</p>
<h3 id="Loss-function-design"><a href="#Loss-function-design" class="headerlink" title="Loss function design"></a>Loss function design</h3><h4 id="Octree-structure-loss"><a href="#Octree-structure-loss" class="headerlink" title="Octree structure loss"></a>Octree structure loss</h4><p>八分圆状态的确定是一个二元分类问题：0 代表空，1 代表非空。 论文使用 O 的每个八分圆处的 sigmoid 交叉熵损失的加权求和来定义八叉树结构损失。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192717.png" alt=""></p>
<h4 id="SDF-loss"><a href="#SDF-loss" class="headerlink" title="SDF loss"></a>SDF loss</h4><p>IMLS曲面的预测值和真实值之间的差异用SDF损失表示</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192809.png" alt=""></p>
<p>这里 F 的梯度可以近似为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192845.png" alt=""></p>
<h4 id="MLS-point-repulsion-loss"><a href="#MLS-point-repulsion-loss" class="headerlink" title="MLS point repulsion loss"></a>MLS point repulsion loss</h4><p>用于改善生成的 MLS 点的局部规律性。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192956.png" alt=""></p>
<p>其中 $||p_{i}-p_{j}||_{proj}=||(T-n_{i}n_{i}^{T})(p_{i}-p_{j})||$ 是 $p_{i}-p_{j}$ 在 $p_{i}$ 处的切平面上的投影长度， $w_{ij}$ 是关于两个 MLS 点差和法向差的双边权重，定义如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193039.png" alt=""></p>
<p>上述设计将 $p_{j}$ 推离 $p_{i}$ ，尤其是当他们的法线和他们的位置是相似的。</p>
<h4 id="Projection-smoothness-loss"><a href="#Projection-smoothness-loss" class="headerlink" title="Projection smoothness loss"></a>Projection smoothness loss</h4><p>为了实现局部表面平滑度，论文鼓励 MLS 点靠近其相邻 MLS 点的切平面。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193200.png" alt=""></p>
<h4 id="Radius-smoothness-loss"><a href="#Radius-smoothness-loss" class="headerlink" title="Radius smoothness loss"></a>Radius smoothness loss</h4><p>同样，为了提高表面平滑度，相邻 MLS 点的半径变化通过对半径进行加权拉普拉斯平滑来惩罚</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193248.png" alt=""></p>
<h4 id="Weight-decay"><a href="#Weight-decay" class="headerlink" title="Weight decay"></a>Weight decay</h4><p>在损失函数中加入一项小的权重衰减项，系数为$\lambda_{w}$</p>
<h1 id="Efficient-Training-of-Physics-Informed-Neural-Networks-via-Importance-Sampling"><a href="#Efficient-Training-of-Physics-Informed-Neural-Networks-via-Importance-Sampling" class="headerlink" title="Efficient Training of Physics-Informed Neural Networks via Importance Sampling"></a>Efficient Training of Physics-Informed Neural Networks via Importance Sampling</h1><h2 id="Abstract-2"><a href="#Abstract-2" class="headerlink" title="Abstract"></a>Abstract</h2><p>PINN训练只需要问题描述，定义域，初始/边界条件，这种训练通常涉及使用随机梯度下降法的变体来解决一个非凸优化问题，将损失函数的梯度近似于一批配点中，在每次迭代中按均匀分布随机选取。在每次训练迭代中，按照与损失函数成正比的分布对搭配点进行采样，将改善PINNs训练的收敛行为。</p>
<h2 id="Introduction-6"><a href="#Introduction-6" class="headerlink" title="Introduction"></a>Introduction</h2><p>由于计算资源和优化算法的限制，PINN没有得到太多的关注。PINN网络的训练通常涉及到使用迭代法求解非凸优化问题。在给定的迭代中，这种批量选择可能会导致在一些配置点上计算梯度，在这些配置点上，近似解相对于其他点已经满足了微分算子的一个令人满意的程度。因此，得到的梯度信息很少或根本没有，从而延缓了收敛速度。或者，通过采用重要采样方案，在每次迭代中，我们可以选择一批能提供更多梯度信息的配点，以加速收敛。</p>
<p>首先，我们借鉴文献的理论发现，提出了一种基于重要度抽样的PINN网络加速训练方法。据作者所知，这是第一次使用重要抽样方案对pin网络进行训练。其次，我们展示了如何使用最近邻搜索或Voronoi分布来逼近建议分布，以进一步改善PINN训练的收敛行为。提出的重要度抽样方法简单明了，易于应用于现有的重要度抽样方法通过修改代码的几行PINN代码。此外，该方法没有引入新的超参数。</p>
<h2 id="Deep-Learning-of-Differential-Equations"><a href="#Deep-Learning-of-Differential-Equations" class="headerlink" title="Deep Learning of Differential Equations"></a>Deep Learning of Differential Equations</h2><p>PINNs基础知识</p>
<h2 id="Importance-Sampling-for-Training-of-PINNs"><a href="#Importance-Sampling-for-Training-of-PINNs" class="headerlink" title="Importance Sampling for Training of PINNs"></a>Importance Sampling for Training of PINNs</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418100747.png" alt=""></p>
<p>$f(x)$ 是训练点的采样分布，一种典型的采样分布是定义域上的均匀分布。在一种重要抽样方法中，我们寻求从一个备选抽样分布（用 $q(x)$ 表示）中提取训练样本，并根据如下更新网络参数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418101053.png" alt=""></p>
<p>在本工作中，我们有效地实现了一种离散采样方案，将连续域 $D$ 转化为 $N$  个采样点在 $D$ 上均匀选取的离散集合，其中 $N&gt;&gt; 1$ 。因此，我们将分别处理离散分布 $\{f_{j}\}_{j=1}^{N}$ 和 $\{ q_{j} \}_{j=1}^{N}$ ，而不是采样密度函数 $f(x_{j})$ 和 $q(x_{j})$，在任意候选点 $j$ 处 $f_{j} = \frac{1}{N}$ 。</p>
<p>为了构建相应的SGD，为了简洁起见，我们先考虑no mini batch，即 $m = 1$ ，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418102832.png" alt=""></p>
<p>在这项工作中，我们的目标是设计一个具有抽样分布 $q$ 的训练方案，它可以加速Eq. 12的收敛。[32]中的作者考虑了以下关于收敛速度的定义</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418103015.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418103050.png" alt=""></p>
<p>然后得出结论，通过从一个最小的分布 $Tr(\mathbb{V}_{P}[G^{(i)}])$ 中采样输入变量，可以加速收敛。如[32,34]所示，如果根据 $q^{\star}\propto||\triangledown_{\theta}J(\theta^{(i)})||_{2}$ 选择训练样本，则这一项可以被最小化。对于批量大小为m的小批量SGD，这个目标可以有效地被实现通过计算抽样分布</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418104326.png" alt=""></p>
<p>通过从概率为 $p^{(i)} = \{q_{1}^{(i)},\dots,q_{N}^{(i)}\}$ 的多项式中抽样 $M$ 个指标，选择小批量样本集 $M^{(i)}$ 。为了得到梯度 $\triangledown_{\theta}J(\theta)$ 的无偏估计，则根据式8，11给出的小批量梯度下降更新规则</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418104941.png" alt=""></p>
<p>这一推导提供了一个理论证据，即使用重要抽样方法可以加速PINN网络的训练，其中训练样本是根据与模型参数相关的损失函数梯度的2-范数成比例的分布获得的。然而，在每次迭代中为所有的并置点计算这个梯度的2-范数需要通过计算图进行额外的反向传播，这在计算上可能非常昂贵。为了缓解这一问题，在[33]中从理论上和数值上表明，在训练示例中损耗值的线性变换总是大于该示例中损耗梯度的2-范数，配点的梯度范数排序与损失值排序是一致的。因此，可以使用损失值代替梯度值作为重要性度量</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418105440.png" alt=""></p>
<p>具体来说，利用该proposal分布，可以选择前面解释的m个小批量样本，并结合公式16中的梯度下降规则来更新模型参数。</p>
<p>虽然与梯度计算相比，损失函数的计算成本较低，但在每次迭代中对整个配置点集进行这样的计算仍然非常昂贵。为了缓解这种情况，我们提出了一个分段常数近似的损失函数。也就是说，我们不是在每个配置点上计算损失函数，而是只在一个点子集上计算损失，以下称为”种子”，用 $\{x_{s}\}_{s=1}^{N}$ 表示， $S&lt;N$ 。然后，利用最近邻搜索算法，对每个配点 $j$ ，求出最接近的种子 $s = \rho(j)$，并设置该搭配点的损失值等于最接近种子的损失，即 $J(\cdot;x_{j}):=J(\cdot;x_{\rho(j)})$ 。这相当于使用种子生成Voronoi镶嵌，并在每个Voronoi单元中使用一个常数近似的损失。在数值例子中可以看出，与对整个配点求损函数的情况相比，这种分段常数近似提供了更高的计算效率。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418112136.png" alt=""></p>
<h1 id="PAGP-A-physics-assisted-Gaussian-process-framework-with-active-learning-for-forward-and-inverse-problems-of-partial-differential-equations"><a href="#PAGP-A-physics-assisted-Gaussian-process-framework-with-active-learning-for-forward-and-inverse-problems-of-partial-differential-equations" class="headerlink" title="PAGP: A physics-assisted Gaussian process framework with active learning for forward and inverse problems of partial differential equations"></a>PAGP: A physics-assisted Gaussian process framework with active learning for forward and inverse problems of partial differential equations</h1><h2 id="Abstract-3"><a href="#Abstract-3" class="headerlink" title="Abstract"></a>Abstract</h2><p>在这项工作中，建立了一个在偏微分方程(PDEs)中包含给定物理信息的高斯过程回归(GPR)模型:物理辅助高斯过程(PAGP)。该模型的目标可分为两类问题:给定偏微分方程的初始条件和边界条件的解或未知系数的发现。给定的物理信息被集成到高斯过程模型通过我们设计的GP损失函数。基于两种不同的训练标准GP模型的方法，本文给出了三种类型的损失函数。本文的第一部分介绍了连续时间模型，该模型将时域和空间域等同看待。已知的未知系数通过最小化设计的损失函数，偏微分方程可以与GP超参数联合学习。在离散时间模型中，我们首先选择一种时间离散方案来离散时域。然后在每个时间步上应用PAGP模型和该方案来近似最后时刻给定测试点的偏微分方程解。为了在这种情况下发现未知系数，需要两个特定时间的观测数据，并构造一个混合均方误差函数来获得最优系数。最后，提出了一种新的连续时间和离散时间混合模型。它融合了连续时间模型的灵活性和离散时间模型的精确性。讨论了采用不同GP损失函数选择不同模型的性能。建议的有效性PAGP方法在我们的数值部分进行了说明。</p>
<h2 id="Introduction-7"><a href="#Introduction-7" class="headerlink" title="Introduction"></a>Introduction</h2><p>如今，数据驱动的机器学习(ML)模型在科学计算和许多学科的发现中取得了巨大的成功。然而，仅仅将ML模型作为黑盒函数使用可能会由于忽略现有的物理规律或其他领域专业知识而导致性能较差。此外，目前大多数黑盒ML模型往往需要大量的数据和有限的泛化属性。因此，将ML模型与通常以偏微分方程(PDEs)形式存在的物理规律相结合就成为一个自然的热门话题。在所有数据驱动的ML模型中，高斯过程回归(GPR)，又称地质统计学中的克里格(Kriging)，是一种应用广泛的非参数模型贝叶斯模型构建一个廉价的代理复杂的科学和工程问题。高斯过程是唯一由其规定形式的均值和协方差函数决定的。它具有一个概率工作流，具有分析的易处理性，并从其后验分布返回稳健的方差估计。这也自然地量化了模型的不确定性。本文旨在将偏微分方程中包含的物理信息与GPR模型结合起来，解决正问题，即求解给定偏微分方程的解，以及反问题，即发现给定偏微分方程的未知系数。</p>
<p>简要介绍以前处理这类问题的两篇著作。</p>
<p>本文提出了一种将物理原理引入高斯过程回归模型的新方法。在标准GP中，均值函数和协方差函数的最优超参数可以通过两种不同的方式进行优化，即最小化负对数边际似然(NLML)或使用交叉验证的方法。在PAGP模型中，基于这两种方法构造了三种类型的损失函数。对于第一种方法，我们应用留一交叉验证(LOO-CV)构造一个损失函数。验证密度的对数作为拟合的交叉验证测度。根据惩罚GPR的思想，在这个损失函数中增加了一个额外的惩罚条款。这一项实际上是由配置点集上的PDE残差的绝对误差之和组成。第二个损失函数是相似的，除了对LOO-CV的拟合度的衡量是平方误差。对于最后一个，在原来的NLML函数中增加了一个相同的惩罚项。此外，还提出了一种自适应权值选择方法，以确定与惩罚项相乘的权值系数，使损失函数具有意义。在GP训练过程中，惩罚期限需要根据预先设定的配点来计算。因此，首先需要推导GP预测对时间t和空间位置x的导数。我们根据不同的问题设置开发连续时间模型和离散时间模型。对于连续时间模型，我们遵循中的步骤，直接使用GP预测公式，根据给定推导出关于t和x的n阶导数的解析表达式PDEs。对于离散时间模型，可以用类似的方法计算GP对x的导数。但是GP对t的导数需要用不同的方法计算。这里采用有限差分法进行计算。此外，还提出了一种新的两步混合模型，将连续时间模型和离散时间模型结合在一起。第一步遵循离散时间模型，但具有较大的时间步长。每一项的预测时间步长，和根据给定的初始条件和边界条件抽取的样本一起构成了偏微分方程第二步训练的数据集。然后利用连续时间模型对整个域的测试点进行预测。</p>
<h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>本文的目的是利用包含物理信息的GP来求解偏微分方程的正问题和反问题。在这项工作中，我们考虑一般形式的参数化偏微分方程</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418171923.png" alt=""></p>
<p>边界条件</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418172009.png" alt=""></p>
<p>初值条件</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418172045.png" alt=""></p>
<p>其中 $\mathcal{T}_{x}^{\lambda}$ 是一个一般的微分算子，可以是线性的，也可以是非线性的。下标表示操作符 $\mathcal{T}$ 作用的空间位置 $x$ 。上标表示只能部分知道的参数 $\lambda$ 。 $\Omega$ 是 $\mathbb{R}^{d}$ 的一个子集，$\Gamma$ 是 $\Omega$ 的边界。例如，考虑一维热方程： $u_{t}-\lambda u_{xx}=0$ 。这里，微分算子是 $\mathcal{T}_{x}^{\lambda}=\lambda \frac{\partial^{2}}{\partial x^{2}}$ 并且 $\lambda$ 是位置参数。在这种情况下我们考虑的正问题是找出解 $u(x,t)$ 给定特定边界条件 $g(x,t)$ ，初始条件 $h(x)$ 和系数 $\lambda$ ，而反问题是在偏微分方程中恢复未知系数 $\lambda$ 。注意，对于这两种类型的问题，偏微分方程的边界和初始条件也可以用可能被噪声污染的观测值来代替。</p>
<h3 id="Gaussian-process-regression"><a href="#Gaussian-process-regression" class="headerlink" title="Gaussian process regression"></a>Gaussian process regression</h3><p>略</p>
<h3 id="Derivatives-of-Gaussian-process-regression"><a href="#Derivatives-of-Gaussian-process-regression" class="headerlink" title="Derivatives of Gaussian process regression"></a>Derivatives of Gaussian process regression</h3><p>略</p>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><p>连续模型、离散模型、混合模型</p>
<h3 id="Active-Learning"><a href="#Active-Learning" class="headerlink" title="Active Learning"></a>Active Learning</h3><p>假设训练数据集D由N个样本组成。这代表了知识的当前状态，给定PDE域中信息量最大的样本是通过最大化获取函数 $a_{N}(x)$ 来选择的</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419144543.png" alt=""></p>
<p>获取功能实际上量化了我们可以获得多少信息来评估或在这个数据站点上执行一个昂贵的实验。然后 $(x_{N+1},y_{N+1})$ 加到原始训练数据集D中，此时如果达到了预先设定的条件，则停止处理。否则，该过程重复迭代，直到满足停止条件或达到最大迭代次数。在我们的PAGP模型中，采集函数被选择为后验分布的方差:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419144750.png" alt=""></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>这篇文章主要就是在训练GPR时通过对不同问题模型的设定设置不同的损失函数，然后在新一轮选点时采用后验方差大的点。</p>
<h1 id="Breaking-the-Dilemma-of-Medical-Image-to-image-Translation"><a href="#Breaking-the-Dilemma-of-Medical-Image-to-image-Translation" class="headerlink" title="Breaking the Dilemma of Medical Image-to-image Translation"></a>Breaking the Dilemma of Medical Image-to-image Translation</h1><h2 id="Abstract-4"><a href="#Abstract-4" class="headerlink" title="Abstract"></a>Abstract</h2><p>有监督的Pix2Pix和无监督的Cycle-consistency两种模式在医学图像到图像的转换中占主导地位。然而，这两种模式都不是理想的。Pix2Pix模式具有出色的性能。但它需要成对和像素对齐的图像，这可能不总是可以实现，因为在获得成对图像期间，呼吸运动或解剖变化。循环一致性模式对训练数据不太严格，对未配对或错位的图像也能很好地工作。但它的性能可能不是最优的。为了打破现有模式的困境，我们提出了一种新的无监督模式RegGAN用于医学图像到图像的转换。它基于“损失校正”理论。在RegGAN算法中，将失调的目标图像作为噪声标签，利用附加的配准网络对生成器进行训练，自适应地拟合失调的噪声分布。目标是搜索图像之间的转换和配准任务的共同最优解。我们将RegGAN合并到一些最先进的图像到图像的转换方法中，并证明RegGAN可以很容易地与这些方法结合起来，以提高它们的性能。例如，在我们的模式中，简单的CycleGAN超过了最新的NICEGAN，即使使用更少的网络参数。根据我们的结果，RegGAN在对齐数据上优于Pix2Pix，在未对齐或未配对的数据上优于Cycle-consistency。RegGAN对噪声不敏感，这使得它在很多情况下都是更好的选择，特别是在无法获得像素级对齐数据的医学图像到图像转换任务中。</p>
<h2 id="Introduction-8"><a href="#Introduction-8" class="headerlink" title="Introduction"></a>Introduction</h2><p>生成对抗网络(GANs)是一个通过对抗过程同时训练生成器G和鉴别器D的框架。该生成器用于将源域图像X的分布转换为目标域图像Y的分布。判别器用于确定目标域图像可能来自生成器还是来自真实数据。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210104.png" alt=""></p>
<p>Pix2Pix更新生成器 $(G:X \rightarrow Y)$ ，使源图像x和目标图像Y之间的像素级L1损失最小。因此，它要求对齐良好的成对图像，其中每个像素都有对应的标签。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210302.png" alt=""></p>
<p>然而，在现实场景中，对齐良好的成对图像并不总是可用的。为了解决图像不对齐所带来的挑战，我们开发了循环一致性算法，该算法基于这样的假设:从源域X到目标域Y $(G:X \rightarrow Y)$ 是生成器F从Y到X的反向 $(F:Y \rightarrow X)$ .与Pix2Pix模式相比，循环一致性模式在不对齐或未配对的图像上工作得更好。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210602.png" alt=""></p>
<p>然而，Cycle-consistency模式有其局限性。在医学图像到图像的转换中，不仅需要图像域之间的风格转换，还需要特定图像对之间的转换。最佳解决方案应该是唯一的。例如，翻译后的图像应尽可能保持原图像的解剖特征。众所周知，Cycle-consistency模式可能会产生多个解，这意味着训练过程可能比较混乱，结果可能不准确。Pix2Pix模式也不理想。即使它有唯一的解决方案，也很难满足成对图像对齐的要求。对于错位的图像，误差通过Pix2Pix模式，可能导致最终的平移图像不合理的位移。</p>
<p>到目前为止，还没有一种图像到图像的转换模式可以在对齐数据上优于Pix2Pix模式，在未对齐或未配对数据上优于Cycle-consistency模式。受[6-10]的启发，我们将失调的目标图像视为有噪声的标签，这意味着我们将存在的问题视为带噪声标签的监督学习。</p>
<h2 id="Methodology-1"><a href="#Methodology-1" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Theoretical-Motivation"><a href="#Theoretical-Motivation" class="headerlink" title="Theoretical Motivation"></a>Theoretical Motivation</h3><p>如果我们将失调的目标图像视为有噪声的标签，那么图像到图像的翻译训练就变成了一个有噪声标签的监督学习过程。给定一个训练数据集 $\{ (x_{n},\widetilde{y}_{n}) \}_{n=1}^{N}$ ，有n个噪声标签，其中 $x_{n}$, $\widetilde{y}_{n}$ 是来自两种模式的图像，假设 $y_{n}$ 是 $x_{n}$ 的正确标签，但在现实场景中是未知的。我们的目标是使用数据集 $\{ (x_{n},\widetilde{y}_{n}) \}_{n=1}^{N}$ 带噪声的标签，其性能相当于在干净数据集 $\{ (x_{n},y_{n}) \}_{n=1}^{N}$ 尽可能多。基于方程4的直接优化通常是无效的，并且会导致不好的结果，因为发生器不能挤出噪声的影响。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419212746.png" alt=""></p>
<p>为了解决噪声问题，我们提出了一个基于“损耗校正”的解决方案，如方程5所示。我们的解决方案通过建模噪声转移 $\phi$ 来匹配噪声分布来校正生成器 $G(x_{n})$ 的输出。之前，Patrini et al从数学上证明了用噪声标签训练的模型可以等价于用干净标签训练的模型，只要噪声发生转移 $\phi$ 匹配噪声分布。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419213250.png" alt=""></p>
<p>为此，Goldberger等提出将正确的标签视为潜在的随机变量，并将标签噪声显式建模为网络结构的一部分，记为 $R$ 。方程5可以改写为对数似然的形式，将对数似然作为神经网络训练的损失函数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419213846.png" alt=""></p>
<h3 id="RegGAN"><a href="#RegGAN" class="headerlink" title="RegGAN"></a>RegGAN</h3><p>与现有的使用的求解方程6的方法例如最大化期望，全连通层、锚点估计和Drichlet分布比较。在我们的问题中，噪声分布的类型更清楚，它可以表示为位移误差: $\widetilde{y}=y\circ T$ 。这里T表示为一个随机变形场，它为每个像素产生随机位移。因此，我们采用生成器G后的配准网络R作为标签噪声模型对结果进行校正。修正损失如式7所示</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419214445.png" alt=""></p>
<p>式中 $R(G(x), \widetilde{y})$ 为变形场， $\circ$ 代表重采样操作。注册网络基于U-Net。在式8中定义了平滑损失来评价变形场的平滑性，使变形场的梯度最小。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419214930.png" alt=""></p>
<p>最后，将产生器与鉴别器之间的平均损耗相加(式1)，总损耗如式9所示</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419215013.png" alt=""></p>
<h1 id="Characterizing-possible-failure-modes-in-physics-informed-neural-networks"><a href="#Characterizing-possible-failure-modes-in-physics-informed-neural-networks" class="headerlink" title="Characterizing possible failure modes in physics-informed neural networks"></a>Characterizing possible failure modes in physics-informed neural networks</h1><h2 id="Abstract-5"><a href="#Abstract-5" class="headerlink" title="Abstract"></a>Abstract</h2><p>我们证明，虽然现有的PINN方法可以学习相对次要问题的良好模型，但它们很容易无法学习相关的物理现象，即使是稍微复杂一点的问题。特别地，我们分析了几个不同的情况，广泛的物理兴趣，包括学习微分方程的对流，反应和扩散算子。我们提供证据，软正则化的PINN，其中涉及到基于偏微分算子，可以引入许多微妙的问题，包括使问题更病态。重要的是，我们表明，这些可能的失效模式不是由于缺乏神经网络结构的表现力，而是PINN的设置使损失景观非常难以优化。然后，我们描述了解决这些故障模式的两个有希望的解决方案。第一种方法是使用课程正则化，其中PINN的损失项从一个简单的PDE正则化开始，并随着NN的训练逐渐变得更加复杂。第二种方法是将问题作为一个顺序对顺序的学习任务，而不是学习一次性预测整个时空。大量的测试表明，与常规的PINN训练相比，我们可以实现高达1-2个数量级的误差。</p>
<h2 id="Introduction-9"><a href="#Introduction-9" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Problem-overview"><a href="#Problem-overview" class="headerlink" title="Problem overview"></a>Problem overview</h3><p>PINN 相关知识</p>
<h3 id="Main-contributions-1"><a href="#Main-contributions-1" class="headerlink" title="Main contributions"></a>Main contributions</h3><ul>
<li>我们分析了简单但物理相关的对流、反应和反应扩散问题的PINN模型。我们发现，普通/常规的PINN方法只适用于非常简单的参数体系。</li>
<li>我们分析了训练过的PINN模型的损失情况，发现增加基于pde的软约束正则化使其更加复杂和难以优化，特别是对于具有非平凡系数的情况。</li>
<li>我们证明了 NN 架构有能力/表现力来找到一个好的解，从而表明这些问题不是由于NN网格结构的容量有限引起的。相反，我们认为失败是由于相关的优化困难使用 PINN 的软 PDE 约束。</li>
<li>我们提出了解决这些失败模式的两种途径:(i)课程正规化(ii)将学习问题作为一个序列对序列的学习任务。</li>
</ul>
<h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><p>一些关于机器学习和PDE结合的工作</p>
<h2 id="Possible-failure-modes-for-physics-informed-neural-networks"><a href="#Possible-failure-modes-for-physics-informed-neural-networks" class="headerlink" title="Possible failure modes for physics-informed neural networks"></a>Possible failure modes for physics-informed neural networks</h2><h3 id="Experiment-setup"><a href="#Experiment-setup" class="headerlink" title="Experiment setup."></a>Experiment setup.</h3><p>4-layer fully-connected NN with 50 neurons per layer; tangent activation function; randomly sample collocation points on the domain; measure relative error and absolute error</p>
<h3 id="convection、reaction-diffusion"><a href="#convection、reaction-diffusion" class="headerlink" title="convection、reaction-diffusion"></a>convection、reaction-diffusion</h3><p> we can see that the PINN also fails to learn advection and reaction-diffusion.  </p>
<h2 id="Diagnosing-possible-failure-modes-for-physics-informed-NNs"><a href="#Diagnosing-possible-failure-modes-for-physics-informed-NNs" class="headerlink" title="Diagnosing possible failure modes for physics-informed NNs"></a>Diagnosing possible failure modes for physics-informed NNs</h2><h3 id="Soft-PDE-regularization-and-optimization-difficulties"><a href="#Soft-PDE-regularization-and-optimization-difficulties" class="headerlink" title="Soft PDE regularization and optimization difficulties"></a>Soft PDE regularization and optimization difficulties</h3><p>我们表明，添加软正则化实际上可以使问题更难优化，即正则化导致更不平滑的损失景观。</p>
<p>最后，我们研究了改变软正则化项的权重/乘子的影响，这可能与提高PINN性能有关。虽然我们发现调谐λ可以帮助改变误差，但它不能解决问题。</p>
<h2 id="Expressivity-versus-optimization-difficulty"><a href="#Expressivity-versus-optimization-difficulty" class="headerlink" title="Expressivity versus optimization difficulty"></a>Expressivity versus optimization difficulty</h2><h3 id="Curriculum-PINN-Regularization"><a href="#Curriculum-PINN-Regularization" class="headerlink" title="Curriculum PINN Regularization"></a>Curriculum PINN Regularization</h3><p>我们设计了一个“课程正则化”，方法通过为权值找到一个好的初始化值来热启动神经网络训练。对于$\beta/\rho$较高的情况，我们不是训练PINN立即学习解，而是先在较低的$\beta/\rho$上训练PINN(对PINN来说更容易学习)，然后逐渐分别在较高的$\beta/\rho$上训练PINN。</p>
<h3 id="Sequence-to-sequence-learning-vs-learning-the-entire-space-time-solution"><a href="#Sequence-to-sequence-learning-vs-learning-the-entire-space-time-solution" class="headerlink" title="Sequence-to-sequence learning vs learning the entire space-time solution"></a>Sequence-to-sequence learning vs learning the entire space-time solution</h3><p>在这里，我们证明，将问题作为一个序列对序列(seq2seq)学习任务可能更好，其中神经网络学习预测下一个时间步骤的解决方案，而不是一直预测。这样，我们就可以使用时间推进方案来预测不同的序列/时间点。注意，这里唯一可用的数据来自PDE本身，也就是说，只有初始条件。我们取在$t=\Delta t$处的预测，以此作为在$t=2\Delta t$处的预测的初始条件，依此类推。</p>
<h1 id="Uncertainty-Quantification-in-Scientific-Machine-Learning-Methods-Metrics-and-Comparisons"><a href="#Uncertainty-Quantification-in-Scientific-Machine-Learning-Methods-Metrics-and-Comparisons" class="headerlink" title="Uncertainty Quantification in Scientific Machine Learning:Methods, Metrics, and Comparisons"></a>Uncertainty Quantification in Scientific Machine Learning:Methods, Metrics, and Comparisons</h1><h2 id="Abstract-6"><a href="#Abstract-6" class="headerlink" title="Abstract"></a>Abstract</h2><p>神经网络在如何将数据和物理工程方面的数学定理融合方面正在改变新的计算范式。然而，在基于神经网络的推理中，对误差和不确定性的量化比传统方法更加复杂。这是因为除了与噪声数据相关的任意不确定性外，还存在数据有限的不确定性，还有神经网络超参数、过度参数化、优化和采样误差以及模型误规范等。在这项工作中，我们提出了一个全面的框架，包括不确定性建模、新的和现有的解决方法，以及评估指标和事后改进方法。为了证明我们的框架的适用性和可靠性，我们提出了一个广泛的比较研究，其中各种方法在原型问题上进行了测试，包括混合输入输出数据问题和高维随机问题。</p>
<h2 id="Introduction-10"><a href="#Introduction-10" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Novel-contributions-of-this-work"><a href="#Novel-contributions-of-this-work" class="headerlink" title="Novel contributions of this work"></a>Novel contributions of this work</h3><ol>
<li>我们测试并将各种用于后验推理、先验学习、数据噪声建模以及训练后校准的方法集成到物理信息神经网络、神经算子和SPDE求解器中。</li>
<li>我们演示了如何使用函数先验来解决具有异方差噪声的历史数据的函数逼近问题。</li>
<li>将高斯过程回归和生成式对抗网络相结合，提出了一种解决确定性正向偏微分方程问题的新方法，并与现有方法进行了比较。</li>
<li>我们求解源项、问题参数和解数据中含有异方差噪声的混合偏微分方程问题。</li>
<li>我们解决了带有噪声的随机实现的混合SPDE问题，并提出了一种新的神经网络结构，用于使用多项式混沌量化不确定性。</li>
<li>我们演示了如何处理有噪声和不完整的推断数据给出一个预先训练的神经算子对干净的数据。</li>
<li>我们提出了检测神经算子外分布数据的方法，这对风险相关的应用是至关重要的。</li>
<li>我们提出了一个统一的UQ框架，通过无缝地将物理与可能被各种类型的噪声污染的新数据和历史数据结合起来，解决科学机器学习中的各种问题。</li>
</ol>
<h2 id="Neural-PDEs-and-neural-operators"><a href="#Neural-PDEs-and-neural-operators" class="headerlink" title="Neural PDEs and neural operators"></a>Neural PDEs and neural operators</h2><h3 id="Solving-forward-and-mixed-PDE-problems-Overview-of-PINN-method"><a href="#Solving-forward-and-mixed-PDE-problems-Overview-of-PINN-method" class="headerlink" title="Solving forward and mixed PDE problems: Overview of PINN method"></a>Solving forward and mixed PDE problems: Overview of PINN method</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506153709.png" alt=""></p>
<h3 id="Learning-operator-mappings-Overview-of-DeepONet-method"><a href="#Learning-operator-mappings-Overview-of-DeepONet-method" class="headerlink" title="Learning operator mappings: Overview of DeepONet method"></a>Learning operator mappings: Overview of DeepONet method</h3><p>DeepONet方法通过构造一个以 $\theta$ 为参数的神经网络逼近器来处理算子学习问题，来对 $u(x;\xi)$ 。</p>
<h2 id="Modeling-total-uncertainty"><a href="#Modeling-total-uncertainty" class="headerlink" title="Modeling total uncertainty"></a>Modeling total uncertainty</h2><h3 id="Uncertainty-in-function-approximation"><a href="#Uncertainty-in-function-approximation" class="headerlink" title="Uncertainty in function approximation"></a>Uncertainty in function approximation</h3><p>为了定义 $p(u|x,\theta)$ ，我们构建一个模型 $u_{\theta}(x)$ 在一些 $x$ 点来捕捉 $u(x)$ 的确定性部分并且为噪声假定一个模型。例如，因式高斯似然函数，通过如下式子给出</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506161343.png" alt=""></p>
<p>下标 $d$ 表示 $u$ 的每个 $D_{u}$ 维，通常用于多维函数逼近问题。在公式(4)中，输出向量 $u_{\theta}(x)$ 是假设 $u$ 在位置 $x$ 处的高斯分布的均值， $diag(\Sigma^{2}_{u})$ 是一个对角协方差矩阵 $\Sigma_{u}^{2} = [\sigma_{u}^{2},\dots,\sigma_{u}^{2}]$ 可以是已知的，也可以是假设的，也可以是从数据推断出来的。</p>
<p>在给定数据 $\mathcal{D}$ 的情况下， $x$ 位置 $u$ 的值是一个随机变量，表示为 $(u|x,\mathcal{D})$。为了求 $(u|x;\mathcal{D})$ 积分出模型参数 $\theta$，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506163025.png" alt=""></p>
<p>利用贝叶斯规则，后验 $p(\theta|\mathcal{D})$ 可以通过下式获得</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506185405.png" alt=""></p>
<p>式(6)中， $p(\mathcal{D}|\theta)$ 是数据的似然，即 $p(\mathcal{D}|\theta) = \prod_{i=1}^{N}p(u_{i}|x_{i},\theta)$ 为独立同分布(i.i.d.)数据； $p(\theta)$为模型 $\mathcal{H}$ 定义的参数 $\theta$ 的先验概率；而 $p(\mathcal{D})$ 被称为边际可能性或证据，因为它代表了在所有由 $\mathcal{H}$ 建模的可能数据集中，我们观察到 $\mathcal{D}$ 发生的概率。证据 $p(\mathcal{D})$ 给出如下</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506190851.png" alt=""></p>
<p>即，给定从先验 $p(\theta)$ 中抽取的随机样本，然后与似然函数结合使用， $p(\mathcal{D})$ 表示数据集 $\mathcal{D}$ 产生的概率。</p>
<p>后验推断阶段之后，Eq.(5)的BMA可以用蒙特卡罗(MC)来近似。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506191803.png" alt=""></p>
<p>这个方程提供了 $(u|x,\mathcal{D})$ 以预测PDF $\overline{p}(\mu|x)$ 的形式。 $(\mu|x,\mathcal{D})$ 通过 $\hat{u}(x) = E[\mu|x]$ 建模并且用 $\overline{\mu}(x)$近似表示为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506193734.png" alt=""></p>
<p>其中 $\{\mu_{\hat{\theta}_{j}}(x)\}_{j=1}^{M}$ 是样本 $\{\hat{\theta}_{j} \}_{j=1}^{M}$ 对应的NN预测集。求 $(u|x,\mathcal{D})$ ，将式(4)的高斯似然值代入式(8)，得到高斯混合协方差矩阵的对角线部分由下式给出</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506195407.png" alt=""></p>
<h3 id="Uncertainty-in-PINNs"><a href="#Uncertainty-in-PINNs" class="headerlink" title="Uncertainty in PINNs"></a>Uncertainty in PINNs</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922185741.png" alt=""></p>
<h3 id="Uncertainty-in-DeepONets"><a href="#Uncertainty-in-DeepONets" class="headerlink" title="Uncertainty in DeepONets"></a>Uncertainty in DeepONets</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922190052.png" alt=""></p>
<h2 id="Methods-for-uncertainty-quantification"><a href="#Methods-for-uncertainty-quantification" class="headerlink" title="Methods for uncertainty quantification"></a>Methods for uncertainty quantification</h2><ul>
<li>Bayesian methods</li>
<li>Ensembles</li>
<li>Functional priors (FPs)</li>
<li>Solving stochastic PDEs (SPDEs)</li>
<li>Towards a unified view of the presented methods</li>
</ul>
<h1 id="Multi-Objective-Loss-Balancing-for-Physics-Informed-Deep-Learning"><a href="#Multi-Objective-Loss-Balancing-for-Physics-Informed-Deep-Learning" class="headerlink" title="Multi-Objective Loss Balancing for Physics-Informed Deep Learning"></a>Multi-Objective Loss Balancing for Physics-Informed Deep Learning</h1><h2 id="Abstract-7"><a href="#Abstract-7" class="headerlink" title="Abstract"></a>Abstract</h2><p>在这项工作中，我们观察到对多个竞争损失函数组合进行正确加权对有效训练PINN的重要作用。为此，我们实现并评估了不同的方法，旨在平衡PINN损失函数的多个项及其梯度的贡献。我们提出了一种新的自适应损失平衡称为ReLoBRaLo(相对随机回看的损失平衡)。我们的模拟研究证明了这一点与使用其他平衡方法训练PINN相比，ReLoBRaLo训练速度更快，准确率更高，因此非常有效，并增加了PINN算法的可持续性。</p>
<h2 id="Introduction-11"><a href="#Introduction-11" class="headerlink" title="Introduction"></a>Introduction</h2><p>物理信息神经网络的出现引起了人们对经常面临低数据系统问题的领域的极大兴趣。通过利用已知的物理定律，并将其作为隐式先验并入深度学习管道，PINN被证明需要很少或不需要数据，以近似不同复杂度的偏微分方程(PDE)。</p>
<h2 id="Physics-Informed-Neural-Networks-PINNs"><a href="#Physics-Informed-Neural-Networks-PINNs" class="headerlink" title="Physics-Informed Neural Networks (PINNs)"></a>Physics-Informed Neural Networks (PINNs)</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922182417.png" alt=""></p>
<p>然而，PINN训练的效率、收敛性和准确性仍面临严峻挑战。目前的研究可分为四种主要方法:修改神经网络的结构、分治/区域分解、参数初始化和损失平衡。</p>
<p>根据文献综述，自适应PINN训练过程可以被视为PDE约束的优化问题。本文关注的是对竞争力和适应性的仔细考虑，并从跨机器学习的几个领域提出的损失平衡技术中寻求灵感。</p>
<h2 id="Methodology-2"><a href="#Methodology-2" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Multi-Objective-Optimisation"><a href="#Multi-Objective-Optimisation" class="headerlink" title="Multi-Objective Optimisation"></a>Multi-Objective Optimisation</h3><p>多目标优化可以通过线性扩展转化为单一目标：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183152.png" alt=""></p>
<h3 id="Adaptive-Loss-Balancing-Methods"><a href="#Adaptive-Loss-Balancing-Methods" class="headerlink" title="Adaptive Loss Balancing Methods"></a>Adaptive Loss Balancing Methods</h3><h4 id="Learning-Rate-Annealing"><a href="#Learning-Rate-Annealing" class="headerlink" title="Learning Rate Annealing"></a>Learning Rate Annealing</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183302.png" alt=""></p>
<h4 id="GradNorm"><a href="#GradNorm" class="headerlink" title="GradNorm"></a>GradNorm</h4><p>更新内部刻度的损失GradNorm的计算方法如下:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183445.png" alt=""></p>
<p>更新网络参数的最终损失只是使用之前更新的缩放值进行线性扩展：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183525.png" alt=""></p>
<h4 id="SoftAdapt"><a href="#SoftAdapt" class="headerlink" title="SoftAdapt"></a>SoftAdapt</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183605.png" alt=""></p>
<h2 id="Relative-Loss-Balancing-with-Random-Lookback-ReLoBRaLo"><a href="#Relative-Loss-Balancing-with-Random-Lookback-ReLoBRaLo" class="headerlink" title="Relative Loss Balancing with Random Lookback (ReLoBRaLo)"></a>Relative Loss Balancing with Random Lookback (ReLoBRaLo)</h2><p>从现有平衡技术中汲取灵感，我们提出了一种新的方法和实现，用于平衡扩展MOO损失函数中的多个项，用于训练PINN：</p>
<ul>
<li>采用SoftAdapt的平衡方法，利用连续训练步骤之间的变化率，并通过softmax函数进行归一化。</li>
<li>与学习率退火类似，为了利用过去不止一个训练步骤的损失统计数据，使用指数衰减来更新标量。</li>
<li>此外，在指数衰减中引入了一个随机回看(称为saudade $\rho$)，它决定是使用穿透步骤的损失统计来计算缩放，还是一直回看直到训练$\mathcal{L}_{i}^{(0)}$开始。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922184617.png" alt=""></p>
<h2 id="Hyperparameter-Tuning-and-Meta-Learning"><a href="#Hyperparameter-Tuning-and-Meta-Learning" class="headerlink" title="Hyperparameter Tuning and Meta Learning"></a>Hyperparameter Tuning and Meta Learning</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922184701.png" alt=""></p>
<h1 id="A-Unified-Hard-Constraint-Framework-for-Solving-Geometrically-Complex-PDEs"><a href="#A-Unified-Hard-Constraint-Framework-for-Solving-Geometrically-Complex-PDEs" class="headerlink" title="A Unified Hard-Constraint Framework for Solving Geometrically Complex PDEs"></a>A Unified Hard-Constraint Framework for Solving Geometrically Complex PDEs</h1><h2 id="Abstract-8"><a href="#Abstract-8" class="headerlink" title="Abstract"></a>Abstract</h2><p>a unified hard-constraint framework  $\rightarrow$ geometrically complex PDEs</p>
<p>introduce the “extra fields” $\rightarrow$ reformulate the PDEs so as to equivalently transform the three types of BCs into linear forms.  </p>
<p>derive the general solutions of the BCs analytically</p>
<h2 id="Introduction-12"><a href="#Introduction-12" class="headerlink" title="Introduction"></a>Introduction</h2><p>Among all types of BCs, Dirichlet, Neumann, and Robin are the most commonly used</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018145545.png" alt=""></p>
<p>in practical problems, physical systems can be very geometrically complex, there exists an unbalanced competition between the<br>terms of PDEs and BCs, limiting the application of PINNs to geometrically complex problems. There are some imroved methods. Nevertheless, these methods are only applicable to specific BCs (e.g., Dirichlet BCs, homogeneous BCs, etc) or geometrically simple PDEs.</p>
<h3 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h3><ul>
<li>a unified hard-constraint framework for all the three most commonly used BCs</li>
<li>introduce the extra fields, substitutes the gradient of a physical quantity with new variables, allowing the BCs to be reformulated as linear equations. </li>
<li>summarize a paradigm for constructing the hard-constraint ansatz under time-dependent, multiboundary, and high-dimensional cases </li>
</ul>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Physics-Informed-Neural-Networks"><a href="#Physics-Informed-Neural-Networks" class="headerlink" title="Physics-Informed Neural Networks"></a>Physics-Informed Neural Networks</h3><p>basic introduction to PINNs</p>
<h3 id="Hard-Constraint-Methods"><a href="#Hard-Constraint-Methods" class="headerlink" title="Hard-Constraint Methods"></a>Hard-Constraint Methods</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018154155.png" alt=""></p>
<p>where $x$ is the coordinate, $\Omega$ is the domain of interest, $u^{\partial\Omega}(x)$ is the general solution at the boundary $\partial\Omega$, and $l^{\partial\Omega}(x)$ is an extended distance function which satisfies</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018154550.png" alt=""></p>
<p>However, it is hard to directly extend this method to more general cases of Robin BCs (see Eq. (7)), since we cannot obtain the general solution $u^{\partial\Omega}(x)$ analytically. </p>
<h2 id="Methodology-3"><a href="#Methodology-3" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Problem-Setup"><a href="#Problem-Setup" class="headerlink" title="Problem Setup"></a>Problem Setup</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115190422.png" alt=""></p>
<p>其中：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115191221.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115191016.png" alt=""></p>
<p>边界条件为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115191607.png" alt=""></p>
<h3 id="Reformulating-PDEs-via-Extra-Fields"><a href="#Reformulating-PDEs-via-Extra-Fields" class="headerlink" title="Reformulating PDEs via Extra Fields"></a>Reformulating PDEs via Extra Fields</h3><p>引入中间变量：$p_{j}(x)=(p_{j1}(x),\cdots,p_{jd}(x))=\nabla u_{j},j=1,\cdots,n$，方程变成如下形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116200121.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116200232.png" alt=""></p>
<p>边界条件变成了有关 $u_{j}$ 和 $p_{j}(x)$ 的线性方程，该方程的通解比上面的通解更容易求，求通解的第一步是要在零空间内找一组基 $B(x)$，经过作者证明，这组基是存在的，只是需要carefully chosen。于是该方程的通解可以写成：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116205653.png" alt=""></p>
<h3 id="A-Unified-Hard-Constraint-Framework"><a href="#A-Unified-Hard-Constraint-Framework" class="headerlink" title="A Unified Hard-Constraint Framework"></a>A Unified Hard-Constraint Framework</h3><p>最终解的形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116213608.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116213714.png" alt=""></p>
<p>最终的loss形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221118212130.png" alt=""></p>
<h1 id="DeepONet-Learning-nonlinear-operators-for-identifying-differential-equations-based-on-the-universal-approximation-theorem-of-operators"><a href="#DeepONet-Learning-nonlinear-operators-for-identifying-differential-equations-based-on-the-universal-approximation-theorem-of-operators" class="headerlink" title="DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators"></a>DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators</h1><h2 id="Abstract-9"><a href="#Abstract-9" class="headerlink" title="Abstract"></a>Abstract</h2><p>具有单个隐藏层的神经网络可以精确逼近任何非线性连续算子。这个万能逼近定理暗示了神经网络在从数据中学习非线性算子方面的潜在应用。然而，对于一个足够大的网络，该定理只保证了一个很小的近似误差，而没有考虑重要的优化和泛化误差。</p>
<h2 id="Introduction-13"><a href="#Introduction-13" class="headerlink" title="Introduction"></a>Introduction</h2><p>万能逼近定理指出，在不限制隐藏层的宽度和深度的情况下，神经网络可以将任何连续函数近似到任意精度。然而，另一个更令人惊讶的近似结果（到目前为止尚未得到重视）指出，具有单一隐藏层的神经网络可以精确近似任何非线性连续泛函（从一个函数空间到实数的映射）或（非线性）算子（从一个函数空间到另一个函数空间的映射）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122154217.png" alt=""></p>
<p>这个近似定理表明了神经网络在从数据中学习非线性运算符方面的潜在应用，也就是说，类似于深度学习社区目前正在做的事情，即从数据中学习函数。然而，这个定理并没有告诉我们如何有效地学习运算符。以经典的图像分类任务为例，函数神经网络的普遍逼近定理表明，全连接神经网络(FNNs)能够精确地近似地真分类函数，但在实践中，FNNs的性能与具有特定架构的网络相去甚远，如广泛使用的卷积神经网络(CNN)或较新的胶囊神经网络(CapsNet)。性能差距主要在于神经网络的准确性可以通过将整个的误差分为三种主要类型：近似、优化和泛化来表征。对于一个足够大的网络，万能逼近定理只保证了一个很小的逼近误差，但它们根本没有考虑优化误差和泛化误差，这两个误差在实践中对总误差同样重要，而且往往占主导地位。有用的网络应该易于训练，即具有较小的优化误差，并且能够很好地泛化到不可见的数据，即具有较小的泛化误差。</p>
<p>为了准确、高效地学习算子，我们提出了一种特定的网络结构——深度算子网络(DeepONet)，以实现更小的总误差。我们将证明，基于两个子网络的设计，DeepONet显著改善了泛化，分支网络用于输入函数，主干网络用于评估输出函数的位置。</p>
<h2 id="Methodology-4"><a href="#Methodology-4" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Deep-operator-networks-DeepONets"><a href="#Deep-operator-networks-DeepONets" class="headerlink" title="Deep operator networks (DeepONets)"></a>Deep operator networks (DeepONets)</h3><p>我们专注于在更一般的设置中学习算子，其中对训练数据集的唯一要求是传感器的一致性 $\{x_{1},x_{2},\cdots,x_{m}\}$ 用于输入函数。在这种一般设置中，网络输入由两个独立的部分组成： $[u(x_{1}),u (x_{2}),\cdots,u(x_{m})]^{T}$ 和 $y$，目标是通过设计网络架构来实现良好的性能。一个简单的解决方案是直接使用一个经典网络，如FNN, CNN或RNN，并将两个输入连接在一起作为网络输入，即 $[u(x_{1}),u (x_{2}),\cdots,u(x_{m}),y]^{T}$ 。然而，输入没有任何特定的结构，因此选择CNN或RNN这样的网络是没有意义的。这里我们使用FNN作为基线模型。</p>
<p>在高维问题中， $y$ 是一个有 $d$ 个分量的向量，所以 $y$ 的维数和 $u(x_{i})$的维数不匹配。我们提出的架构如图1C所示。首先是“中继”网络，以 $y$ 为输入，输出为 $[t_{1},t_{2},\cdots,t_{p}]\in \mathbb{R}^{p}$ ；除了主干网络，还有 $p$ 个“分支”网络，每个“分支”网络 $[u(x_{1}),u(x_{2}),\cdots,u(x_{m})]^{T}$ 作为输入和输出标量 $b_{k}\in \mathbb{R}$ 对于 $k=1,2,\cdots,p$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122160053.png" alt=""></p>
<p>在实践中， $p$ 至少是10的数量级，并且使用大量的分支网络在计算和内存方面都很昂贵。因此，我们将所有的分支网络合并为一个单独的分支网络（图1D），即单个分支网络输出一个向量 $[b_{1},b_{2},\cdots,b_{p}^{T}]\in \mathbb{R}^{p}$ 。</p>
<p>DeepONet是一种高级网络架构，没有定义内部主干和分支网络的架构。为了展示DeepONet单独的能力和良好的性能，我们选择了最简单的FNN作为子网络的体系结构。使用卷积层我们有可能进一步提高精度。</p>
<p>将一些先验知识融入到神经网络体系结构中通常能产生良好的泛化效果。这种归纳偏差已经反映在许多网络中，如CNN用于图像，RNN用于顺序数据。DeepONet即使使用FNN作为子网络也能取得成功，这也是由于其强烈的归纳偏差。输出 $G(u)(y)$ 有两个独立的输入 $u$ 和 $y$ ，因此显式地使用中继和分支网络与这个先验知识是一致的。更广泛地说， $G(u)(y)$ 可以被视为 $y$ 条件作用于 $u$ 的函数。寻找一种有效的方式来表示条件作用输入仍然是一个开放的问题，已经提出了不同的方法，如特征明智的转换。</p>
<h3 id="Data-generation"><a href="#Data-generation" class="headerlink" title="Data generation"></a>Data generation</h3><p>过程的输入信号 $u(x)$ 在系统辨识中起着重要作用。显然，为了收集其响应的信息，输入信号是影响过程的唯一可能，而识别信号的质量决定了精度的上限，在最好的情况下，任何模型都可以达到这个上限。在本研究中，我们主要考虑两个函数空间:高斯随机场(GRF)和正交(Chebyshev)多项式。</p>
<p>mean-zero GRF:  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122193732.png" alt=""></p>
<p>Chebyshev polynomials:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122193746.png" alt=""></p>
<p>从选定的函数空间中采样u后，采用龙格-库塔(4,5)法求解ODE系统，采用二阶有限差分法求解pde系统，得到参考解。我们注意到一个数据点是三元组 $(u,y,G(u)(y))  $ ，因此一个特定的输入 $u$ 可能出现在具有不同 $y$ 值的多个数据点中。例如，一个10000大小的数据集可能只由100个 $u$ 轨迹生成，每个轨迹对100个 $y$ 位置计算 $G(u)(y)$ 。</p>
<h2 id="Conclusion-1"><a href="#Conclusion-1" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>在本文中，我们在一个更一般的设置中提出了算子学习的问题，并提出了学习非线性算子的DeepONets。在DeepONets中，我们首先构建两个子网络分别编码输入函数和位置变量，然后将它们合并在一起计算输出。我们在四个常/偏微分方程问题上测试了DeepONets，并表明DeepONets可以通过使用这种归纳偏差实现小的泛化误差。在仿真中，我们系统地研究了不同因素对测试误差的影响，包括传感器数量、最大预测时间、输入函数空间复杂度、训练数据集大小和网络规模。我们观察到与训练数据集大小相关的不同阶多项式甚至指数误差收敛。据我们所知，这是第一次在深度学习中观察到指数收敛。此外，从理论上推导了近似误差对不同因素的依赖性，这与我们的计算结果一致。尽管取得了上述成就，但还需要进行更多的理论和计算工作。例如，算子近似的网络大小还没有任何理论结果，类似于函数近似的宽度和深度界限。我们还不明白为什么DeepONets会导致小的泛化误差。另一方面，在本文中，我们对两个子网络使用了完全连接的神经网络，但正如我们在2.1节中讨论的那样，我们也可以使用其他网络架构，如卷积神经网络或“注意”机制。这些修改可能会进一步提高DeepONets的准确性。</p>
<h1 id="FOURIER-NEURAL-OPERATOR-FOR-PARAMETRIC-PARTIAL-DIFFERENTIAL-EQUATIONS"><a href="#FOURIER-NEURAL-OPERATOR-FOR-PARAMETRIC-PARTIAL-DIFFERENTIAL-EQUATIONS" class="headerlink" title="FOURIER NEURAL OPERATOR FOR PARAMETRIC PARTIAL DIFFERENTIAL EQUATIONS"></a>FOURIER NEURAL OPERATOR FOR PARAMETRIC PARTIAL DIFFERENTIAL EQUATIONS</h1><p>傅里叶神经算子起作用的原因可能是做傅里叶变换时过滤了高频的噪声信号。</p>
<p>物理空间 (即以x为变量的空间)上的<strong>微分</strong>等效于傅立叶空间中的<strong>乘法</strong>，因此通过傅立叶变换，PDE上的一部分偏微分被消除，<strong>PDE也被转化成一个ODE</strong>。</p>
<p>FNO的一些优点：</p>
<ul>
<li>Fourier Filter是global的，而如果只使用CNN filter的话，感受是local的。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306281141887.png" alt=""></p>
<ul>
<li>FNO的一个设计目的就是要与分辨率无关，而传统的偏微分方程求解方法之一的谱方法也有可借鉴的思路。因为从傅立叶空间中学习参数，相当于将物理空间投影在以 $e^{2\pi i<x,k>}$ 为基的空间下，而这个空间下是处处well-defined，与离散无关。</li>
<li>除此之外，使用FFT之后，计算复杂度变成了准线性的，为大规模计算提供了可能。</li>
</ul>
<h2 id="Abstract-10"><a href="#Abstract-10" class="headerlink" title="Abstract"></a>Abstract</h2><p>神经网络的经典发展主要集中在有限维欧几里得空间之间的学习映射。最近，这已被推广到学习函数空间之间映射的神经算子。对于偏微分方程(PDEs)，神经算子直接学习从任何泛函参数依赖到解的映射。因此，他们学习了一整套的偏微分方程，而不是求解一个方程实例的经典方法。在这项工作中，我们通过在傅里叶空间中直接参数化积分核来构造一种新的神经算子，从而实现了一种具有表达性和效率的体系结构。我们对Burgers方程、Darcy flow和N-S方程进行了实验。傅里叶神经算子是第一个基于机器学习的零射超分辨率湍流模型。与传统的PDE求解器相比，它的速度快了3个数量级。此外，与以前的基于学习的固定分辨率求解器相比，它具有更高的精度。</p>
<h2 id="Introduction-14"><a href="#Introduction-14" class="headerlink" title="Introduction"></a>Introduction</h2><p>科学和工程中的许多问题都涉及到求解复杂的偏微分方程(PDE)系统重复对某些参数的不同值。分子动力学、微观力学和湍流流动中都有例子。通常这样的系统需要精细的离散化，以便捕捉被建模的现象。因此，传统的数值求解很慢，有时效率很低。例如，在设计机翼等材料时，需要解决相关的逆向问题，其中需要对正向模型进行数千次评估。一个快速的方法可以使这些问题变得可行。</p>
<h3 id="Conventional-solvers-vs-Data-driven-methods"><a href="#Conventional-solvers-vs-Data-driven-methods" class="headerlink" title="Conventional solvers vs. Data-driven methods."></a>Conventional solvers vs. Data-driven methods.</h3><p>传统的求解方法如有限元法和有限差分法是通过对空间离散化来求解方程的。因此，它们对分辨率进行了权衡：粗糙的网格速度快，但准确性较低；精细的网格是准确的，但速度慢。如上所述，复杂的PDE系统通常需要非常精细的离散化，因此对于传统的求解器来说非常具有挑战性和耗时。另一方面，数据驱动方法可以直接从数据中学习方程组族的轨迹。因此，基于学习的方法可以比传统的求解器快几个数量级。通过提供近似或增强传统算法的快速求解器，机器学习方法可能是科学学科革命的关键。然而，经典的神经网络在有限维空间之间映射，因此只能学习与特定离散化相关的解。这往往是实际应用的一个限制，因此需要开发网格不变神经网络。我们首先概述了两种主流的基于神经网络的方法有限维算子和神经有限元。</p>
<h3 id="Finite-dimensional-operators"><a href="#Finite-dimensional-operators" class="headerlink" title="Finite-dimensional operators."></a>Finite-dimensional operators.</h3><p>这些方法将解算子参数化为有限维欧氏空间之间的深度卷积神经网络。根据定义，这样的方法是依赖于网格的，并且需要针对不同的分辨率和离散化进行修改和调优，以便实现一致的误差（如果可能的话）。此外，这些方法受限于训练数据的离散化大小和几何形状，因此不可能在域中的新点查询解。相反，对于我们的方法，我们展示了误差对网格分辨率的不变性，以及在网格之间传递解的能力。</p>
<h3 id="Neural-FEM"><a href="#Neural-FEM" class="headerlink" title="Neural-FEM."></a>Neural-FEM.</h3><p>第二种方法直接将解函数参数化为神经网络。这种方法设计用于建模PDE的一个特定实例，而不是解决方案操作符。它是网格无关的和准确的，但对于任何给定的功能参数/系数的新实例，它需要训练一个新的神经网络。该方法与有限元等经典方法非常相似，用神经网络的空间代替了局部基函数有限集的线性跨度。神经有限元方法与经典方法存在相同的计算问题：优化问题需要针对每个新实例进行求解。此外，该方法仅限于已知底层PDE的设置。</p>
<h3 id="Neural-Operators"><a href="#Neural-Operators" class="headerlink" title="Neural Operators."></a>Neural Operators.</h3><p>最近，一项新的工作提出了使用神经网络学习无网格、无限维算子。神经算符通过产生一组可用于不同离散化的网络参数，弥补了上面讨论的有限维算符方法的网格依赖特性。它具有在网格之间传输解的能力。此外，神经算子只需要训练一次。获得参数的新实例的解只需要网络的向前通过，减轻了神经有限元方法产生的主要计算问题。最后，神经算符不需要基础PDE的知识，只需要数据。到目前为止，由于计算积分算子的成本，神经算子还没有产生有效的数值算法，可以在有限维环境下与卷积或递归神经网络的成功并行。通过快速傅里叶变换，我们的工作缓解了这个问题。</p>
<h3 id="Fourier-Transform"><a href="#Fourier-Transform" class="headerlink" title="Fourier Transform."></a>Fourier Transform.</h3><p>傅立叶变换常用于求解微分方程的谱方法中，因为微分等价于傅立叶域中的乘法。傅里叶变换在深度学习的发展中也扮演了重要的角色。理论上，它们出现在万能逼近定理的证明中，而在经验上，它们已被用于加速卷积神经网络。涉及傅里叶变换或使用正弦激活函数的神经网络架构也被提出和研究。最近，一些PDE的谱方法已经扩展到神经网络。在这些工作的基础上，我们提出了一个直接定义在傅里叶空间中的神经算子体系结构，具有准线性时间复杂度和最先进的逼近能力。</p>
<h2 id="LEARNING-OPERATORS"><a href="#LEARNING-OPERATORS" class="headerlink" title="LEARNING OPERATORS"></a>LEARNING OPERATORS</h2><p>我们的方法从观察到的有限的输入输出对集合中学习两个无限维空间之间的映射。再者让 $G^{\dagger}:\mathcal{A}\rightarrow \mathcal{U}$ 是一个(典型的)非线性映射。我们研究了作为参数偏微分方程解算符出现的映射 $G^{\dagger}$ - 参见第5节的例子。我们的目标是通过构造一个参数映射来建立一个近似的 $G^{\dagger}$:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122213846.png" alt=""></p>
<p>对某有限维参数空间 $\Theta$ ，选择 $\theta^{\dagger}\in \Theta$ ，使 $G(\cdot,\theta^{\dagger})=G_{\theta^{\dagger}}\approx G^{\dagger}$ 。这是无限维学习的自然框架，就像我们可以定义成本函数一样 $C:\mathcal{U}\times\mathcal{U}\rightarrow\mathbb{R}$ ，寻找问题的最小值</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122214437.png" alt=""></p>
<p>这直接与经典的有限维设定平行。在无限维环境中，如何证明最小化函数的存在性，仍然是一个具有挑战性的开放问题。我们将通过使用用于确定 $\theta$ 和测试近似准确性的成本的数据驱动的经验近似，在测试训练设置中处理这个问题。因为我们在无限维环境中概念化了我们的方法，所有有限维近似都有一组在无限维环境中一致的参数。</p>
<h3 id="Learning-the-Operator"><a href="#Learning-the-Operator" class="headerlink" title="Learning the Operator."></a>Learning the Operator.</h3><p>近似算符 $G^{\dagger}$ 是一项不同的任务，通常比为参数 $a\in \mathcal{A}$ 的单个实例寻找PDE的解 $u\in \mathcal{U}$ 更具挑战性。大多数现有的方法，从经典的有限元、有限差分和有限体积到现代机器学习方法，如物理信息神经网络(PINN)针对的是后者，因此计算成本可能很高。这使得它们对于对于许多不同的参数实例都需要PDE解决方案的应用程序来说是不切实际的。另一方面，我们的方法直接逼近运算符，因此更便宜和更快，与传统求解器相比，提供了巨大的计算节省。有关贝叶斯逆问题的示例应用程序，请参见第5.5节。</p>
<h3 id="Discretization"><a href="#Discretization" class="headerlink" title="Discretization."></a>Discretization.</h3><p>由于我们的数据 $a_{j}$ 和 $u_{j}$ 通常是函数，要在数值上使用它们，所以我们假设只能访问按点计算的值。设 $D_{j}=\{x_{1},x_{2},\cdots,x_{n}\} \subset D$ 是定义域 $D$ 的 $n$ - 点离散化，假设我们有 $a_{j}|_{D_{j}}\in \mathbb{R}^{n\times d_{a}},u_{j}|_{D_{j}}\in\mathbb{R}^{n\times d_{v}}$ ，对于 $j$ 索引的输入输出对的有限集合。要做到离散不变，神经算子可以对任何 $x\in D$产生答案 $u(x)$ ，可能 $x \notin D_{j}$。这样的特性是非常可取的，因为它允许在不同的网格几何形状和离散化之间传递解。</p>
<h2 id="NEURAL-OPERATOR"><a href="#NEURAL-OPERATOR" class="headerlink" title="NEURAL OPERATOR"></a>NEURAL OPERATOR</h2><p>神经算子被表述为迭代体系结构 $v_{0} \mapsto v_{1} \mapsto \cdots \mapsto v_{T}$ 其中 $v_{j}$ 对于 $j=0,1,\cdots,T−1$ 是一个函数序列，每个函数都有一个值 $\mathbb{R}^{d_{v}}$ 。如图2 (a)所示，输入 $a\in \mathcal{A}$ 首先通过局部变换 $P$ 提升到高维表示 $v_{0}(x) = P(a(x))$，局部变换 $P$ 通常由浅全连通神经网络参数化。然后我们然后我们应用几次更新迭代 $v_{t}\mapsto v_{t+1}$ (定义如下)。输出 $u(x) = Q(v_{T}(x))$ 是 $v_{T}$ 通过局部变换 $Q: \mathbb{R}^{d_{v}}\mapsto \mathbb{R}^{d_{u}}$ 。在每一次迭代中，更新 $v_{t}\mapsto v_{t+1}$ 被定义为一个非局部积分算子的复合 $\mathcal{K}$ 和一个局部非线性激活函数 $\sigma$ 。</p>
<p>$a(x)$ 作为输入，经过 $P$ 这个神经网络映射到高维（为了高斯平滑），然后经历T个Fourier Layer，经过 $Q$ 之后恢复回 $u(x)$ 。具体对于一个Fourier layer来说， $v(x)$ 进来以后，经过Fourier变换，将其转化到Fourier空间， $R$ 则是一个线性变换，目的是滤掉高频模态，然后用Fourier逆变换将其转化回源空间， $R$ 之所以不选用神经网络映射作者说是因为实验发现线性效果更好，下面那条支路就类似于ResNet的“短路”结构，相加求和之后，经过激活函数进行非线性映射。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123152103.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123170343.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123170408.png" alt=""></p>
<p>在这里， $k_{\phi}$ 起着核函数的作用。定义1和2构成了神经网络到无限维空间的泛化。注意，即使积分算符是线性的，神经算符可以通过将线性积分算符与非线性激活函数组合在一起来学习高度非线性的算符，类似于标准神经网络。如果我们去掉函数 $\kappa(x,y,a(x),a(y))$ 对 $a$ 的依赖并强加 $\kappa(x,y)=\kappa(x-y)$ ，那么(3)是一个卷积算子（$f_{1} \ast f_{2}=\int_{-\infty}^{\infty}f_{1}(\tau)f_{2}(t-\tau)d\tau$）。</p>
<h2 id="FOURIER-NEURAL-OPERATOR"><a href="#FOURIER-NEURAL-OPERATOR" class="headerlink" title="FOURIER NEURAL OPERATOR"></a>FOURIER NEURAL OPERATOR</h2><p>我们建议用傅里叶空间中定义的卷积算子替换(3)中的核积分算子。设 $\mathcal{F}$ 表示函数 $f:D\rightarrow \mathbb{R}^{d_{v}}$ 的傅里叶变换和 $\mathcal{F}^{-1}$ 是它的倒数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123183426.png" alt=""></p>
<p>取 $\kappa_{\phi}(x, y, a(x), a(y)) = \kappa_{\phi}(x-y)$ ，应用卷积定理，得到</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123184335.png" alt=""></p>
<p>因此，我们建议在傅里叶空间中直接参数化 $\kappa_{\phi}$ 。</p>
<p>两函数的傅里叶变换的乘积等于它们卷积后的傅里叶变换，简单证明：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202307272018331.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123184435.png" alt=""></p>
<p>对于频率模态 $k \in D$ ，我们有 $(\mathcal{F}v_{t})(k)\in\mathbb{C}^{d_{v}}$ 和 $R_{\phi}(k)\in \mathbb{C}^{d_{v}\times d_{v}}$ 。注意，因为我们假设 $\kappa$ 是周期性的，它允许傅里叶级数展开，所以我们可以用离散模 $k\in \mathbb{Z}^{d}$ 。我们通过在最大模数处截断傅立叶级数来选择有限维参数化 $k_{max}=|Z_{k_{max}}|=|\{k\in\mathbb{Z}^{d}:|k_{j}|\leq k_{max,j}, for \ j=1,\cdots,d\}|$ 。因此，我们将 $R_{\phi}$ 直接参数化为复值 $(k_{max} \times d_{v} \times d_{v})$ - 张量，由截断傅里叶模的集合组成，因此从我们的符号中去掉 $\phi$ 。因为 $\kappa$ 是实值的，我们施加共轭对称性。我们注意到集合 $Z_{k_{max}}$ 不是 $v_{t}$ 的低频模态的规范选择。事实上，低频模态通常是通过在的上限界来定义的 $k\in \mathbb{Z}^{d}$ 的 $l_{1}$ - 范数。我们像上面那样选择 $Z_{k_{max}}$ ，因为它允许高效的实现。</p>
<h3 id="The-discrete-case-and-the-FFT"><a href="#The-discrete-case-and-the-FFT" class="headerlink" title="The discrete case and the FFT."></a>The discrete case and the FFT.</h3><p>假设域 $D$ 被 $n\in \mathbb{N}$ 个点离散，我们得到 $v_{t} \in \mathbb{R}^{n \times d_{v}}$ 和 $\mathcal{F}(v_{t}) \in \mathbb{C}^{n \times d_{v}}$ 。由于我们将 $v_{t}$ 与一个只有 $k_{max}$ 傅里叶模态的函数进行卷积，我们可以简单地截断更高的模态，从而得到 $\mathcal{F}(v_{t}) \in \mathbb{C}^{k_{max} \times d_{v}}$ 。乘以权重张量 $R \in \mathbb{C}^{k_{max} \times d_{v} \times d_{v}}$ 是</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123203344.png" alt=""></p>
<p>当离散化均匀，分辨率为 $s_{1} \times \cdots \times s_{d} = n$ 时， $\mathcal{F}$ 可以用快速傅里叶变换代替。对于 $f \in \mathbb{R}^{n \times d_{v}}$ ， $k = (k_{1}, \cdots, k_{d}) \in \mathbb{Z}_{s_{1}} \times \cdots \times \mathbb{Z}_{s_{d}}$ ，且 $x=(x_{1}, \cdots, x_{d}) \in D$ ， 快速傅里叶变换 $\hat{\mathcal{F}}$ 及其逆 $\hat{\mathcal{F}}^{-1}$ 定义为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123203431.png" alt=""></p>
<p>在这种情况下，截断模的集合变成</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123204243.png" alt=""></p>
<h3 id="Parameterizations-of-R"><a href="#Parameterizations-of-R" class="headerlink" title="Parameterizations of R."></a>Parameterizations of R.</h3><p>一般情况下，R 可以定义为依赖于 $(\mathcal{F}a)$ 平行于(3)。确实，我们可以定义 $R_{\phi}:\mathbb{Z}^{d} \times \mathbb{R}^{d_{v}} \rightarrow \mathbb{R}^{d_{v} \times d_{v}}$ 作为将 $(k,(\mathcal{F}a)(k))$ 映射到相应的傅里叶模的值的参数函数。我们对 $R_{\phi}$ 进行了线性和神经网络参数化实验。我们发现线性参数化与前面描述的直接参数化具有相似的性能，而神经网络的性能更差。这可能是由于空间 $\mathbb{Z}^{d}$ 的离散结构。</p>
<h3 id="Invariance-to-discretization"><a href="#Invariance-to-discretization" class="headerlink" title="Invariance to discretization."></a>Invariance to discretization.</h3><p>傅里叶层是离散不变的，因为它们可以从以任意方式离散的函数中学习和求值。由于参数是在傅里叶空间中直接学习的，所以在物理空间中解析函数就相当于在 $\mathbb{R}^{d}$ 上处处定义良好的 $e^{2 \pi i<x,k>}$ 的基础上投影。这允许我们实现如5.4节所示的零射超分辨率。此外，我们的体系结构在输入和输出的任何分辨率上都有一致的错误。另一方面，请注意，在图3中，我们比较的标准CNN方法有一个随着分辨率增加而增加的错误。</p>
<p>傅里叶神经算子与输入的分辨率无关的原因是因为它利用了傅里叶变换的性质。傅里叶变换是一种在时间和频率域之间转换信号或数据的方法。在傅里叶神经算子中，输入信号经过傅里叶变换后，被转换到频域，而频域的运算不受分辨率的影响。因此，即使输入信号的分辨率改变，傅里叶神经算子的输出结果也不会受到影响。</p>
<p>具体来说，傅里叶神经算子将输入信号的每个像素值视为一个复数，然后对其进行傅里叶变换，得到频域下的复数系数。这些系数代表了输入信号在不同频率下的贡献。由于傅里叶变换的性质，高频成分对应于图像的细节和边缘信息，而低频成分对应于图像的整体轮廓和形状。因此，傅里叶神经算子对图像进行特征提取时，主要关注的是图像的轮廓和形状信息，而忽略了一些细节和噪声。</p>
<p>由于傅里叶变换已经将输入信号从时域转换到了频域，所以傅里叶神经算子的运算都是在频域进行的。这种频域运算不受分辨率的影响，因此傅里叶神经算子的输出结果也不受输入分辨率的影响。</p>
<h3 id="Quasi-linear-complexity"><a href="#Quasi-linear-complexity" class="headerlink" title="Quasi-linear complexity."></a>Quasi-linear complexity.</h3><p>权重张量 $R$ 包含 $k_{max} &lt; n$ 个模态，因此内部乘法的复杂度为 $O(k_{max})$ 。因此，大部分的计算成本在于计算傅里叶变换 $\mathcal{F}(v_{t})$ 及其反变换。一般的傅里叶变换的复杂度是 $O(n^{2})$ ，然而，由于我们截断了级数，复杂度实际上是 $O(nk_{max})$ ，而快速傅里叶变换的复杂度是 $O(n \log n)$ 。通常，我们发现使用快速傅里叶变换非常高效。然而，统一的离散化是必需的。</p>
<h2 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h2><p>假设我们有一个二阶椭圆偏微分方程如下，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123210401.png" alt=""></p>
<p>其中 $u$ 是我们的目标求解对象， $f(x)$ 就是右端项，在很多物理方程中被视为强迫项，而这个 $a(x)$ 是参数， $a \in \mathcal{A}$ ，其中 $\mathcal{A}$ 是参数空间。如果我们把其写成算子的形式，则表达成如下形式</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123210533.png" alt=""></p>
<p>其中 $\mathcal{L} \cdot =−div⁡(a\triangledown \cdot)$ ，下标 $a$ 的意思是说在参数 $a$ 时的算子 $\mathcal{L}$ 。</p>
<p>有一种偏微分方程求解析解的方法，被称作格林函数法。大概意思就是说，可以构造一个格林函数 $G$ ，定义域满足 $D \times D \rightarrow R$ ，使得方程解 $u$ 的形式可以写为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123210855.png" alt=""></p>
<p>这个格林函数 $G$ 可以理解为是一个核函数，这个思想大体就是说，假设 $x$ 的定义域是 $[0,1]$ ，则 $x=0.5$ 处的解 $u(0.5)$ 是受 $x$ 在 $[0,1]$ 所有点影响的，而这个影响大小取决于 $G$ ，比如 $G(0.5,0)$ 就是 $x=0$ 这个点对 $x=0.5$ 的影响，而 $G(0.5,1)$ 则同理。因为定义域是连续的，所以累加就变成了积分，而 $y$ 只是个积分符号而已，就代表格林函数后面的那个点在 $D$ 上积分。</p>
<p>之所以可以这么表达，是因为格林函数 $G$ 满足 $\mathcal{L}_{a}G(x, \cdot)=\delta a$ 其中 $\delta x$ 被称为狄拉克测度（dirac delta measure），测度这个概念比较抽象，在实数域里不妨就当dirac函数理解即可。dirac函数有一个性质，就是和任意函数积分后为函数本身，这样就可以证明了。下式成功的从左边推到了右边，和方程原始形式一致。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123211556.png" alt=""></p>
<p>受格林函数法的指导下，设计出了这么一个神经网络架构。这时候熟悉格林函数的朋友可能会问了，格林函数法成立的前提不是叠加原理么？叠加原理的前提不是线性微分方程么？难道其不能解决非线性方程么？其实神经网络的非线性激活函数就把这个问题解决了。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123211716.png" alt=""></p>
<h3 id="FFT"><a href="#FFT" class="headerlink" title="FFT"></a>FFT</h3><p>为什么截断corner，这与numpy、pytorch对FFT的实现有关，先是低频，然后慢慢增长到高频，然后变成负的高频，慢慢增长到负的低频，所以低频信息就存在边角corner处。</p>
<h3 id="代码流程"><a href="#代码流程" class="headerlink" title="代码流程"></a>代码流程</h3><ol>
<li>输入是 $5\ast128\ast128\ast10\ast2$，分别代表批大小，x轴分辨率，y轴分辨率，时间步长，物理量数目；</li>
<li>首先将最后两维合并，变成 $5\ast128\ast128\ast20$；</li>
<li>接着将x轴和y轴坐标合并进来（坐标进行傅里叶变换有利于学到结构和形状），变成 $5\ast128\ast128\ast22$；</li>
<li>通过fc层进行升维，变成 $5<em>128</em>128*20$；</li>
<li>转换维度，变成 $5\ast20\ast128\ast128$；</li>
<li>做padding，变成 $5\ast20\ast130\ast130$；</li>
<li>做FFT，得到x_ft，大小为 $5\ast20\ast130\ast66$</li>
<li>生成一个同样大小的out_ft，按照需要的modes截断填充</li>
<li>做IRFFT，得到输出，大小为 $5\ast20\ast130\ast130$</li>
<li>unpadding，大小为 $5\ast20\ast128\ast128$</li>
<li>permutate之后得到输出，大小为 $5\ast128\ast128\ast20$</li>
<li>通过fc变换维度，变成 $5\ast20\ast128\ast128\ast128$</li>
<li>通过fc层转换到输出的维度，变成 $50\ast20\ast128\ast128\ast2$</li>
<li>通过unsqueeze函数增加时间维度，变成 $50\ast20\ast128\ast128\ast1\ast2$</li>
</ol>
<h1 id="A-composite-neural-network-that-learns-from-multi-fidelity-data-Application-to-function-approximation-and-inverse-PDE-problems"><a href="#A-composite-neural-network-that-learns-from-multi-fidelity-data-Application-to-function-approximation-and-inverse-PDE-problems" class="headerlink" title="A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems"></a>A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems</h1><p>我们提出了一种新的复合神经网络(NN)，可以基于多保真度数据进行训练。它由三个神经网络组成，第一个神经网络使用低保真度数据训练，并与两个高保真度数据耦合为了分别发现和利用低保真度和高保真度数据之间的非线性和线性相关性，一个具有激活函数，另一个没有激活函数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205170739.png" alt=""></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>主要就是充分利用不同精度的数据来得到更加精确的结果</p>
<ol>
<li>给定低精度数据 $\{x_{i}, y_{i}\}_{i=1}^{N_{l}}$ ，我们可以训练出一个低精度神经网络 $    \mathcal{NN}_{lf}$</li>
<li>同样，给定高精度数据 $\{x_{i},y_{i}\}_{i=N_{l}+1}^{N_{l}+N_{h}}$ ，我们可以训练出一个高精度神经网络 $\mathcal{NN}_{hf}$</li>
<li>然后将高精度数据输入到低精度网络当中，得到 $z_{i}$ ，即为高精度数据的低精度网络预测值。</li>
<li>将 $\{(x_{i},z_{i}),y_{i}\}_{i=N_{l}+1}^{N_{l}+N_{h}}$ 作为训练数据训练一个神经网络 $\mathcal{NN}_{lf \rightarrow hf}$ ，这个神经网络可以实现将低精度数据变为高精度数据。</li>
<li>考虑到线性和非线性的影响，$\mathcal{NN}_{lf\rightarrow hf}$ 可以变成两个神经网络的和，一个使用激活函数（非线性），另一个不使用激活函数。</li>
</ol>
<h1 id="NSFnets-Navier-Stokes-flow-nets-Physics-informed-neural-networks-for-the-incompressible-Navier-Stokes-equations"><a href="#NSFnets-Navier-Stokes-flow-nets-Physics-informed-neural-networks-for-the-incompressible-Navier-Stokes-equations" class="headerlink" title="NSFnets (Navier-Stokes flow nets): Physics-informed neural networks for the incompressible Navier-Stokes equations"></a>NSFnets (Navier-Stokes flow nets): Physics-informed neural networks for the incompressible Navier-Stokes equations</h1><h2 id="Abstract-11"><a href="#Abstract-11" class="headerlink" title="Abstract"></a>Abstract</h2><p>在许多实际情况下，我们仍然不能将无缝(多保真)数据合并到现有的算法中，而且对于工业复杂性的应用程序，网格生成是耗时的，仍然是一门艺术。此外，解决不适定问题（例如，缺乏边界条件）或逆问题通常是非常昂贵的，需要不同的公式和新的计算机代码。我们开发了通过考虑Navier-Stokes方程的两种不同的数学公式：速度-压力(VP)公式和涡速(VV)公式来建立Navier-Stokes流网(NSFnets)。与传统的数值方法不同，NSFnets继承了神经网络(NNs)的特性，因此总误差由近似误差、优化误差和泛化误差组成。在这里，我们尝试通过改变抽样来量化这些残差点，迭代求解器，以及NN体系结构的大小。</p>
<h2 id="Introduction-15"><a href="#Introduction-15" class="headerlink" title="Introduction"></a>Introduction</h2><p>在超过50年的时间里发展出了许多不同的计算流体动力学(CFD)方法，如果能精确地知道控制方程或精确地求解所有的尺度，这些方法就能非常有效地工作。然而，在许多现实世界的应用中，要么物理是不完全知道的，例如在反应输运中，要么解决尺度的大时空谱可能是非常昂贵的，因此求助于亚网格尺度闭包。在过去的五年中，人们采用不同的方法将神经网络(NNs)集成到不可压缩Navier-Stokes方程的求解中。对于湍流流动，最常见的方法是推导数据驱动的湍流闭合模型。</p>
<p>我们通过利用神经网络的普遍近似性质走了一条不同的道路，它使用自动微分使我们能够开发不需要网格生成的Navier-Stokes“求解器”。它们很容易实现，对于多物理和逆流体力学问题尤其有效（多保真度）数据可以为缺失的物理起到闭合的作用。Raissi等人首次引入了物理信息神经网络(PINN)的概念，以解决涉及几种不同类型的偏微分方程的正向和逆向问题。这一方法还被用于模拟涡旋诱导振动，并用于解决不适定逆流体力学问题，即“隐藏流体力学”的框架。一个基本问题是PINN是否可以直接模拟湍流，类似于使用高阶离散化的直接数值模拟(DNS)。另一个重要的问题是，是否有另一种Navier-Stokes方程的公式，例如涡速(VV)形式，可以达到更高的精度或可能适合更有效的训练。</p>
<p>VP-NSFnet的输入是时空坐标，输出是瞬时速度场和压力场。对于VV-NSFnet，输入仍然是空间和时间坐标，输出是瞬时速度和涡量场。</p>
<h2 id="Methodology-5"><a href="#Methodology-5" class="headerlink" title="Methodology"></a>Methodology</h2><p>不可压缩Navier-Stokes方程的VP形式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205203028.png" alt=""></p>
<p>Navier-Stokes方程的解决方案采用深度神经网络逼近，以空间和时间坐标作为输入，预测相应的速度场和压力场，VP形式的网络结构示意图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205214837.png" alt=""></p>
<p>Navier-Stokes方程VV形成的旋转形式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205215023.png" alt=""></p>
<p>VV形式的网络结构示意图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205214955.png" alt=""></p>
<h1 id="Spatio-Temporal-Super-Resolution-of-Dynamical-Systems-using-Physics-Informed-Deep-Learning"><a href="#Spatio-Temporal-Super-Resolution-of-Dynamical-Systems-using-Physics-Informed-Deep-Learning" class="headerlink" title="Spatio-Temporal Super-Resolution of Dynamical Systems using Physics-Informed Deep-Learning"></a>Spatio-Temporal Super-Resolution of Dynamical Systems using Physics-Informed Deep-Learning</h1><h2 id="Abstract-12"><a href="#Abstract-12" class="headerlink" title="Abstract"></a>Abstract</h2><p>这项工作提出了一种基于物理的深度学习超分辨率框架，以提高时间相关偏微分方程(PDE)解的时空分辨率。先前关于基于深度学习的超分辨率模型的工作已经显示出通过减少传统数值格式的计算费用来加速工程设计的前景。然而，这些模型严重依赖训练期间所需的高分辨率(HR)标记数据的可用性。</p>
<p>在这项工作中，我们提出了一个基于物理的深度学习框架，以增强粗尺度(空间和时间上)PDE解决方案的空间和时间分辨率，而不需要任何HR数据。该框架由两个可训练模块组成，首先在空间上，然后在时间方向上独立地对PDE解决方案进行超分辨。基于物理的损失以一种新颖的方式实现，以确保不同时间的时空细化输出之间的紧密耦合，并提高框架精度。我们通过研究其在弹性动力学问题上的表现来分析所开发的框架的能力。结果表明，该框架在满足物理约束条件的同时，能够成功地在空间和时间上对低分辨率偏微分方程解进行超解析，并获得较高的精度。此外，分析和得到的加速结果表明，所提出的框架非常适合与传统数值方法集成，以降低工程设计中的计算复杂度。</p>
<h2 id="Introduction-16"><a href="#Introduction-16" class="headerlink" title="Introduction"></a>Introduction</h2><p>非线性系统动态行为的精确建模对于从微型MEMS传感器到大型结构系统的许多工业应用都是至关重要的。因此，人们正在进行重要的研究，以理解和解决在极小的空间和时间尺度上发生在这些动力系统内的复杂物理现象。这种捕捉发生在广泛变化的时空尺度上的复杂物理现象的科学追求导致了物理系统控制偏微分方程(PDEs)的日益复杂。例如，基于PDE的模型在纳米尺度上捕捉材料中的缺陷演化已被证明优于传统理论，具有广泛的应用范围。然而，大量的数据存储和高保真度模拟这种多物理场耦合偏微分方程所需的计算费用使传统的数值求解方法达到了极限。因此，在多尺度上快速准确地执行这些多物理场模拟的技术是至关重要的。</p>
<p>另一方面，机器学习(ML)的最新进展导致了几个数据驱动和物理知情ML模型的发展，以解决流体中发生的偏微分方程和固体力学。然而，从其理论考虑(如收敛性、稳定性、准确性和可泛化性)到边界条件、神经网络架构设计或优化方面的问题仍需要完全解决。因此，将基于物理的ML与传统方法相结合的混合策略正在成为解决复杂的多物理场微分方程的计算挑战的一个有前途的选择。</p>
<p>为此，在本研究中，我们旨在研究一种集成ML和传统方法的两阶段混合方法，以获得(重建)时空偏微分方程的解。1）在第一阶段，通过在空间和时间上进行粗尺度的数值模拟(使用大网格尺寸和时间步长)获得低分辨率PDE解。与精细尺度的PDE求解相比，可以生成具有满意精度的低分辨率解，并大大减少了计算费用。2）在第二阶段，使用物理形成的基于深度学习的框架增强了该粗尺度解决方案的时空分辨率。这种“物理引导分辨率增强”方法的一个显著优势是减少了科学探索阶段的计算费用和数据存储需求，这将大大加快科学调查和工程设计的进程。这种分辨率的增强在本研究中也被称为上采样或超分辨率(SR)。</p>
<p>最近的工作涉及物理系统的时空超分辨率使用标记高分辨率(HR)真实数据进行模型训练。Fukami等人提出了一个纯数据驱动的SR框架，因此超分辨场可能无法准确地满足基于物理的约束。Ren等人和Soheil等人“几乎是数据驱动的”，因为预测/数据损失的比例系数被选择为总损失中物理损失系数的20倍，以获得最佳精度。事实上，如果不考虑人力资源标签数据(纯物理驱动)，误差是巨大的。此外，获得人力资源标记的数据的计算成本很高。因此，在训练期间使用它完全否定了ML模型旨在实现的加速科学计算的巨大好处。在这项研究中，我们提出了一个基于物理信息的端到端深度学习框架，以增强粗尺度(空间和时间)PDE解决方案的空间和时间分辨率，而不需要任何高分辨率标记的数据。</p>
<h2 id="Background-1"><a href="#Background-1" class="headerlink" title="Background"></a>Background</h2><h3 id="Governing-equations"><a href="#Governing-equations" class="headerlink" title="Governing equations"></a>Governing equations</h3><p>控制动力系统的典型的时空偏微分方程可以写成如下形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217220123.png" alt=""></p>
<p>初始条件和边界条件：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217220133.png" alt=""></p>
<p>式中， $z$ 表示由 $m$ 个状态变量组成的系统解， $\dot{z}$ 表示其时间导数。 $\mathcal{F}$ 是多项式的非线性泛函及其参数的导数项。 $\Omega$ 和 $\partial\Omega$ 分别表示物理域及其边界。系统中固有的或由于数值方法(如混合有限元方法)而需要的任何附加约束，都可以组合成 $\mathcal{C}(z)=0$ 。</p>
<p>给出方程在粗尺度上求解得到的解 $z_{c}$ (大网格尺寸和时间步长)，我们的目标是通过使用基于物理的深度学习方法来提高解决方案的空间和时间分辨率。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217220736.png" alt=""></p>
<h2 id="Methodology-6"><a href="#Methodology-6" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Objective-function"><a href="#Objective-function" class="headerlink" title="Objective function"></a>Objective function</h3><p>我们注意到，在这项工作中提出的框架是无监督的，因此复合损失函数只能从系统的控制方程-初始条件，边界条件和偏微分方程中获得。我们以“硬”方式（准确地）施加边界条件，从而消除了复合损失对边界条件损失的贡献。基于物理的目标函数如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217221314.png" alt=""></p>
<p>我们使用四阶有限差分格式来计算网格上解的空间导数。对于时间离散化，我们使用了Crank-Nicholson算法，该算法具有无条件稳定的优点，并且在空间和时间维度上都是二阶精确的。</p>
<h3 id="Input-and-output-for-the-framework"><a href="#Input-and-output-for-the-framework" class="headerlink" title="Input and output for the framework"></a>Input and output for the framework</h3><p>框架的输入由LR粗尺度偏微分方程在连续时间步长 $t$ 和 $t+\Delta t$ 的解所构成的元组 $\mathcal{I}_{c}^{t}=\{z_{c}^{t},z_{c}^{t+\Delta t}\}$ 组成。该框架的输出包括在相同时间步长的空间上放大的偏微分方程解 $\{\hat{z}^{t},\hat{z}^{t+\Delta t}\}$ 和 (k−1)中间时间步长的HR快照的合成 $\{\hat{z}^{t+\frac{\Delta}{k}},\hat{z}^{t+2\frac{\Delta}{k}},\cdots,\hat{z}^{t+(k-1)\frac{\Delta}{k}} \}$ 。因此，该框架在(k + 1)个时间步 $\mathcal{O}^{t}$ 产生空间上放大的PDE解决方案。我们将标量k称为时间上标因子，它表示为粗尺度时间步与细尺度时间步的比值，即 $k=\frac{\Delta t_{c}}{\Delta t_{f}}$ 。同样，空间方向s上的升尺度因子为粗网格分辨率与细网格分辨率之比，即 $s=\frac{\Delta x_{c}}{\Delta x_{f}}$ 。</p>
<h3 id="Framework-Architecture"><a href="#Framework-Architecture" class="headerlink" title="Framework Architecture"></a>Framework Architecture</h3><p>该框架由两个可训练模块组成:空间分辨率增强模块和时间分辨率增强模块。这两个模块分别独立执行空间和时间上的超分辨率。我们观察到，这种双模块方法首先在空间中执行超分辨率，随后增加时间分辨率，从而导致超分辨率场的更好收敛性和准确性，这也在Fukami等人的数据驱动方法中观察到。</p>
<p>任何动力系统的典型解 $z$ 由 $m$ 个状态变量组成。因此，框架中的每个模块由 $m$ 个深度学习模型(具有相同的架构)组成，分别重构每个状态变量。然而，这些模型在训练过程中通过目标函数(损失)进行耦合。第3.3.1节和3.3.2节分别更详细地讨论了这些空间和时间超分辨率模块。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217223920.png" alt=""></p>
<h4 id="Spatial-resolution-enhancement-module"><a href="#Spatial-resolution-enhancement-module" class="headerlink" title="Spatial resolution enhancement module"></a>Spatial resolution enhancement module</h4><p>对于状态向量 $z$ ，给定两个连续时间步长的LR快照元组 $\mathcal{I}_{c}^{t}=\{z_{c}^{t},z_{c}^{t+\Delta t}\}$ ，空间提升模块输出相应的HR帧 $\{\hat{z}^{t},\hat{z}^{t+\Delta t}\}$ 表示输入状态在原时间步长的增强空间分辨率。因此，输入（输出）由表示时间步长 $t$ 和 $t+\Delta t$ 时LR (HR)状态变量值的双通道图像组成。</p>
<p>在训练过程中，我们观察到，为了从两个输出通道中的初始条件成功地演化出解决方案，PDE损失必须在输出内部和跨输出实现。这种损耗耦合有助于减轻该模块的传输故障模式。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217232831.png" alt=""></p>
<p>空间提升模块中的每个模型都建立在中提出的残差密集网络(Residual Dense Network, RDN)之上，与其他网络相比，RDN在图像SR方面具有独特的优势。我们使用4个残差块，每个块有8层，特征通道大小为32。卷积的核大小设置为3。</p>
<h4 id="Temporal-resolution-enhancement-module"><a href="#Temporal-resolution-enhancement-module" class="headerlink" title="Temporal resolution enhancement module"></a>Temporal resolution enhancement module</h4><p>时态模块增强了状态变量在时间上的分辨率。空间模块的输出作为时间模块的输入。因此，输入是表示时间步长 $t$ 和 $t+\Delta t$ 的HR状态变量值的双通道图像。该模块输出带有(k+1)个通道的图像，用来表示在时间步长 $\{t, t+\frac{\Delta t}{k},\cdots, t+\Delta t\}$ 的状态变量。我们在这里注意到，时间模块的输入仍然存在 $O(\Delta t^{2})$ 阶的时间离散化误差。因此，时间模块也会在初始时间 $t$ 和最终时间 $t+\Delta t$ 重建解，将此误差减小到 $O((\frac{\Delta t}{k})^{2})$ 。为了训练这个模块，我们对复合损失做了如下修改:</p>
<ul>
<li>类似于空间模块中PDE损耗的实现，空间模块的PDE损失也是实现在输出和跨输出。</li>
<li>由于我们在初始时间步长和最终时间步长( $t$ 和 $t+\Delta t$ )重构了输出，因此我们在这些输入和输出之间增加了约束损失，这有助于更快地收敛模块。</li>
</ul>
<h1 id="Error-Aware-B-PINNs-Improving-Uncertainty-Quantification-in-Bayesian-Physics-Informed-Neural-Networks"><a href="#Error-Aware-B-PINNs-Improving-Uncertainty-Quantification-in-Bayesian-Physics-Informed-Neural-Networks" class="headerlink" title="Error-Aware B-PINNs: Improving Uncertainty Quantification in Bayesian Physics-Informed Neural Networks"></a>Error-Aware B-PINNs: Improving Uncertainty Quantification in Bayesian Physics-Informed Neural Networks</h1><h2 id="Abstract-13"><a href="#Abstract-13" class="headerlink" title="Abstract"></a>Abstract</h2><p>基于物理的神经网络(PINN)作为求解微分方程的一种方法正越来越受欢迎。虽然在某些情况下比经典的数值技术更可行，PINN仍然缺乏可信度。在不确定性量化(UQ)中可以找到一种补救方法，它刚刚开始出现在PINN的背景下。评估训练好的PINN是否符合强加微分方程是解决不确定性问题的关键，但目前还缺乏全面的方法。我们提出了一个贝叶斯PINN (B-PINN)中UQ的框架，它包含了B-PINN解和未知真解之间的差异。我们利用线性动力系统上PINN的误差界的最新结果，证明了一类线性ODE的预测不确定性。</p>
<h2 id="Introduction-17"><a href="#Introduction-17" class="headerlink" title="Introduction"></a>Introduction</h2><p>物理神经网络(PINN)是深度神经网络(DNN)，能够将微分方程(PDEs)编码为神经网络本身的一个组成部分。Lagaris等的早期结果首次提出使用神经网络求解微分方程，随后近年来关于PINN的出版物迅速增长。与传统数值求解器相比，PINN具有许多优点，例如，它们提供封闭形式的解，是无网格的。例如，在培训后支持按需解决方案计算，可以通过利用迁移学习快速发现新的解决方案，等等。</p>
<p>然而，为了真正蓬勃发展并部署在安全关键应用中，像PINN这样的深度学习技术需要是可靠的，即赋予高质量的不确定性量化(UQ)方法。在PINN的背景下，UQ方法仍然很少被使用，也没有公认的黄金标准。最近，基于物理的高斯过程(PIGP)和贝叶斯PINNs (B-PINNs)已被提出作为经典贝叶斯概率机器学习技术的对应物。另一个研究方向考虑了生成对抗网络的使用，其中贝叶斯推理在潜在空间而不是参数空间中执行。</p>
<p>由于存在多种不确定性来源，从噪声数据到模型架构相关问题，B-PINN中的UQ可以被视为比传统数值求解器中的UQ更具挑战性。还有一个黑盒不确定性，与网络实际上如何被告知控制物理方程有关。它源于PINN的无监督性质，但由于考虑到有噪声的测量数据，它经常被掩盖。作为一项规则，所有前面提到的不确定性来源都是使用一个“一概而论”的术语来建模的。在这项工作中，我们的目标是解开这些不确定性，并展示如何用有用的误差估计在总不确定性中增加单独的项，从而提高UQ方法的预测质量。</p>
<h2 id="Background-2"><a href="#Background-2" class="headerlink" title="Background"></a>Background</h2><h3 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h3><p>PINN可以解最一般形式的微分方程，如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218200105.png" alt=""></p>
<h3 id="Physics-Informed-Neural-Networks-1"><a href="#Physics-Informed-Neural-Networks-1" class="headerlink" title="Physics-Informed Neural Networks"></a>Physics-Informed Neural Networks</h3><p>软约束：边界/初值条件作为损失项加入loss当中</p>
<p>硬约束： $\widetilde{u}_{\theta}(x)=u_{0}+(1 - e^{-(x-x_{0})})u_{\theta}(x)$</p>
<h3 id="Uncertainty-Quantification-in-Bayesian-Neural-Networks"><a href="#Uncertainty-Quantification-in-Bayesian-Neural-Networks" class="headerlink" title="Uncertainty Quantification in Bayesian Neural Networks"></a>Uncertainty Quantification in Bayesian Neural Networks</h3><p>假设我们有一个有限的观测集合 $O$ ，在一个有界的区域 $\Omega_{O} \subset \Omega$ 。假设观测值是独立同分布的，并且是从分布 $p(O|\theta)$ 中得出的。这种分布被称为似然函数并且通常是由一个可分解的高斯分布建模的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218202953.png" alt=""></p>
<p>均值 $y_{\theta}$ 是由相关神经网络给出的并且 $\Sigma_{O} = \sigma^{2}_{O}I$ 。因此，假设观测结果 $O$ 是由数据生成过程产生的，该过程包含由 $y_{\theta}$ 建模的确定性部分以及一些附加噪声。此噪声表示不可约或任意的不确定性，其协方差矩阵 $\Sigma_{O}$ 可能是已知的或假设的，也可能是从数据中推断出来的。</p>
<p>标准的神经网络训练以频率论的方式进行，不考虑不确定性。模型参数 $\theta$ 通过最大化似然来推断为点估计，假设似然是高斯的，则等于均方误差最小化。请注意，在无监督PINN的情况下，为了推导MSE损失，我们假设虚拟“观测值”总是等于零，而均值由剩余网络 $r_{\theta}$ 给出， $\sigma^{2}_{O}$ 可以是任意的。</p>
<p>与频率论推理相反，贝叶斯推理不仅在观测值 $O$ 上放置分布，而且在参数 $\theta$ 上也放置分布，从而形成贝叶斯神经网络(BNNs)。贝叶斯框架中参数的概率性导致了认知的不确定性。</p>
<p>参数 $θ$ 的后验分布，即基于观测值 $O$ 的“合理”参数值的分布，由贝叶斯定理给出，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218205354.png" alt=""></p>
<p>其中 $p(\theta)$ 是参数的先验分布， $p(O)$ 是证据。通过(5)精确地获得后验值通常在计算和分析上是难以解决的。</p>
<p>UQ的目标是估计预测分布 $p(y |x,O)$ 。其中,  $\hat{y}$ 表示在 $x$ 预测并且在给定的观测 $O$ 上具有条件分布。它可以通过对模型参数 $\theta$ 积分得到，或者，如果难以计算，可以用蒙特卡罗估计进行近似，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218210144.png" alt=""></p>
<p>其中 $θ^{∗}_{i} \thicksim p(\theta|O)$ 为后验样本。</p>
<p>预测分布的均值可近似计算为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218212706.png" alt=""></p>
<p>预测分布的方差也可以近似计算。利用总方差定律，并假设分布 $p(y|x,\theta)$ 具有与(4)相同的均值和方差，我们有</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218212838.png" alt=""></p>
<p>(8)中的第一个和第二个总和分别表示总不确定性的任意部分和认识部分。</p>
<h4 id="Methods-for-Finding-the-Posterior-Distribution"><a href="#Methods-for-Finding-the-Posterior-Distribution" class="headerlink" title="Methods for Finding the Posterior Distribution"></a>Methods for Finding the Posterior Distribution</h4><p>最流行的后验逼近方法可分为两大类:抽样法和变分法。对于简化后的BNN，还有一种有效的封闭解，即丢弃隐层中的参数分布，只保留最后一层中的参数分布。我们将其称为神经线性模型(NLM)。</p>
<p>抽样方法。马尔可夫链蒙特卡罗方法利用 $p(\theta|O)$ 为平稳分布的马尔可夫链从后验中抽取参数样本。广泛使用的方法是哈密顿蒙特卡罗和朗之万动力学。这种方法的缺点是计算成本高。在本文中我们将不考虑它们。</p>
<p>变分方法。变分推理(VI)方法通过使用变分分布 $q_{w}(θ)$ 来近似 $p(\theta|O)$ ，该分布通过最大化证据下界来优化 $w$ 。流行的方法是反向传播贝叶斯(利用因式高斯变分分布)和蒙特卡洛Dropout (通过对每个样本随机降低固定百分比的参数来抽取样本)。</p>
<p>确切的方法。NLM 代表了可处理性和表达性之间的妥协。可以将NLM解释为学习到的特征基 $\Phi_{w} =[\phi_{w}(x_{1}),\cdots,\phi_{w}(x_{M})]^{T}$对其进行贝叶斯线性回归执行 $\Phi_{w}\theta$ 。我们将用 $r_{\theta}^{NLM}$ 表示用NLM训练的残差网络，以便与标准BNN区分开来。</p>
<h2 id="Uncertainty-Quantification-in-B-PINNs"><a href="#Uncertainty-Quantification-in-B-PINNs" class="headerlink" title="Uncertainty Quantification in B-PINNs"></a>Uncertainty Quantification in B-PINNs</h2><p>在前一节中，我们在一个集合术语 $O$ 下考虑了所有可观测信息。事实上，在PINN的背景下，这些观测包括各种来源：噪声和/或有限的数据，与控制物理方程的一致性，物理模型中的随机性，神经网络架构。我们将用 $\mathcal{D}$ 表示与数据相关的观测值，用 $\mathcal{P}$表示与方程相关的观测值，其余观测值统称为 $\mathcal{H}$ 。如前所述，我们的主要目标是研究具有固定DNN架构的无数据确定性情况，因此我们将专注于建模 $\mathcal{P}$ 对不确定性的影响。随后，可以将其纳入一般框架，从而得到预测分布 $p(u|x,\mathcal{D},\mathcal{P},\mathcal{H})$ 。这里， $u$ 表示DE解的概率预测。</p>
<p>据我们所知，与B-PINN相关的方程观测在文献中还没有被彻底研究过。其中一个原因可能是不可能完全理清不确定性的不同来源：</p>
<ul>
<li>$f$ 的观测值可以同时看作数据相关观测值 $\mathcal{D}$ 和方程相关观测值 $\mathcal{P}$ 。因此，由于不需要为 $\mathcal{P}$ 构造一个特殊的似然函数，这可能会模糊了在后面的推理阶段明确考虑 $\mathcal{P}$ 的重要性。</li>
<li>(8)中的总方差受任意不确定性影响不仅通过相应的项，而且通过认知项，预计会随着噪音的增加而增加。这就模糊了 $Var(\hat{u} |x,\mathcal{P})$ 中任意项 $\sigma_{\mathcal{P}}^{2}$ 正确建模的重要性。事实上，现有的B-PINN方法中没有这项，这可能导致不确定性估计不太可靠。</li>
</ul>
<h3 id="Existing-Approach"><a href="#Existing-Approach" class="headerlink" title="Existing Approach"></a>Existing Approach</h3><p>由于我们假设 $f$ 是完全已知的，并且没有噪声，我们可以考虑一个虚拟数据集 $\mathcal{D} = \{(x_{j},0)\}^{M}_{j=1}$，而相应的似然由</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219220719.png" alt=""></p>
<p>如果 $\sigma^{2}_{\mathcal{D}}$ 是未知的，可以估计，例如，通过分层建模。假设先验分布 $p(\theta)$ 为零均值和对角协方差矩阵的高斯分布。相应的方差，如果不知道，可以类似地推断 $\sigma^{2}_{\mathcal{D}}$ 。然后，在我们使用第2.3.1节的方法从后验中获得样本后，我们估计预测分布</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219221457.png" alt=""></p>
<p>由于我们处于无数据的情况下，(10)右边的分布的自然选择是</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219222626.png" alt=""></p>
<p>将(11)代入(8)产生如下式子，其中只有认知不确定性的项</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219222817.png" alt=""></p>
<p>虽然(12)中的预测方差通过 $\mathcal{D}$ 隐式地“告知”了底层DE，但它可能不足以覆盖训练区域之外的真实解，或者当B-PINN由于某种原因没有得到很好的训练时，如图1所示。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219225014.png" alt=""></p>
<p>当前方法的另一个缺点是它与 $r_{\theta}^{NLM}$ 不兼容。通过施加 $\mathcal{F}_{\lambda}[\Phi_{w}\theta]$ ，我们失去了推导封闭形式解的能力。</p>
<h3 id="Error-Aware-B-PINNs"><a href="#Error-Aware-B-PINNs" class="headerlink" title="Error-Aware B-PINNs"></a>Error-Aware B-PINNs</h3><p>在带BNN的经典函数逼近问题中，除非对函数类没有特定的假设，否则不能保证不确定性覆盖无数据区域的误差 $y−y_{\theta}$ 。与BNN不同，B-PINN在一定程度上意识到代理网络和真实解之间的差异。当然，这取决于对损失函数的选择，以及所选损失函数与代理网络所犯错误之间的联系。</p>
<p>在本节中，我们引入一个伪任意不确定性，量化 $u$ 和 $u_{\theta}$ 之间的差异。我们仍然称它为任意不确定性，因为它在经典贝叶斯框架中充当了任意不确定性的对应物。另一方面，它不是来自数据，而是来自PINN本身。</p>
<p>我们的目标是构造一个分布 $p(\hat{u}|x,\theta,\mathcal{P})$ ，其均值由 $u_{\theta}(x)$ 给出，伪任意方差由某个算子 $E$ 给出，该算子作用于预训练的PINN，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219230838.png" alt=""></p>
<p>其中 $r_{MSE}(x)$ 表示用MSE训练的PINN。显然，这不是一个简单的任务，它提出了如何构造 $E$ 以及如何找到PDE的适当功能形式的问题。在这一点上，我们能够在线性动力系统的特殊情况下用可证明的保证回答第一个问题(见第3.2.1节)。对于 $p(\hat{u}|x,\theta,\mathcal{P})$ 的泛函形式，我们考虑正态分布作为概念的证明。虽然它不代表真实解的概率，但它确保了在误差高的区域不确定性被夸大，并且真实解被不确定性覆盖。</p>
<p>误差感知情况下的预测方差为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219232152.png" alt=""></p>
<p>对于不属于第3.2.1节类别的DE，没有关于如何构造(13)的严格理论。可以考虑各种启发式方法，而最简单的方法是使用 $E[r_{MSE}(x)] = r_{MSE}(x)$ 或 $E[r_{MSE}(x_{n})] =\Sigma_{i=0}^{n} r_{MSE}(x_{i})$ 。我们在第3.2.2节中用一个非线性偏微分方程的例子来测试后者。</p>
<p>现在我们展示如何将我们的方法与rθNLM结合起来，这样封闭形式的解仍然存在。也就是说，我们的伪随机方差分布可以作为模拟数据 $\mathcal{D}_{\mathcal{P}}=\{(x_{j},u_{MSE}(x_{j}))\}^{M}_{j=1}$的似然函数，其中 $u_{MSE}$ 表示用MSE训练的代理网络，得到</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219235252.png" alt=""></p>
<p>如果与这种可能性结合使用， $r_{\theta}^{NLM}$ 提供了可处理的推断。注意 $\sigma^{2}_{\mathcal{P}}(x_{j})$ 现在是异方差的。只要具有异方差的贝叶斯线性回归模型不太常用，我们在这里给出了预测分布的显式形式，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219235653.png" alt=""></p>
<p>其中后验协方差矩阵和平均值是由</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221220000003.png" alt=""></p>
<p>我们在算法2中总结了我们的错误感知B-PINN的方法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221220001036.png" alt=""></p>
<h2 id="My-Summary"><a href="#My-Summary" class="headerlink" title="My Summary"></a>My Summary</h2><p>这篇文章使用B-PINN的相关做法来表达认知不确定性，使用PINN训练的结果来表达偶然不确定性。</p>
<h1 id="A-Dimension-Augmented-Physics-Informed-Neural-Network-DaPINN-with-High-Level-Accuracy-and-Efficiency"><a href="#A-Dimension-Augmented-Physics-Informed-Neural-Network-DaPINN-with-High-Level-Accuracy-and-Efficiency" class="headerlink" title="A Dimension-Augmented Physics-Informed Neural Network(DaPINN) with High Level Accuracy and Efficiency"></a>A Dimension-Augmented Physics-Informed Neural Network(DaPINN) with High Level Accuracy and Efficiency</h1><h2 id="Abstract-14"><a href="#Abstract-14" class="headerlink" title="Abstract"></a>Abstract</h2><p>在DaPINN模型中，我们在神经网络中引入了归纳偏差，通过在损失函数中添加一个特殊的正则化项来增强网络的泛化性。此外，我们通过插入额外的样本特征来操纵网络输入维度，并将扩展的维度合并到损失函数中。</p>
<h2 id="Introduction-18"><a href="#Introduction-18" class="headerlink" title="Introduction"></a>Introduction</h2><p>PINN的输入维数通常取决于方程变量的数量，这比自然语言处理和计算机视觉等其他领域的神经网络中的变量数量要低得多。网络的输入维数客观上影响着网络的准确性。例如，在卷积神经网络(CNN)中，图像分辨率的降低降低了模型性能。因此，输入维度可以通过在输入向量中插入更多的特征来增强PINN。</p>
<p>在这项工作中，我们提出了一种维数增强的PINN (DaPINN)，通过系统地操纵网络输入维数来提高PINN的准确性和效率，扩展维数由考虑偏导数的损失函数约束。DaPINN模型采用幂级数增广、傅立叶级数增广和复制增广等方法提高了求解精度。</p>
<h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><h3 id="Physics-informed-neural-networks-PINN"><a href="#Physics-informed-neural-networks-PINN" class="headerlink" title="Physics-informed neural networks (PINN)"></a>Physics-informed neural networks (PINN)</h3><p>PINN相关知识</p>
<h3 id="Dimension-augmentated-PINN"><a href="#Dimension-augmentated-PINN" class="headerlink" title="Dimension-augmentated PINN"></a>Dimension-augmentated PINN</h3><p>引入映射函数：<img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230211153611.png" alt=""></p>
<p>新的神经网络的输入维数为n，而PINN的输入维数只与x的大小相关。</p>
<p>DaPINN模型的损失函数中PDE的残差项和边界/初始误差可以重新表示为如下形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230211155200.png" alt=""></p>
<p>例如，对于一维拉普拉斯方程： $\Delta u(x)=0$ ，通过使用映射 $t_{1}:x \rightarrow x,t_{2}:x \rightarrow x^{2}$ 时，双输入神经网络可构造为 $\mathcal{N}(\tau_{1},\tau_{2})$ 。将微分方程的残差项可以很简单地表示为（根据复合函数求导得来）</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212144228.png" alt=""></p>
<h3 id="Several-input-dimension-augmentation-methods"><a href="#Several-input-dimension-augmentation-methods" class="headerlink" title="Several input dimension augmentation methods"></a>Several input dimension augmentation methods</h3><ol>
<li>Power series augmentation（幂级数增广）：这个想法是从函数的泰勒展开得来的</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212153208.png" alt=""></p>
<ol>
<li>Fourier series augmentation（傅里叶级数增广）：引入这样的映射 $t_{1}: x \rightarrow x, t_{2} : x \rightarrow sin(\frac{2 \pi nx}{T}),<br>t3 : x \rightarrow cos(\frac{2 \pi nx}{T})$ 。由于任何周期函数都可以写成三角函数的和，通过傅里叶级数的增广公式，可以用三角级数近似表示该函数。傅立叶级数增广法可用于具有周期性边界条件的问题。</li>
<li>Replica augmentation（复制增广）：引入映射 $t{1} : x \rightarrow x; t_{2} : x \rightarrow x  $ 。这种扩展方法引入了镜像输入，为网络逼近提供了多条路径，从而提高了模型的精度。</li>
</ol>
<h1 id="L-HYDRA-MULTI-HEAD-PHYSICS-INFORMED-NEURAL-NETWORKS"><a href="#L-HYDRA-MULTI-HEAD-PHYSICS-INFORMED-NEURAL-NETWORKS" class="headerlink" title="L-HYDRA: MULTI-HEAD PHYSICS-INFORMED NEURAL NETWORKS"></a>L-HYDRA: MULTI-HEAD PHYSICS-INFORMED NEURAL NETWORKS</h1><h2 id="Abstract-15"><a href="#Abstract-15" class="headerlink" title="Abstract."></a>Abstract.</h2><p>我们将多头神经网络(MH-NNs)引入到基于物理的机器学习中，它是一种以所有非线性隐藏层为主体，以多个线性输出层为多头的神经网络。因此，我们构建了多头物理神经网络(MH-PINNs)，作为多任务学习(MTL)、生成建模和科学机器学习(SciML)中各种问题的少镜头学习的有效工具。MH-PINNs通过共享主体作为基本功能和头部的共享分布连接多个功能/任务。前者通过MH-PINNs解决多个任务，每个头独立对应于每个任务，而后者通过采用归一化流(NFs)进行密度估计和生成建模。</p>
<h2 id="Introduction-19"><a href="#Introduction-19" class="headerlink" title="Introduction."></a>Introduction.</h2><p>一些相关背景知识。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212155919.png" alt=""></p>
<h2 id="Methodology-7"><a href="#Methodology-7" class="headerlink" title="Methodology."></a>Methodology.</h2><p>在本文中，我们将 $\{ \mathcal{T_{k}} \}_{k=1}^{M}$ 作为一个整体，并将它们与MH-PINNs连接起来，在解决方案 $u_{k}$ 上强制执行基函数共享预测。除了信息表示/主体，我们进一步将 $\{ \mathcal{T_{k}} \}_{k=1}^{M}$ 联系起来，假设它们在MH-PINNs中对应的头部，记为 $\{ H_{k} \}_{k=1}^{M}$ ，分别是具有未知概率密度函数(PDF)的随机变量的样本，记为 $H$ 和 $P(H)$ 。通过将 $u$ 代入和自动微分，共享体和 $H$ 的生成模型立即形成解 $u$ 的生成模型，同时生成源项 $f$ 和边界/初始项 $b$ 的生成项，由此无缝地发展了随机过程近似的生成方法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212163209.png" alt=""></p>
<p>主体表示从MH-PINNs求解 $\{ \mathcal{T_{k}} \}_{k=1}^{M}$ 中学习到的基函数集，头部的密度使用NFs从其样本中估计出来，与主体一起作为正则化、先验分布或生成器，这取决于MH-PINNs在应用中的使用情况。</p>
<h3 id="Multi-head-physics-informed-neural-networks-MH-PINNs"><a href="#Multi-head-physics-informed-neural-networks-MH-PINNs" class="headerlink" title="Multi-head physics-informed neural networks (MH-PINNs)."></a>Multi-head physics-informed neural networks (MH-PINNs).</h3><p>我们用 $\Phi$ 表示主体，用 $H_{k}$ 表示 $\mathcal{T}_{k}$ 的头部。注意这里 $\Phi: \mathbb{R}^{D_{x}} \rightarrow \mathbb{R}^{L}$ 是一个参数为 $\theta$ 的神经网络参数化的函数， $H_{k} \in \mathbb{R}^{L+1}$ 是一个向量，其中 $L$ 是主体最后一层神经元的数量。让我们定义 $H_{k} = [h^{0}_{k},h^{1}_{k},\cdots,h^{L}_{k}]^{T}$ ， $\Phi(x) = [\phi^{1}(x),\cdots,\phi^{L}(x)]^{T}$ ，其中 $\phi : \mathbb{R}^{D_{x}} \rightarrow \mathbb{R}$ ，则 $\mathcal{T}_{k}$ 中解的代入式可改写为 $\hat{u}_{k}(x)=h_{k}^{0}+\sum_{l=1}^{L}h_{k}^{l}\phi^{l}(x),\forall x \in \Omega$ 。</p>
<h3 id="Generative-modeling-and-normalizing-flows-NFs"><a href="#Generative-modeling-and-normalizing-flows-NFs" class="headerlink" title="Generative modeling and normalizing flows (NFs)."></a>Generative modeling and normalizing flows (NFs).</h3><p>MH-PINNs通过两个假设连接 $\{ \mathcal{T}_{k} \}_{k=1}^{M}$ ：(1)解 $u_{k},k=1,\cdots,M$ 共享同一组基函数， $\Phi$ (2)对应系数为同一随机变量 $H$ 的样本。在这项工作中，我们通过利用来自头部的信息，以及通过估计PDF和来自其样本的 $H$ 的生成器 $\{ H_{k} \}_{k=1}^{M}$ ，使用归一化流来扩展它(NFs)。我们选择NFs而不是其他常用的生成模型，例如生成对抗网络(GANs)，变分自动编码器(VAE)，或扩散模型，因为NF既可以作为密度估计器，也可以作为生成器。前者能够在下游的少量物理信息学习任务中提供适当的正则化，而后者则导致了一种物理信息生成方法来逼近随机过程。我们的模型通过头部的样本进行学习，这是第一步从MTL中获得的。这种学习策略带来了两个巨大的优势：(1)处理非结构化数据的灵活性，例如跨任务的不一致测量；(2)通过将物理知识学习和生成建模分离，实现训练的简单性和可控性。</p>
<h3 id="Prior-knowledge-utilized-in-the-downstream-tasks"><a href="#Prior-knowledge-utilized-in-the-downstream-tasks" class="headerlink" title="Prior knowledge utilized in the downstream tasks."></a>Prior knowledge utilized in the downstream tasks.</h3><p>在这里，我们详细描述了如何利用MH-PINNs中存储的先验知识，用于下游的少量物理知识学习任务 $\tilde{\\ \mathcal{T} \\}$ ，它的定义与上游训练中的所有其他任务相同，但测量量要少得多。训练MH-PINNs和NFs得到一个主体 $\Phi$ ，头部样本 $\{ H_{k} \}_{k=1}^{M}$ ，以及对头部的估计 $\hat{p}(H)=p(H)$ 。在用 $\tilde{\mathcal{D}}$ 求解 $\tilde{\\ \mathcal{T} \\}$ 时，我们固定了主体 $\Phi$ ，找到了头部 $\tilde{H}$ 最好地解释了数据 $\tilde{\mathcal{D}}$ 和物理知识。</p>
<p>本文考虑了无噪声数据和有噪声数据：对于无噪声数据，针对新任务对头部进行常规NN训练，以提供确定性预测，其中学习到的头部PDF $\hat{p}(H)$ 作为损失函数中的正则化项；对于有噪声的数据，贝叶斯推理也在头部进行，其中 $\hat{p}(H)$ 表示先验分布。</p>
<h4 id="Regularization-in-optimization"><a href="#Regularization-in-optimization" class="headerlink" title="Regularization in optimization."></a>Regularization in optimization.</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212201155.png" alt=""></p>
<h4 id="Prior-distribution-in-Bayesian-inference"><a href="#Prior-distribution-in-Bayesian-inference" class="headerlink" title="Prior distribution in Bayesian inference."></a>Prior distribution in Bayesian inference.</h4><p>与通过求解优化问题(2.4)得到的点估计不同，头部在 $\tilde{\\ \mathcal{T} \\}$ 的后验分布是通过贝叶斯推理得到的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212202332.png" alt=""></p>
<h2 id="My-Summary-1"><a href="#My-Summary-1" class="headerlink" title="My Summary"></a>My Summary</h2><p>文章整体思路有点类似神经算子的思路。用了类似DeepONet中的方式，提取出基函数，对于训练数据 $x \in \mathbb{R}^{D}$ ，训练神经网络得到维度为 $L$ 的body向量 $\Phi(x)$ ；同时对于每一个任务，我们采样维度为 $L+1$ 的head向量 $H_{k}$ ，通过这些向量我们可以推测出head向量的密度分布。对于每个任务，我们想要的解就是 $\hat{u}_{k}(x)=h_{k}^{0}+\sum_{l=1}^{L}h_{k}^{l}\phi^{l}(x)$ ，然后使用这个解正常进行PINN的损失函数构建训练即可。对于新的任务来说，我们前面已经训练好了body向量 $\Phi(x)$ 并且得到了head向量的密度分布，如果此时的训练数据是无噪声的，我们就可以训练一个NN来获得最优的 $H^{\star}$ ；如果训练数据是带噪声的，则通过贝叶斯推断来获取 $H^{\star}$ 。既然我们得到了新任务的body向量和head向量，则新任务的 $u(x)$ 也可以得到。</p>
<h1 id="LSA-PINN-Linear-Boundary-Connectivity-Loss-for-Solving-PDEs-on-Complex-Geometry"><a href="#LSA-PINN-Linear-Boundary-Connectivity-Loss-for-Solving-PDEs-on-Complex-Geometry" class="headerlink" title="LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex Geometry"></a>LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex Geometry</h1><h2 id="Abstract-16"><a href="#Abstract-16" class="headerlink" title="Abstract"></a>Abstract</h2><p>现有版本的PINN被认为在许多问题上学习能力很差，特别是对于复杂的几何图形。如果样本过于稀疏，现有PINN容易过拟合近边界区域，导致不正确的解。为了防止这样的问题，我们提出了一个新的边界连接(BCXN)损失函数，它提供了线性局部结构近似(LSA)对PINN边界梯度行为的影响。</p>
<h2 id="Introduction-20"><a href="#Introduction-20" class="headerlink" title="Introduction"></a>Introduction</h2><p>现有PINN通过自动微分(AD)或数值微分(ND)类型的方法来评估训练损失中的PDE约束。最近的研究表明，ND型方法，特别是耦合自动数值微分(CAN)-loss可以在训练样本更少的情况下更健壮有效地生成准确的解，而传统的AD-loss在训练过程中容易失败。这是因为ND型方法使用来自邻近样本的PINN输出来近似高阶导数，因此，它们可以通过这些局部近似有效地将稀疏样本连接到分段区域，从而促进在整个范围内使用更稀疏样本的快速物理知识学习。</p>
<p>在处理不规则几何图形时，现有PINN很难将域内部的训练样本完美地连接到边界。如果不这样做，可能会导致意想不到的训练失败，因为PINN开始在近边界区域过拟合。由于许多具有实际意义的偏微分方程是边值问题，因此最好有PINN为正确的边界行为建模。</p>
<p>这种新的边界连通性(BCXN)损失函数是一种新型LSA-PINN方法的关键，它可以更有效地学习具有稀疏训练样本的偏微分方程的解，而不考虑域几何结构。此外，该方法可以与其他PINN在优化方面的进展联合实现，如损失平衡、区域分解和自适应采样。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230213101414.png" alt=""></p>
<h2 id="Related-Work-1"><a href="#Related-Work-1" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Efficient-sampling-in-PINNs"><a href="#Efficient-sampling-in-PINNs" class="headerlink" title="Efficient sampling in PINNs."></a>Efficient sampling in PINNs.</h3><p>一些研究集中在有效的抽样策略，如重要抽样，自适应抽样和顺序抽样，以减少PINN训练所需的训练样本数量。域分解和并行化策略也被用于加速PINN的训练。我们的LSA-PINN与这些工作的不同之处在于，我们通过新提出的BCXN-loss使基于物理的学习在稀疏样本体系中更加健壮。</p>
<h3 id="CNN-architecture-and-numerical-differentiation-ND-type-loss-for-PINNs"><a href="#CNN-architecture-and-numerical-differentiation-ND-type-loss-for-PINNs" class="headerlink" title="CNN architecture and numerical differentiation (ND)-type loss for PINNs."></a>CNN architecture and numerical differentiation (ND)-type loss for PINNs.</h3><p>为了更好地处理不规则域，以CNN为基础的形式可能需要执行繁琐的坐标转换。我们的方法进一步提高了ND型损失在不规则几何上的算法的效率和适用性。</p>
<h3 id="Enforcing-BC-constraint-in-PINN-loss"><a href="#Enforcing-BC-constraint-in-PINN-loss" class="headerlink" title="Enforcing BC constraint in PINN loss."></a>Enforcing BC constraint in PINN loss.</h3><p>通常采用惩罚法将BCs作为软约束施加到PINN损失中。在此背景下，研究了各种策略来动态校准PDE和BC约束之间的相对重要性PINN训练。（动态加权方式）</p>
<p>还有其他方法可以绕过损失平衡问题。例如，可以设计一个ansatz函数，使BC完全满足构造，或隐式地将BC约束表述为PDE损失，只留下单个损失项PDE残差有待优化。（硬约束方式）</p>
<p>另一个例子是使用增广拉格朗日方法将BC约束施加到PINN损耗中。</p>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>一些相关的背景知识</p>
<h2 id="Method-2"><a href="#Method-2" class="headerlink" title="Method"></a>Method</h2><h3 id="Enforcing-linear-constraint-at-near-boundary-samples"><a href="#Enforcing-linear-constraint-at-near-boundary-samples" class="headerlink" title="Enforcing linear constraint at near-boundary samples"></a>Enforcing linear constraint at near-boundary samples</h3><p>这里我们将近边界样本的外部(域外)模板表示为ES点。在域内边界点P和选定的镜像点Q处定义边界条件 $\vec{u}_{BC}$ 和场值 $\vec{u}_{MI}$ ，在ES点A处的场值 $\vec{u}_{ES}$ 为待定值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302131715182.png" alt=""></p>
<p>通过对点A和点Q沿 $\overline{AQ}$ 相对于局部坐标n(曲面法线方向)对点P进行泰勒级数展开，可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230213161638.png" alt=""></p>
<p>其中 $\overline{AP}$ 和 $\overline{PQ}$ 是A和P之间以及P和Q之间的距离， $\overline{AQ}=\overline{AP}+\overline{PQ}$。则A点的场值 $\vec{u}_{ES}$ 可导出为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230213161939.png" alt=""></p>
<p>由上式可知 $\vec{u}_{ES}$ 受 $\vec{u}_{BC}$ 和 $\vec{u}_{MI}$ 的线性约束。镜点Q可以方便地选择在模具中心，即近边界的样本位置，但我们选择沿边界P法线方向的镜点Q，因为它更通用，在我们的实验中表现更好。因此， $\overline{AP}=\overline{PQ}$ ，式(4)为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302131656136.png" alt=""></p>
<p>类似的过程可以应用于推导Neumann-型和Robin-型边界条件的相应线性约束。</p>
<h3 id="Boundary-connectivity-BCXN-loss-with-direct-forcing"><a href="#Boundary-connectivity-BCXN-loss-with-direct-forcing" class="headerlink" title="Boundary connectivity (BCXN)-loss with direct forcing"></a>Boundary connectivity (BCXN)-loss with direct forcing</h3><p>我们可以直接应用式(5)计算在ND型格式下近边界样本PDE约束评估时，任意外部模板点的场值 $\vec{u}_{ES}$ 。这种直接强迫方法与数值计算中的直接强迫浸没边界方法有关。</p>
<p>然后我们可以使用以下BCXN-loss：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302131924672.png" alt=""></p>
<p>作为我们的LSA-PINN的PDE损失项，其中近边界样本上的PDE约束由局部线性约束调制。在这种实现中，BC被隐式地注入到训练损失中，避免了BC损失项。</p>
<h3 id="Procedure-to-evaluate-the-field-value-vec-u-MI-at-mirror-point"><a href="#Procedure-to-evaluate-the-field-value-vec-u-MI-at-mirror-point" class="headerlink" title="Procedure to evaluate the field value $\vec{u}_{MI}$ at mirror point"></a>Procedure to evaluate the field value $\vec{u}_{MI}$ at mirror point</h3><p>我们首先描述计算镜像点位置(法线方向)的步骤：</p>
<ol>
<li><p>如何确定模板是否为外部模板？</p>
<p>在本研究中，我们首先构造了目标几何结构的水平集函数 $\phi$ ，其中可以找到模板点A到边界点P之间的最短距离 $\overline{AP}$ 。从水平集函数的符号，我们可以判断一个模具是否是外部的。</p>
</li>
<li><p>如何计算外部模板的镜像点位置？</p>
<p>一旦 $\overline{AP}$ 确定，我们计算镜像点Q在流体域内的位置，其中满足 $\overline{AP}=\overline{PQ}$。</p>
</li>
</ol>
<p>在实践中，给定一组固定的训练样本，可以预先计算出所有外部模板点及其镜像位置。另一方面，镜像点上的字段值 $\vec{u}_{MI}$ 取决于LSA-PINN的输出，并在训练迭代中评估：</p>
<ol>
<li><p>针对MLP模型</p>
<p>通过在镜像点处求 $\vec{u}_{MI}(\vec{x},w)$ ，可以直接得到 $\vec{u}_{MI}$ 值。</p>
</li>
<li><p>针对CNN模型</p>
<p>当镜像点位置与CNN网格不重合时，可以利用以下反距离加权插值函数得到镜像点处 $\vec{u}_{MI}$ 值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302132056756.png" alt=""></p>
</li>
</ol>
<h1 id="DMIS-Dynamic-Mesh-based-Importance-Sampling-for-Training-Physics-Informed-Neural-Networks"><a href="#DMIS-Dynamic-Mesh-based-Importance-Sampling-for-Training-Physics-Informed-Neural-Networks" class="headerlink" title="DMIS: Dynamic Mesh-based Importance Sampling for Training Physics-Informed Neural Networks"></a>DMIS: Dynamic Mesh-based Importance Sampling for Training Physics-Informed Neural Networks</h1><h2 id="Abstract-17"><a href="#Abstract-17" class="headerlink" title="Abstract"></a>Abstract</h2><p>DMIS是一种基于重要性抽样的新型抽样方案，它构造一个动态三角网格来有效估计样本权重。</p>
<h2 id="Introduction-21"><a href="#Introduction-21" class="headerlink" title="Introduction"></a>Introduction</h2><p>虽然经典数值算法极大地促进了相关领域的发展，但这些算法计算成本高，在多物理场和多尺度系统中面临严峻的挑战。随着数据采集能力的提高，如何利用数据进行模拟结果的修改成为一个重要问题。一般来说，数据同化是经典数值算法与观测数据结合的主要方法，但数据同化会引入额外的不确定性，严重影响收敛。</p>
<p>实践表明，PINN可用于求解不同类型的偏微分方程，包括整数阶偏微分方程、分数阶偏微分方程和随机偏微分方程。</p>
<p>PINN的三个主流改进方向：损失项权重、并行计算和采样。</p>
<p>在本文中，我们提出了一种新的抽样方案，称为基于动态网格的重要性抽样(DMIS)，在不显著增加计算成本的情况下加快收敛速度。为了从理论上保证抽样方法的正确性，在DMIS中引入了重要抽样的概念。但是，重要性抽样需要计算每个点的抽样概率，计算成本很高。为了降低计算成本，我们提出了一种新的采样权值估计方法，称为基于动态网格的权值估计(DMWE)，该方法构造一个动态三角网格，有效地估计每个数据点的权重。DMWE构造的网格在训练过程中根据整个域的损耗分布进行动态更新。</p>
<h2 id="Related-Work-2"><a href="#Related-Work-2" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Physics-Informed-Neural-Networks-2"><a href="#Physics-Informed-Neural-Networks-2" class="headerlink" title="Physics-Informed Neural Networks"></a>Physics-Informed Neural Networks</h3><p>PINN相关介绍</p>
<h3 id="Importance-Sampling"><a href="#Importance-Sampling" class="headerlink" title="Importance Sampling"></a>Importance Sampling</h3><p>重要抽样是加速蒙特卡罗积分的一种有效方法，已被应用于训练神经网络。从理论上证明，如果小批按照唯一的分布进行抽样，即每个点的抽样概率与损失梯度的2范数与参数成正比，则SGD具有最快的收敛速度。</p>
<h2 id="Optimization-Problem-of-PINNs"><a href="#Optimization-Problem-of-PINNs" class="headerlink" title="Optimization Problem of PINNs"></a>Optimization Problem of PINNs</h2><p>把PINN看成是优化问题，从而对PINN进行重述</p>
<h2 id="Method-3"><a href="#Method-3" class="headerlink" title="Method"></a>Method</h2><h3 id="Importance-Sampling-for-PINNs"><a href="#Importance-Sampling-for-PINNs" class="headerlink" title="Importance Sampling for PINNs"></a>Importance Sampling for PINNs</h3><p>基于重要性抽样的理论完备性和小批量抽样的不可忽略性，我们设计了一种基于重要性抽样的小批量抽样方法，以提高PINN的收敛速度和模型精度。根据蒙特卡罗近似，我们可以引入一种更有效的采样方法。由于边界条件和初始条件都是惩罚项，所以我们只在对 $N_{f}$ 的抽样中引入了重要性抽样。PDE残差 $L_{f}$ 结合重要性抽样的损失为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302212130293.png" alt=""></p>
<p>其中 $\alpha_{i}$、 $p_{i}$ 和 $q_{i}$ 分别为数据点 $x_{i}$ 的样本权值、抽样概率和备选抽样概率。考虑到小批量一般是通过均匀采样获得的，所以 $p_{i}$ 等于 $\frac{1}{N_{f}}$</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221930860.png" alt=""></p>
<h3 id="Simplified-Calculation-amp-Reweighting"><a href="#Simplified-Calculation-amp-Reweighting" class="headerlink" title="Simplified Calculation &amp; Reweighting"></a>Simplified Calculation &amp; Reweighting</h3><p>配点的最佳采样概率由 $q^{\star} \propto ||\triangledown_{\theta}l(x,\theta)||_{2}$ 决定。然而，这种理论最优采样方法的计算成本是不可接受的，有必要寻找替代方法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221935195.png" alt=""></p>
<p>因此，式(8)是一个合理的近似。但是，我们发现由式(8)计算的样本权值在初始阶段会导致训练不稳定。这一问题是由于数据点损耗大，导致局部梯度急剧。为了解决这个问题，我们引入了一个超参数 $\beta$ 来调整 $\alpha$ 。对于 $\beta &gt; 1$ ，对损失大的数据点施加更大的惩罚，结果记为 $\alpha^{‘}$ ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221938520.png" alt=""></p>
<h3 id="DMWE"><a href="#DMWE" class="headerlink" title="DMWE"></a>DMWE</h3><p>由于式(8)降低了每个数据点的计算成本，采样概率仍然需要逐点计算，这对于求解复杂的偏微分方程是一个巨大的负担。为了进一步降低计算成本，我们提出了基于动态网格的权重估计(DMWE)，通过插值来计算样本权重。</p>
<p>在DMWE中，采用了基于Delaunay三角剖分的插值方法。具体来说，我们从 $N_{f}$ 动态生成一个子集S来构造一个三角形网格。DMWE只精确地计算了S中点的样本权值，其他点的权值通过插值得到。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221943064.png" alt=""></p>
<p>基于Delaunay的插值算法耗时较长，且无需在每个迭代步骤中更新三角网格。因此，我们引入基于余弦相似度的评估方法来决定是否重新选择S并重建三角形网格。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221945395.png" alt=""></p>
<h1 id="Transfer-Learning-Enhanced-DeepONet-for-Long-Time-Prediction-of-Evolution-Equations"><a href="#Transfer-Learning-Enhanced-DeepONet-for-Long-Time-Prediction-of-Evolution-Equations" class="headerlink" title="Transfer Learning Enhanced DeepONet for Long-Time Prediction of Evolution Equations"></a>Transfer Learning Enhanced DeepONet for Long-Time Prediction of Evolution Equations</h1><h2 id="Abstract-18"><a href="#Abstract-18" class="headerlink" title="Abstract"></a>Abstract</h2><p>深度算子网络(DeepONet)在各种学习任务中取得了巨大的成功，包括学习偏微分方程的解算子。特别地，它提供了一种在有限时间范围内预测演化方程的有效方法。然而，普通的DeepONet在长期预测中存在稳定性退化的问题。本文提出了一种迁移学习辅助方法增强DeepONet的稳定性。我们的想法是使用迁移学习来按顺序更新DeepONet，作为在不同时间框架中学习的传播体的替代品。进化中的DeepONet可以更好地跟踪进化方程的不同复杂性，而只需要通过对一小部分操作网络进行有效训练来进行更新。通过系统实验，我们证明了该方法不仅提高了DeepONet的长期精度，同时保持了相似的计算成本，而且大幅减少了训练集的样本量。</p>
<h2 id="Introduction-22"><a href="#Introduction-22" class="headerlink" title="Introduction"></a>Introduction</h2><p>利用深度学习方法求解偏微分方程近年来受到广泛关注。由于神经网络的万能逼近定理，用神经网络来近似偏微分方程的解是很自然的。最近提出了许多流行的基于神经网络的方法，如Deep Ritz Method，Deep Galerkin Method，Physics Informed Neural Networks(PINNs) 和弱对抗网络(Zang et al. 2020)。尽管这些方法在求解各种偏微分方程方面取得了巨大成功，但如果要为同一偏微分方程寻找对应于不同初始条件(IC)、边界条件(BC)或参数的解，则需要重新训练神经网络。相反，最近提出的参数算子学习方法，如DeepONet和FNO可以在不重新训练网络的情况下学习不同BC或IC对应的PDE。然而，在前面提到的算子神经网络中有一个重要的限制。也就是说，它们本质上是监督学习，通常需要求解大量的偏微分方程来形成训练数据，这可能是非常广泛的，特别是当感兴趣的偏微分方程位于高维空间时。为了克服这个问题，Wang等人提出了物理信息的DeepONet，它只使用物理信息(例如PDE的支配律)来构建损失函数，从而使DeepONet自监督。然而，在实践中，物理信息DeepONet与普通版本相比更难训练，因为精确的微分算子作用于网络，并使收敛行为高度依赖于潜在的物理问题。</p>
<p>最近DeepONet也被应用于进化方程的传播子的学习。基本思想是使用DeepONets在短时间间隔内学习PDE的解算符，这取决于(随机)初始条件的集合。PDE在以后的时间的解可以计算为训练有素的网络算子的递归动作在先前的步骤中获得的解决方案。然而，从长远来看，至少有两个原因会导致解的近似精度下降。首先，由于近似误差的存在，经过训练的DeepONet作为代理传播器，即使精确传播器是非可膨胀的，也可能是可膨胀的，这导致了近似误差在时间上的累积，从而难以长期预测解。其次，在偏微分方程的时间演化过程中，传播器输入和输出的函数可以随时间变化，即使在固定时隙内传播器的形式可能保持不变(例如，当动态是自主的)。以扩散方程为例，我们观察到传播子或半群的范围空间中的函数比定义域中的函数平滑得多，因此，后一时刻的解比前一时刻的解越来越正则。此外，一些演化方程可能在较长的时间范围内发展出各种复杂性，如湍流和尺度分离。对于这些方程，迭代通常只在单一(短)时间框架内使用有限初始函数集合训练的DeepONet代理可能无法在长时间内捕获正确的正则性或解的复杂性。</p>
<p>迁移学习是一类重要的机器学习技术，它将一个用于某一任务的神经网络用于另一个用于不同相关任务的新神经网络。其思想是，通过训练前一种神经网络获得的某个问题的知识或重要特征可以转移到其他问题上。迁移学习已广泛应用于图像识别，以及最近的。据我们所知，目前的工作是第一个将迁移学习应用于进化偏微分方程的学习解算子的工作。</p>
<h3 id="Related-works-1"><a href="#Related-works-1" class="headerlink" title="Related works"></a>Related works</h3><p>迁移学习之前已经与物理神经网络相结合，用于解决来自不同领域的偏微分方程问题，包括裂缝的相场建模，湍流的超分辨率，多保真数据上的CNN训练(例如细网格和粗网格上偏微分方程解的多分辨率图像)等。迁移学习也被应用于复杂几何上定义的pde的学习解的领域适应方法。最近的论文提出了一种一次性迁移学习策略，该策略冻结了预训练PINN的隐藏层，并将用于求解新微分方程的训练神经网络减少到仅优化最后一层(线性)。这种方法消除了重新训练整个网络参数的需要，同时仍然通过在最后一层调整一小部分参数来产生高质量的解决方案。本文将这种迁移学习思想与DeepONet相结合，学习进化方程的传播子，以预测长时间进化。</p>
<p>虽然我们正在完成当前的论文，但我们注意到最近的预印本，其中迁移学习与DeepONet一起用于在条件移位下学习PDE。其目的是用一个源域的足够标记数据训练一个源PDE模型，并将学习到的参数转移到一个标记数据有限的目标域。这里开发的技术主要用于将在PDE系统上受过训练的解决方案算子的知识从一个领域转移到另一个领域。与其不同的是，我们利用迁移学习来连续调优通过物理感知的DeepONet学习的传播体代理模型，以便调优的算子网络可以自适应地跟踪携带进化输入和输出的进化传播体。实验证明，该方法对于学习偏微分方程的长期演化具有更高的准确性和鲁棒性。</p>
<h2 id="Numerical-method"><a href="#Numerical-method" class="headerlink" title="Numerical method"></a>Numerical method</h2><p>考虑一般进化方程的初边值问题：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032014921.png" alt=""></p>
<p>在整个论文中，我们假设方程在 $\int_{\Omega_{x}}f\mathcal{L}fdx\leq 0$ 的意义上是耗散的。给定时间步长 $\Delta t$ ，我们考虑解 $f(n\Delta t,x)$ 的半离散近似 $f^{n}(x)$ 由向后定义欧拉离散化：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032028309.png" alt=""></p>
<p>我们的目标是近似传播子</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032029896.png" alt=""></p>
<p>通过算子神经网络 $\mathcal{P}_{NN}$ ，使神经网络只有一次向前传递才能实现从一个步骤到下一个步骤的时间推进解决方案，并且可以在很长的时间范围内捕获进化动态。需要指出的是，向后欧拉格式并不是时间行进的唯一选择。人们可以将其扩展到高阶时间离散化方案，如RungeKutta方法，只要选择 $\Delta t$ ，使得 $\mathcal{P}^{\Delta t}$ 是非展开算子。</p>
<h3 id="Physics-informed-DeepONet"><a href="#Physics-informed-DeepONet" class="headerlink" title="Physics-informed DeepONet"></a>Physics-informed DeepONet</h3><p>DeepONet中输出的形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032100151.png" alt=""></p>
<p>整个网络的loss：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032100790.png" alt=""></p>
<p>训练数据是一对对样本，获取代价太大，于是使用physics-informed DeepONet：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032101711.png" alt=""></p>
<h3 id="DeepONet-with-transfer-learning"><a href="#DeepONet-with-transfer-learning" class="headerlink" title="DeepONet with transfer learning"></a>DeepONet with transfer learning</h3><p>迁移学习的主要思想是在大数据集上训练神经网络，然后部分冻结并将其应用于相关但不可见的任务。我们使用迁移学习技术在预测步骤中依次纠正训练好的DeepONet：我们冻结大部分训练良好的DeepONet，仅通过拟合底层定义的相同物理信息损失(4)来重新训练分支网络最后一个隐藏层的权重PDE。</p>
<h2 id="Theoretical-result"><a href="#Theoretical-result" class="headerlink" title="Theoretical result"></a>Theoretical result</h2><p>理论方面的证明</p>
<h2 id="Numerical-experiments"><a href="#Numerical-experiments" class="headerlink" title="Numerical experiments"></a>Numerical experiments</h2><p>Reaction diffusion equation、Allen-Cahn and Cahn-Hilliard equations、Allen-Cahn and Cahn-Hilliard equations和Multiscale linear radiative transfer equation做了实验</p>
<h1 id="Theory-guided-physics-informed-neural-networks-for-boundary-layer-problems-with-singular-perturbation"><a href="#Theory-guided-physics-informed-neural-networks-for-boundary-layer-problems-with-singular-perturbation" class="headerlink" title="Theory-guided physics-informed neural networks for boundary layer problems with singular perturbation"></a>Theory-guided physics-informed neural networks for boundary layer problems with singular perturbation</h1><h2 id="Abstract-19"><a href="#Abstract-19" class="headerlink" title="Abstract"></a>Abstract</h2><p>PINNs尽管发展很快，但是大梯度和高度非线性特征仍然具有很大的挑战。薄边界层问题是大梯度的突出例子，通常出现在传输问题。通过将薄边界层问题看成是奇异摄动问题，本文提出了BL-PINNs。定义了不同的并行PINN网络来表示内部和外部区域边界层问题的不同近似阶数。在不同的基准问题（正问题和逆问题）中，BL-PINN表现出优于传统PINN方法的性能，能够得到准确的结果，而经典PINN方法无法提供有意义的解决方案。与其他扩展PINN(XPINN)方法相比，BL-PINN也显示出明显更好的结果。BL-PINN中扰动参数的自然结合提供了评估参数解的机会，而不需要重新训练。BL-PINN演示了如何使用经典数学理论来指导深度神经网络的设计，以解决具有挑战性的问题。</p>
<h2 id="Introduction-23"><a href="#Introduction-23" class="headerlink" title="Introduction"></a>Introduction</h2><p>大梯度薄边界层是高雷诺数流动和高Peclet数传热/传质的共同特征。湍流边界层的减阻气动问题、冷却边界层的对流换热问题和浓度边界层的生物输运问题是几个重要的例子。普朗特在20世纪初提出的边界层理论引发了过去这一领域的持续研究120年了。由于薄边界层固有的大梯度，对它的建模在计算上具有挑战性。在动量输运分析中，薄边界层在实践中通常是湍流的，因此在数值上建模昂贵。在热和质量传输中，由于扩散系数的降低，薄边界层也可以出现在层流区。例如，由于生物化学物质在血液中的扩散系数非常小，心血管质量运输问题的浓度边界层非常薄，这使得数值模拟非常具有挑战性。</p>
<p>近年来，数据驱动建模和科学机器学习方法在流体流动和输运建模方面引起了相当大的兴趣。也许最早的关于边界层的工作是由Thwaites在1949年的论文中，通过使用一系列可用的实验和分析结果来拟合动量积分方程中的一项，从而找到了边界层动量积分方程的解，并实现了封闭形式的解析解。Thwaites的相关方法是流体力学和边界层中数据驱动和基于物理的混合建模的早期例子。</p>
<p>基于物理的神经网络(PINN)是科学机器学习中的一个热门话题，它可以在深度学习设置中实现基于物理和数据驱动的混合建模。PINN已应用于各种流体力学和热传导问题。然而，PINN在某些问题中的鲁棒性仍然是一个问题。PINN在复杂和高度非线性的流型中精度有限，如湍流、涡结构和边界层。开发健壮可靠的模型已被确定为科学机器学习研究的优先事项。边界层是挑战PINN鲁棒性的课题之一。在现有的PINN模型中，当边界层厚度足够减小后（如扩散系数减小），PINN会出现收敛问题。这种难度也给DeepONet等算子学习方法带来了挑战，它们可能无法学习所有参数解中的参数变化，因此鲁棒性将难以实现。</p>
<p>在过去的几年中，人们提出了原始PINN方法的各种变体，试图克服某些PINN限制。在PINN中使用傅立叶特征网络，以克服深度神经网络中的频谱偏差，这限制了高频函数的学习效果。保守PINN (cPINN)，扩展PINN (XPINN)和其他类似的域分解技术已经被提出，以利用高梯度或复杂模式区域的局部神经网络来实现复杂函数的有效学习。另外，其他方法使用了对高梯度区域附近的搭配点或训练点进行增强的局部采样来提高收敛性。然而，这些技术都没有研究薄边界层。我们证明，不经过特殊处理的域分解不能解决学习薄边界层的问题，因为薄边界层具有高度局域化的突变行为。此外，我们还表明，增加边界层内搭配点的分辨率并不能解决PINN训练问题。PINN已应用于各种平流-扩散输运问题，包括边界层。这些研究研究了损失项的最佳加权，主要集中在低Peclet数上，以解决这些具有挑战性的问题。然而，薄边界层（粘度/扩散系数消失的极限）仍然是PINN难以捉摸的目标。</p>
<p>在本文中，我们提出了一种理论指导和模型驱动的机器学习方法来学习薄边界层行为。我们的框架受到求解微分方程的奇异摄动和渐近展开方法的启发。奇异摄动理论是应用数学中公认的方法，它的许多发展都受到流体动力学社区的启发。在奇异摄动问题中，一个小的摄动参数（例如，动量传输中的粘度或热/质量传输中的扩散率）乘以最高阶导数。问题的奇异性质使得系统在微扰消失极限下的行为与微扰参数的零值非常不同。在这样的问题中会产生一个非常薄的边界层，由此导致的解中的突变甚至很难用传统的和已建立的数值技术来解决，如有限元方法。奇异摄动解是为这种情况量身定做的，因为随着边界层变薄和梯度增加，它们实际上变得越来越准确。例如，Galerkin投影中使用了这种渐近基函数作为基函数，以便准确地捕捉和表示这种解中固有的奇异行为。受摄动理论及其在投影方法中作为渐近基函数的启发，我们提出了边界层物理信息神经网络(BL-PINN)来克服目前深度学习在解决薄边界层方面的局限性。也就是说，通过渐近展开的透镜，我们的BL-PINN方法可以被视为PINN驱动的降阶模型(ROM)，其中与传统ROM模型（例如，适当的正交分解或动态模式分解）不同，我们的ROM方法不是数据驱动的，而是物理驱动的。这篇文章的主要贡献：</p>
<ol>
<li>本文提出了一种新的基于物理信息的薄边界层神经网络建模方法。我们在基准问题中证明了我们的方法克服了PINN在解决正反薄边界层问题时的局限性。</li>
<li>我们演示了经典数学理论（摄动方法）如何在理论指导/模型驱动的方法中与PINN结合。</li>
<li>我们的方法在PINN中提供了一个简化物理模型(RPM)。这种方法完全由控制的数学方程驱动，与目前的数据驱动ROM方法不同，后者依赖数据来形成基函数。BL-PINN可以被理解为RPM和PINN的组合。</li>
<li>我们在BL-PINN中的渐近基函数方法结合了规范函数（包含摄动参数）和空间坐标依赖性，因此可以用于在小参数(此处为扩散系数)变化时重新评估解。与传统的数据驱动方法相比，这种参数依赖性的自然结合是一种改进。BL-PINN能够在不需要重新训练的情况下进行参数PINN评估，因此提供了类似于DeepONet等算子学习方法的有吸引力的优势。事实上，随着雷诺数/Peclet数的增加，BL-PINN变得更加精确，这与传统PINN随着边界层变薄和相应梯度的增加而失效相反。</li>
</ol>
<h2 id="Methods-1"><a href="#Methods-1" class="headerlink" title="Methods"></a>Methods</h2><h3 id="Problem-statement-singularly-perturbed-differential-equations"><a href="#Problem-statement-singularly-perturbed-differential-equations" class="headerlink" title="Problem statement: singularly perturbed differential equations"></a>Problem statement: singularly perturbed differential equations</h3><p>考虑一个这样的微分方程：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132019570.png" alt=""></p>
<p>在适当的边界条件下，其中是$\epsilon$出现在算子$L_{\epsilon}$中的小参数（例如，给定的小扩散系数）。我们假设这是一个奇摄动问题，这意味着微分方程在$\epsilon=0$时得到的解与在极限$\epsilon\rightarrow0$时得到的解有很大不同。一个常见的情况是当它乘以最高阶导数项。这将导致一个“边界层”，在这个“边界层”中，解在一个小区域内迅速变化。该区域的厚度在极限$\epsilon\rightarrow0$时趋近于零。在摄动理论中，这类问题的解用渐近展开式表示，解分为内外区域，如图1所示。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132057323.png" alt=""></p>
<p>外层区域（远离边界层）近似为规则扩展：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132101706.png" alt=""></p>
<p>其中$\delta(\epsilon)$是规范函数，表示解中项的渐近序列（例如，$\epsilon^{n}$），而$\phi(x)$是嵌入$\epsilon$每一阶解的空间函数。由于这是一个正则展开，前导阶解对应于$\epsilon=0$。另一方面，引入拉伸变量来近似边界层区域$\xi=\frac{x-x_{0}}{\delta(\epsilon)}$，使我们可以放大到薄边界层区域，并局部表示为解：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132119440.png" alt=""></p>
<p>其中$\bar{\psi}_{n}(\xi)$是$\psi_{n}(x,\xi)$以拉伸变量的形式表示的空间函数。最后利用匹配渐近展开式在重叠区域内匹配外解和内解，得到最终解。简而言之，当$\xi\rightarrow\infin$时的内解被强制与$x\rightarrow0$时的外解匹配。</p>
<h3 id="Boundary-layer-physics-informed-neural-networks-BL-PINN"><a href="#Boundary-layer-physics-informed-neural-networks-BL-PINN" class="headerlink" title="Boundary layer physics-informed neural networks (BL-PINN)"></a>Boundary layer physics-informed neural networks (BL-PINN)</h3><p>我们建议使用PINN来解决上述扰动框架下的边界层问题，因此利用PINN提供的混合数据驱动和模型驱动的深度学习框架。在提出的BL-PINN方法中，我们使用独立的神经网络来近似外部和内部展开中的每个解级别，并使用匹配条件来获得一致的解。该框架的概述如图1所示。多个并行PINN用于表示内部和外部表示的不同近似阶数。每个PINN网络都有自己的物理损失函数，该函数基于为指定的近似顺序和区域（内部或外部）推导的偏微分方程。内部和外部区域的最终解是通过形成由已知规范函数$\delta_{n}(\epsilon)$加权的每个PINN输出的线性组合来推导的。最后的解仅在提供测量数据并定义了数据丢失的情况下才用于训练过程。最后，对每个网络施加适当的边界条件，并使用匹配条件确保内外解在重叠区域内一致。每个神经网络表示外层解$\phi_{n}(x)$和内层解$\psi_{n}(x)$是使用以下损失函数进行优化的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132153659.png" alt=""></p>
<p>其中$n=1,2,\cdots$表示不同阶的渐近展开解，每个解都具有适当的物理$\mathcal{L}_{phys}^{n}$和边界条件$\mathcal{L}_{BC}^{n}$损失函数，这些损失函数是根据它们的定义域（内与外）和对$\epsilon$近似阶(n)定义的。利用匹配损失函数$\mathcal{L}_{match}^{n}$作为内外神经网络的匹配条件。总损失$\mathcal{L}_{tot}$是通过将内外损失函数在其近似阶上与匹配条件相加来定义的。最后，如果数据可用，则定义数据损失函数$\mathcal{L}_{data}$，并根据所有解的线性组合产生的最终输出进行反传播，如图1所示。$\lambda$超参数被设置为加权每个损失项的贡献。使用标准的随机梯度下降算法(Adam)为每一层i和每个内外网络n找到最佳权重$W_{i}$和偏差$b_{i}$。</p>
<p>匹配条件将要求内部PINN的$\xi\rightarrow\infin$输出与对应的外部PINN的$x\rightarrow0$输出匹配。然而，无限限制是不可能的，因为神经网络输入应该是理想的标准化。为了解决这个问题，一个新的变量$0 &lt; z &lt; 1$被定义为$z = \frac{\xi}{A}$，并使用该变量重新缩放内部方程。常数A被设置为一个足够大的值，$\xi\rightarrow\infin$近似为$z = 1$。这种方法受到边界层理论中的经典相似解的启发，其中根据方程估计一个适当的大值，近似于无穷大。下面我们讨论常数A的选择。</p>
<p>总而言之，BL-PINN利用了摄动理论不过是一系列微分方程的观察，这些微分方程在适当的边界/匹配条件下求解，并将解相加形成最终解。因此，人们可以使用不同的PINN网络来求解这些微分方程中的每一个，然后将这些预测线性相加，形成最终的解。</p>
<h1 id="Is-L2-Physics-Informed-Loss-Always-Suitable-for-Training-Physics-Informed-Neural-Network"><a href="#Is-L2-Physics-Informed-Loss-Always-Suitable-for-Training-Physics-Informed-Neural-Network" class="headerlink" title="Is L2 Physics-Informed Loss Always Suitable for Training Physics-Informed Neural Network?"></a>Is L2 Physics-Informed Loss Always Suitable for Training Physics-Informed Neural Network?</h1><h2 id="Abstract-20"><a href="#Abstract-20" class="headerlink" title="Abstract"></a>Abstract</h2><p>某些情况下， $L^{2}$ 损失函数可能不适合， $L^{p}$ 才适合。</p>
<h2 id="Introduction-24"><a href="#Introduction-24" class="headerlink" title="Introduction"></a>Introduction</h2><p>我们知道一个简单的事实当L2损失为零时，学习解等于精确解。然而，具有小但非零损失的学习解的质量仍然是未知的，没有任何近似保证，这是实践中更现实的场景。我们的目标是回答一个基本问题：我们能保证具有小物理信息损失的学习解总是对应于精确解的良好近似值吗？</p>
<h2 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h2><p>一些PINN收敛性的工作。</p>
<h2 id="Preliminary-1"><a href="#Preliminary-1" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>PINN和随机最优控制的相关背景知识。</p>
<h2 id="Failure-Mode-of-PINN-on-High-Dimensional-Stochastic-Optimal-Control"><a href="#Failure-Mode-of-PINN-on-High-Dimensional-Stochastic-Optimal-Control" class="headerlink" title="Failure Mode of PINN on High-Dimensional Stochastic Optimal Control"></a>Failure Mode of PINN on High-Dimensional Stochastic Optimal Control</h2><p>在这种情况下，一个自然的问题出现了：一个具有小损失的学习 $u(x)$ 是否对应于精确解 $u ^{\ast} (x)$ 的良好近似值？作者针对HJB方程的稳定性给出了证明。</p>
<h2 id="Solving-HJB-Equations-with-Adversarial-Training"><a href="#Solving-HJB-Equations-with-Adversarial-Training" class="headerlink" title="Solving HJB Equations with Adversarial Training"></a>Solving HJB Equations with Adversarial Training</h2><p>当p很大的时候，p范数和无穷范数的效果是差不多的，所以我们使用无穷范数来代替p范数。因此，训练目标就变成了如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305241731730.png" alt=""></p>
<p>上式其实可以看作是一个min-max优化问题。内部循环是一个最大化问题，以找到 $\Omega$ 和 $\partial \Omega$ 上u违反PDE最多的数据点，外部循环是一个最小化问题，以找到 $u$ ，使这些点的损失最小化。</p>
<p>我们首先固定模型 $u$ 和随机采样数据点 $x^{(1)},\cdots,x^{(N_{1})}\in \Omega$ 和 $\widetilde{x}^{(1)},\cdots,\widetilde{x}^{(N_{2})}\in \partial \Omega$ ，作为内循环优化的随机初始化。然后，我们执行基于梯度的方法来获得具有较大PDE损失的数据点，坐标更新方式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305241749960.png" alt=""></p>
<p>当内环优化完成后，我们将生成的数据点固定，并计算梯度g到模型参数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305241755648.png" alt=""></p>
<h1 id="Extended-physics-informed-neural-networks-XPINNs-A-generalized-space-time-domain-decomposition-based-deep-learning-framework-for-nonlinear-partial"><a href="#Extended-physics-informed-neural-networks-XPINNs-A-generalized-space-time-domain-decomposition-based-deep-learning-framework-for-nonlinear-partial" class="headerlink" title="Extended physics-informed neural networks (XPINNs) : A generalized space-time domain decomposition based deep learning framework for nonlinear partial"></a>Extended physics-informed neural networks (XPINNs) : A generalized space-time domain decomposition based deep learning framework for nonlinear partial</h1><p>differential equations</p>
<h2 id="Abstract-21"><a href="#Abstract-21" class="headerlink" title="Abstract"></a>Abstract</h2><p>提出了一种基于物理信息的神经网络的广义时空域分解框架来求解非线性偏微分方程在任意复杂几何区域上。与PINN方法相比，XPINN方法由于在较小的子域中部署多个神经网络的固有特性，具有<strong>更大的表示和并行化能力</strong>。深度神经网络可以应用于具有复杂解的子域，而浅神经网络可以应用于具有相对简单和光滑解的子域。</p>
<h2 id="Introduction-25"><a href="#Introduction-25" class="headerlink" title="Introduction"></a>Introduction</h2><p>DNN的发展；PINN的发展；PINN的不足之处以及XPINN的优点。</p>
<ol>
<li>广义空时域分解：XPINN的形式提供了高度不规则的，凸/非凸时空域分解。</li>
<li>对任意微分方程的扩展：与cPINN方法不同，基于XPINN的域分解方法可以扩展到任何类型的PDE，而不考虑其物理性质。</li>
<li>简单界面条件：在XPINN中，对于任意形状的接口，接口条件非常简单，不需要法线方向，因此，所提出的方法可以很容易地扩展到任何复杂的几何形状，甚至在更高的维度上。</li>
</ol>
<h2 id="Problem-Formulation-1"><a href="#Problem-Formulation-1" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h2><p>简单介绍偏微分方程</p>
<h2 id="Methodology-8"><a href="#Methodology-8" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Mathematical-setup-for-fully-connected-neural-networks"><a href="#Mathematical-setup-for-fully-connected-neural-networks" class="headerlink" title="Mathematical setup for fully connected neural networks"></a>Mathematical setup for fully connected neural networks</h3><p>本文采用的是局部自适应激活函数。数学上，可以通过比较自适应激活函数方法和固定激活方法的梯度动力学来证明这一点。自适应激活的梯度动态通过将条件矩阵乘以梯度并添加近似二阶项来修改标准动态（固定激活）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291451457.png" alt=""></p>
<h3 id="Extended-Physics-Informed-Neural-Networks"><a href="#Extended-Physics-Informed-Neural-Networks" class="headerlink" title="Extended Physics-Informed Neural Networks"></a>Extended Physics-Informed Neural Networks</h3><ul>
<li>Subdomains：不相交；所有subdomain的并集是全集；交集就是它们的连接部分</li>
<li>Interface：两个或多个subdomain的边界</li>
<li>Sub-Net：指在每个子域中使用自己的一组优化超参数的单个PINN</li>
<li>Interface Conditions：利用这些条件将分解的子域拼接在一起，从而得到控制偏微分方程在整个域上的解</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291457474.png" alt=""></p>
<p>则最终解的形式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291556942.png" alt=""></p>
<p>其中距离函数的定义如下，如果点不在subdomain中，系数为0；如果点在subdomain中，系数为1；如果点在连接处，系数为$\frac{1}{S}$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291556510.png" alt=""></p>
<h4 id="Subdomain-loss-function"><a href="#Subdomain-loss-function" class="headerlink" title="Subdomain loss function"></a>Subdomain loss function</h4><p>XPINN的损失函数是按子域定义的，它在每个子域中具有与PINN损失函数相似的结构，但被赋予了将子域拼接在一起的接口条件。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291616203.png" alt=""></p>
<p>上式中各项的具体形式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291619802.png" alt=""></p>
<p>其中 $MSE_{\mathcal{R}}$ 表达的是残差连续性条件， $MSE_{u_{avg}}$ 表达的是值的连续性条件，$\{ \{ u_{\widetilde{\Theta}_{q}} \}\}=\frac{u_{\widetilde{\Theta}_{q}}+u_{\widetilde{\Theta}_{q^{+}}}}{2}$ ， $q^{+}$ 表示的邻居，这里以两个邻居为例。</p>
<h1 id="Conservative-physics-informed-neural-networks-on-discrete-domains-for-conservation-laws-Applications-to-forward-and-inverse-problems"><a href="#Conservative-physics-informed-neural-networks-on-discrete-domains-for-conservation-laws-Applications-to-forward-and-inverse-problems" class="headerlink" title="Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems"></a>Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems</h1><h2 id="Abstract-22"><a href="#Abstract-22" class="headerlink" title="Abstract"></a>Abstract</h2><p>介绍了本文的工作；cPINN的优点；简要讨论了各种误差及其来源；cPINN当中使用的局部自适应激活函数。</p>
<h2 id="Introduction-26"><a href="#Introduction-26" class="headerlink" title="Introduction"></a>Introduction</h2><p>DNN的发展；SciML的发展；PINN的发展以及不足之处。</p>
<h2 id="Problem-setup"><a href="#Problem-setup" class="headerlink" title="Problem setup"></a>Problem setup</h2><p>引出待解决的问题</p>
<h2 id="Methodology-9"><a href="#Methodology-9" class="headerlink" title="Methodology"></a>Methodology</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292133138.png" alt=""></p>
<h3 id="Sub-domain-loss-function-and-optimization-algorithm"><a href="#Sub-domain-loss-function-and-optimization-algorithm" class="headerlink" title="Sub-domain loss function and optimization algorithm"></a>Sub-domain loss function and optimization algorithm</h3><p>损失函数的形式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292200111.png" alt=""></p>
<p>每个损失项的具体表达形式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292201794.png" alt=""></p>
<p>$f_{p}\cdot \mathbf{n}$ 和 $f_{p^{+}}\cdot \mathbf{n}$ 是垂直于公共面的界面通量由两个不同的神经网络分别在子域 $p$ 和 $p^{+}$ 上给出的接口；</p>
<h3 id="Error-analysis-for-cPINN"><a href="#Error-analysis-for-cPINN" class="headerlink" title="Error analysis for cPINN"></a>Error analysis for cPINN</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292208610.png" alt=""></p>
<p>cPINN中的总误差定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292208510.png" alt=""></p>
<h1 id="ADAPTIVE-FOURIER-NEURAL-OPERATORS-EFFICIENT-TOKEN-MIXERS-FOR-TRANSFORMERS"><a href="#ADAPTIVE-FOURIER-NEURAL-OPERATORS-EFFICIENT-TOKEN-MIXERS-FOR-TRANSFORMERS" class="headerlink" title="ADAPTIVE FOURIER NEURAL OPERATORS: EFFICIENT TOKEN MIXERS FOR TRANSFORMERS"></a>ADAPTIVE FOURIER NEURAL OPERATORS: EFFICIENT TOKEN MIXERS FOR TRANSFORMERS</h1><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>ViT在表示学习方向取得了巨大的成功，主要是由于借助自注意力的token mixing。但是随着像素点的增加会有一个平方倍地缩减，这就使得其对于高精度输入不可行。为了解决的这个问题，文章提出了AFNO(Adaptive Fourier Neural Operator)，核心思想是在傅里叶空间做token mixing。AFNO的理论基础是算子学习，将token mixing看作是一个与输入分辨率无关的连续全局卷积。为了应对视觉表征学习中的挑战，如图像不连续和高分辨率输入，我们提出了FNO的原则性架构修改，从而提高了内存和计算效率。主要包括在不同通道之间的mixing weights使用了一个块对角结构，token之间动态地共享权重，通过软阈值和收缩对频率模式进行稀疏化。</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>ViT在为识别和生成任务生成丰富的上下文表示方面做出了很大的贡献。然而，一个主要的挑战是来自高分辨率图像和视频的长序列。在这里，远程和多向依赖关系对于理解场景中对象之间的组合性和关系至关重要。Transformer有效性的一个关键组成部分归因于token的适当混合。然而，找到一个好的mixer是具有挑战性的，因为它需要随序列大小缩放，并系统地推广到下游任务。</p>
<p>原始的自注意力施加图结构，并使用标记之间的相似性来捕获长期依赖关系；它具有参数高效和自适应的特点，但在序列大小上具有二次复杂度。为了实现与线性复杂性的有效混合，引入了几个自注意力的近似。这些近似通常会为了效率而牺牲精度。例如，long-short Transformer聚集了具有动态投影的远程注意力来模拟远距离相关性，并聚集了短期注意力来捕捉局部相关性。长距离依赖关系是在低维中建模的，这可能会限制表达性。</p>
<p>最近，引入了自注意力的替代方案，放宽了图假设以实现有效混合。相反，他们利用傅里叶变换来利用几何结构。例如，Global Filter Networks (GFN)提出了用于token mixing的深度全局卷积，该卷积在傅里叶域中得到了有效的实现。GFN主要包括三个步骤：(i)通过快速傅里叶变换(FFT)进行空间标记混合；(ii)频率门控；(iii)用于令牌分离的逆FFT。然而，GFN在高分辨率下缺乏自适应性和表达性，因为参数数量随着序列大小而增长，并且在(ii)中不涉及channel mixing。</p>
<p>为了解决这些缺点，我们将token mixing作为学习无限维空间中连续函数之间映射的算子学习。我们将token视为函数空间中的连续元素，并将token mixing建模为连续的全局卷积，以捕获几何空间中的全局关系。一种有效解决全局卷积的方法是通过FFT。更一般地，我们将这样的全局卷积运算与非线性（如ReLU）组合在一起，以学习任何一般的非线性算子。这构成了设计傅里叶神经算子(FNOs)的基础，FNOs在解决PDEs方面显示出希望。因此，我们采用FNO作为设计高效token mixing的起点。</p>
<p>从PDE中调整FNO到视觉需要几个设计修改。图像具有由于边缘和其他结构而不连续性的高分辨率内容。标准FNO中的channel mixing导致channel大小的二次复杂度。为了控制这种复杂性，我们对token mixing权重施加块对角结构。为了增强泛化能力，受稀疏回归的启发，通过软阈值化对频率进行稀疏化。此外，为了参数效率，我们的MLP层在token之间共享权重。我们将由此产生的模型称为自适应FNO (AFNO)。</p>
<h2 id="RELATED-WORKS"><a href="#RELATED-WORKS" class="headerlink" title="RELATED WORKS"></a>RELATED WORKS</h2><p>提升自注意力的方法：</p>
<ul>
<li>基于图的Mixer：核心是找到合适的代理来近似自注意力。稀疏attention；低秩attention；核方法；聚类方法。</li>
<li>基于MLP的Mixer：利用MLP投影放宽自注意力和空间混合标记的图相似性约束。</li>
<li>基于傅里叶的Mixer：将傅里叶变换作用于空间混合标记。</li>
</ul>
<p>算子学习处理函数到函数的映射问题，并且经常用于PDEs。算子学习也可以被应用于计算机视觉当中，因为图像是二维平面上的RGB值函数。</p>
<h2 id="PRELIMINARIES-AND-PROBLEM-STATEMENT"><a href="#PRELIMINARIES-AND-PROBLEM-STATEMENT" class="headerlink" title="PRELIMINARIES AND PROBLEM STATEMENT"></a>PRELIMINARIES AND PROBLEM STATEMENT</h2><p>将一个二维图像分成 $h \times w$ 的patch，每个patch都是d维的，所以每一个token tensor就被表示为 $X \in \mathbb{R}^{h \times w \times d}$ 。</p>
<p>一些背景知识。</p>
<h3 id="Discrete-FNO"><a href="#Discrete-FNO" class="headerlink" title="Discrete FNO"></a>Discrete FNO</h3><p>受FNO的启发，对于离散网格上有限维的图像，我们的想法是使用离散傅里叶变换(DFT)混合标记。对于输入变量$X \in \mathbb{R}^{h \times w \times d}$，定义复值权重张量 $W:=DFT(k) \in \mathbb{C}^{h \times w \times d \times d}$ 来参数化核。然后，FNO混合需要对每个token进行以下操作：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151113163.png" alt=""></p>
<h3 id="Local-Features"><a href="#Local-Features" class="headerlink" title="Local Features"></a>Local Features</h3><p>DFT假设在周期性图像上应用了一个全局卷积，这对于真实世界的图像来说通常是不成立的。为了补偿局部特征和非周期边界，我们可以在FNO中的token分解步骤3中添加残差项 $x_{m,n}$ （也可以参数化为简单的局部卷积）。</p>
<h3 id="Resolution-Invariance"><a href="#Resolution-Invariance" class="headerlink" title="Resolution Invariance"></a>Resolution Invariance</h3><p>FNO模型对离散的 $h,w$ 是不变的，它是通过对潜在分辨率不变的傅里叶基来参数化token函数的。因此，在一个分辨率上训练后，可以直接在另一个分辨率上进行评估（zero-shot 超分辨率）。</p>
<h2 id="ADAPTIVE-FOURIER-NEURAL-OPERATORS-FOR-TRANSFORMERS"><a href="#ADAPTIVE-FOURIER-NEURAL-OPERATORS-FOR-TRANSFORMERS" class="headerlink" title="ADAPTIVE FOURIER NEURAL OPERATORS FOR TRANSFORMERS"></a>ADAPTIVE FOURIER NEURAL OPERATORS FOR TRANSFORMERS</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151156212.png" alt=""></p>
<h3 id="Block-Diagonal-Structure-on-W"><a href="#Block-Diagonal-Structure-on-W" class="headerlink" title="Block-Diagonal Structure on W"></a>Block-Diagonal Structure on W</h3><p>FNO对每个token都涉及一个 $k \times k$ 的权重矩阵，这就导致了 $O(Nd^{2})$ 的参数量。为了减少参数量，我们采用了块对角结构，权重矩阵被分成 $k$ 个大小维 $d/k \times d/k$ 的权重块。其实可以看成是多头自注意力，它投射到数据的一个子空间。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151134329.png" alt=""></p>
<h3 id="Weight-Sharing"><a href="#Weight-Sharing" class="headerlink" title="Weight Sharing"></a>Weight Sharing</h3><p>FNO的另一个不足之处在于权重是静态的，一旦学习，它们将不会自适应地改变新的样本。受自注意力的启发，我们希望tokens具有适应性。此外，静态权重在tokens之间是独立的，但我们希望tokens相互作用并决定传递某些低频和高频模式。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151152897.png" alt=""></p>
<h3 id="Soft-Thresholding-and-Shrinkage"><a href="#Soft-Thresholding-and-Shrinkage" class="headerlink" title="Soft-Thresholding and Shrinkage"></a>Soft-Thresholding and Shrinkage</h3><p>图像在傅里叶空间是天然稀疏的，大部分都集中在低频模式中。因此，我们可以动态地根据它们对终端任务的重要性对tokens进行掩码。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151155277.png" alt=""></p>
<h1 id="FOURCASTNET-A-GLOBAL-DATA-DRIVEN-HIGH-RESOLUTION-WEATHER-MODEL-USING-ADAPTIVE-FOURIER-NEURAL-OPERATORS"><a href="#FOURCASTNET-A-GLOBAL-DATA-DRIVEN-HIGH-RESOLUTION-WEATHER-MODEL-USING-ADAPTIVE-FOURIER-NEURAL-OPERATORS" class="headerlink" title="FOURCASTNET: A GLOBAL DATA-DRIVEN HIGH-RESOLUTION WEATHER MODEL USING ADAPTIVE FOURIER NEURAL OPERATORS"></a>FOURCASTNET: A GLOBAL DATA-DRIVEN HIGH-RESOLUTION WEATHER MODEL USING ADAPTIVE FOURIER NEURAL OPERATORS</h1><h2 id="Abstract-23"><a href="#Abstract-23" class="headerlink" title="Abstract"></a>Abstract</h2><p>FourCastNet以0.25°分辨率（遥感图像能分辨的最小地物单元为0.25经/纬度）提供准确的短期到中期全球预测。FourCastNet可以准确预测高分辨率、快速的时间尺度变量，如地面风速、降水和大气水蒸气。它对规划风能资源、预测热带气旋、热带外气旋和大气河流等极端天气事件具有重要意义。FourCastNet在短时间内的大尺度变量的预测精度与ECMWF的Integrated Forecasting System (IFS)的精度相当，然而在小尺度变量上的精度高于IFS。FourCastNet在不到2秒的时间内生成一个为期一周的预测，比IFS快了几个数量级。FourCastNet的速度使创建快速和廉价的大型集合预测与数以千计的集合成员，以提高概率预测。我们讨论了数据驱动的深度学习模型(如FourCastNet)如何成为气象工具包的一个有价值的补充，以帮助和增强NWP模型。</p>
<h2 id="Introduction-27"><a href="#Introduction-27" class="headerlink" title="Introduction"></a>Introduction</h2><p>数值天气预报的重要性以及其发展历程。</p>
<p>现在数据驱动的深度学习也开始发展起来。</p>
<p>数据驱动模型克服了NWP模型中存在的模型偏差，能够以较低的计算成本为概率预报和数据同化生成大集合，在改善天气预报方面具有很大的潜力。</p>
<p>大多数数据驱动的天气模型使用低分辨率数据进行训练。然而，粗化过程会导致关键的、精细的物理信息的丢失。数据驱动的模型要想真正发挥作用，就必须以与当前最先进的数值天气模型相同或更高的分辨率生成预报。</p>
<p>我们开发了基于傅里叶的神经网络预测模型FourCastNet，以0.25°分辨率生成关键大气变量的全球数据驱动预测，这对应于赤道附近大约30 km × 30km的空间分辨率和720 × 1440像素的全球网格大小。</p>
<p>我们选择了ViT作为主干网络，因为它能够很好地建模远程依赖关系。将ViT与基于傅立叶的令牌混合相结合，可以产生最先进的高分辨率模型，该模型可以解析细粒度特征，并可以很好地扩展数据集的分辨率和大小。这种方法能够以真正前所未有的分辨率训练高保真的数据驱动模型。</p>
<h2 id="Training-Methods"><a href="#Training-Methods" class="headerlink" title="Training Methods"></a>Training Methods</h2><p>在这项工作中，我们重点预测了两个重要且具有挑战性的大气变量，即(1)距离地球表面10米的风速和(2)6小时总降水量。由于计算和模型架构的限制，以前基于DL的天气预报工作无法在全ERA5分辨率下对这些变量进行全球预报。近地面风速预报在陆上和海上风电场的储能规划、电网传输和其他操作考虑中发挥着关键作用，因此具有巨大的实用性。正如我们在3.1节中所展示的，近地风预报（以及大气边界层以上的风预报）可以帮助跟踪极端风事件，如飓风，并可用于备灾。我们的第二个重点是预测总降水量，其中DL模型可能显示出很大的潜力。NWP模型，如可操作的IFS，有几种参数化方案来可跟踪地预测降水，由于神经网络在从高分辨率观测数据推断参数化方面具有令人印象深刻的能力，因此它们非常适合这项任务。</p>
<h3 id="FourCastNet-Model-Description"><a href="#FourCastNet-Model-Description" class="headerlink" title="FourCastNet: Model Description"></a>FourCastNet: Model Description</h3><p>为了产生高分辨率的预测，我们选择了自适应傅立叶神经算子(AFNO)模型。这种特殊的神经网络架构很有吸引力，因为它是专门为高分辨率输入设计的，并将深度学习的几个关键最新进展综合到一个模型中。也就是说，它结合了傅里叶神经的算子学习方法与ViT主干，前者已被证明在建模复杂PDE系统非常有优势。</p>
<p>ViT架构及其变体在过去几年中已经成为计算机视觉领域的最新技术，在许多任务上表现出卓越的性能，并且随着模型和数据集大小的增加而良好地扩展。这种性能主要归功于这些网络中的多头自注意力机制，该机制允许网络在每一层全局建模特征（在ViT表示术语中称为token）之间的相互作用。然而，通过自注意力进行的空间混合在token数量上是二次的，因此对于高分辨率输入很快变得不可行。</p>
<p>ViT的一些变体通过找到一些可替代的空间token混合的机制来降低计算复杂度。然而，AFNO模型的独特之处在于，它将混合操作表征为连续的全局卷积，通过FFT在傅里叶域中有效地实现，这允许灵活地、可扩展地跨空间和通道维度建模依赖关系。</p>
<p>鉴于卷积网络架构的普遍流行，特别是它们在先前预测ERA5变量的工作中的使用，值得将我们的AFNO模型与这些更传统的架构进行比较。首先，AFNO能够很好地随分辨率进行扩展，从而产生直接的实际好处——在我们的720x1440分辨率下，FourCastNet模型的内存占用约为10GB，批处理大小为1。为了对比这一点，我们可以从WeatherBench的先前结果中看到19层的ResNet架构，它以非常粗糙的分辨率（32×64像素）进行训练。将此架构转移到我们的数据集并以720×1440分辨率进行训练，对于批大小为1的数据集将需要83GB。</p>
<p>除了实际考虑之外，我们初步的非详尽实验表明，在自回归推理中，卷积架构在捕获小尺度上的许多时间步长表现不佳。这些观察结果以及我们对图像去噪、超分辨率和去模糊的高分辨率图像处理当前状态的了解是我们选择ViT架构而不是卷积架构的强烈动机。</p>
<h3 id="Model-structure"><a href="#Model-structure" class="headerlink" title="Model structure"></a>Model structure</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202307271409187.png" alt=""></p>
<h3 id="Training-methods"><a href="#Training-methods" class="headerlink" title="Training methods"></a>Training methods</h3><p>模型的训练分为两个阶段：预训练阶段，从x(k)生成x(k+1)，使用x(k+1)和x(k+1)的真实值做损失；微调阶段，从x(k)生成x(k+1)，再用生成的x(k+1)生成x(k+2)，然后使用x(k+1)和x(k+2)的真实值分别做损失。</p>
<h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p>模型的预测是一个迭代式的方式：先用x(k)生成x(k+1)，再从x(k+1)生成x(k+2)，依此类推，直到我们想要的步长。</p>
<h1 id="Prediction-of-transonic-flow-over-supercritical-airfoils-using-geometric-encoding-and-deep-learning-strategies"><a href="#Prediction-of-transonic-flow-over-supercritical-airfoils-using-geometric-encoding-and-deep-learning-strategies" class="headerlink" title="Prediction of transonic flow over supercritical airfoils using geometric-encoding and deep-learning strategies"></a>Prediction of transonic flow over supercritical airfoils using geometric-encoding and deep-learning strategies</h1><h2 id="Methods-2"><a href="#Methods-2" class="headerlink" title="Methods"></a>Methods</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101600250.png" alt=""></p>
<p>输入是翼型和自由流条件的几何信息。首先做一个网格变换来利用结构化网络；接着采用多种方法对几何信息进行编码，选择神经网络的有效特征输入；AI模型方面采用了基于小波变换和梯度分布的各种损失函数，尤其是在激波附近。</p>
<h3 id="Encoding-of-geometric-information"><a href="#Encoding-of-geometric-information" class="headerlink" title="Encoding of geometric information"></a>Encoding of geometric information</h3><p>机翼周围的边界层附近网格是细化处理的，因为需要保留流动细节。基于CNN和Transformer的模型需要均匀和结构化的输入，通过一元变换将几何信息和流信息从笛卡尔坐标转换为曲线坐标。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101633201.png" alt=""></p>
<p>文章共采用了四种Encoding的方法：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101641619.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101644169.png" alt=""></p>
<h3 id="Neural-network-architecture"><a href="#Neural-network-architecture" class="headerlink" title="Neural network architecture"></a>Neural network architecture</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101707037.png" alt=""></p>
<h3 id="Loss-functions"><a href="#Loss-functions" class="headerlink" title="Loss functions"></a>Loss functions</h3><p>平均绝对误差(MAE)通常用于训练神经网络来预测翼型上的流场。本研究将剧烈变化视为流场的高频信号，并在 $l_{1}$ 损失函数中加入两个损失函数，即多层小波变换的损失函数($l_{wt}$)和梯度分布的损失函数($l_{grad}$)。</p>
<h4 id="Multilevel-wavelet-transformation"><a href="#Multilevel-wavelet-transformation" class="headerlink" title="Multilevel wavelet transformation"></a>Multilevel wavelet transformation</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101725583.png" alt=""></p>
<p>其中，$\psi^{H}$为运行k−1次DWT后的高频分量，$\psi^{L}_{k-1}$为运行k−1次DWT后的低频分量。DWT实现后，结合$l_{wt}$得到总损失函数的最终形式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101735864.png" alt=""></p>
<p>这些系数是可训练的，可以通过多任务损失优化来学习：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101735384.png" alt=""></p>
<h4 id="Gradient-distribution"><a href="#Gradient-distribution" class="headerlink" title="Gradient distribution"></a>Gradient distribution</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308111724017.png" alt=""></p>
<p>通过中心差分法可以得到 $\xi$ 和 $\eta$ 方向上的梯度。总损失函数表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308111728085.png" alt=""></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%80%BB%E7%BB%93/" rel="tag"># 总结</a>
              <a href="/tags/%E8%AE%BA%E6%96%87/" rel="tag"># 论文</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/10/09/%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E6%80%BB%E7%BB%93/" rel="prev" title="项目部署总结">
                  <i class="fa fa-chevron-left"></i> 项目部署总结
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/11/07/Python%E6%8B%BE%E9%81%97/" rel="next" title="Python知识点">
                  Python知识点 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">木霈玖</span>
</div>

    </div>
  </footer>

  
  <script src="//unpkg.com/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'none'
      },
      options: {
        renderActions: {
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//unpkg.com/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



</body>
</html>
