<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Git使用总结</title>
    <url>/2022/02/25/Git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下使用<code>Git</code>过程中遇到的问题</p>
<a id="more"></a>
<h1 id="提交项目至GitHub仓库"><a href="#提交项目至GitHub仓库" class="headerlink" title="提交项目至GitHub仓库"></a>提交项目至GitHub仓库</h1><ol>
<li><p>新建仓库，会出现仓库地址，例如：<a href="https://github.com/TankManBeta/xxx.git">https://github.com/TankManBeta/xxx.git</a></p>
</li>
<li><p>本地项目文件夹，打开根目录命令行窗口，输入以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建说明文档</span></span><br><span class="line">git touch README.md</span><br><span class="line"><span class="meta">#</span><span class="bash"> 初始化本地仓库</span></span><br><span class="line">git init</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加全部已修改的文件，效果等同于git add -A</span></span><br><span class="line">git add .</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改后为文件提交到本地仓库</span></span><br><span class="line">git commit -m &quot;first commit&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 强制修改分支名</span></span><br><span class="line">git branch -M main</span><br><span class="line"><span class="meta">#</span><span class="bash"> 连接到远程仓库并为该仓库创建别名，别名为origin；远程仓库地址就是新建的仓库的地址</span></span><br><span class="line">git remote add origin https://github.com/TankManBeta/xxx.git</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建一个upSrtream，并将本地代码通过这个upStream推送到别名为origin的仓库中的main分支上</span></span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure></li>
<li>本地项目上传至<code>GitHub</code>仓库成功</li>
</ol>
<h1 id="克隆项目"><a href="#克隆项目" class="headerlink" title="克隆项目"></a>克隆项目</h1><ol>
<li>新建一个文件夹</li>
<li>打开<code>CMD</code>或者右键<code>Git Bash Here</code></li>
<li>命令行中输入<code>git init</code>，此时刚创建的文件夹中出现一个<code>.git</code>文件夹</li>
<li>先在<code>GitHub</code>中复制<code>URL</code>，然后命令行窗口中输入<code>git clone [URL] [需要新建的文件夹名]</code>，回车，等待下载完成即可</li>
</ol>
<h1 id="每次上传需要登陆"><a href="#每次上传需要登陆" class="headerlink" title="每次上传需要登陆"></a>每次上传需要登陆</h1><p><code>git</code>使用<code>https</code>协议，每次<code>pull</code>, <code>push</code>都要输入密码。使用<code>git</code>协议，然后使用<code>SSH</code>密钥，可以不用每次都输密码。</p>
<ol>
<li><p>生成<code>SSH</code></p>
<ol>
<li><p>打开<code>Git</code>，输入：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen</span><br></pre></td></tr></table></figure></li>
<li><p>设定保存<code>key</code>的文件名</p>
</li>
<li><p>设定密码</p>
</li>
</ol>
</li>
<li><p><code>GitHub</code>主页添加<code>SSH</code>： <code>Settings</code> —&gt; <code>SSH and GPG keys</code> —&gt; <code>New SSH key</code> —&gt; 输入自定义标题和刚刚生成的pub文件 —&gt; <code>Add SSH key</code></p>
</li>
<li><p>本地登陆<code>SSH</code></p>
<ol>
<li><p>添加<code>Key</code>到<code>ssh</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-add  ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-add  ~/.ssh/你的私钥名</span><br></pre></td></tr></table></figure></li>
<li><p><code>Git</code>输入命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -T -i 你的私钥名 git@github.com</span><br></pre></td></tr></table></figure>
<p><strong>注：设置了自定义名字的SSH密钥后，还需要再设置一下<code>SSH</code>的配置文件（见另一篇），否则会导致拒绝连接。</strong></p>
</li>
</ol>
</li>
<li><p>移除旧的提交方式：</p>
<ol>
<li><p>查看项目采用的提交方式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure></li>
<li><p>删除旧的提交方式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote rm origin</span><br></pre></td></tr></table></figure></li>
<li><p>修改提交方式</p>
<ol>
<li><p><code>GitHub</code>仓库 —&gt; <code>Clone or download</code> —&gt; <code>User SSH</code>，获取<code>SSH</code>链接</p>
</li>
<li><p>添加新的<code>SSH</code>提交方式</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote add origin git@github.com:TankManBeta/xxx.git</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li>提交新代码，不再需要输入账号密码</li>
</ol>
<h1 id="多人协作开发"><a href="#多人协作开发" class="headerlink" title="多人协作开发"></a>多人协作开发</h1><p>如果是多人协作开发的话，一定要先<code>pull</code>，将最新版本的代码拉取到本地</p>
<h1 id="多个远程仓库或多个分支"><a href="#多个远程仓库或多个分支" class="headerlink" title="多个远程仓库或多个分支"></a>多个远程仓库或多个分支</h1><p>如果有多个远程仓库或者多个分支，并且需要将代码推送到指定仓库的指定分支上，那么在<code>pull</code>或<code>push</code>的时候，就需要按照下面的格式书写：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git pull 仓库别名 仓库分支名</span><br><span class="line">git push 仓库别名 仓库分支名</span><br></pre></td></tr></table></figure>
<h1 id="关于-idea文件夹"><a href="#关于-idea文件夹" class="headerlink" title="关于.idea文件夹"></a>关于<code>.idea</code>文件夹</h1><p><code>.idea</code>文件夹是<code>Pycharm</code>等<code>IDE</code>生成的项目配置文件。</p>
<ol>
<li><p>如果<code>.idea</code>文件夹为提交至仓库，则在项目中添加<code>.gitignore</code>文件，在其中设置需要忽略的文件或文件夹，然后再<code>push</code>即可</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">.idea/</span><br></pre></td></tr></table></figure></li>
<li><p>如果已经把<code>.idea</code>已经提交了，则需要先将远端的文件给删掉，然后再同第一步进行相同的设置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git rm -r --cached .idea</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="修改Github仓库名后的操作"><a href="#修改Github仓库名后的操作" class="headerlink" title="修改Github仓库名后的操作"></a>修改<code>Github</code>仓库名后的操作</h1><p>在<code>Github</code>上修改完仓库名之后，再<code>push</code>会报错，需要采取如下措施</p>
<ul>
<li><p>首先查看本地仓库对应的远程仓库名</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure></li>
<li><p>修改链接</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote set-url origin xxx.git</span><br></pre></td></tr></table></figure></li>
<li>再次push也可能报错，需要输入用户名密码（由于我配置过<code>ssh</code>私钥，所以未出现这种情况）</li>
</ul>
]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>我的第一篇文章</title>
    <url>/2021/01/31/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</url>
    <content><![CDATA[<p>这是一篇测试文章，没有后续~~~</p>
]]></content>
  </entry>
  <entry>
    <title>搭建个人博客</title>
    <url>/2021/03/31/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>新手上路，多多指教</p>
<a id="more"></a>
<h1 id="搭建个人博客"><a href="#搭建个人博客" class="headerlink" title="搭建个人博客"></a>搭建个人博客</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ol>
<li><p>安装<code>Git</code></p>
</li>
<li><p>安装<code>Nodejs</code></p>
<p>安装完成后查看<code>node</code>版本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure>
<p>查看<code>npm</code>包管理器版本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm -v</span><br></pre></td></tr></table></figure>
<p>国内安装镜像源很慢，所以可以利用<code>npm</code>安装<code>cnpm</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Hexo框架搭建博客"><a href="#Hexo框架搭建博客" class="headerlink" title="Hexo框架搭建博客"></a>Hexo框架搭建博客</h2><ol>
<li><p>安装<code>hexo</code>框架</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cnpm install -g hexo-cli</span><br></pre></td></tr></table></figure></li>
<li><p>查看是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo -v</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_1.png" alt="pic_1"></p>
</li>
<li><p><code>Hexo</code>框架初始化：选择存放博客所有内容的文件夹，命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_2.png" alt="pic_2"></p>
</li>
<li><p>本地启动博客</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure></li>
<li><p>浏览器访问<a href="http://localhost:4000">http://localhost:4000</a> ，可以看到搭建成功</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_4.png" alt="pic_4"></p>
</li>
</ol>
<h2 id="博客进阶"><a href="#博客进阶" class="headerlink" title="博客进阶"></a>博客进阶</h2><h3 id="新建文章"><a href="#新建文章" class="headerlink" title="新建文章"></a>新建文章</h3><ol>
<li><p>命令行输入：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo new &quot;我的第一篇文章&quot;</span><br></pre></td></tr></table></figure></li>
<li><p>查看是否新建文章成功</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_5.png" alt="pic_5"></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_6.png" alt="pic_6"></p>
</li>
<li><p>接着输入以下命令，浏览器访问<a href="http://localhost:4000">http://localhost:4000</a> ，可以看到新建的文章已经上传</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo cl</span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>
<p><strong>注：如果\source\_posts文件夹下没有任何文章，则访问会报错</strong></p>
</li>
</ol>
<h3 id="博客部署到GitHub"><a href="#博客部署到GitHub" class="headerlink" title="博客部署到GitHub"></a>博客部署到GitHub</h3><ol>
<li><p>新建<code>GitHub</code>仓库</p>
<p>注：一定要以<code>username.github.io</code>创建。假如我没有用<code>tankmanbeta.github.io</code>而是用了<code>jeeby.github.io</code>，那么当我浏览器访问博客的时候会出现404错误。这里并不是没有部署成功，而是把它部署在了这里:<code>http://tankmanbeta.github.io/jeeby.github.io</code>。所以，如果想直接<code>tankmanbeta.github.io</code>访问，那么就需要和用户名保持一致。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_7.png" alt="pic_7"></p>
</li>
<li><p>修改本地<code>Hexo</code>目录下文件<code>_config.yml</code>，在最后添加如下代码</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">    <span class="attr">repository:</span> <span class="string">https://github.com/TankManBeta/tankmanbeta.github.io</span></span><br><span class="line">    <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure>
<p>注：2020年10月1日起，<code>GitHub</code>把<code>master</code>分支换成<code>main</code>分支，据说与种族歧视有关。</p>
</li>
<li><p>安装<code>Git</code>部署的插件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cnpm install --save hexo-deployer-git</span><br></pre></td></tr></table></figure></li>
<li><p>输入以下命令，完成博客在<code>GitHub</code>上的部署</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo cl</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></li>
<li><p>浏览器访问<code>tankmanbeta.github.io</code>，成功访问</p>
<p><strong>注：每次部署都需要输入<code>GitHub</code>账号密码的解决方法：修改本地<code>Hexo</code>目录下文件<code>_config.yml</code>的<code>deploy</code>属性：（需要先设置<code>SSH-key</code>）</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:TankManBeta/tankmanbeta.github.io</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="博客主题更改"><a href="#博客主题更改" class="headerlink" title="博客主题更改"></a>博客主题更改</h3><ol>
<li><p>主题选取地址：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a></p>
</li>
<li><p>在博客根目录下的<code>themes</code>文件夹下克隆主题：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/next-theme/hexo-theme-next</span><br></pre></td></tr></table></figure></li>
<li><p>打开本地<code>Hexo</code>目录下文件<code>_config.yml</code>，修改<code>theme</code>属性：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">hexo-theme-next</span></span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_8.png" alt="pic_8"></p>
</li>
<li><p>输入以下命令，更新博客在<code>GitHub</code>上的部署</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g -d</span><br></pre></td></tr></table></figure></li>
<li><p>浏览器访问<code>tankmanbeta.github.io</code>，可以看到主题更新成功</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_9.png" alt="pic_9"></p>
</li>
</ol>
<h3 id="Next主题切换"><a href="#Next主题切换" class="headerlink" title="Next主题切换"></a>Next主题切换</h3><ol>
<li>打开<code>next</code>主题下的<code>_config.yml</code>文件，修改<code>theme</code>属性，将其选择成自己想要的</li>
<li>重新部署，步骤同上</li>
</ol>
<h3 id="中英文切换"><a href="#中英文切换" class="headerlink" title="中英文切换"></a>中英文切换</h3><ol>
<li>打开博客根目录下的<code>_config.yml</code>文件，修改<code>Site</code>属性下的<code>language</code>，将其改成<code>zh-CN</code>即可</li>
<li>重新部署，步骤同上</li>
<li>同理可以更改<code>title</code>、<code>author</code>等</li>
</ol>
<h3 id="添加标签页面"><a href="#添加标签页面" class="headerlink" title="添加标签页面"></a>添加标签页面</h3><ol>
<li><p>在博客根目录下打开<code>cmd</code>，使用<code>hexo new page tags</code>新建一个页面</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_10.png" alt="pic_10"></p>
</li>
<li><p>打开新建的页面，将页面的类型设置为<code>tags</code></p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">title: tags</span></span><br><span class="line"><span class="section">date: 2021-03-31 11:20:38</span></span><br><span class="line"><span class="section">type: &quot;tags&quot;</span></span><br></pre></td></tr></table></figure></li>
<li><p>修改Next主题下的<code>_config.yml</code>，将<code>tags</code>添加到<code>menu</code>属性当中</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="attr">home:</span> <span class="string">/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-home</span></span><br><span class="line">  <span class="comment">#about: /about/ || fa fa-user</span></span><br><span class="line">  <span class="attr">tags:</span> <span class="string">/tags/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-tags</span></span><br><span class="line">  <span class="attr">categories:</span> <span class="string">/categories/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-th</span></span><br><span class="line">  <span class="attr">archives:</span> <span class="string">/archives/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-archive</span></span><br><span class="line">  <span class="comment">#schedule: /schedule/ || fa fa-calendar</span></span><br><span class="line">  <span class="comment">#sitemap: /sitemap.xml || fa fa-sitemap</span></span><br><span class="line">  <span class="comment">#commonweal: /404/ || fa fa-heartbeat</span></span><br></pre></td></tr></table></figure></li>
<li><p>重新部署，步骤同上，刷新页面后的结果</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_11.png" alt="pic_11"></p>
</li>
<li><p><code>home</code>、<code>categories</code>、<code>archives</code>等操作也是相同的</p>
</li>
</ol>
<h3 id="添加搜索功能"><a href="#添加搜索功能" class="headerlink" title="添加搜索功能"></a>添加搜索功能</h3><ol>
<li><p>打开博客根目录，添加博客搜索插件，在<code>cmd</code>中输入以下命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cnpm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>
<p>安装成功：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_12.png" alt="pic_12"></p>
</li>
<li><p>打开博客根目录下的<code>_config.yml</code>，在任意位置添加以下配置（有教程说新版的<code>hexo</code>中，<code>search.xml</code>需要改成<code>search.json</code>，否则部署到服务器搜索图标不能正常显示）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Search Config</span></span><br><span class="line"><span class="attr">search:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">search.xml</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">post</span></span><br><span class="line">  <span class="attr">format:</span> <span class="string">html</span></span><br><span class="line">  <span class="attr">limit:</span> <span class="number">1000</span></span><br></pre></td></tr></table></figure></li>
<li><p>修改Next主题下的<code>_config.yml</code>，修改<code>local_search</code>属性下的<code>enable</code>，将其改为<code>true</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Local Search</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/next-theme/hexo-generator-searchdb</span></span><br><span class="line"><span class="attr">local_search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># If auto, trigger search by changing input.</span></span><br><span class="line">  <span class="comment"># If manual, trigger search by pressing enter key or search button.</span></span><br><span class="line">  <span class="attr">trigger:</span> <span class="string">auto</span></span><br><span class="line">  <span class="comment"># Show top n results per article, show all results by setting to -1</span></span><br><span class="line">  <span class="attr">top_n_per_article:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment"># Unescape html strings to the readable one.</span></span><br><span class="line">  <span class="attr">unescape:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Preload the search data when the page loads.</span></span><br><span class="line">  <span class="attr">preload:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></li>
<li>重新部署，步骤同上</li>
</ol>
<h3 id="使用外链图片"><a href="#使用外链图片" class="headerlink" title="使用外链图片"></a>使用外链图片</h3><ol>
<li><p>注册腾讯云账号，选择对象存储</p>
</li>
<li><p>创建存储桶</p>
</li>
<li><p>创建成功之后上传文件</p>
</li>
<li><p>修改安全管理中的防盗链设置</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_13.png" alt="pic_13"></p>
</li>
<li><p>修改权限管理中的存储桶访问权限</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_14.png" alt="pic_14"></p>
</li>
<li><p>上传图片至存储桶，复制详情中的对象地址</p>
</li>
<li><p>在文章中使用外链</p>
</li>
<li><p>重新部署，步骤同上</p>
</li>
</ol>
<h3 id="增加统计信息"><a href="#增加统计信息" class="headerlink" title="增加统计信息"></a>增加统计信息</h3><ol>
<li><p>打开博客根目录，添加博客搜索插件，在<code>cmd</code>中输入以下命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cnpm install hexo-symbols-count-time --save</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>打开博客根目录下的<code>_config.yml</code>，在任意位置添加以下配置</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">symbols:</span> <span class="literal">true</span> <span class="comment"># 文章字数</span></span><br><span class="line">  <span class="attr">time:</span> <span class="literal">true</span> <span class="comment"># 阅读时长</span></span><br><span class="line">  <span class="attr">total_symbols:</span> <span class="literal">false</span> <span class="comment"># 所有文章总字数</span></span><br><span class="line">  <span class="attr">total_time:</span> <span class="literal">false</span> <span class="comment"># 所有文章阅读中时长</span></span><br><span class="line">  <span class="attr">awl:</span> <span class="number">4</span></span><br><span class="line">  <span class="attr">wpm:</span> <span class="number">275</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>修改Next主题下的<code>_config.yml</code>，修改如下配置</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">separated_meta:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">item_text_total:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">item_text_post:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li>
<li>重新部署，步骤同上</li>
</ol>
<h3 id="使用PicGo上传图片至图床"><a href="#使用PicGo上传图片至图床" class="headerlink" title="使用PicGo上传图片至图床"></a>使用PicGo上传图片至图床</h3><ol>
<li><p>下载PicGo，下载地址<a href="https://github.com/Molunerfinn/PicGo/releases">https://github.com/Molunerfinn/PicGo/releases </a> </p>
</li>
<li><p>腾讯云新建密钥：[访问密钥]—&gt;[API密钥管理]—&gt;[新建密钥]</p>
</li>
<li><p>打开安装完成后的PicGo，进行图床设置，设置后的结果为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_15.png" alt="pic_15"></p>
</li>
<li><p>点击确定并设置为默认图床，拖动本地图片上传，即可成功</p>
</li>
<li>文章中可以直接使用刚刚产生的外链</li>
<li>重新部署，步骤同上</li>
</ol>
]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库面试题总结</title>
    <url>/2022/03/20/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>总结一下网上的数据库面试题</p>
<a id="more"></a>
<h1 id="事务四大特性"><a href="#事务四大特性" class="headerlink" title="事务四大特性"></a>事务四大特性</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">原子性，要么执行，要么不执行  </span><br><span class="line">隔离性，所有操作全部执行完以前其它会话不能看到过程</span><br><span class="line">一致性，事务前后，数据总额一致</span><br><span class="line">持久性，一旦事务提交，对数据的改变就是永久的</span><br></pre></td></tr></table></figure>
<h1 id="数据库隔离级别"><a href="#数据库隔离级别" class="headerlink" title="数据库隔离级别"></a>数据库隔离级别</h1><p>数据库事务的隔离级别有4个，由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">脏读</th>
<th style="text-align:center">不可重复读</th>
<th style="text-align:center">幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Read uncommitted</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center">Read committed（Sql Server，Oracle）</td>
<td style="text-align:center">×</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center">Repeatable read（Mysql）</td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center">Serializable</td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
</tr>
</tbody>
</table>
</div>
<p>脏读：事务 B 去查询了事务 A 修改过的数据，但是此时事务 A 还没提交，所以事务 A 随时会回滚导致事务 B 再次查询就读不到刚才事务 A 修改的数据了，这就是脏读。</p>
<p>不可重复读：假设一个前提是事务 A 只能在事务 B 提交之后读取到它修改的数据，所以此时必然是不会发生脏读的。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。</p>
<p>不可重复读和脏读的区别是，脏读读取到的是一个未提交的数据，而不可重复读读取到的是前一个事务提交的数据。</p>
<p>幻读：幻读就是你一个事务用一样的 SQL 多次查询，结果每次查询都会发现查到一些之前没看到过的数据。注意，幻读特指的是你查询到了之前查询没看到过的数据。此时说明你是幻读了。</p>
<p>幻读和不可重复读所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。</p>
<h1 id="Mysql的存储引擎以及区别"><a href="#Mysql的存储引擎以及区别" class="headerlink" title="Mysql的存储引擎以及区别"></a>Mysql的存储引擎以及区别</h1><p>Mysql默认支持九种存储引擎（数据用各种不同的技术存储在文件或内存中。这些技术中的每一种技术都使用不同的存储机制、索引技巧、锁定水平并且最终提供广泛的不同的功能和能力。通过选择不同的技术，你能够获得额外的速度或者功能，从而改善你的应用的整体功能。）</p>
<ol>
<li>MyISAM：适合读密集的表<ol>
<li>不支持行锁(MyISAM只有表锁)，读取时对需要读到的所有表加锁，写入时则对表加排他锁；MyISAM表进行读操作时，它不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写操作；而对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作。</li>
<li>不支持事务</li>
<li>不支持外键</li>
<li>不支持崩溃后的安全恢复</li>
<li>在表有读取查询的同时，支持往表中插入新记录</li>
<li>支持BLOB和TEXT的前500个字符索引，支持全文索引和空间索引</li>
<li>支持延迟更新索引，极大地提升了写入性能</li>
<li>对于不会进行修改的表，支持压缩表，极大地减少了磁盘空间的占用</li>
<li>存储表的总行数，执行select count(*) from table时只要简单的读出保存好的行数即可</li>
<li>采用非聚集索引，索引文件的数据域存储指向数据文件的指针。</li>
</ol>
</li>
<li>InnoDB：InnoDB是MySQL的默认数据库引擎（5.5版之后），适合写密集的表<ol>
<li>支持行锁，采用MVCC来支持高并发，有可能死锁</li>
<li>支持事务</li>
<li>支持外键</li>
<li>支持崩溃后的安全恢复</li>
<li>不支持全文索引</li>
<li>不存储表的总行数，执行select count(*) from table时，InnoDB要扫描一遍整个表来计算有多少行。注意的是，当count(*)语句包含 where条件时，两种表的操作是一样的</li>
<li>主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问主键索引；最好使用自增主键，防止插入数据时，为维持B+树结构，文件的大调整。</li>
<li>DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除</li>
<li>对于AUTO_INCREMENT类型的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中，可以和其他字段一起建立联合索引更好和更快的auto_increment处理</li>
</ol>
</li>
</ol>
<h1 id="B-索引和hash索引"><a href="#B-索引和hash索引" class="headerlink" title="B+索引和hash索引"></a>B+索引和hash索引</h1><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20181107184452575.png" alt=""></p>
<p>在MySQL中，只有HEAP/MEMORY引擎表才能显式支持哈希索引（NDB也支持，但这个不常用），InnoDB引擎的自适应哈希索引（adaptive hash index）不在此列，因为这不是创建索引时可指定的。</p>
<ul>
<li>如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；</li>
<li>如果是范围查询检索，这时候哈希索引就毫无用武之地了 ，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；</li>
<li>同理， 哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；</li>
<li>哈希索引也不支持多列联合索引的最左匹配规则；</li>
<li>B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大， 在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题 。</li>
</ul>
<h1 id="索引的优缺点，什么时候使用索引，什么时候不能使用索引"><a href="#索引的优缺点，什么时候使用索引，什么时候不能使用索引" class="headerlink" title="索引的优缺点，什么时候使用索引，什么时候不能使用索引"></a>索引的优缺点，什么时候使用索引，什么时候不能使用索引</h1><ul>
<li>索引最大的好处是提高查询速度</li>
<li>缺点是更新数据时效率低，因为要同时更新索引</li>
<li>对数据进行频繁查询进建立索引，如果要频繁更改数据不建议使用索引</li>
</ul>
<h1 id="InnoDB索引和MyISAM索引的区别"><a href="#InnoDB索引和MyISAM索引的区别" class="headerlink" title="InnoDB索引和MyISAM索引的区别"></a><strong>InnoDB索引</strong>和<strong>MyISAM索引</strong>的区别</h1><p>InnoDB的数据文件本身就是主索引文件。而MyISAM的主索引和数据是分开的。</p>
<p>InnoDB的辅助索引data域存储相应记录主键的值而不是地址。而MyISAM的辅助索引和主索引没有多大区别。</p>
<h1 id="索引的底层实现（B-树，为何不采用红黑树，B树）重点"><a href="#索引的底层实现（B-树，为何不采用红黑树，B树）重点" class="headerlink" title="索引的底层实现（B+树，为何不采用红黑树，B树）重点"></a>索引的底层实现（B+树，为何不采用红黑树，B树）重点</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">树</th>
<th style="text-align:center">区别</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">红黑树</td>
<td style="text-align:center">增加，删除，红黑树会进行频繁的调整，来保证红黑树的性质，浪费时间</td>
</tr>
<tr>
<td style="text-align:center">B树也就是B-树</td>
<td style="text-align:center">B树，查询性能不稳定，查询结果高度不致，每个结点保存指向真实数据的指针，相比B+树每一层每屋存储的元素更多，显得更高一点。</td>
</tr>
<tr>
<td style="text-align:center">B+树</td>
<td style="text-align:center">B+树相比较于另外两种树,显得更矮更宽，查询层次更浅</td>
</tr>
</tbody>
</table>
</div>
<h1 id="为什么使用B-树"><a href="#为什么使用B-树" class="headerlink" title="为什么使用B+树"></a>为什么使用B+树</h1><ol>
<li>B+树是多路平衡查找树（B-Tree）的变种（Plus版本），多路绝对平衡查找树，他拥有B-树的优势</li>
<li>B+树的扫库扫表能力更强。</li>
<li>B+树的磁盘读写能力更强。</li>
<li>B+树的排序能力更强。</li>
<li>B+树的查询效率更加稳定（仁者见仁，智者见智）</li>
</ol>
<h1 id="Sql的优化"><a href="#Sql的优化" class="headerlink" title="Sql的优化"></a>Sql的优化</h1><ol>
<li>sql尽量使用索引，而且查询要走索引</li>
<li>对sql语句优化<ul>
<li>子查询变成left join</li>
<li>limit 分布优化，先利用ID定位，再分页</li>
<li>or条件优化，多个or条件可以用union all对结果进行合并（union all结果可能重复）</li>
<li>不必要的排序</li>
<li>where代替having,having 检索完所有记录，才进行过滤</li>
<li>避免嵌套查询</li>
<li>对多个字段进行等值查询时，联合索引</li>
</ul>
</li>
</ol>
<h1 id="索引最左前缀问题"><a href="#索引最左前缀问题" class="headerlink" title="索引最左前缀问题"></a>索引最左前缀问题</h1><p>假设你在表的state、city和zip数据列上建立了复合索引。索引中的数据行按照state/city/zip次序排列，因此它们也会自动地按照state/city/zip次序排列。这意味着，即使你在查询中只指定了state值，或者指定state和city值，MySQL也可以使用这个索引。因此，这个索引可以被用于搜索如下所示的数据列组合：state/city/zip；state/city；state。</p>
<p>MySQL不能利用这个索引来搜索没有包含在最左前缀的内容。例如，如果你按照city或zip来搜索，<br>就不会使用到这个索引。如果你搜索给定的state和具体的ZIP代码（索引的1和3列），该索引也是不能用于这种组合值的，尽管MySQL可以利用索引来查找匹配的state从而缩小搜索的范围。</p>
<p>explain命令的结果需要考虑属性type：ref就是使用了索引，index是对所有索引树进行扫描，而all是对整个磁盘的数据进行全表扫描。</p>
<h1 id="索引分类及索引失效条件"><a href="#索引分类及索引失效条件" class="headerlink" title="索引分类及索引失效条件"></a>索引分类及索引失效条件</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">索引类型</th>
<th style="text-align:center">概念</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">普通索引</td>
<td style="text-align:center">最基本的索引，没有任何限制</td>
</tr>
<tr>
<td style="text-align:center">唯一索引</td>
<td style="text-align:center">与”普通索引”类似，不同的就是：索引列的值必须唯一，但允许有空值。</td>
</tr>
<tr>
<td style="text-align:center">主键索引</td>
<td style="text-align:center">它是一种特殊的唯一索引，不允许有空值。</td>
</tr>
<tr>
<td style="text-align:center">全文索引</td>
<td style="text-align:center">针对较大的数据，生成全文索引很耗时间空间。</td>
</tr>
<tr>
<td style="text-align:center">组合索引</td>
<td style="text-align:center">为了更多的提高mysql效率可建立组合索引，遵循”最左前缀“原则</td>
</tr>
</tbody>
</table>
</div>
<p>失效条件：</p>
<ol>
<li>如果条件中有or，即使其中有条件带索引也不会使用</li>
<li>对于多列索引，不是使用的第一部分，则不会使用索引</li>
<li>like查询是以%开头</li>
<li>如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引</li>
<li>如果mysql估计使用全表扫描要比使用索引快,则不使用索引</li>
<li>where中索引列有运算</li>
<li>where中索引列使用了函数（+，-，*，/，! ）</li>
<li>当变量采用的是times变量，而表的字段采用的是date变量时</li>
<li>隐式类型转换导致索引失效</li>
</ol>
]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Python知识点</title>
    <url>/2021/11/07/Python%E6%8B%BE%E9%81%97/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下一些Python的知识点</p>
<a id="more"></a>
<h1 id="垃圾回收机制"><a href="#垃圾回收机制" class="headerlink" title="垃圾回收机制"></a>垃圾回收机制</h1><p>参考链接：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/83251959">Python垃圾回收机制！非常实用</a></li>
<li><a href="https://www.cnblogs.com/fat-girl-spring/p/15094805.html">Python垃圾回收机制</a></li>
</ol>
<p>Python采用的是引用计数机制为主，标记-清除和分代收集两种机制为辅的策略</p>
<h2 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h2><p>在Python中每一个对象的核心就是一个结构体PyObject，它的内部有一个引用计数器（ob_refcnt）。程序在运行的过程中会实时的更新ob_refcnt的值，来反映引用当前对象的名称数量。当某对象的引用计数值为0,那么它的内存就会被立即释放掉。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> struct_object &#123;</span><br><span class="line"> <span class="keyword">int</span> ob_refcnt;</span><br><span class="line"> struct_typeobject *ob_type;</span><br><span class="line">&#125; PyObject;</span><br></pre></td></tr></table></figure>
<p>以下情况是导致引用计数加一的情况:</p>
<ul>
<li>对象被创建，例如a=2</li>
<li>对象被引用，b=a</li>
<li>对象被作为参数，传入到一个函数中</li>
<li>对象作为一个元素，存储在容器中</li>
</ul>
<p>下面的情况则会导致引用计数减一:</p>
<ul>
<li>对象别名被显示销毁 del</li>
<li>对象别名被赋予新的对象</li>
<li>一个对象离开他的作用域</li>
<li>对象所在的容器被销毁或者是从容器中删除对象</li>
</ul>
<p>引用计数机制的优点：</p>
<ol>
<li>简单</li>
<li>实时性：一旦没有引用，内存就直接释放了。不用像其他机制等到特定时机。实时性还带来一个好处：处理回收内存的时间分摊到了平时。</li>
</ol>
<p>引用计数机制的缺点：</p>
<ol>
<li>维护引用计数消耗资源</li>
<li>循环引用</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list1 = []</span><br><span class="line">list2 = []</span><br><span class="line">list1.append(list2)</span><br><span class="line">list2.append(list1)</span><br></pre></td></tr></table></figure>
<p>list1与list2相互引用，如果不存在其他对象对它们的引用，list1与list2的引用计数也仍然为1，所占用的内存永远无法被回收，这将是致命的。</p>
<h2 id="标记-清除"><a href="#标记-清除" class="headerlink" title="标记-清除"></a>标记-清除</h2><p>Python采用了<strong>“标记-清除”(Mark and Sweep)</strong>算法，解决容器对象可能产生的循环引用问题。（注意，只有容器对象才会产生循环引用的情况，比如列表、字典、用户自定义类的对象、元组等。而像数字，字符串这类简单类型不会出现循环引用。作为一种优化策略，对于只包含简单类型的元组也不在标记清除算法的考虑之列）</p>
<p>该算法在进行垃圾回收时分成了两步，分别是：</p>
<ul>
<li>A）标记阶段，遍历所有的对象，如果是可达的（reachable），也就是还有对象引用它，那么就标记该对象为可达；</li>
<li>B）清除阶段，再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。</li>
</ul>
<p>在标记清除算法中，为了追踪容器对象，需要每个容器对象维护两个额外的指针，用来将容器对象组成一个双端链表，指针分别指向前后两个容器对象，方便插入和删除操作。python解释器(Cpython)维护了两个这样的双端链表，一个链表存放着需要被扫描的容器对象，另一个链表存放着临时不可达对象。每一个节点除了有一个记录当前引用计数的变量ref_count还有一个gc_ref变量，这个gc_ref是ref_count的一个副本，所以初始值为ref_count的大小。</p>
<p>过程：</p>
<ol>
<li>gc启动的时候，会逐个遍历”Object to Scan”链表中的容器对象，并且将当前对象所引用的所有对象的gc_ref减一。</li>
<li>接着，gc会再次扫描所有的容器对象，如果对象的gc_ref值为0，那么这个对象就被标记为GC_TENTATIVELY_UNREACHABLE，并且被移至”Unreachable”链表中。</li>
<li>如果对象的gc_ref不为0，那么这个对象就会被标记为GC_REACHABLE。同时当gc发现有一个节点是可达的，那么他会递归式的将从该节点出发可以到达的所有节点标记为GC_REACHABLE。</li>
<li>除了将所有可达节点标记为GC_REACHABLE之外，如果该节点当前在”Unreachable”链表中的话，还需要将其移回到”Object to Scan”链表中。</li>
<li>第二次遍历的所有对象都遍历完成之后，存在于”Unreachable”链表中的对象就是真正需要被释放的对象。</li>
</ol>
<h2 id="分代回收"><a href="#分代回收" class="headerlink" title="分代回收"></a>分代回收</h2><p>在循环引用对象的回收中，整个应用程序会被暂停，为了减少应用程序暂停的时间，Python 通过<strong>“分代回收”(Generational Collection)</strong>以空间换时间的方法提高垃圾回收效率。</p>
<p>分代回收是基于这样的一个统计事实，<strong>对于程序，存在一定比例的内存块的生存周期比较短；而剩下的内存块，生存周期会比较长，甚至会从程序开始一直持续到程序结束。生存期较短对象的比例通常在 80%～90% 之间，这种思想简单点说就是：对象存在时间越长，越可能不是垃圾，应该越少去收集。这样在执行标记-清除算法时可以有效减小遍历的对象数，从而提高垃圾回收的速度。</strong></p>
<p>python gc给对象定义了三种世代(0,1,2),每一个新生对象在generation zero中，如果它在一轮gc扫描中活了下来，那么它将被移至generation one,在那里他将较少的被扫描，如果它又活过了一轮gc,它又将被移至generation two，在那里它被扫描的次数将会更少。</p>
<p>gc的扫描在什么时候会被触发呢?答案是当某一世代中被分配的对象与被释放的对象之差达到某一阈值的时候，就会触发gc对某一世代的扫描。值得注意的是当某一世代的扫描被触发的时候，比该世代年轻的世代也会被扫描。也就是说如果世代2的gc扫描被触发了，那么世代0,世代1也将被扫描，如果世代1的gc扫描被触发，世代0也会被扫描。</p>
<p>该阈值可以通过下面两个函数查看和调整:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gc.get_threshold() <span class="comment"># (threshold0, threshold1, threshold2).</span></span><br><span class="line">gc.set_threshold(threshold0[, threshold1[, threshold2]])</span><br></pre></td></tr></table></figure>
<p>下面对set_threshold()中的三个参数threshold0, threshold1, threshold2进行介绍。gc会记录自从上次收集以来新分配的对象数量与释放的对象数量，当两者之差超过threshold0的值时，gc的扫描就会启动，初始的时候只有世代0被检查。如果自从世代1最近一次被检查以来，世代0被检查超过threshold1次，那么对世代1的检查将被触发。相同的，如果自从世代2最近一次被检查以来，世代1被检查超过threshold2次，那么对世代2的检查将被触发。get_threshold()是获取三者的值，默认值为(700,10,10).</p>
<h1 id="整数缓存问题"><a href="#整数缓存问题" class="headerlink" title="整数缓存问题"></a>整数缓存问题</h1><p>Python仅仅对比较小的整数对象进行缓存（范围为[-5,256]），而并非所有的整数对象。需要注意的是，这仅仅是在<strong>命令行</strong>中执行，而在Pycharm或保存为文件执行，结果是不一样的，因为解释器做了一部分优化（范围变成了[-5, 任意正整数]）（注：自己在Pycharm中实践发现小于-5的好像也可）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="number">1000</span></span><br><span class="line">b = <span class="number">1000</span></span><br><span class="line">a <span class="keyword">is</span> b <span class="comment"># False</span></span><br><span class="line"></span><br><span class="line">a = <span class="number">100</span></span><br><span class="line">b = <span class="number">100</span></span><br><span class="line">a <span class="keyword">is</span> b <span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<h1 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h1><ol>
<li>字符串拼接尽量使用<code>join()</code>而不是<code>+=</code>，因为<code>+=</code>每次会创建新对象</li>
<li><strong>字符串驻留</strong>：仅保存一份相同且不可变的字符串的方法，不同的值被存放在字符串驻留池中。Python支持字符串驻留机制，对于符合标识规则的字符串（仅包含下划线<code>_</code>，字母和数字）会启用字符串驻留机制。（似乎Pycharm中不需要满足命名规则）</li>
</ol>
<h1 id="字典核心底层原理"><a href="#字典核心底层原理" class="headerlink" title="字典核心底层原理"></a>字典核心底层原理</h1><p>字典对象核心是散列表。散列表是一个稀疏数组（总有空白元素的数组），数组的每个单元叫做bucket。每个bucket有两个部分：一是键对象的引用，一个是值对象的引用。可以通过偏移量来读取指定的bucket。</p>
<p>键值对放进字典的底层过程：</p>
<ol>
<li>计算见的散列值，python中通过<code>hash()</code>来计算。</li>
<li>查看偏移量对应的bucket是否为空，如果为空，则放入。如果不为空，则取新的偏移量，查看新偏移量对应的bucket是否为空，直到找到空的bucket存放。</li>
<li>如果数组2/3已经满了，自动扩容，已存放的自动复制</li>
</ol>
<p>根据键查找键值对的底层过程：</p>
<ol>
<li>算散列值</li>
<li>根据散列值找bucket，bucket为空，返回None；bucket不为空则取出键，并计算新散列值，比较第一步的散列值和当前散列值是否相同。相同返回，不同则继续取新的散列值。</li>
</ol>
<h1 id="判断"><a href="#判断" class="headerlink" title="判断"></a>判断</h1><p><code>if not A</code> 和 <code>if A is None</code> 看起来都是在判断<code>A</code>是否为<strong>空</strong>，实际上这两者是不同的：</p>
<ul>
<li><code>if not A</code> 判断的是<code>A</code>是否为<strong>空</strong>，也就是说里面有东西没？</li>
<li><code>if A is None</code>则判断的是<code>A</code>是否<strong>声明并定义</strong>了？</li>
</ul>
<h1 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h1><p>代码优化：</p>
<ol>
<li>尽量减少循环内部不必要的计算</li>
<li>嵌套循环中，尽量减少内层循环的计算，尽可能向外提</li>
<li>局部变量查询较快，尽量使用局部变量</li>
</ol>
<h2 id="for…else循环"><a href="#for…else循环" class="headerlink" title="for…else循环"></a>for…else循环</h2><p>当迭代的对象迭代完并为空时，位于else的子句将执行，而如果在for循环中含有break时则直接终止循环，并不会执行else子句。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2022/2/24 18:51</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">5</span>:</span><br><span class="line">        print(<span class="string">f&quot;Find <span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">&quot;Not find&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>预期的结果是找到5时打印出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Find <span class="number">5</span></span><br></pre></td></tr></table></figure>
<h1 id="浅拷贝和深拷贝"><a href="#浅拷贝和深拷贝" class="headerlink" title="浅拷贝和深拷贝"></a>浅拷贝和深拷贝</h1><p>浅拷贝：不拷贝子对象的内容，只是拷贝子对象的引用</p>
<p>深拷贝：会连子对象的内存也全部拷贝一份，对子对象的修改不会影响源对象</p>
<p><strong>浅拷贝</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">a = [<span class="number">10</span>, <span class="number">20</span>, [<span class="number">30</span>, <span class="number">40</span>]]</span><br><span class="line">b_shallow = copy.copy(a)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;a:&quot;</span>, a)</span><br><span class="line">print(<span class="string">&quot;b_shallow:&quot;</span>, b_shallow)</span><br><span class="line"></span><br><span class="line">b_shallow.append(<span class="number">60</span>)</span><br><span class="line">b_shallow[<span class="number">2</span>].append(<span class="number">70</span>)</span><br><span class="line">print(<span class="string">&quot;######浅拷贝后######&quot;</span>)</span><br><span class="line">print(<span class="string">&quot;a:&quot;</span>, a)</span><br><span class="line">print(<span class="string">&quot;b_shallow:&quot;</span>, b_shallow)</span><br><span class="line"></span><br><span class="line"><span class="comment"># a: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># b_shallow: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># ######浅拷贝后######</span></span><br><span class="line"><span class="comment"># a: [10, 20, [30, 40, 70]]</span></span><br><span class="line"><span class="comment"># b_shallow: [10, 20, [30, 40, 70], 60]</span></span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/shallow.png" alt="浅拷贝"><strong>深拷贝</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">a = [<span class="number">10</span>, <span class="number">20</span>, [<span class="number">30</span>, <span class="number">40</span>]]</span><br><span class="line">b_deep = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;a:&quot;</span>, a)</span><br><span class="line">print(<span class="string">&quot;b_deep:&quot;</span>, b_deep)</span><br><span class="line"></span><br><span class="line">b_deep.append(<span class="number">60</span>)</span><br><span class="line">b_deep[<span class="number">2</span>].append(<span class="number">70</span>)</span><br><span class="line">print(<span class="string">&quot;######深拷贝######&quot;</span>)</span><br><span class="line">print(<span class="string">&quot;a:&quot;</span>, a)</span><br><span class="line">print(<span class="string">&quot;b_deep:&quot;</span>, b_deep)</span><br><span class="line"></span><br><span class="line"><span class="comment"># a: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># b_deep: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># ######深拷贝######</span></span><br><span class="line"><span class="comment"># a: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># b_deep: [10, 20, [30, 40, 70], 60]</span></span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/deep.png" alt="深拷贝"></p>
<h1 id="LEGB规则"><a href="#LEGB规则" class="headerlink" title="LEGB规则"></a>LEGB规则</h1><p>Python在查找名称时，是按照LEGB规则查找的：Local $\longrightarrow$ Enclosed $\longrightarrow$ Global $\longrightarrow$ Built in</p>
<ul>
<li>Local：指的是函数或者类的方法的内部</li>
<li>Enclosed：指的是嵌套函数（一个函数内包裹另一个函数，闭包）</li>
<li>Global：指的是模块中的全局变量</li>
<li>Built in：指的是Python为自己保留的特殊名称</li>
</ul>
<h1 id="MRO"><a href="#MRO" class="headerlink" title="MRO"></a>MRO</h1><p>Python支持多继承，如果父类中有相同名字的方法，在子类没有指定父类名时，解释器将“从左到右”顺序搜索。</p>
<p>MRO（Method Resolution Order）：方法解析顺序。我们可以通过<code>mro()</code>方法获取类的层次结构，方法也是按照这个类的层次结构寻找的。</p>
<h1 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h1><p>Serialization系列化，将内存中对象存储下来，变成一个个字节。</p>
<p>deSerialization反序列化，将文件的一个个字节到内存中。</p>
<p>序列化保存到文件就是持久化。</p>
<p>可将数据序列化后持久化，或者网络传输，也可以将文件中或者网络接受到的字节序列反序列化。</p>
<h1 id="sys-path和模块路径搜索"><a href="#sys-path和模块路径搜索" class="headerlink" title="sys.path和模块路径搜索"></a>sys.path和模块路径搜索</h1><p>当我们导入某个模块文件时，<code>Python</code>解释器一般按照以下路径寻找模块文件（按照顺序寻找，找到即停不继续往下寻找）：</p>
<ol>
<li>内置模块</li>
<li>当前目录</li>
<li>程序的主目录</li>
<li><code>pythonpath</code>目录（如果已经设置了<code>pythonpath</code>环境变量）</li>
<li>标准链接库目录</li>
<li>第三方库目录（<code>site-packages</code>目录）</li>
<li><code>.pth</code>文件的内容（如果存在的话）</li>
<li><code>sys.path.append()</code>临时添加的目录</li>
</ol>
<h1 id="进程和线程区别"><a href="#进程和线程区别" class="headerlink" title="进程和线程区别"></a>进程和线程区别</h1><div class="table-container">
<table>
<thead>
<tr>
<th>区别</th>
<th>进程</th>
<th>线程</th>
</tr>
</thead>
<tbody>
<tr>
<td>根本区别</td>
<td>作为资源分配的单位</td>
<td>调度和执行的单位</td>
</tr>
<tr>
<td>开销</td>
<td>每个进程都有独立的代码和数据空间，进程间的切换会有较大的开销</td>
<td>线程可以看成是轻量级的进程，多个线程共享内存，线程切换的开销小</td>
</tr>
<tr>
<td>所处环境</td>
<td>在操作系统中，同时运行的多个任务</td>
<td>在程序中多个顺序流同时执行</td>
</tr>
<tr>
<td>分配内存</td>
<td>系统在运行的时候为每一个进程分配不同的内存区域</td>
<td>线程使用的资源是他所属进程的资源</td>
</tr>
<tr>
<td>包含关系</td>
<td>一个进程可以拥有多个线程</td>
<td>线程是进程的一部分，所有线程有时候称为是轻量级的进程</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习Tricks</title>
    <url>/2022/10/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Tricks/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>总结一些自己在机器学习应用过程中遇到的一些问题，包括理论、代码实践等方面。</p>
<a id="more"></a>
<h1 id="One-Hot编码"><a href="#One-Hot编码" class="headerlink" title="One-Hot编码"></a>One-Hot编码</h1><p>One-hot编码也叫独热编码，又称一位有效编码。方法就是用N位对N个状态进行表示，但是其中只有一位为1，剩下N-1位全为0。例如，特征为性别，就需要变成10和01。</p>
<p>在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的。而常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。使用独热编码（One-Hot Encoding），将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。将离散型特征使用独热编码（One-Hot Encoding），会让特征之间的距离计算更加合理。</p>
<p>举个例子，如果我们现在一个特征有五个取值，如果不采用One-Hot编码，则分别表示为演员=0，厨师=1，公务员=2，教师=3，律师=4，那么教师和厨师的距离为2，律师与厨师的距离为3，这显然是不合理的。比较合理的做法是将两个工作之间的距离表示为sqrt(2)，即两个工作之间的距离是一样的。</p>
<p>总结一下，如果特征的大小表示如果有意义的话，比如我们用1-9表示年龄，这种特征的大小表示就是有意义的，所以这种情况下就不需要进行One-Hot编码；如果特征的大小没有意义，仅仅表示状态时则使用One-Hot编码。</p>
<p>pandas实现：首先对f3这个特征做One-Hot编码，接着将生成的df和原来的df进行拼接，最后删除原来的f3特征</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 1: using get_dummies to encode feature</span></span><br><span class="line">dummy_df = pd.get_dummies(df[<span class="string">&quot;gender&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 2: concat dummy_df with original df</span></span><br><span class="line">df = pd.concat((df, dummy_df), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 3: remove original feature</span></span><br><span class="line">df = df.drop(<span class="string">&quot;gender&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># simplified form</span></span><br><span class="line"><span class="comment"># df = pd.concat((df, pd.get_dummies(df[&quot;gender&quot;])), axis=1)</span></span><br><span class="line"><span class="comment"># df = df.drop(&quot;gender&quot;, axis=1)</span></span><br></pre></td></tr></table></figure>
<p>存在问题：</p>
<ol>
<li><p>采用这种方法实现会存在问题，比如将性别划分成gender_male和gender_female时，这两种特征其实是冗余的，这个问题在数学中叫做多重共线性(Multicollinearity)，在pandas处理时也有人称之为虚拟变量陷阱(Dummy Varialble Trap)。解决办法就是加入参数drop_first=True，作用是除去第一个虚拟变量，然转化后的虚拟变量从k和变成k-1个。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 1: using get_dummies to encode feature</span></span><br><span class="line">dummy_df = pd.get_dummies(df[<span class="string">&quot;gender&quot;</span>], drop_first=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 2: concat dummy_df with original df</span></span><br><span class="line">df = pd.concat((df, dummy_df), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 3: remove original feature</span></span><br><span class="line">df = df.drop(<span class="string">&quot;gender&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># simplified form</span></span><br><span class="line"><span class="comment"># df = pd.concat((df, pd.get_dummies(df[&quot;gender&quot;], drop_first=True)), axis=1)</span></span><br><span class="line"><span class="comment"># df = df.drop(&quot;gender&quot;, axis=1)</span></span><br></pre></td></tr></table></figure></li>
<li><p>测试集中可能出现训练集中没出现过的变量。解决办法：①将训练集和测试集一起get_dummies，然后再切分；②检测不一致的列，然后在缺少这些列的数据集中加入取值全为0的同名列。③使用sklearn的OneHotEncoder</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>],</span><br><span class="line">        [<span class="number">1003</span>, <span class="string">&quot;unknown&quot;</span>, <span class="number">88</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train = pd.concat((train, pd.get_dummies(train[<span class="string">&quot;gender&quot;</span>], drop_first=<span class="literal">True</span>)), axis=<span class="number">1</span>)</span><br><span class="line">train.drop(<span class="string">&quot;gender&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line">test = pd.concat((test, pd.get_dummies(test[<span class="string">&quot;gender&quot;</span>], drop_first=<span class="literal">True</span>)), axis=<span class="number">1</span>)</span><br><span class="line">test.drop(<span class="string">&quot;gender&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">list</span>(test.columns.difference(train.columns)):<span class="comment">#train没有的列</span></span><br><span class="line">    df_obj = pd.DataFrame(&#123;col:np.squeeze(np.zeros((<span class="number">1</span>,train.shape[<span class="number">0</span>])))&#125;)</span><br><span class="line">    train = pd.concat([train,df_obj], axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">list</span>(train.columns.difference(test.columns)):<span class="comment">#test没有的列</span></span><br><span class="line">    df_obj = pd.DataFrame(&#123;col:np.squeeze(np.zeros((<span class="number">1</span>,test.shape[<span class="number">0</span>])))&#125;)</span><br><span class="line">    test = pd.concat([test,df_obj], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>sklearn实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line">train = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>],</span><br><span class="line">        [<span class="number">1003</span>, <span class="string">&quot;unknown&quot;</span>, <span class="number">88</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># drop:k-1 to represent k; handle_unknown:for missing value</span></span><br><span class="line">encoder = OneHotEncoder(sparse=<span class="literal">False</span>, handle_unknown=<span class="string">&#x27;ignore&#x27;</span>, drop=<span class="string">&quot;first&quot;</span>)</span><br><span class="line"><span class="comment"># fit</span></span><br><span class="line">enc = encoder.fit(train[[<span class="string">&quot;gender&quot;</span>]])</span><br><span class="line"><span class="comment"># 获取新列名</span></span><br><span class="line">columns = enc.get_feature_names_out([<span class="string">&quot;gender&quot;</span>])</span><br><span class="line"><span class="comment"># 转换测试数据</span></span><br><span class="line">enc_arr = enc.transform(test[[<span class="string">&quot;gender&quot;</span>]])</span><br><span class="line"><span class="comment"># 生成dataframe</span></span><br><span class="line">enc_df = pd.DataFrame(enc_arr, columns=columns)</span><br><span class="line">new_data = pd.concat([test, enc_df], axis=<span class="number">1</span>)</span><br><span class="line">new_data.drop([<span class="string">&quot;gender&quot;</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">new_data</span><br></pre></td></tr></table></figure>
<h1 id="编码转换"><a href="#编码转换" class="headerlink" title="编码转换"></a>编码转换</h1><p>对于某一个特征，比如频率，原始数据可能时low、mid、high这种字符类型，模型是没办法利用这些信息的，所以应当把这种字符类型的变量转变成数值类型的变量。</p>
<p>pandas实现：</p>
<p>最常用的是pd.factorize()，返回值为一个元组，分别表示转换之后的数字和原来的index。我们应该取元组的第一个元素作为我们的结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;../dataset/dataTrain.csv&#x27;</span>)</span><br><span class="line">data[<span class="string">&quot;f3&quot;</span>] = pd.factorize(data[<span class="string">&quot;f3&quot;</span>])[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>但是这种方法有个缺点，先出现的编码小，后出现的编码大。比如频率越高，编码的值应该越大，但是pd.factorize()就捕捉不到这个特征，此时我们可以使用map映射。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;../dataset/dataTrain.csv&#x27;</span>)</span><br><span class="line">col_mapping = &#123;</span><br><span class="line">    <span class="string">&quot;low&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">&quot;mid&quot;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;high&quot;</span>: <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line">data.f3 = data.f3.<span class="built_in">map</span>(col_mapping)</span><br></pre></td></tr></table></figure>
<p>sklearn实现：和One-Hot编码相似，先fit，然后再transform</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;../dataset/dataTrain.csv&#x27;</span>)</span><br><span class="line">cat_columns = [<span class="string">&#x27;f3&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cat_columns:</span><br><span class="line">    lb = LabelEncoder()</span><br><span class="line">    lb.fit(data[col])</span><br><span class="line">    data[col] = lb.transform(data[col])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式</title>
    <url>/2021/11/25/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>设计模式是面向对象语言特有的内容，是面对某一类问题时的固定做法。</p>
<a id="more"></a>
<h1 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h1><p>工厂模式（Factory Pattern）的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<p>在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2021/11/25 13:07</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Factory</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">manufacture</span>(<span class="params">self, brand</span>):</span></span><br><span class="line">        <span class="keyword">if</span> brand == <span class="string">&quot;Benz&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> Benz()</span><br><span class="line">        <span class="keyword">elif</span> brand == <span class="string">&quot;Ferrari&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> Ferrari()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Benz</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;I am Benz&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ferrari</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;I am Ferrari&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    factory = Factory()</span><br><span class="line">    factory.manufacture(<span class="string">&quot;Benz&quot;</span>)</span><br><span class="line">    factory.manufacture(<span class="string">&quot;Ferrari&quot;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h1><p>单例模式（Singleton Pattern）的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<p>这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2021/11/25 14:08</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySingleton</span>:</span></span><br><span class="line">    __obj = <span class="literal">None</span></span><br><span class="line">    __init_flag = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>(<span class="params">cls, *args, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">if</span> cls.__obj <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            cls.__obj = <span class="built_in">object</span>.__new__(cls)</span><br><span class="line">        <span class="keyword">return</span> cls.__obj</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        <span class="keyword">if</span> MySingleton.__init_flag:</span><br><span class="line">            print(<span class="string">&quot;init.....&quot;</span>)</span><br><span class="line">            self.name = name</span><br><span class="line">            MySingleton.__init_flag = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    a = MySingleton(<span class="string">&quot;aa&quot;</span>)</span><br><span class="line">    b = MySingleton(<span class="string">&quot;bb&quot;</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>毕设知识点总结</title>
    <url>/2021/04/06/%E6%AF%95%E8%AE%BE%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>毕设的项目也算是做完了，总结一下项目过程中遇见的一些问题和解决方案，避免以后再次踩坑。</p>
<a id="more"></a>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="current-user的实现机制"><a href="#current-user的实现机制" class="headerlink" title="current_user的实现机制"></a>current_user的实现机制</h2><ol>
<li><p>首先需要创建一个<code>LoginManager</code>的对象实例并注册到<code>app</code>对象实例之中，并提供一个<code>load_user</code>回调函数来获取当前登录的对象</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 会话管理</span></span><br><span class="line">login_manager = LoginManager()</span><br><span class="line"><span class="comment"># 绑定登陆视图的路由</span></span><br><span class="line">login_manager.login_view = <span class="string">&quot;login&quot;</span></span><br><span class="line">login_manager.login_message = <span class="string">&quot;请您先登陆！&quot;</span></span><br><span class="line">login_manager.session_protection = <span class="string">&quot;strong&quot;</span></span><br><span class="line">app.config[<span class="string">&quot;SECRET_KEY&quot;</span>] = <span class="string">&quot;123456&quot;</span></span><br><span class="line">login_manager.init_app(app)</span><br><span class="line"></span><br><span class="line"><span class="meta">@login_manager.user_loader</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_user</span>(<span class="params">user_id</span>):</span></span><br><span class="line">    <span class="keyword">return</span> User.query.filter_by(user_id=user_id).first()</span><br></pre></td></tr></table></figure>
<p>注：<code>load_user</code>接受一个<code>unicode</code>编码的 <code>ID</code>并返回一个用户对象，如果用户不存在就返回<code>None</code>。</p>
</li>
</ol>
<ol>
<li><p>接着你的<code>User</code>模型要继承<code>UserMixin</code>这个类，并且实现<code>is_authenticated</code>、<code>is_active</code>、<code>is_anonymous</code>、<code>get_id</code>方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_authenticated</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_active</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_anonymous</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 后面login_user用来作为用户的id</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_id</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> self.user_id</span><br></pre></td></tr></table></figure></li>
<li><p>在登陆时调用<code>login_user</code>方法，然后就可以在上下文之中随时随地使用<code>current_user</code>了</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login_user</span>(<span class="params">user, remember=<span class="literal">False</span>, force=<span class="literal">False</span>, fresh=<span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> force <span class="keyword">and</span> <span class="keyword">not</span> user.is_active:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    user_id = <span class="built_in">getattr</span>(user, current_app.login_manager.id_attribute)()</span><br><span class="line">    session[<span class="string">&#x27;user_id&#x27;</span>] = user_id</span><br><span class="line">    session[<span class="string">&#x27;_fresh&#x27;</span>] = fresh</span><br><span class="line">    session[<span class="string">&#x27;_id&#x27;</span>] = current_app.login_manager._session_identifier_generator()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> remember:</span><br><span class="line">        session[<span class="string">&#x27;remember&#x27;</span>] = <span class="string">&#x27;set&#x27;</span></span><br><span class="line"></span><br><span class="line">    _request_ctx_stack.top.user = user</span><br><span class="line">    user_logged_in.send(current_app._get_current_object(), user=_get_user())</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>用户的<code>user_id</code>是通过<code>get_attr</code>方法访问<code>login_manager</code>的<code>id_attribute</code>属性实现的，而最终访问的<code>user_id</code>就是在上一步在模型中添加的<code>get_id</code>方法获取到的值</p>
</li>
</ol>
<h2 id="openpyxl对excel的操作"><a href="#openpyxl对excel的操作" class="headerlink" title="openpyxl对excel的操作"></a>openpyxl对excel的操作</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> openpyxl</span><br><span class="line"><span class="comment"># 创建工作簿（默认创建一个工作表）</span></span><br><span class="line">new_excel = openpyxl.Workbook()</span><br><span class="line"><span class="comment"># 选中第一个工作簿</span></span><br><span class="line">work_sheet = new_excel.active</span><br><span class="line"><span class="comment"># 设置表头</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(optional_headers)):</span><br><span class="line">    work_sheet.cell(row=<span class="number">1</span>, column=i+<span class="number">1</span>, value=optional_headers[i]).alignment = Alignment(wrapText=<span class="literal">True</span>, horizontal=<span class="string">&#x27;center&#x27;</span>, vertical=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">    <span class="comment"># 填写内容</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(data_list)):</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(data_list[<span class="number">0</span>])):</span><br><span class="line">        work_sheet.cell(row=j+<span class="number">2</span>, column=k+<span class="number">1</span>, value=data_list[j][k]).alignment = Alignment(wrapText=<span class="literal">True</span>, horizontal=<span class="string">&#x27;center&#x27;</span>, vertical=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"><span class="comment"># 用时间戳给文件命名</span></span><br><span class="line">now_time = datetime.now().strftime(<span class="string">&quot;%Y-%m-%d-%H-%M-%S&quot;</span>).replace(<span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">excel_name = current_user.user_name + <span class="string">&#x27;_&#x27;</span> + now_time + <span class="string">&#x27;_&#x27;</span></span><br><span class="line"><span class="keyword">if</span> data[<span class="string">&quot;export_type&quot;</span>] == <span class="number">0</span>:</span><br><span class="line">    excel_name = excel_name + <span class="string">&quot;专利信息.xls&quot;</span></span><br><span class="line"><span class="keyword">elif</span> data[<span class="string">&quot;export_type&quot;</span>] == <span class="number">1</span>:</span><br><span class="line">    excel_name = excel_name + <span class="string">&quot;论文信息.xls&quot;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    excel_name = excel_name + <span class="string">&quot;项目信息.xls&quot;</span></span><br><span class="line">new_excel.save(<span class="string">&quot;.\\files\\&quot;</span> + excel_name)</span><br><span class="line">new_excel.close()</span><br></pre></td></tr></table></figure>
<h2 id="后端发送文件到前端"><a href="#后端发送文件到前端" class="headerlink" title="后端发送文件到前端"></a>后端发送文件到前端</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = make_response(send_from_directory(<span class="string">&quot;.\\files&quot;</span>, excel_name))</span><br><span class="line">res.headers[<span class="string">&#x27;Content-Type&#x27;</span>] = <span class="string">&#x27;text/plain;charset=UTF-8&#x27;</span></span><br><span class="line">res.headers[<span class="string">&#x27;filename&#x27;</span>] = quote(excel_name.encode(<span class="string">&quot;utf-8&quot;</span>))</span><br></pre></td></tr></table></figure>
<h2 id="前端以POST方式请求下载文件"><a href="#前端以POST方式请求下载文件" class="headerlink" title="前端以POST方式请求下载文件"></a>前端以POST方式请求下载文件</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$.ajax(&#123;</span><br><span class="line">    type: <span class="string">&quot;POST&quot;</span>,</span><br><span class="line">    url: <span class="built_in">window</span>.location.pathname,</span><br><span class="line">    contentType: <span class="string">&quot;application/json;charset=UTF-8&quot;</span>,</span><br><span class="line">    data:<span class="built_in">JSON</span>.stringify(data),</span><br><span class="line">    xhrFields:&#123;</span><br><span class="line">        responseType: <span class="string">&#x27;blob&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="function"><span class="title">success</span>(<span class="params">res, status, xhr</span>)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (res)&#123;</span><br><span class="line">            <span class="keyword">let</span> parse_data = <span class="keyword">new</span> Blob([res]);</span><br><span class="line">            <span class="keyword">let</span> download_url = <span class="built_in">window</span>.URL.createObjectURL(parse_data);</span><br><span class="line">            <span class="keyword">let</span> filename = xhr.getResponseHeader(<span class="string">&quot;filename&quot;</span>);</span><br><span class="line">            <span class="keyword">let</span> link = <span class="built_in">document</span>.createElement(<span class="string">&#x27;a&#x27;</span>);</span><br><span class="line">            link.href = download_url;</span><br><span class="line">            link.download = filename;</span><br><span class="line">            link.click();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="邮件及缓存"><a href="#邮件及缓存" class="headerlink" title="邮件及缓存"></a>邮件及缓存</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask_mail <span class="keyword">import</span> Message, Mail</span><br><span class="line"><span class="keyword">from</span> flask_caching <span class="keyword">import</span> Cache</span><br><span class="line"></span><br><span class="line"><span class="comment"># 邮件</span></span><br><span class="line">mail = Mail(app)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 缓存</span></span><br><span class="line">cache = Cache(app)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成验证码</span></span><br><span class="line">code_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    random_num = random.randint(<span class="number">0</span>, <span class="number">9</span>)</span><br><span class="line">    code_list.append(<span class="built_in">str</span>(random_num))</span><br><span class="line">verification_code = <span class="string">&#x27;&#x27;</span>.join(code_list)</span><br><span class="line"><span class="comment"># 发送邮件</span></span><br><span class="line">message = Message(<span class="string">&#x27;科研信息管理系统验证码&#x27;</span>, recipients=[email_account], body=<span class="string">&#x27;您的验证码是：%s&#x27;</span> % verification_code)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 发送</span></span><br><span class="line">    mail.send(message)</span><br><span class="line">    <span class="comment"># 验证码放入缓存</span></span><br><span class="line">    cache.<span class="built_in">set</span>(email_account, verification_code)</span><br><span class="line">    data = <span class="string">&quot;验证码发送成功&quot;</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    data = <span class="string">&quot;验证码发送失败，请检查邮箱是否输入正确&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="推送flask上下文"><a href="#推送flask上下文" class="headerlink" title="推送flask上下文"></a>推送flask上下文</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">app.app_context().push()</span><br></pre></td></tr></table></figure>
<h2 id="前端拖动插件dragula-js"><a href="#前端拖动插件dragula-js" class="headerlink" title="前端拖动插件dragula.js"></a>前端拖动插件dragula.js</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Modal Popup--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal fade&quot;</span> <span class="attr">id</span>=<span class="string">&quot;exampleModalCenter&quot;</span> <span class="attr">tabindex</span>=<span class="string">&quot;-1&quot;</span> <span class="attr">role</span>=<span class="string">&quot;dialog&quot;</span> <span class="attr">aria-labelledby</span>=<span class="string">&quot;exampleModalCenterTitle&quot;</span> <span class="attr">aria-hidden</span>=<span class="string">&quot;true&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-dialog modal-dialog-centered&quot;</span> <span class="attr">role</span>=<span class="string">&quot;document&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-content&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-header&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">h5</span> <span class="attr">class</span>=<span class="string">&quot;modal-title&quot;</span> <span class="attr">id</span>=<span class="string">&quot;exampleModalCenterTitle&quot;</span>&gt;</span>请选择需要导出的信息项<span class="tag">&lt;/<span class="name">h5</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> <span class="attr">class</span>=<span class="string">&quot;close&quot;</span> <span class="attr">data-dismiss</span>=<span class="string">&quot;modal&quot;</span> <span class="attr">aria-label</span>=<span class="string">&quot;Close&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">aria-hidden</span>=<span class="string">&quot;true&quot;</span>&gt;</span><span class="symbol">&amp;times;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-body&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;row&quot;</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;bagger&quot;</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;col-md-6&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;left&quot;</span> <span class="attr">class</span>=<span class="string">&quot;includer&quot;</span> <span class="attr">style</span>=<span class="string">&quot;background-color: rgb(161, 211, 169);&quot;</span>&gt;</span></span><br><span class="line">                            &#123;% if patent_headers %&#125;</span><br><span class="line">                            &#123;% for item in patent_headers  %&#125;</span><br><span class="line">                            <span class="tag">&lt;<span class="name">div</span>&gt;</span>&#123;&#123; item &#125;&#125;<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                            &#123;% endfor %&#125;</span><br><span class="line">                            &#123;% endif %&#125;</span><br><span class="line">                        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;right&quot;</span> <span class="attr">class</span>=<span class="string">&quot;includer&quot;</span> <span class="attr">style</span>=<span class="string">&quot;background-color: rgb(187, 206, 235);&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;col-md-6&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;col-md-6&quot;</span> <span class="attr">style</span>=<span class="string">&quot;text-align: center;&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">strong</span>&gt;</span>可选信息项<span class="tag">&lt;/<span class="name">strong</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;col-md-6&quot;</span> <span class="attr">style</span>=<span class="string">&quot;text-align: center;&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">strong</span>&gt;</span>已选信息项<span class="tag">&lt;/<span class="name">strong</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-footer&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> <span class="attr">class</span>=<span class="string">&quot;btn btn-secondary&quot;</span> <span class="attr">data-dismiss</span>=<span class="string">&quot;modal&quot;</span>&gt;</span>关闭<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- /.col-sm-9 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- /Modal Popup--&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="前端省市区地址选择distpicker-js"><a href="#前端省市区地址选择distpicker-js" class="headerlink" title="前端省市区地址选择distpicker.js"></a>前端省市区地址选择distpicker.js</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">data-toggle</span>=<span class="string">&quot;distpicker&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-inline&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">data-province</span>=<span class="string">&quot;省&quot;</span> <span class="attr">name</span>=<span class="string">&quot;province&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">data-city</span>=<span class="string">&quot;市&quot;</span> <span class="attr">name</span>=<span class="string">&quot;city&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">data-district</span>=<span class="string">&quot;区/县&quot;</span> <span class="attr">name</span>=<span class="string">&quot;district&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">placeholder</span>=<span class="string">&quot;详细通讯地址&quot;</span> <span class="attr">name</span>=<span class="string">&quot;address&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="前端表格datatable-js"><a href="#前端表格datatable-js" class="headerlink" title="前端表格datatable.js"></a>前端表格datatable.js</h2><ol>
<li><p>生成<code>datatable</code></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$(<span class="string">&quot;#select-all&quot;</span>).prop(<span class="string">&quot;checked&quot;</span>, <span class="literal">false</span>);</span><br><span class="line">atable = $(<span class="string">&#x27;#patent_table&#x27;</span>).dataTable();</span><br><span class="line">atable.fnClearTable(); <span class="comment">//清空一下table</span></span><br><span class="line">atable.fnDestroy();<span class="comment">//还原初始化了的datatable;</span></span><br><span class="line">$(<span class="string">&quot;#patent_table&quot;</span>).css(<span class="string">&#x27;display&#x27;</span>, <span class="string">&#x27;none&#x27;</span>);</span><br><span class="line">btable = $(<span class="string">&#x27;#project_table&#x27;</span>).dataTable();</span><br><span class="line">btable.fnClearTable(); <span class="comment">//清空一下table</span></span><br><span class="line">btable.fnDestroy();<span class="comment">//还原初始化了的datatable;</span></span><br><span class="line">$(<span class="string">&quot;#project_table&quot;</span>).css(<span class="string">&#x27;display&#x27;</span>, <span class="string">&#x27;none&#x27;</span>);</span><br><span class="line">$(<span class="string">&quot;#paper_table&quot;</span>).show();</span><br><span class="line">otable = $(<span class="string">&#x27;#paper_table&#x27;</span>).dataTable();</span><br><span class="line">otable.fnClearTable(); <span class="comment">//清空一下table</span></span><br><span class="line">otable.fnDestroy();<span class="comment">//还原初始化了的datatable;</span></span><br><span class="line">$(<span class="string">&quot;#paper_table tbody&quot;</span>).empty().append(table_data[<span class="string">&quot;html&quot;</span>]);</span><br><span class="line">$(<span class="string">&#x27;#paper_table&#x27;</span>).DataTable(&#123;</span><br><span class="line">    <span class="string">&quot;order&quot;</span>: [],</span><br><span class="line">    <span class="string">&quot;columnDefs&quot;</span>: [&#123;</span><br><span class="line">        <span class="string">&quot;targets&quot;</span>: <span class="string">&#x27;no-sort&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;orderable&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">    &#125;],</span><br><span class="line">    <span class="string">&quot;lengthMenu&quot;</span>: [<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>],</span><br><span class="line">    <span class="string">&quot;bAutoWidth&quot;</span>: <span class="literal">false</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>获取<code>datatable</code>被选中的数据</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> table = $(<span class="string">&quot;#project_table&quot;</span>).dataTable();</span><br><span class="line"><span class="keyword">let</span> projects_delete = [];</span><br><span class="line"><span class="keyword">let</span> checked_collection = table.$(<span class="string">&quot;input[type=&#x27;checkbox&#x27;]:checked&quot;</span>,&#123;<span class="string">&quot;page&quot;</span>:<span class="string">&quot;all&quot;</span>&#125;);</span><br><span class="line">checked_collection.each(<span class="function"><span class="keyword">function</span> (<span class="params">index, elem</span>) </span>&#123;</span><br><span class="line">    projects_delete.push($(elem).attr(<span class="string">&quot;id&quot;</span>));</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="前端柱状图"><a href="#前端柱状图" class="headerlink" title="前端柱状图"></a>前端柱状图</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">(<span class="function"><span class="keyword">function</span>(<span class="params">$</span>) </span>&#123;</span><br><span class="line"><span class="meta">    &quot;use strict&quot;</span>; <span class="comment">// Start of use strict</span></span><br><span class="line">    <span class="comment">//line Morris</span></span><br><span class="line">    <span class="keyword">var</span> lineMorris = <span class="keyword">new</span> Morris.Line(&#123;</span><br><span class="line">        element: <span class="string">&#x27;lineMorris&#x27;</span>,</span><br><span class="line">        resize: <span class="literal">true</span>,</span><br><span class="line">        data: paper_data,</span><br><span class="line">        xkey: <span class="string">&#x27;year&#x27;</span>,</span><br><span class="line">        ykeys: [<span class="string">&#x27;amounts&#x27;</span>],</span><br><span class="line">        labels: [<span class="string">&#x27;论文数量&#x27;</span>],</span><br><span class="line">        gridLineColor: <span class="string">&#x27;#eef0f2&#x27;</span>,</span><br><span class="line">        lineColors: [<span class="string">&#x27;#E57498&#x27;</span>],</span><br><span class="line">        lineWidth: <span class="number">2</span>,</span><br><span class="line">        hideHover: <span class="string">&#x27;auto&#x27;</span></span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">//barmorris</span></span><br><span class="line">    <span class="keyword">var</span> ctx = <span class="built_in">document</span>.getElementById(<span class="string">&quot;barMorris&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (ctx === <span class="literal">null</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> chart = Morris.Bar(&#123;</span><br><span class="line">        element: <span class="string">&#x27;barMorris&#x27;</span>,</span><br><span class="line">        data: project_data,</span><br><span class="line">        xkey: <span class="string">&#x27;year&#x27;</span>,</span><br><span class="line">        ykeys: [<span class="string">&#x27;amounts&#x27;</span>],</span><br><span class="line">        labels: [<span class="string">&#x27;项目数量&#x27;</span>],</span><br><span class="line">        barColors: [<span class="string">&#x27;#FF7D00&#x27;</span>],</span><br><span class="line">        barOpacity: <span class="number">1</span>,</span><br><span class="line">        barSizeRatio: <span class="number">0.5</span>,</span><br><span class="line">        hideHover: <span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">        gridLineColor: <span class="string">&#x27;#eef0f2&#x27;</span>,</span><br><span class="line">        resize: <span class="literal">true</span></span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">// morris donut charts</span></span><br><span class="line">    <span class="keyword">if</span> ($(<span class="string">&quot;#donutMorris&quot;</span>).length == <span class="number">1</span>) &#123;</span><br><span class="line">        Morris.Donut(&#123;</span><br><span class="line">            element: <span class="string">&#x27;donutMorris&#x27;</span>,</span><br><span class="line">            data: patent_data,</span><br><span class="line">            barSize: <span class="number">0.1</span>,</span><br><span class="line">            labelColor: <span class="string">&#x27;#3e5569&#x27;</span>,</span><br><span class="line">            resize: <span class="literal">true</span>, <span class="comment">//defaulted to true</span></span><br><span class="line">            colors: [<span class="string">&#x27;#FFAA2A&#x27;</span>, <span class="string">&#x27;#E57498&#x27;</span>, <span class="string">&#x27;#22c6ab&#x27;</span>]</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)(jQuery);</span><br></pre></td></tr></table></figure>
<h2 id="截图工具"><a href="#截图工具" class="headerlink" title="截图工具"></a>截图工具</h2><ol>
<li><p><code>tkinter</code>制作简易主界面</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 让系统知道使用者看到的尺寸</span></span><br><span class="line">user32 = windll.user32</span><br><span class="line">user32.SetProcessDPIAware()</span><br><span class="line"><span class="comment"># 主窗体</span></span><br><span class="line">root = Tk()</span><br><span class="line">root.wm_attributes(<span class="string">&#x27;-topmost&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">root.title(<span class="string">&quot;文字识别&quot;</span>)</span><br><span class="line">root.geometry(<span class="string">&quot;300x100&quot;</span>)</span><br><span class="line">root.resizable(width=<span class="literal">False</span>, height=<span class="literal">False</span>)</span><br><span class="line">new_menu = Menu(root)</span><br><span class="line">new_menu.add_command(label=<span class="string">&quot;开始识别&quot;</span>, command=cut)</span><br><span class="line">new_text = Text(root, show=<span class="literal">None</span>)</span><br><span class="line">new_text.place(width=<span class="number">300</span>, height=<span class="number">100</span>)</span><br><span class="line">root[<span class="string">&quot;menu&quot;</span>] = new_menu</span><br><span class="line"><span class="comment"># 识别之后的结果</span></span><br><span class="line">text = <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>调用<code>ImageGrab.grab()</code>方法截全屏并处理选中区域</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 截图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut</span>():</span></span><br><span class="line">    <span class="keyword">global</span> img</span><br><span class="line">    screen_cut()</span><br><span class="line">    img = cv2.imread(<span class="string">&#x27;screen.jpg&#x27;</span>)</span><br><span class="line">    cv2.namedWindow(<span class="string">&#x27;image&#x27;</span>)</span><br><span class="line">    cv2.setMouseCallback(<span class="string">&#x27;image&#x27;</span>, on_mouse)</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;image&#x27;</span>, img)</span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">    os.remove(<span class="string">&#x27;screen.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 截取整个屏幕</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">screen_cut</span>():</span></span><br><span class="line">    image = ImageGrab.grab()</span><br><span class="line">    image.save(<span class="string">&quot;screen.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据鼠标事件进行裁剪</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">on_mouse</span>(<span class="params">event, x, y, flags, param</span>):</span></span><br><span class="line">    <span class="keyword">global</span> img, point1, point2</span><br><span class="line">    img2 = img.copy()</span><br><span class="line">    <span class="comment"># 左键点击</span></span><br><span class="line">    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDOWN:</span><br><span class="line">        point1 = (x, y)</span><br><span class="line">        cv2.circle(img2, point1, <span class="number">10</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">5</span>)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;image&#x27;</span>, img2)</span><br><span class="line">    <span class="comment"># 按住左键拖曳</span></span><br><span class="line">    <span class="keyword">elif</span> event == cv2.EVENT_MOUSEMOVE <span class="keyword">and</span> (flags &amp; cv2.EVENT_FLAG_LBUTTON):</span><br><span class="line">        cv2.rectangle(img2, point1, (x, y), (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">5</span>)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;image&#x27;</span>, img2)</span><br><span class="line">    <span class="comment"># 左键释放</span></span><br><span class="line">    <span class="keyword">elif</span> event == cv2.EVENT_LBUTTONUP:</span><br><span class="line">        point2 = (x, y)</span><br><span class="line">        cv2.rectangle(img2, point1, point2, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">5</span>)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;image&#x27;</span>, img2)</span><br><span class="line">        min_x = <span class="built_in">min</span>(point1[<span class="number">0</span>], point2[<span class="number">0</span>])</span><br><span class="line">        min_y = <span class="built_in">min</span>(point1[<span class="number">1</span>], point2[<span class="number">1</span>])</span><br><span class="line">        width = <span class="built_in">abs</span>(point1[<span class="number">0</span>] - point2[<span class="number">0</span>])</span><br><span class="line">        height = <span class="built_in">abs</span>(point1[<span class="number">1</span>] - point2[<span class="number">1</span>])</span><br><span class="line">        cut_img = img[min_y:min_y+height, min_x:min_x+width]</span><br><span class="line">        <span class="comment"># 不存在则新建目录</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;.\\photos&quot;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;.\\photos&#x27;</span>)</span><br><span class="line">        path = <span class="string">&#x27;.\\photos\\cut.png&#x27;</span></span><br><span class="line">        new_text.delete(<span class="number">0.0</span>, END)</span><br><span class="line">        cv2.imwrite(path, cut_img)</span><br><span class="line">        get_text_by_ocr(path)</span><br><span class="line">        new_text.insert(<span class="string">&quot;insert&quot;</span>, text)</span><br><span class="line">        cv2.waitKey(<span class="number">1000</span>)</span><br><span class="line">        cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>调用百度接口进行文字识别，<code>APP_ID</code>、<code>APP_KEY</code>、<code>SECRET_KEY</code>需要自己申请</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 图片识别成文字</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_text_by_ocr</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">global</span> text</span><br><span class="line">    client = AipOcr(APP_ID, APP_KEY, SECRET_KEY)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        image = f.read()</span><br><span class="line">        all_data = client.basicAccurate(image)</span><br><span class="line">        text = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, all_data[<span class="string">&quot;words_result_num&quot;</span>]):</span><br><span class="line">            text += all_data[<span class="string">&quot;words_result&quot;</span>][i][<span class="string">&quot;words&quot;</span>]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="爬虫"><a href="#爬虫" class="headerlink" title="爬虫"></a>爬虫</h2><p>选取了request和selenium（自动化测试常用库，但用于爬虫简单易上手）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 不显式打开浏览器以及不使用GPU加速</span></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)</span><br><span class="line">browser = webdriver.Chrome(self.executable_path, options=options)</span><br><span class="line"><span class="comment"># 使用xpath获取元素</span></span><br><span class="line">keywords = browser.find_element_by_xpath(<span class="string">&quot;//span[text()=&#x27;关键词：&#x27;]/following-sibling::p&quot;</span>).text</span><br><span class="line">keywords = browser.find_element_by_xpath(<span class="string">&quot;//span[contains(text(),&#x27;关键词：&#x27;)]&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="pyinstaller打包成exe报毒"><a href="#pyinstaller打包成exe报毒" class="headerlink" title="pyinstaller打包成exe报毒"></a>pyinstaller打包成exe报毒</h2><p>下面的方法可以完全不报毒，但是原理未知。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pyinstaller -w 你的文件名.py --onefile</span><br></pre></td></tr></table></figure>
<h2 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h2><p>前端上传：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$(<span class="string">&quot;#new_projects_submit&quot;</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    $(<span class="string">&quot;#projects_upload&quot;</span>).click();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">$(<span class="string">&quot;#projects_upload&quot;</span>).on(<span class="string">&quot;change&quot;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    $(<span class="string">&quot;#projects_confirm&quot;</span>).click();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">$(<span class="string">&quot;#projects_confirm&quot;</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> fileObj = <span class="built_in">document</span>.getElementById(<span class="string">&quot;projects_upload&quot;</span>).files[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">typeof</span>(fileObj) == <span class="string">&quot;undefined&quot;</span> || fileObj.size &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        alert(<span class="string">&quot;未选择文件,请重试！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    $(<span class="string">&quot;#projects_upload&quot;</span>).val(<span class="string">&quot;&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> formFile = <span class="keyword">new</span> FormData();</span><br><span class="line">    formFile.append(<span class="string">&quot;action&quot;</span>, <span class="string">&quot;UploadVMKImagePath&quot;</span>);</span><br><span class="line">    formFile.append(<span class="string">&quot;file&quot;</span>, fileObj); <span class="comment">//加入文件对象</span></span><br><span class="line">    $.ajax(&#123;</span><br><span class="line">        url: <span class="string">&quot;/add/projects&quot;</span>,</span><br><span class="line">        data: formFile,</span><br><span class="line">        type: <span class="string">&quot;POST&quot;</span>,</span><br><span class="line">        dataType: <span class="string">&quot;json&quot;</span>,</span><br><span class="line">        cache: <span class="literal">false</span>, <span class="comment">//上传文件无需缓存</span></span><br><span class="line">        processData: <span class="literal">false</span>, <span class="comment">//用于对data参数进行序列化处理 这里必须false</span></span><br><span class="line">        contentType: <span class="literal">false</span>, <span class="comment">//必须</span></span><br><span class="line">        success: <span class="function"><span class="keyword">function</span>(<span class="params">result</span>) </span>&#123;&#125;,</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>后端获取：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">file = request.files.get(<span class="string">&#x27;file&#x27;</span>)  <span class="comment"># 获取文件</span></span><br><span class="line"><span class="keyword">if</span> file:</span><br><span class="line">    filename = file.filename</span><br><span class="line">    <span class="keyword">if</span> filename.split(<span class="string">&#x27;.&#x27;</span>)[-<span class="number">1</span>] <span class="keyword">in</span> [<span class="string">&quot;xls&quot;</span>, <span class="string">&quot;xlsx&quot;</span>]:</span><br><span class="line">        <span class="comment"># 用时间戳给文件命名</span></span><br><span class="line">        now_time = datetime.now().strftime(<span class="string">&quot;%Y-%m-%d-%H-%M-%S&quot;</span>).replace(<span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        file_path = FILE_SAVE_PATH + <span class="string">&quot;\\&quot;</span> + now_time + <span class="string">&#x27;_&#x27;</span> + filename</span><br><span class="line">        file.save(file_path)</span><br></pre></td></tr></table></figure>
<h2 id="构造字典的方法"><a href="#构造字典的方法" class="headerlink" title="构造字典的方法"></a>构造字典的方法</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cooperate_dict[i] = cooperate_dict.get(i, &#123;&#125;)</span><br><span class="line">cooperate_dict[i][<span class="string">&quot;patents&quot;</span>] = cooperate_dict[i].get(<span class="string">&quot;patents&quot;</span>, <span class="number">0</span>)</span><br><span class="line">cooperate_dict[i][<span class="string">&quot;papers&quot;</span>] = cooperate_dict[i].get(<span class="string">&quot;papers&quot;</span>, <span class="number">0</span>)</span><br><span class="line">cooperate_dict[i][<span class="string">&quot;projects&quot;</span>] = cooperate_dict[i].get(<span class="string">&quot;projects&quot;</span>, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">cooperate_dict[i][<span class="string">&quot;total&quot;</span>] = cooperate_dict[i].get(<span class="string">&quot;total&quot;</span>, <span class="number">0</span>) + <span class="number">1</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>毕设</tag>
      </tags>
  </entry>
  <entry>
    <title>项目部署总结</title>
    <url>/2021/10/09/%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下毕设项目部署上线遇见的一些问题</p>
<a id="more"></a>
<h2 id="购买服务器"><a href="#购买服务器" class="headerlink" title="购买服务器"></a>购买服务器</h2><p>阿里云轻量应用服务器，装的是<code>CentOS7.3</code></p>
<h2 id="设置服务器密码"><a href="#设置服务器密码" class="headerlink" title="设置服务器密码"></a>设置服务器密码</h2><h2 id="切换超级用户"><a href="#切换超级用户" class="headerlink" title="切换超级用户"></a>切换超级用户</h2><p>貌似需要使用<code>su -</code></p>
<h2 id="系统升级"><a href="#系统升级" class="headerlink" title="系统升级"></a>系统升级</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum update</span><br></pre></td></tr></table></figure>
<h2 id="下载python环境"><a href="#下载python环境" class="headerlink" title="下载python环境"></a>下载python环境</h2><ol>
<li>下载：<code>wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz</code></li>
<li>解压：<code>tar Jxvf  Python-3.7.0.tar.xz</code></li>
<li>创建一个文件夹存放<code>python3.7.0</code>程序：<code>mkdir /usr/lib/Python3.7.0</code></li>
<li>设置配置文件：<code>./configure --prefix=/usr/lib/python3.7.0</code></li>
<li>编译安装：<code>make &amp;&amp; make install</code></li>
<li>建立软连接，使用已安装的<code>python3.7.0</code>：<code>ln -sb /usr/lib/python3.7.0/bin/python3.7 /usr/bin/python3</code></li>
</ol>
<p>报错：<code>zipimport.ZipImportError: can’t decompress data; zlib not available make: *** [install] Error 1</code></p>
<p>解决方案：<code>yum -y install zlib*</code></p>
<p>报错：<code>ModuleNotFoundError: No module named &#39;_ctypes&#39;</code></p>
<p>解决方案：<code>yum install libffi-devel</code></p>
<h2 id="安装虚拟环境"><a href="#安装虚拟环境" class="headerlink" title="安装虚拟环境"></a>安装虚拟环境</h2><p><code>pip3 install virtualenv</code></p>
<p>建立软连接：<code>ln -s /usr/local/python3/bin/virtualenv /usr/bin/virtualenv</code></p>
<p>建立目录，管理各虚拟环境：<code>mkdir my_env</code></p>
<p>建立虚拟环境：<code>virtualenv graduation</code></p>
<p>切换到<code>bin</code>目录下激活虚拟环境：<code>source activate</code></p>
<p>取消激活：<code>deactivate</code></p>
<h2 id="安装pip"><a href="#安装pip" class="headerlink" title="安装pip"></a>安装pip</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget --no-check-certificate https://github.com/pypa/pip/archive/9.0.1.tar.gz </span><br><span class="line">tar -zvxf 9.0.1.tar.gz  # 解压文件 </span><br><span class="line">cd pip-9.0.1</span><br><span class="line">python3 setup.py install # 使用 Python3 安装</span><br></pre></td></tr></table></figure>
<p>创建链接</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ln -s /usr/local/python3/bin/pip /usr/bin/pip3</span><br></pre></td></tr></table></figure>
<p>升级<code>pip</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install --upgrade pip</span><br></pre></td></tr></table></figure>
<h2 id="安装mysql："><a href="#安装mysql：" class="headerlink" title="安装mysql："></a>安装mysql：</h2><p>下载<code>mysql</code>的<code>repo</code>源</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;repo.mysql.com&#x2F;mysql-community-release-el7-5.noarch.rpm</span><br></pre></td></tr></table></figure>
<p>安装<code>mysql-community-release-el7-5.noarch.rpm</code>包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -ivh mysql-community-release-el7-5.noarch.rpm</span><br></pre></td></tr></table></figure>
<p>安装<code>MYSQL</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install -y  mysql-server</span><br></pre></td></tr></table></figure>
<p> 更改<code>MYSQL</code>用户权限：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo chown -R root:root &#x2F;var&#x2F;lib&#x2F;mysql</span><br></pre></td></tr></table></figure>
<p>重启服务：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart mysql.service</span><br></pre></td></tr></table></figure>
<p>登录，并修改密码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root</span><br><span class="line">mysql &gt; use mysql;</span><br><span class="line">mysql &gt; update user set password=password(&#x27;123456&#x27;) where user=&#x27;root&#x27;;</span><br><span class="line">mysql &gt; flush privileges;</span><br><span class="line">mysql &gt; exit;</span><br></pre></td></tr></table></figure>
<h2 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h2><p>下载对应当前系统版本的<code>nginx</code>包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm</span><br></pre></td></tr></table></figure>
<p> 建立<code>nginx</code>的<code>yum</code>仓库（默认<code>yum</code>是没有<code>nginx</code>的）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -ivh nginx-release-centos-7-0.el7.ngx.noarch.rpm</span><br></pre></td></tr></table></figure>
<p>下载并安装<code>nginx</code></p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y nginx</span><br></pre></td></tr></table></figure>
<p><code>nginx</code>启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start nginx.service</span><br></pre></td></tr></table></figure>
<p>配置<code>nginx</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">server</span> &#123;</span><br><span class="line">    <span class="string">listen</span>       <span class="number">80</span><span class="string">;</span></span><br><span class="line">    <span class="string">server_name</span> <span class="number">120.27</span><span class="number">.209</span><span class="number">.102</span><span class="string">;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#access_log  /var/log/nginx/host.access.log  main;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">location</span> <span class="string">/</span> &#123;</span><br><span class="line">        <span class="comment">#root   /home/admin/my_projects/graduation;</span></span><br><span class="line">        <span class="comment">#index  index.html index.htm;</span></span><br><span class="line">		<span class="string">proxy_pass</span> <span class="string">http://127.0.0.1:5000;</span> <span class="comment"># 这里是指向 gunicorn host 的服务地址</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">Host</span> <span class="string">$host;</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">X-Forwarded-For</span> <span class="string">$proxy_add_x_forwarded_for;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#error_page  404              /404.html;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># redirect server error pages to the static page /50x.html</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="string">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  <span class="string">/50x.html;</span></span><br><span class="line">    <span class="string">location</span> <span class="string">=</span> <span class="string">/50x.html</span> &#123;</span><br><span class="line">        <span class="string">root</span>   <span class="string">/usr/share/nginx/html;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># proxy the PHP scripts to Apache listening on 127.0.0.1:80</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#location ~ \.php$ &#123;</span></span><br><span class="line">    <span class="comment">#    proxy_pass   http://127.0.0.1;</span></span><br><span class="line">    <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#location ~ \.php$ &#123;</span></span><br><span class="line">    <span class="comment">#    root           html;</span></span><br><span class="line">    <span class="comment">#    fastcgi_pass   127.0.0.1:9000;</span></span><br><span class="line">    <span class="comment">#    fastcgi_index  index.php;</span></span><br><span class="line">    <span class="comment">#    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;</span></span><br><span class="line">    <span class="comment">#    include        fastcgi_params;</span></span><br><span class="line">    <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># deny access to .htaccess files, if Apache&#x27;s document root</span></span><br><span class="line">    <span class="comment"># concurs with nginx&#x27;s one</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#location ~ /\.ht &#123;</span></span><br><span class="line">    <span class="comment">#    deny  all;</span></span><br><span class="line">    <span class="comment">#&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="上传本地flask项目"><a href="#上传本地flask项目" class="headerlink" title="上传本地flask项目"></a>上传本地flask项目</h2><p>我使用的是<code>Xftp 7</code>，一开始准备使用<code>git</code>直接在<code>GitHub</code>上下载，但是速度太慢</p>
<h2 id="安装需要依赖的库"><a href="#安装需要依赖的库" class="headerlink" title="安装需要依赖的库"></a>安装需要依赖的库</h2><ol>
<li><p>使用虚拟环境</p>
</li>
<li><p>切换到项目路径下</p>
</li>
<li><p>从<code>requirements.txt</code>安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install -r requirements.txt</span><br></pre></td></tr></table></figure>
<h2 id="新建项目数据库"><a href="#新建项目数据库" class="headerlink" title="新建项目数据库"></a>新建项目数据库</h2></li>
<li><p>登陆<code>mysql</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure></li>
<li><p>创建与文件名相同的数据库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash">create database graduation;</span></span><br></pre></td></tr></table></figure></li>
<li><p>使用创建好的数据库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> use graduation;</span></span><br></pre></td></tr></table></figure></li>
<li><p>导入数据库文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"><span class="built_in">source</span> ./graduation.sql;</span></span><br></pre></td></tr></table></figure>
<h2 id="安装gunicorn"><a href="#安装gunicorn" class="headerlink" title="安装gunicorn"></a>安装gunicorn</h2></li>
<li><p>安装<code>gunicorn</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install gunicorn</span><br></pre></td></tr></table></figure></li>
<li><p>启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gunicorn -w 4 -b 0.0.0.0:8080 yourpyfilename:yourappname --log-level DEBUG</span><br><span class="line">gunicorn -w 4 -b 127.0.0.1:5000 app:app --log-level DEBUG</span><br></pre></td></tr></table></figure></li>
<li><p>获取<code>gunicorn</code>进程树</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pstree -ap|grep gunicorn</span><br></pre></td></tr></table></figure></li>
<li><p>终止任务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kill -9 pid</span><br></pre></td></tr></table></figure>
<h2 id="selenium的使用"><a href="#selenium的使用" class="headerlink" title="selenium的使用"></a>selenium的使用</h2></li>
<li><p>下载<code>chrome</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm</span><br></pre></td></tr></table></figure></li>
<li><p>安装<code>chrome</code>依赖的包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install libX11 libXcursor libXdamage libXext libXcomposite libXi libXrandr gtk3 libappindicator-gtk3 xdg-utils libXScrnSaver liberation-fonts</span><br></pre></td></tr></table></figure></li>
<li><p>安装<code>chrome</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -ivh google-chrome-stable_current_x86_64.rpm</span><br></pre></td></tr></table></figure></li>
<li><p>查看<code>chrome</code>是否安装完成</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">google-chrome --version</span><br></pre></td></tr></table></figure></li>
<li><p>下载<code>chrome</code>对应的<code>chromedriver</code>，下载地址<a href="http://npm.taobao.org/mirrors/chromedriver/">http://npm.taobao.org/mirrors/chromedriver/</a></p>
</li>
<li><p>安装完成之后上传至服务器</p>
</li>
</ol>
<p>一些报错：</p>
<ol>
<li><p><code>WEBDRIVEREXCEPTION: MESSAGE: &#39;CHROMEDRIVER&#39; EXECUTABLE MAY HAVE WRONG PERMISSIONS.</code></p>
<p>我的情况是没有执行权限，其他可能性见<a href="https://www.freesion.com/article/25041327554/">这里</a></p>
<p>解决方案：</p>
<ol>
<li><p>在<code>chromedriver</code>所在的路径下查看执行权限</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -l</span><br></pre></td></tr></table></figure></li>
<li><p>赋予执行权限</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod -R 777 chromedriver</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p><code>selenium WebDriverException: Message: unknown error: DevToolsActivePort file doesn&#39;t exist</code></p>
</li>
<li><p><code>WebDriverException: Message: chrome not reachable</code></p>
</li>
</ol>
<h2 id="使用screen"><a href="#使用screen" class="headerlink" title="使用screen"></a>使用screen</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install screen</span><br><span class="line">screen -S graduation</span><br></pre></td></tr></table></figure>
<p>恢复会话</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -r graduation</span><br></pre></td></tr></table></figure>
<h2 id="绑定域名"><a href="#绑定域名" class="headerlink" title="绑定域名"></a>绑定域名</h2><ol>
<li><p>首先去阿里云购买域名</p>
</li>
<li><p>工信部实名认证</p>
</li>
<li><p>域名解析</p>
</li>
<li><p>如果觉得域名后面带端口号不太美观，可以设置一下</p>
<ol>
<li><p>选择添加新记录</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220116122249.png" alt=""></p>
</li>
<li><p>记录类型选择隐性URL，主机记录就是想要设置的名字，记录值填写<a href="http://域名:端口号">http://域名:端口号</a></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220116122426.png" alt=""></p>
</li>
<li><p>浏览器中输入主机记录的值即可访问</p>
</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>项目部署</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习总结</title>
    <url>/2021/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>小白上路啦！</p>
<p>主要参考吴恩达的《机器学习》</p>
<a id="more"></a>
<h1 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h1><h2 id="学习方式分类"><a href="#学习方式分类" class="headerlink" title="学习方式分类"></a>学习方式分类</h2><ul>
<li>监督学习</li>
<li>无监督学习</li>
<li>半监督学习</li>
<li>强化学习</li>
</ul>
<h2 id="学习结果分类"><a href="#学习结果分类" class="headerlink" title="学习结果分类"></a>学习结果分类</h2><ul>
<li>回归</li>
<li>分类</li>
</ul>
<h1 id="模型学习"><a href="#模型学习" class="headerlink" title="模型学习"></a>模型学习</h1><h2 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h2><h3 id="线性回归模型特点"><a href="#线性回归模型特点" class="headerlink" title="线性回归模型特点"></a>线性回归模型特点</h3><ul>
<li>线性回归时一种回归算法</li>
<li>模型简单、计算量较小</li>
<li>对误差敏感</li>
<li>对数据预处理要求较高</li>
</ul>
<h3 id="线性回归模型主要思想"><a href="#线性回归模型主要思想" class="headerlink" title="线性回归模型主要思想"></a>线性回归模型主要思想</h3><p>通过运用该简单的线性函数，可模拟<code>x</code>和<code>y</code>之间的关系。关键在于该函数不仅与输入变量x成线性关系，而且与参数<code>a</code>、<code>b</code>成线性关系。当前目标是确定最符合训练数据的参数<code>a</code>和<code>b</code>的值。</p>
<p>这可通过测量每个输入x的实际目标值<code>y</code>和模型<script type="math/tex">f(x)</script>之间的失配来实现，并将失配最小化。这种失配（最小值）被称为误差函数。</p>
<p>有多种误差函数可供选择，但其中最简单的要数<code>RSS</code>，即每个数据点x对应的模型<script type="math/tex">f(x)</script>与目标值y的误差平方和。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_16.png" alt=""></p>
<p>对于<code>w</code>,<code>b​</code>作为自变量，取何值时，<code>RSS</code>最小？转化为求极值问题，极值点偏导为0。</p>
<p>避免过拟合，引入正则化技术（将参数作为项加入损失函数）</p>
<p>L1正则化（LASSO回归）：具有稀疏作用</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_17.png" alt=""></p>
<p>L2正则化（Ridge回归）：收敛更快</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_18.png" alt=""></p>
<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><ul>
<li>评估是否准确：查看在训练集上的准确率</li>
<li>评估泛化性能：查看在测试集（<code>K</code>折）上的准确率</li>
</ul>
<h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>梯度：$gradf(x,y)=\nabla f(x,y)=f_{x}(x,y)\vec{i}+f_{y}(x,y)\vec{j}$ 和法向向量（是一个单位向量）$n$ 相乘后就是沿着边界外法线方向的导数值</p>
<ul>
<li>更新规则（多个$\theta$同时更新）：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_19.png" alt=""></p>
<ul>
<li><p>$\alpha$太小，$J(\theta)$收敛太慢；$\alpha$太大，$J(\theta)$也许每次迭代不会减少或者不会收敛</p>
</li>
<li><p>注意特征缩放，使得特征在相似的范围</p>
</li>
<li><p>梯度下降的方向与等高线的切线方向垂直 ⇒ 梯度下降方向与等高线的法线方向相同</p>
</li>
<li><p>对于一元函数来说：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116095053.png" alt=""></p>
</li>
<li><p>多元函数的梯度方向和法向量方向</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116162051.png" alt=""></p>
<p>梯度方向是一个函数任一点处上升最快的方向。梯度的投影就是法向量，法向量需要做等高线才能求。$z=f(x,y)$ 是一个函数，$f(x,y)=C$ 则是一个等式。</p>
</li>
</ul>
<h3 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_45.png" alt=""></p>
<p>具体步骤：对参数进行细微的修改，使其对第一个数据拟合得非常好，以此类推</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_46.png" alt=""></p>
<p>如何确定算法已经收敛：每次使用一个训练样本更新$\theta$之前计算$cost(\theta,(x^{(i)},y^{(i)}))$；每1000次迭代计算一下$cost(\theta,(x^{(i)},y^{(i)}))$的均值</p>
<h3 id="Mini-batch-梯度下降法"><a href="#Mini-batch-梯度下降法" class="headerlink" title="Mini-batch 梯度下降法"></a>Mini-batch 梯度下降法</h3><p>主要思想：每次迭代使用b个样本（向量化的时候更好）</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_47.png" alt=""></p>
<h3 id="正规方程法"><a href="#正规方程法" class="headerlink" title="正规方程法"></a>正规方程法</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_20.png" alt=""></p>
<h2 id="logistic回归模型"><a href="#logistic回归模型" class="headerlink" title="logistic回归模型"></a>logistic回归模型</h2><h3 id="logistic回归模型特点"><a href="#logistic回归模型特点" class="headerlink" title="logistic回归模型特点"></a>logistic回归模型特点</h3><ul>
<li>logistic回归是一种分类算法</li>
<li>模型简单、计算量较小</li>
<li>对异常数据点并不敏感</li>
<li>对数据预处理要求较高</li>
</ul>
<h3 id="logistic回归模型主要思想"><a href="#logistic回归模型主要思想" class="headerlink" title="logistic回归模型主要思想"></a>logistic回归模型主要思想</h3><h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><p>sigmoid函数的数学形式是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_21.png" alt=""></p>
<p>对应的函数曲线如下图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/sigmoid.png" alt="sigmod.png"></p>
<h4 id="决策函数"><a href="#决策函数" class="headerlink" title="决策函数"></a>决策函数</h4><p>一个机器学习的模型，实际上是把决策函数限定在某一组条件下，这组限定条件就决定了模型的假设空间。当然，我们还希望这组限定条件简单而合理。而逻辑回归模型所做的假设是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_22.png" alt=""></p>
<p>这里的 <script type="math/tex">g(h)</script> 是上边提到的<code>sigmoid</code>函数，相应的决策函数为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_23.png" alt=""></p>
<p>选择<code>0.5</code>作为阈值是一个一般的做法，实际应用时特定的情况可以选择不同阈值，如果对正例的判别准确性要求高，可以选择阈值大一些，对正例的召回要求高，则可以选择阈值小一些。（根据<code>sigmod</code>函数，即$\theta^{T}x&gt;0$）</p>
<h4 id="参数求解"><a href="#参数求解" class="headerlink" title="参数求解"></a>参数求解</h4><p>模型的数学形式确定后，剩下就是如何去求解模型中的参数。统计学中常用的一种方法是最大似然估计，即找到一组参数，使得在这组参数下，我们的数据的似然度（概率）越大。在逻辑回归模型中，似然度可表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_24.png" alt=""></p>
<p>取对数可以得到对数似然度：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_25.png" alt=""></p>
<h2 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h2><h3 id="决策树算法特点"><a href="#决策树算法特点" class="headerlink" title="决策树算法特点"></a>决策树算法特点</h3><ul>
<li>决策树能用来做回归，也可以用来做分类，是一类算法的总称</li>
<li>决策树是一种弱分类器</li>
<li>决策树是一类具有可解释性、泛化性能较好的模型</li>
<li>精度高、无需特征归一化，能够处理缺失值，共线性特征</li>
<li>适合于低维稠密数据，不适合高维稀疏数据</li>
<li>决策树类算法兼具特征选择能力</li>
</ul>
<h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><p>信息熵<code>S</code>表征了信息不确定性的程度，分类属性应当以最高熵减为标准进行：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_48.png" alt=""></p>
<h3 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h3><p><code>C4.5</code>算法过程跟<code>ID3</code>算法一样，只是选择特征的方法由信息增益改成信息增益比。</p>
<p>特征<code>A</code>对训练数据集<code>D</code>的信息增益比<script type="math/tex">GainRatio(D,A)</script>定义为其信息增益<script type="math/tex">Gain(D,A)</script>与训练数据集D的经验熵<script type="math/tex">H(D)</script>之比</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_49.png" alt=""></p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><h3 id="随机森林算法主要思想"><a href="#随机森林算法主要思想" class="headerlink" title="随机森林算法主要思想"></a>随机森林算法主要思想</h3><ol>
<li><code>bootstrap</code>采样</li>
<li>随机选择特征，选择最佳属性建立决策树</li>
<li>形成随机森林，通过投票得到结果</li>
</ol>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_26.png" alt=""></p>
<h3 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h3><p>输入层、输出层、隐藏层、偏置单元</p>
<p>如果第<code>i</code>层有$s_{i}$个，第<code>i+1</code>层有$s_{i+1}$个，则$\theta$规模为$s_{i+1}*(s_{i}+1)$</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_27.png" alt=""></p>
<h3 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_28.png" alt=""></p>
<h4 id="检测方法"><a href="#检测方法" class="headerlink" title="检测方法"></a>检测方法</h4><p>双侧差分：$\frac{J(\theta+\varepsilon)-J(\theta-\varepsilon)}{2\varepsilon}\approx\frac{\partial}{\partial z_{j}^{l}}cost(i)$</p>
<p>训练集（60%）、验证集（20%）、测试集（20%）</p>
<p>$J_{train}(\theta)$和$J_{cv}(\theta)$都高时，欠拟合；$J_{train}(\theta)$低$J_{cv}(\theta)$高时，过拟合</p>
<p>随多项式次数增长的关系</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_29.png" alt=""></p>
<p>随$\lambda$增长的关系</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_30.png" alt=""></p>
<p>bias：偏差（underfit）；variance：方差（overfit）</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_31.png" alt=""></p>
<p>Precision：$\frac{true}{predicted}$ ；Recall：$\frac{true}{actual}$；F：$2\frac{PR}{P+R}$</p>
<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_32.png" alt=""></p>
<p>$y^{(i)}=1$时，$\theta^{T}x\geq1$，即$p^{(i)}||\theta||\geq1$；$y^{(i)}=0$时，$\theta^{T}x\leq-1$，即$p^{(i)}||\theta||\leq-1$，$\theta$垂直于边界函数</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_33.png" alt=""></p>
<h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_34.png" alt=""></p>
<p>$x\approx l^{(1)}:f_{1}\approx exp(-\frac{0^{2}}{2\sigma^{2}})\approx 1;else:f_{1}=exp(-\frac{large^{2}}{2\sigma^{2}})\approx 0$</p>
<p>给定$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),(x^{(3)},y^{(3)}),(x^{(4)},y^{(4)})$，</p>
<p>选定$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},l^{(3)}=x^{(3)},l^{(4)}=x^{(4)}$；</p>
<p>对于给定的训练集$(x^{(i)},y^{(i)})$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_35.png" alt=""></p>
<h2 id="高斯过程回归"><a href="#高斯过程回归" class="headerlink" title="高斯过程回归"></a>高斯过程回归</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>现有如下方程：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418193805.png" alt=""></p>
<p>尝试用高斯过程回归解上述的微分方程。</p>
<h3 id="先验知识"><a href="#先验知识" class="headerlink" title="先验知识"></a>先验知识</h3><h4 id="一维高斯分布"><a href="#一维高斯分布" class="headerlink" title="一维高斯分布"></a>一维高斯分布</h4><p>高斯分布又称正态分布，若随机变量 $X$ 服从一个位置参数为 $\mu$ 、尺度参数为 $\sigma$ 的概率分布，且其概率密度为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418193914.png" alt=""></p>
<p>则这个随机变量就称为正态随机变量，正态随机变量服从的分布就称为正态分布，记作 $X \sim N(\mu,\sigma^{2})$</p>
<h4 id="多维高斯分布"><a href="#多维高斯分布" class="headerlink" title="多维高斯分布"></a>多维高斯分布</h4><p>多维高斯分布其变量为 $n$ 维变量，每个变量之间可能会存在关系，为了描述这种关系，我们引入了协方差矩阵 $\Sigma$ ，其大小为 $n{\times}n$ ，其中每一个元素为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194006.png" alt=""></p>
<p>当维度为2时，2维的高斯分布公式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194048.png" alt=""></p>
<p>当维度大于2时，$n$ 维的高斯分布公式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194122.png" alt=""></p>
<h4 id="高斯过程"><a href="#高斯过程" class="headerlink" title="高斯过程"></a>高斯过程</h4><p>首先当随机变量是1维的时候，我们称之为一维高斯分布，概率密度函数 $p(x)=N(\mu,\sigma^{2})$，当随机变量的维度上升到有限的 $p$ 维的时候，就称之为高维高斯分布 $p(x)=N(\mu,\Sigma_{p \times p})$。而高斯过程则更进一步，他是一个定义在连续域上的无限多个高斯随机变量所组成的随机过程，换句话说，高斯过程是一个无限维的高斯分布。</p>
<p>对于一个连续域 $T$ (假设是一个时间轴)，如果我们在连续域上任选个时刻：$t_{1},t_{2},t_{3},\dots,t_{n}\in T$，使得获得的一个 $n$ 维向量 ${\xi_{1},\xi_{2},\xi_{3},\dots,\xi_{n}}$ 都满足其是一个2维高斯分布，那么这个 ${\xi_{t}}$ 就是一个高斯过程。</p>
<p>举一个实际的例子，直观地建立高斯过程的印象，下面的图中，横轴 $T$ 是一个关于时间的连续域，表示人的一生，而纵轴表示的是体能值，对于同一个人种的男性而言，在任意不同的时间点体能值都服从正态分布，但是不同时间点分布的均值和方差不同。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220301160123.png" alt=""></p>
<p>图中，我们取出了 $t_{1},t_{2},t_{3},t_{4},t_{5}$ 五个时间点，分别代表同一个男性群体童年、少年、青年、中年、老年的具体时刻， $\xi_{1},\xi_{2},\xi_{3},\xi_{4},\xi_{5}$ 分别对应五个时刻的体能值，他们都服从高斯分布，只不过从图中可以看出，均值和方差都不同，那么概括起来：<br>对于任意 $t \in T$ ， $\xi_{t} \sim N(\mu_{t}, \sigma_{t}^{2})$ ，也就是对于一个确定的高斯过程而言，对于任意时刻 $t$ ，他的 $\mu_{t}$ 和 $\sigma_{t}$ 都已经确定了。而像上图中，我们对同一人种男性体能值在关键节点进行采样，然后平滑连接，也就是图中的两条虚线，就形成了这个高斯过程中的两个样本。</p>
<p>$p$ 维高斯分布两个决定性的参数是均值 $\mu_{p}$ 和 $p \times p$ 的协方差矩阵 $\Sigma_{p \times p}$ ，定义在连续域 $T$ 上的高斯过程也一样，他是无限维的高斯分布。不一样的是他是在连续域上的，维数是无限的，因此均值该定义成一个关于时刻 $t$ 的函数： $m(t)$ 。协方差矩阵也是同理，无限维的情况下就定义为一个核函数 $k(s,t)$ ，其中 $s$ 和 $t$ 表示任意两个时刻，核函数也称协方差函数，核函数是一个高斯过程的核心，他决定了高斯过程的性质。其中最常见的一个核函数是径向核函数 $RBF$，其定义如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194246.png" alt=""></p>
<p>高斯过程的两个核心要素：均值函数和核函数的定义我们就描述清楚了，按照高斯过程存在性定理，一旦这两个要素确定了，那么整个高斯过程就确定了： $\xi_{t} \sim GP(m(t), k(t,s))$</p>
<h5 id="高斯过程求解偏微分方程"><a href="#高斯过程求解偏微分方程" class="headerlink" title="高斯过程求解偏微分方程"></a>高斯过程求解偏微分方程</h5><h6 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h6><p>高斯过程 $u$ 的后验均值为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194526.png" alt=""></p>
<p>后验方差为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194601.png" alt=""></p>
<p>其中</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194636.png" alt=""></p>
<h6 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h6><ol>
<li>在训练的内部和边界分别取 $n^{i}$ ， $n^{b}$ 个点作为训练点，计算 $f(x_{j}^{i})$ ， $g(x_{l}^b)$</li>
<li>定义核函数 $c(x,x’)$ ，目前实现的是一维，取 $d=1$</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194806.png" alt=""></p>
<ol>
<li>计算 $\mathcal{L}c(x,x’)$ ， $\mathcal{B}c(x,x’)$ ， $\mathcal{L}’c(x,x’)$ ， $\mathcal{B}’c(x,x’)$ ， $\mathcal{L}\mathcal{L}’c(X^{i},X^{i})$ ， $\mathcal{L}\mathcal{B}’c(X^{i},X^{b})$ ， $\mathcal{B}\mathcal{B}’c(X^{b},X^{b})$ </li>
<li>寻找最优化的 $\sigma,l_{1},\dots,l_{d}$ ，定义函数 $\mathcal{NLML}(\sigma,l_{1},\dots,l_{d})=\frac{1}{2}y^{T}K^{-1}y+\frac{1}{2}log|K|+\frac{n^{i}+n^{b}}{2}log(2\pi)$ ，求函数的最小值 $f(\sigma^{\star},l_{1}^{\star},\dots,l_{d}^{\star}) \leqslant \mathcal{NLML}(\sigma,l_{1},\dots,l_{d})$ </li>
<li>使用找到的 $\sigma,l_{1},\dots,l_{d}$ 预测 $u(x)$ 在 $x^{\star}$ 的近似值：</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194906.png" alt=""></p>
<h4 id="高斯过程回归-1"><a href="#高斯过程回归-1" class="headerlink" title="高斯过程回归"></a>高斯过程回归</h4><p>高斯过程回归是一个先验+观测值，然后推出后验的过程。</p>
<p>我们先通过 $\mu (t)$ 和 $k(s,t)$ 定义一个高斯过程，但是因为此时并没有任何的观测值，所以是一个先验。获得了一组观测值之后，如何来修正这个高斯过程的均值函数和核函数，使之得到他的后验过程呢？</p>
<p>高斯分布有一个很好的特性，那就是高斯分布的联合概率、边缘概率、条件概率仍然是满足高斯分布的，假设： $n$ 维随机变量满足高斯分布： $x \sim N(\mu, \Sigma_{n \times n})$ ，把这个 $n$ 维随机变量分成两部分： $p$ 维的 $x_{a}$ 和 $q$ 维的 $x_{b}$ ，满足 $n=p+q$ ，那么按照均值向量 $\mu$ 和协方差矩阵 $\Sigma$ 的分块规则，就可以写成：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418195017.png" alt=""></p>
<p>那么根据高斯分布的性质，我们知道下列条件分布依然是一个高维的高斯分布：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418195055.png" alt=""></p>
<p>也就是说，设置了高斯过程的先验参数，一旦我们拿到一些观测值，那么就可以对高斯过程的均值函数和核函数进行修正，得到一个修正后的后验高斯过程，而更新后验参数的信息就来自于观测值。</p>
<p>将高斯过程和多维高斯分布进行类比，均值向量替换成均值函数，协方差矩阵替换成核函数，就能得到高斯过程基于观测值的后验过程的参数表达式。</p>
<p>假设有一组观测值，他们的时刻对应一个向量 $X$ ，那么对应的值是另一个同纬度的向量的 $Y$ ，假设有4组观测值，即 ${(X[1],Y[1]),(X[2],Y[2]),(X[3],Y[3]),(X[4],Y[4])}$ ，那么余下的所有非观测点，在连续域上定义为 $X^{\star}$ ，值定义为 $f(X^{\star})$ 。</p>
<p>首先，联合分布满足无限维高斯分布：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418195132.png" alt=""></p>
<p>从这个联合分布所派生出来的条件概率 $f(X^{\star})|Y$ 同样也服从高斯分布： $f(X^{\star})|Y \sim N(\mu^{\star}, k^{\star})$ ，</p>
<p>类比一下，将 $Y$ 看作 $x_{a}$ ， $f(X^{\star})$ 看作 $x_{b}$ ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418195208.png" alt=""></p>
<h2 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_36.png" alt=""></p>
<ol>
<li>初始化k个中心</li>
<li>根据数据离中心的长短进行划分</li>
<li>重新计算k个簇的中心</li>
<li>继续迭代直到达到某个条件</li>
</ol>
<h3 id="初始化K"><a href="#初始化K" class="headerlink" title="初始化K"></a>初始化K</h3><ol>
<li>K&lt;m</li>
<li>多次随机初始化</li>
</ol>
<h3 id="K聚类数量的选取"><a href="#K聚类数量的选取" class="headerlink" title="K聚类数量的选取"></a>K聚类数量的选取</h3><ol>
<li>Elbow method：可以参考</li>
<li>人工、手动、经验</li>
</ol>
<h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><ol>
<li>预处理：数据标准化$x_{j}^{(i)}=x_{j}-\mu_{j}$</li>
<li>计算协方差矩阵$\Sigma=\frac{1}{m}\sum\limits_{i=1}^{n}(x^{(i)})(x^{(i)})^{T}$</li>
<li>计算$\Sigma$的特征矩阵</li>
<li>取前k列，计算出$(U_{reduce})^{T}x^{(i)}$，$k×n×n×1=k×1$</li>
</ol>
<h3 id="PCA维度的选取"><a href="#PCA维度的选取" class="headerlink" title="PCA维度的选取"></a>PCA维度的选取</h3><p>计算$U_{reduce},z^{(1)},z^{(2)},z^{(3)},\cdots,z^{(m),x_{approx}^{(1)},\cdots,x_{approx}^{(m)}}$，判断$\frac{\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}-x_{approx}^{(i)}||^{2}}{\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}||^{2}}\leq0.01?$</p>
<p>简便方法：使用特征值矩阵，计算$1-\frac{\sum\limits_{i=1}^{k}S_{ii}}{\sum\limits_{i=1}^{n}S_{ii}}\leq0.01?$</p>
<h3 id="PCA压缩重现"><a href="#PCA压缩重现" class="headerlink" title="PCA压缩重现"></a>PCA压缩重现</h3><p>$x_{approx}=U_{reduce}·z$</p>
<h2 id="异常检测算法"><a href="#异常检测算法" class="headerlink" title="异常检测算法"></a>异常检测算法</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_37.png" alt=""></p>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>Precision/Recall；$F_{1}$-score</p>
<h3 id="异常检测vs监督学习"><a href="#异常检测vs监督学习" class="headerlink" title="异常检测vs监督学习"></a>异常检测vs监督学习</h3><ol>
<li>很少的正例</li>
<li>大量负例</li>
<li>多种异常</li>
<li>未来可能以前没有的异常</li>
</ol>
<h3 id="如何选择特征"><a href="#如何选择特征" class="headerlink" title="如何选择特征"></a>如何选择特征</h3><p>如果数据没有呈现出高斯分布的形状，对数据进行一些处理，例如：$log(x),x^{\frac{1}{2}}$。</p>
<p>选择既不特别大也不特别小的特征。</p>
<h2 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h2><h3 id="基于内容的推荐算法"><a href="#基于内容的推荐算法" class="headerlink" title="基于内容的推荐算法"></a>基于内容的推荐算法</h3><p>特定用户：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_39.png" alt=""></p>
<p>整体用户：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_40.png" alt=""></p>
<h3 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h3><p>单部影片的特征：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_41.png" alt=""></p>
<p>所有影片的特征：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_42.png" alt=""></p>
<h4 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_43.png" alt=""></p>
<p>归一化：每一行减去均值$\mu_{i}$，预测变为$(\theta^{(i)})^{T}(x^{(i)})+\mu_{i}$</p>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_44.png" alt=""></p>
<h1 id="性能度量指标"><a href="#性能度量指标" class="headerlink" title="性能度量指标"></a>性能度量指标</h1><h2 id="线性回归决定系数-R-2-（判定系数，拟合优度）"><a href="#线性回归决定系数-R-2-（判定系数，拟合优度）" class="headerlink" title="线性回归决定系数$R^{2}$ （判定系数，拟合优度）"></a>线性回归决定系数$R^{2}$ （判定系数，拟合优度）</h2><p>相关系数 $R$ 就是决定系数的开发</p>
<p>决定系数 $R^{2}$ 是衡量回归的好坏，，也就是回归拟合的曲线的拟合优度，也就是得分。</p>
<p>决定系数是表征回归方程在多大程度上解释了因变量的变化，或者说方程对观测值的拟合程度如何。</p>
<p>计算公式为：</p>
<p>设 $y$ 为待拟合数值，其均值为 $\overline{y}$ ，拟合值为 $\widehat{y}$ ，记：</p>
<ul>
<li>总平方和（$SST$）： $\sum\limits_{i=1}\limits^{N}(y_{i}-\overline{y})^{2}$</li>
<li>回归平方和（$SSR$ ）：$\sum\limits_{i=1}\limits^{N}(\hat{y_{i}}-\overline{y})^{2}$</li>
<li>残差平方和（$SSE$）：$\sum\limits_{i=1}\limits^{N}(y_{i}-\hat{y_{i}})^{2}$</li>
</ul>
<p>则有：$SST=SSR+SSE$</p>
<p>决定系数：$R^{2}=\frac{SSR}{SST}=\frac{\sum\limits_{i=1}\limits^{N}(\hat{y_{i}}-\overline{y})^{2}}{\sum\limits_{i=1}\limits^{N}(y_{i}-\hat{y_{i}})^{2}}=1-\frac{SSE}{SST}$</p>
<p>决定系数越大表明拟合优度越好！</p>
<h2 id="分类问题中的评判标准"><a href="#分类问题中的评判标准" class="headerlink" title="分类问题中的评判标准"></a>分类问题中的评判标准</h2><p>以二分类为例，分类结果的混淆矩阵如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_50.png" alt=""></p>
<p>精确率、准确率：$accuracy=\frac{TP+TN}{TP+TN+FP+FN}$</p>
<p>精准率、查准率：$precision=\frac{TP}{TP+FP}$</p>
<p>召回率、查全率：$recall=\frac{TP}{TP+FN}$</p>
<p>调和平均数：$F_{1}=2 \cdot \frac{precision \cdot recall}{precision+reacall}$</p>
<h3 id="P-R​曲线"><a href="#P-R​曲线" class="headerlink" title="P-R​曲线"></a>P-R​曲线</h3><p>我们希望模型预测结果Precision越高越好，同时Recall也越高越好，但事实上这两者在某些情况下有矛盾的。比如极端情况下，我们只预测出了一个正样本的结果，且是准确的，那么Precision就是100%，但是Recall就很低；而如果我们把所有结果都返回，那么比如Recall是100%，但是Precision就会很低。因此在不同的场合中需要自己判断希望Precision比较高或是Recall比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_51.png" alt=""></p>
<p>P-R图直观的显示出学习器在样本总体上的查全率和查准率，在进行比较时，若一个学习器的PR曲线被另一个学习器的PR曲线完全包住，则可以断言后者的性能优于前者（如图中A优于C）。如果两个学习器发生了交叉，则难以断言孰优孰劣，只能在具体的查准率或查全率条件下进行比较（如图中A和B）。如果一定要比较A和B孰优孰劣，一个合理的比较依据是比较PR曲线下面积的大小。在一定程度上表征了学习器在查准率和查全率上取得“双高”的比例，但这个值不太容易估算。所以设计了一些综合考虑查准率和查全率的性能度量。比如“平衡点”（Break-Even Point，BEP），是“查准率=查全率”时的取值。例如学习器C的BEP是0.64,，基于BEP比较，可认为学习器A优于B。</p>
<h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p>ROC的全称是Receiver Operating Characteristic Curve，中文名字叫“受试者工作特征曲线”，顾名思义，其主要的分析方法就是画这条特征曲线。如果在模型中我们没有定好阈值，而是将模型预测结果从高到低排序，将每次概率值依次作为阈值，那么就可以得到多个混淆矩阵。对于每个混淆矩阵，我们计算两个指标TPR和FPR,以FPR为x轴，TPR为y轴画图，就得到了ROC曲线。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_52.png" alt=""></p>
<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p>按照定义，AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，表明分类器对于正例和负例毫无区分能力。而我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x，因此大部分的ROC曲线长成下面这个样子：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_53.png" alt=""></p>
<p>最理想的情况下，即没有真实类别为1而错分为0的样本（TPRate一直为1），也没有真实类别为0而错分为1的样本（FPRate一直为0），AUC为1，这便是AUC的极大值。</p>
]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper Ideas</title>
    <url>/2021/11/02/Paper-Ideas/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下读过论文的idea</p>
<a id="more"></a>
<h1 id="Physics-Coupled-Spatio-Temporal-Active-Learning-for-Dynamical-Systems"><a href="#Physics-Coupled-Spatio-Temporal-Active-Learning-for-Dynamical-Systems" class="headerlink" title="Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems"></a>Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems</h1><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104195000.png" alt="framework"></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104195040.png" alt="FN-PN"></p>
<ul>
<li>初始化<ul>
<li>选定 $n$ 个点 $\longrightarrow$ $\Omega^{n}_{temp}$</li>
<li>创建训练数据 $\longrightarrow$ $D_{temp}$ （选定 $n$ 个点都取 $T_{\omega}$ 时长的数据）</li>
</ul>
</li>
<li>训练<ul>
<li>learn $\lambda$ $\longleftarrow$ 最小化 $E_{q}$ ，偏微分方程</li>
<li>train ST-PCNN $\longleftarrow$ $\lambda$</li>
<li>predict $[\hat{s}]$ $\longleftarrow$ at all locations</li>
<li>$\Omega_{Kriging}^{n}$ $\longleftarrow$ $n$ 个：largest estimate error</li>
<li>$D_{Kriging}$ $\longleftarrow$ 上一步新选出的 $n$ 个，选取 $T_{\omega}$ 时长数据</li>
<li>更新 $D$</li>
</ul>
</li>
</ul>
<h1 id="ACTIVE-LEARNING-OF-DEEP-SURROGATES-FOR-PDES"><a href="#ACTIVE-LEARNING-OF-DEEP-SURROGATES-FOR-PDES" class="headerlink" title="ACTIVE LEARNING OF DEEP SURROGATES FOR PDES"></a>ACTIVE LEARNING OF DEEP SURROGATES FOR PDES</h1><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104203300.png" alt="model"></p>
<p>algorithm: reduce number of training points(selected based on error measure)</p>
<p>AL: adding the most uncertain points</p>
<ul>
<li><p>Initialize:</p>
<p>random choose $n_{init}$ train 50 epochs $\longrightarrow$ $\widetilde{t^{0}}(p)$</p>
</li>
<li><p>Do T times:</p>
<ul>
<li>evaluate $\widetilde{t^{i}}(p)$ at $M×K$ points</li>
<li>choose $K$ points(largest $\sigma_{*}^{2}$ )</li>
<li>put the $K$ points into training set</li>
</ul>
</li>
</ul>
<h1 id="Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows"><a href="#Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows" class="headerlink" title="Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"></a>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</h1><p>Application：language $\longrightarrow$ vision</p>
<p>Challenges:</p>
<ul>
<li>scale(language Transformer: word tokens)</li>
<li>high resolution of pixels(计算复杂度： $n^{2}$ )</li>
</ul>
<p>Key point:</p>
<ul>
<li>小批量开始 $\longrightarrow$ 逐渐合并邻居</li>
<li>如何实现线性复杂度：在无重叠窗口计算自注意力<ul>
<li>standard transformer architecture: global self-attention $\longrightarrow$ quadratic complexity</li>
<li>Swin Transformer: local self-attention $\longrightarrow$ linear complexity</li>
</ul>
</li>
</ul>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><ul>
<li><p>Overall Framework</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/swin_1.png" alt=""></p>
</li>
<li><p>Two Successive Swin Transformer Blocks  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/swin_2.png" alt=""></p>
</li>
</ul>
<h1 id="Adversarial-Sampling-for-Solving-Differential-Equations-with-Neural-Networks"><a href="#Adversarial-Sampling-for-Solving-Differential-Equations-with-Neural-Networks" class="headerlink" title="Adversarial Sampling for Solving Differential Equations with Neural Networks"></a>Adversarial Sampling for Solving Differential Equations with Neural Networks</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>sample points adversarially to maximize the loss of the current solution estimate  </p>
<p>Advantages on using neural networks:</p>
<ul>
<li>instead of obtaining solution values at discretized points, we get a closed and differentiable solution function</li>
<li>it is more effective in solving high dimensional PDEs by faring better against the “curse of dimensionality” </li>
<li>numerical errors are not accumulated in each iteration</li>
<li>initial and boundary conditions are satisfied by construction</li>
</ul>
<p>Drawbacks  of using a predefined sampling scheme: agnostic to the equation being solved as well as our current estimate $\hat{y}$</p>
<h2 id="Key-Idea"><a href="#Key-Idea" class="headerlink" title="Key Idea"></a>Key Idea</h2><p>present a sampling scheme that is dependent on the current estimate $\hat{y}$, using a neural network to represent a variable sampling distribution.</p>
<p>In each iteration, the sampler is trained to <strong>produce points which maximize the loss of the solver (and a secondary loss). </strong></p>
<p>Thus, it competes with the solver whose weights are updated to minimize the loss at these very points.  </p>
<h2 id="Architecture-1"><a href="#Architecture-1" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/image-20211128164821263.png" alt=""></p>
<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>It is observed that if the sampler is purely optimized with the objective of maximizing $\hat{L}(\hat{y}; x)$(residual loss corresponding to the $DE$ at samples $x$), it tends to collapse all samples to one single point of high loss. </p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>Therefore, use <strong>an additional loss term $D_{k}$,</strong>Given points$\begin{Bmatrix}x_{1},x_{2},\dots,x_{n}\end{Bmatrix}$, we define $d_{k}(x_{i})$ to be the sum of distances of $x_{i}$ from its $k$ nearest neighbors.</p>
<h1 id="Machine-Learning-of-Linear-Differential-Equations-using-Gaussian-Processes"><a href="#Machine-Learning-of-Linear-Differential-Equations-using-Gaussian-Processes" class="headerlink" title="Machine Learning of Linear Differential Equations using Gaussian Processes"></a>Machine Learning of Linear Differential Equations using Gaussian Processes</h1><p>Gaussian process priors are modified according to the particular form of such operators and are employed to infer parameters of the linear equations from scarce and possibly noisy observations.  </p>
<p>optimal model parameters and hyper-parameters are all learned directly from the data by maximizing the joint marginal log-likelihood of the probabilistic model instead of being guessed or tuned manually by the user.  </p>
<h2 id="Priors"><a href="#Priors" class="headerlink" title="Priors"></a>Priors</h2><p>place the $GP$ prior on $u(x)$ instead of $f(x)$ </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/image-20211128222044474.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222142.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222208.png" alt=""></p>
<h2 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222342.png" alt=""></p>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>employing a $Quasi-Newton$ optimizer $L-BFGS$ to minimize the negative log marginal likelihood</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222510.png" alt=""></p>
<h2 id="Predictions"><a href="#Predictions" class="headerlink" title="Predictions"></a>Predictions</h2><p>one can predict the values $u(x)$ and $f(x)$ at a new test point $x$ by writing the posterior distributions</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222753.png" alt=""></p>
<h1 id="Learning-Physics-Informed-Neural-Networks-without-Stacked-Back-propagation"><a href="#Learning-Physics-Informed-Neural-Networks-without-Stacked-Back-propagation" class="headerlink" title="Learning Physics-Informed Neural Networks without Stacked Back-propagation"></a>Learning Physics-Informed Neural Networks without Stacked Back-propagation</h1><h2 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h2><p>PINN training suffers from a significant scalability issue</p>
<h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ul>
<li>developing a novel approach to train the model without stacked back-propagation</li>
<li>parameterize the PDE solution $u(x; θ)$ as a Gaussian smoothed model, $u(x;\theta)=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}f(x+\delta,\theta)$, where $u$ transforms arbitrary base network $f$ by injecting Gaussian noise into input $x$. This transformation gives rise to a key property for $u$ where its derivatives to the input can be efficiently calculated <em>without back-propagation</em>.<ul>
<li>Such property is derived from the well-known Stein’s Identity that essentially tells that the derivatives of any Gaussian smoothed function $u$ can be reformulated as some expectation terms of the output of its base $f$, which can be estimated using Monte Carlo methods. </li>
</ul>
</li>
<li>given any PDE problem, we can replace the derivative terms in the PDE with Stein’s<br>derivative estimators.</li>
</ul>
<h2 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h2><ol>
<li>no longer need stacked back-propagation to compute the loss</li>
<li>parallelize the computation into distributed machines to further accelerate the training </li>
</ol>
<h2 id="Notice"><a href="#Notice" class="headerlink" title="Notice"></a>Notice</h2><p>for large $\sigma$, the induced Gaussian smoothed models may not be expressive enough to approximate functions (i.e., learn solutions) with a large Lipschitz constant. Therefore, using a small value of $\sigma$ is usually a better choice in practice. However, a small $\sigma$ will lead to high-variance Stein’s derivative estimation, which inevitably causes unstable training.  </p>
<h2 id="Two-Sources-of-Inefficiency-In-Computing-the-PINN-Loss"><a href="#Two-Sources-of-Inefficiency-In-Computing-the-PINN-Loss" class="headerlink" title="Two Sources of Inefficiency In Computing the PINN Loss"></a>Two Sources of Inefficiency In Computing the PINN Loss</h2><ol>
<li>different orders of derivatives can only be calculated sequentially  </li>
<li>the dimension-level inefficiency </li>
</ol>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="4-1-Back-propagation-free-Derivative-Estimators"><a href="#4-1-Back-propagation-free-Derivative-Estimators" class="headerlink" title="4.1 Back-propagation-free Derivative Estimators"></a>4.1 Back-propagation-free Derivative Estimators</h3><p>define $u(x)=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}f(x+\delta,\theta)$, then we have $\bigtriangledown_{x}u=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}[\frac{\delta}{\sigma^{2}}f(x+\delta)]$</p>
<h4 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_1.png" alt=""></p>
<p>From the above theorem, we can see that the first-order derivative rxu can be reformulated as an expectation term $E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}[\frac{\delta}{\sigma^{2}}f(x+\delta)]$, To calculate the value of the expectation, we can use Monte Carlo method to obtain an unbiased estimation from K.  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_2.png" alt=""></p>
<h3 id="4-2-Model-Capacity"><a href="#4-2-Model-Capacity" class="headerlink" title="4.2 Model Capacity"></a>4.2 Model Capacity</h3><p>For any measurable function $f : R^{d}\rightarrow R$, define $u(x)=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}f(x+\delta,\theta)$, then<br>$u(x) $is $\frac{F}{\sigma}\sqrt{\frac{2}{\pi}}$-Lipschitz with respect to $l_{2}$-norm, where $F=sup_{x\in R^{d}}|f(x)|$.  </p>
<h4 id="Proof-1"><a href="#Proof-1" class="headerlink" title="Proof"></a>Proof</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_3.png" alt=""></p>
<h3 id="4-3-Variance-Reduced-Stein’s-Derivative-Estimators"><a href="#4-3-Variance-Reduced-Stein’s-Derivative-Estimators" class="headerlink" title="4.3 Variance-Reduced Stein’s Derivative Estimators"></a>4.3 Variance-Reduced Stein’s Derivative Estimators</h3><h4 id="The-control-variate-method"><a href="#The-control-variate-method" class="headerlink" title="The control variate method"></a>The control variate method</h4><p>One generic approach to reducing the variance of Monte Carlo estimates of integrals is to use an additive control variate, which is known as baseline.  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_4.png" alt=""></p>
<h4 id="Further-improvement-using-the-antithetic-variable-method"><a href="#Further-improvement-using-the-antithetic-variable-method" class="headerlink" title="Further improvement using the antithetic variable method"></a>Further improvement using the antithetic variable method</h4><p>The antithetic variable method is yet another powerful technique for variance reduction.  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_5.png" alt=""></p>
<h1 id="Neural-Galerkin-Scheme-with-Active-Learning-for-High-Dimensional-Evolution-Equations"><a href="#Neural-Galerkin-Scheme-with-Active-Learning-for-High-Dimensional-Evolution-Equations" class="headerlink" title="Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations"></a>Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><h3 id="problems"><a href="#problems" class="headerlink" title="problems"></a>problems</h3><ol>
<li>no data are available  </li>
<li>the principal aim is to gather insights from a known model  </li>
</ol>
<p>高维逼近问题需要一个完全不同的“离线”自适应概念来规避维数的诅咒。</p>
<h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p>develop time-integrators for PDEs that use DNNs to represent the solution but update the parameters sequentially from one time slice to another rather than globally over the whole time-space domain.  </p>
<p>use the structural form of the PDEs, but no a priori data about their solution.</p>
<p>leverage adaptivity in both function approximation and data acquisition.   </p>
<h3 id="Main-contributions"><a href="#Main-contributions" class="headerlink" title="Main contributions"></a>Main contributions</h3><ol>
<li><p>derive a nonlinear evolution equation for the parameters. </p>
<p>This equation can then be integrated using standard solvers with different level of sophistication.   </p>
<p>the proposed approach takes larger time steps when possible and corrects to smaller time-step sizes if the dynamics of the solution require it.  </p>
</li>
<li><p>The evolution equations that we derive for the DNN parameters involve operators that require estimation via sampling in space.  propose a dynamical estimation of the loss.   </p>
</li>
<li><p>We illustrate the viability and usefulness of our approach on a series of test cases.  </p>
</li>
</ol>
<h3 id="Related-works"><a href="#Related-works" class="headerlink" title="Related works"></a>Related works</h3><ol>
<li>The need for adaptive data acquisition in the context of machine learning for problems<br>in science and engineering has been emphasized in previous works.</li>
<li>There also is a large body of work on numerically solving PDEs with DNN parametrization based on collocation over the spatio-temporal domain.   </li>
<li>There also is a range of surrogate-modeling methods based on nonlinear parametrizations.  </li>
</ol>
<h2 id="Neural-Galerkin-schemes"><a href="#Neural-Galerkin-schemes" class="headerlink" title="Neural Galerkin schemes"></a>Neural Galerkin schemes</h2><h3 id="Neural-Galerkin"><a href="#Neural-Galerkin" class="headerlink" title="Neural Galerkin"></a>Neural Galerkin</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309201020.png" alt=""></p>
<h4 id="Parametrizing-the-solution"><a href="#Parametrizing-the-solution" class="headerlink" title="Parametrizing the solution"></a>Parametrizing the solution</h4><p>use ansatz $u(t,x)=U(\theta(t),x)$ , It is important to emphasize that U may depend nonlinearly on $\theta (t)$ , which is in stark contrast to the majority of classical approximations in scientific computing that have a linear dependence on the parameter.</p>
<h4 id="Controlling-the-residual"><a href="#Controlling-the-residual" class="headerlink" title="Controlling the residual"></a>Controlling the residual</h4><p>Since we do not have access to the solution $u(t)$ , we will use the structure of the governing equation to control the approximation error. To this end, note that inserting the ansatz solution $U(\theta(t))$ in Eq. (1). assuming differentiability of $\theta(t)$ and using $\partial_{t}U(\theta(t))=\triangledown_{\theta}U(\theta)\cdot \dot{\theta}(t)$ , leads to the residual function r:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309201330.png" alt=""></p>
<p>we will opt for controlling the residual locally in time, which leads to an initial value problem that can be solved over arbitrary long times. Specifically, we will seek $\theta(t)$ such that for all $t &gt; 0$ it holds</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309202447.png" alt=""></p>
<p>where we define the objective function $J_{t}:\Theta \times \dot{\Theta} \rightarrow \mathbb{R}$</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309202721.png" alt=""></p>
<h4 id="Neural-Galerkin-equations"><a href="#Neural-Galerkin-equations" class="headerlink" title="Neural Galerkin equations"></a>Neural Galerkin equations</h4><p>Since $J_{t}(\theta(t); \eta)$ is quadratic in $\eta$ and positive semi-definite, its minimum is unique and its minimizers solve the Euler-Lagrange equation</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309204135.png" alt=""></p>
<p>Written explicitly, Eq. (6) is a system of ODEs for $\theta(t)$:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309204238.png" alt=""></p>
<p>where we defined</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309210508.png" alt=""></p>
<p>in which $\bigotimes$ denotes the outer product.  The initial condition $\theta_{0}$ can be obtained via e.g. minimization of the least-squares loss between $u_{0}$ and $U(\theta_{0})$:  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310155509.png" alt=""></p>
<p>where ν is some user-prescribed measure with full support on $\mathcal{X}$ .  </p>
<h3 id="Estimating-M-theta-and-F-t-theta"><a href="#Estimating-M-theta-and-F-t-theta" class="headerlink" title="Estimating $M(\theta)$ and $F(t, \theta)$"></a>Estimating $M(\theta)$ and $F(t, \theta)$</h3><p>integrals in Eq. (8) do not admit a closed-form solution and so will need to be numerically estimated. In low dimensions,  we perform quadrature on a grid; in high dimensions, If $ν_{\theta}$<br>is a probability measure, we can consider using a vanilla Monte-Carlo estimator for each term,     </p>
<p>by drawing $n$ samples $\{x_{i}\}_{i=1}^{n}$ from $ν_{\theta}$ and replacing the expectations by empirical averages over these samples.  This estimator is efficient to approximate certain kernels uniformly over high-dimensional spaces, but not necessarily if the solution to the PDE develops spatially localized structures. Here are two options:</p>
<h4 id="Importance-sampling-with-a-fixed-measure"><a href="#Importance-sampling-with-a-fixed-measure" class="headerlink" title="Importance sampling with a fixed measure"></a>Importance sampling with a fixed measure</h4><p>importance sampling: <a href="https://zhuanlan.zhihu.com/p/41217212">重要性采样</a></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310165322.png" alt=""></p>
<h4 id="Direct-sampling-with-an-adaptive-measure"><a href="#Direct-sampling-with-an-adaptive-measure" class="headerlink" title="Direct sampling with an adaptive measure"></a>Direct sampling with an adaptive measure</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310170640.png" alt=""></p>
<h3 id="Discretization-in-time"><a href="#Discretization-in-time" class="headerlink" title="Discretization in time"></a>Discretization in time</h3><p>To update $\theta^{k}$, we can either use:  </p>
<h4 id="Explicit-integrators"><a href="#Explicit-integrators" class="headerlink" title="Explicit integrators"></a>Explicit integrators</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310171021.png" alt=""></p>
<h4 id="Implicit-integrators"><a href="#Implicit-integrators" class="headerlink" title="Implicit integrators"></a>Implicit integrators</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310171036.png" alt=""></p>
<h3 id="Neural-architectures"><a href="#Neural-architectures" class="headerlink" title="Neural architectures"></a>Neural architectures</h3><p>The first is a shallow (one-hidden-layer) network with m nodes given by</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180129.png" alt=""></p>
<p> The first is the Gaussian kernel, which we use when $\mathcal{X} = \mathbb{R}^{d}$</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180331.png" alt=""></p>
<p>the second is we use when $\mathcal{X} = L\mathbb{T}^{d}$ with L &gt; 0 and we need to enforce periodicity.</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180732.png" alt=""></p>
<p>The other neural architecture that we use is a feedforward neural network with $l\in \mathbb{N}$ hidden layers and m nodes per layer:  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310182117.png" alt=""></p>
<p>$\varphi_{tanh}^{L}$ is the nonlinear unit</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310182545.png" alt=""></p>
<h1 id="AUTOIP-A-UNITED-FRAMEWORK-TO-INTEGRATE-PHYSICS-INTO-GAUSSIAN-PROCESSES"><a href="#AUTOIP-A-UNITED-FRAMEWORK-TO-INTEGRATE-PHYSICS-INTO-GAUSSIAN-PROCESSES" class="headerlink" title="AUTOIP: A UNITED FRAMEWORK TO INTEGRATE PHYSICS INTO GAUSSIAN PROCESSES"></a>AUTOIP: A UNITED FRAMEWORK TO INTEGRATE PHYSICS INTO GAUSSIAN PROCESSES</h1><h2 id="Introduction-2"><a href="#Introduction-2" class="headerlink" title="Introduction"></a>Introduction</h2><p>To model a system, one usually writes down a set of partial differential equations (PDEs) and/or ordinary differential equations (ODEs) that characterize how the system runs according to physical laws.  Then, one identifies the boundary and/or initial conditions and solves the equations.</p>
<p>Machine learning and data science use a completely different paradigm. They estimate or reconstruct target functions from observed data rather than from solving the equations.</p>
<h3 id="Contribution-1"><a href="#Contribution-1" class="headerlink" title="Contribution"></a>Contribution</h3><p>consider incorporating physics knowledge into Gaussian processes (GPs). Not only flexible enough to learn various, complex functions from data, but also convenient to quantify the uncertainty due to their closed-form posterior distribution. </p>
<ol>
<li>联合采样目标函数在input的值，方程有关的微分的值，多元高斯分布在配点的潜在源. we couple the target function and its derivatives in a probabilistic framework, without the need for conducting differential operations on a nonlinear surrogate (like NNs).  </li>
<li>Next, we feed these samples to two likelihoods. One is to fit the training data. The other is a virtual Gaussian likelihood that encourages the conformity to the equation.</li>
<li>we use the whitening trick to parameterize the latent random variables with a standard Gaussian noise.       </li>
</ol>
<h2 id="Gaussian-Process-Regression"><a href="#Gaussian-Process-Regression" class="headerlink" title="Gaussian Process Regression"></a>Gaussian Process Regression</h2><p>Consider a training dataset $\mathcal{D}=(X,y)$, where $X = [x_{1},\dots,x_{N}]$, $y = [y_{1},\dots, y_{N}]$, each $x_{n}$ is an input, and $y_{n}$ is a noisy observation of $f(x_{n})$.  Then the function values at the training inputs, $f = [f(x_{1}),\dots,f(x_{N})]$, follow a multivariate Gaussian distribution, $p(f|X) = N(f|0,K)$ where each $[K]_{i,j} = κ(x_{i}, x_{j})$  </p>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>Specifically, we first construct a GP prior over $u$, $g$ and the equation-related derivatives, i.e., $\partial_{t}u$ and $\partial_{x}^{2}u$  , The covariance and cross-covariance among $u$ and its derivatives can be obtained outright from $κ_{u}$ via kernel differentiation   </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311161000.png" alt=""></p>
<p>Now, we can leverage the covariance functions in (4) and $k_{g}$ to construct a joint Gaussian prior over $f = [u; \hat{u}; \hat{u}_{t}; \hat{u}_{xx}; g]$ ,</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163413.png" alt=""></p>
<p>Given $f$ , we feed them to two data likelihoods. One is to fit the actual observations from a Gaussian noise model,  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163508.png" alt=""></p>
<p>The other is a virtual Gaussian likelihood that integrates the physics knowledge in the differential equation</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163540.png" alt=""></p>
<h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><p> the virtual likelihood (7) couples the components of $f$ to reflect the equation. Hence, we develop a general variational inference algorithm to jointly estimate the posterior<br>of $f$ and kernel parameters, inverse noise variance $\beta$, $v$, etc. However, we found that a straightforward implementation to optimize the variational posterior $q(f)$ is often stuck at an inferior estimate.  </p>
<p>That is, we parameterize $f$ with a Gaussian noise,</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311164311.png" alt=""></p>
<p>where $\eta \thicksim N(0, I)$, and $A$ is the Cholesky decomposition of the covariance matrix $\Sigma$  i.e., $\Sigma = AA^{T}$ . Therefore, the joint probability of the model can be rewritten as</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311164651.png" alt=""></p>
<p>We then introduce a Gaussian variational posterior for the noise,  $q(\eta) = \mathcal{N}(\eta|\mu,LL^{T})$ where $L$ is a lower-triangular matrix to ensure the positive definiteness of the covariance matrix.   </p>
<p>We then construct a variational evidence lower bound,</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311170307.png" alt=""></p>
<h1 id="RESPECTING-CAUSALITY-IS-ALL-YOU-NEED-FOR-TRAINING-PHYSICS-INFORMED-NEURAL-NETWORKS"><a href="#RESPECTING-CAUSALITY-IS-ALL-YOU-NEED-FOR-TRAINING-PHYSICS-INFORMED-NEURAL-NETWORKS" class="headerlink" title="RESPECTING CAUSALITY IS ALL YOU NEED FOR TRAINING PHYSICS-INFORMED NEURAL NETWORKS"></a>RESPECTING CAUSALITY IS ALL YOU NEED FOR TRAINING PHYSICS-INFORMED NEURAL NETWORKS</h1><h2 id="Introduction-3"><a href="#Introduction-3" class="headerlink" title="Introduction"></a>Introduction</h2><p>Extensions to enhance the accuracy and robustness of PINNs: novel optimization algorithms for adaptive training;  adaptive algorithms for selecting batches of training data; novel network architectures; domain decomposition strategies; new types of activation functions; sequential learning strategies.</p>
<p>notion of temporal dependence is absent in most continuous-time PINNs formulations   </p>
<p>Specific contributions can be summarized as:  </p>
<ul>
<li>We reveal an implicit bias suggesting that continuous-time PINNs models can violate causality, and hence are susceptible to converge towards erroneous solutions.  </li>
<li>We put forth a simple re-formulation of PINNs loss functions that allows us to explicitly respect the causal structure that characterizes the solution of general nonlinear PDEs. </li>
<li>Strikingly, we demonstrate that this simple modification alone is enough to introduce significant accuracy improvements, allowing us to tackle problems that have remained elusive to PINNs.  </li>
<li>We provide a practical quantitative criterion for assessing the training convergence of a PINNs model.  </li>
<li>We examine a collection of challenging benchmarks for which existing PINNs formulations fail, and demonstrate that the proposed causal training strategy leads to state-of-the-art results.  </li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317183104.png" alt=""></p>
<h2 id="Causal-training-for-physics-informed-neural-networks"><a href="#Causal-training-for-physics-informed-neural-networks" class="headerlink" title="Causal training for physics-informed neural networks"></a>Causal training for physics-informed neural networks</h2><p>To this end, we define a weighted residual loss as</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317184032.png" alt=""></p>
<p>We recognize that the weights $w_{i}$ should be large – and therefore allow the minimization of $\mathcal{L}_{r}(t_{i}, \theta)$ – only if all residuals $\{\mathcal{L}_{r}(t_{k}, \theta)\}^{i}_{k=1}$ before $t_{i}$ are minimized properly, and vice versa.   </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317184906.png" alt=""></p>
<p>As such, the weighted residual loss can be written as  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317185502.png" alt=""></p>
<p>$\mathcal{L}_{r}(t_{i}, \theta)$ will not be minimized unless all previous residuals $\{ \mathcal{L}_{r}(t_{k}, \theta) \}_{k=1}^{i-1}$ decrease to<br>some small value such that $w_{i}$ is large enough.</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317192154.png" alt=""></p>
<h1 id="Deep-Implicit-Moving-Least-Squares-Functions-for-3D-Reconstruction"><a href="#Deep-Implicit-Moving-Least-Squares-Functions-for-3D-Reconstruction" class="headerlink" title="Deep Implicit Moving Least-Squares Functions for 3D Reconstruction"></a>Deep Implicit Moving Least-Squares Functions for 3D Reconstruction</h1><h2 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h2><p>点集因为其灵活和轻量级的表示被广泛应用于3D深度学习，但是它的离散特性限制了对连续和精细的几何图形的表示。这篇文章通过引入隐式最小二乘（IMLS）曲面公式，将离散的点集转化成光滑的曲面，定义了点集上的局部隐式函数。IMLSNet预测一个八叉树结构，作为再需要时生成MLS点的支架，并且用学到的先验知识来表征形状几何。同时，一旦MLS点被预测，隐式函数的评估将独立于神经网络，从而实现了快速运行时评估。</p>
<h2 id="Introduction-4"><a href="#Introduction-4" class="headerlink" title="Introduction"></a>Introduction</h2><p>与多边形网格和体积网格等其他3D表示相比，点集作为神经元被自然地嵌入DNN中，易于获取，拥有最小的额外结构，动态捕捉复杂的几何和拓扑，并且不会浪费自由空间区域的计算。事实上，点集已经被用于基于深度学习的不同任务的3D分析。在使用点集进行深度学习生成三维数据时，一方面可以灵活地建模变化的拓扑和复杂的表面，另一方面也会受到离散和粗糙几何的影响。</p>
<p>近年来的研究主要集中在以网格和多边形块的形式生成形状，但由于其离散性和非光滑性，其形状表达能力仍然受到限制。而深度隐式函数方法则在整个三维域上定义光滑函数，以保证结果的连续性，在高质量的三维重建中具有很好的应用前景。然而，隐式曲面生成是低效的，因为对于三维域中的每个点，在提取曲面之前，网络都必须单独评估。在本文中，我们结合了隐函数方法和点集方法的优点，在保留显式点集固有的灵活性和计算效率的同时，将点集表示方法扩展到隐式曲面模型中，以实现高质量的三维生成。</p>
<p>对于通过点集建模光滑曲面，我们采用点集曲面，并使用点的移动最小二乘插值来定义在点集的窄带区域内的局部隐函数。特别是对于本文使用的隐式MLS公式，对于狭窄区域内的任意空间点，采用隐式MLS函数将其映射到零水平集表面的有符号距离值，定义为附近点支持的有符号距离的定向平面的加权混合；然后将零水平集曲面提取为光滑连续的曲面，用于形状表示。</p>
<p>虽然MLS曲面在三维重建和绘制方面已经得到了很好的研究，但将其表示整合到深度学习框架中带来了新的挑战和机遇，这在现有的基于点集或隐式表示的方法中是看不到的。首先，当点足够密集且均匀分布于重构形状上时，才能最有效地定义隐式MLS曲面。然而大多数点生成方法固定点的数量并且消耗大量资源用于难以概括的密集点的预测,我们引入一个octree-based脚手架，只在需要时根据目标形状生成可变数量的MLS点，通过定制损失函数进一步调整点的分布。第二，为了度量训练监督和测试评估的预测隐函数，而现有的隐式方法必须在整个3D域上使用密集抽样，MLS表面自然地定位在生成点的窄带区域内，这促使我们只在八叉树节点上使用更简洁的抽样来进行监督和评估。此外，一旦所有的MLS点都嵌入到三维域中，评估就独立于网络，从而避免了其他隐式方法典型的点网络评估的代价。</p>
<p>我们使用广泛的消融试验来验证设计的选择。我们也通过三维物体的重建任务证明了我们的深度隐式MLS曲面方法比点集生成方法和其他全局或局部隐式函数方法都有更好的性能。</p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Deep-representations-for-3D-generation"><a href="#Deep-representations-for-3D-generation" class="headerlink" title="Deep representations for 3D generation"></a>Deep representations for 3D generation</h3><p>点集是许多著作中常用的表示方法。但由于通常指定了点的个数，其表示细节几何的能力受到限制，需要进一步的点上采样来提高点密度和形状质量。</p>
<p>密集的体素很好地表征了形状占用率，但其高昂的内存成本妨碍了其用于表示高分辨率3D内容。稀疏体素包括八叉树克服了这些问题，在内存和计算方面都有很大的效率。</p>
<p>网格表示和基于patch的表示是提高形状质量的方便的3D表示。然而，它们的能力受到预定义的网格拓扑和分辨率，或多个补丁的断开连接的限制。中间3D表示，如粗体素或形状骨架是进一步提高其质量的可能方法。中间3D表示，如粗体素或形状骨架是进一步提高其质量的可能方法。</p>
<p>基于基元的表示使用一组简单的几何对象，如平面和立方体来近似3D形状。基于结构的表示明确地将语义部件结构编码为长方体，并使用体素表示在每个长方体内重构部件。虽然它们适用于表征形状结构，但由于基元的简单性，它们的近似质量也受到限制。</p>
<p>最近出现了基于隐式表面的深度学习方法提供了一种平滑连续的3D表示，并在连续空间中实现函数评价。对于一个给定的点，网络预测它的占用率或从它到表面的符号距离。这些技术最近得到了进一步的改进，通过整合局部特征来建模更详细的形状几何。</p>
<p>我们的方法属于深度隐式类，通过对光滑、连续的隐式MLS曲面进行建模，同时具有显式点集生成的灵活性和效率；它是一种混合的3D深度学习表示，结合了点集和隐函数的优点。</p>
<h3 id="Surface-reconstruction-from-point-clouds"><a href="#Surface-reconstruction-from-point-clouds" class="headerlink" title="Surface reconstruction from point clouds"></a>Surface reconstruction from point clouds</h3><p>表面重建技术已经研究了几十年。其中，利用全局或局部平滑先验对点云进行高质量重建的方法包括：多层分割的单位云(MPU)、泊松重建、径向基函数和移动最小二乘曲面(MLS) 广泛用于点集曲面建模和绘制。</p>
<p>由于MLS的快速和局部评价特性，我们选择MLS表面作为我们的深层3D表示。MLS曲面可以分为两种类型：投影MLS曲面和隐式MLS曲面(IMLS)。前者通过迭代投影定义一组平稳点，后者直接定义隐函数。我们使用基于IMLS的带符号的距离监控，实现了快速的功能评估。</p>
<h2 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h2><h3 id="IMLS-surface"><a href="#IMLS-surface" class="headerlink" title="IMLS surface"></a>IMLS surface</h3><p>隐式MLS曲面定义如下: 表示 $\mathcal{P}=\{p_{i} \in \mathbb{R}^{3} \}_{i=1}^{N}$ 为三维点集，每个点都具有单位法向 $n_{i} \in \mathbb{R}^{3}$，控制半径 $r_{i} \in \mathbb{R}^{+}$ 。为了方便起见，我们称这些点为MLS点。</p>
<p>对于每个MLS点 $p_{i}$ 到其切平面的有符号距离函数定义为 $＜x-p_{i},n_{i}＞$ ，其中 $＜\cdot,\cdot＞$ 是内积。通过加权平均所有逐点带符号的距离函数，我们得到了一个隐函数 $F(x)$ 的零水平集定义了隐式曲面 $\mathcal{S}$ :</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409163226.png" alt=""></p>
<p>这里我们设权函数 $\theta(d,r)=exp(-d^{2}/r^{2})$ 。Kolluri证明了在均匀采样条件下IMLS曲面 $\mathcal{S}$ 是对 $\mathcal{P}$ 进行采样的原始曲面的几何和拓扑正确的近似，而IMLS函数 $F$ 是对原始曲面的有符号距离函数的紧密近似。</p>
<p>由于当 $x$ 远离 $p_{i}$ 时，权函数衰减，因此只考虑附近的MLS点可以加速 $F(x)$ 的求值。Eq.(1)可以修改为:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409163632.png" alt=""></p>
<p>其中 $\Omega(x)$ 表示以 $x$ 为中心，半径为 $r_{b}$ 的球内的MLS点集合。 $r_{b}$ 可由用户设置为截断点距离值。</p>
<p>由于上述公式，函数值为零 $F(x)$ 存在于IMLS点的窄带区域。通过对边界区域内的规则网格进行函数求值，通过移动立方体可以有效地将 $\mathcal{S}$ 显式地提取为三角形网格。</p>
<h3 id="Deep-IMLS-surface"><a href="#Deep-IMLS-surface" class="headerlink" title="Deep IMLS surface"></a>Deep IMLS surface</h3><p>在实际三维重建中，稀疏的、无方向的点云可能带有噪声和缺失区域，这是典型的输入，但传统方法无法很好地处理这些输入三维重建方法，比如泊松重建。为了处理这种不完美的数据，我们的目标是设计一个自编码的神经网络来生成IMLS曲面。</p>
<p>定义网络输出的一种简单方法是设置固定数量的IMLS点元组 $\{ p_{i},n_{i},r_{i} \}_{i=1}^{N}$ 。但是，它会限制IMLS的表示能力，不能很好地从数据中学习局部几何先验。我们引入了一个中间网络输出：基于八叉树的脚手架，以帮助生成需要的MLS点。基于八叉树的支架是一个 $d$ 深度的八叉树 $\mathcal{O}$ ，它在多分辨率下大致近似3D表面。对于每一个最细的非空八分位数 $o_{k}$ ，也就是八叉树中最小的非空体素，我们关联一个小集合的MLS点，这些点的位置靠近八分位数中心 $c_{k}$ 。具体来说与 $o_{k}$ 关联的MLS点定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409170339.png" alt=""></p>
<p>其中 $t_{k,l}\in \mathbb{R}^{3}$ 是 $p_{k,l}$ 到 $c_{k}$ 的偏移向量， $s$ 是一个预定义的点的数目。由于基于八叉树的支架的结构依赖于目标表面，因此需要自适应地确定MLS点的总数及其位置。</p>
<p>有了上面的设置，一个适合IMLS生成的网络应该输出：</p>
<p>（1）一个基于八叉树的脚手架 $\mathcal{O}$ </p>
<p>（2）一个最细的非空八分圆 $o_{k}$ 的MLS点偏移量、MLS点法线和控制半径</p>
<p>这里我们注意到，由输入噪声和稀疏点云创建的八叉树不能用作脚手架，因为它可能是不完整和不准确的，并且不同于目标形状。</p>
<h4 id="Scaffold-prediction"><a href="#Scaffold-prediction" class="headerlink" title="Scaffold prediction"></a>Scaffold prediction</h4><p>使用基于八叉树的卷积神经网络(O-CNN)自动编码器来生成支架。其编码器采用输入点云构建的深度 $d_{in}$ 八叉树作为输入，并仅在八叉树内进行CNN计算。它的解码器以4 × 4 × 4的单元格开始，预测每个单元格是否空，如果单元格不空，则将其细分为8个八边形。这个过程递归地对每个非空的八进制执行，直到达到最大输出八叉树深度 $d_{out}$ 。</p>
<h4 id="MLS-point-prediction"><a href="#MLS-point-prediction" class="headerlink" title="MLS point prediction"></a>MLS point prediction</h4><p>与之前工作不同，解码器在每个最细的非空八分圆处回归定向点或平面补丁以实现亚体素精度，我们通过一个具有如下隐含层的多层感知器(MLP)来预测MLS点元组，该元组的特征向量用 $f(o_{k})$ 表示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409190020.png" alt=""></p>
<p>注意，MLP预测了 $p_{k,l}$ 的局部坐标，即 $t_{k,l}$ ，因此它可以从数据中学习局部先验。为了保证 $p_{k,l}$ 接近 $c_{k}$ ， $t_{k,l}$ 的每个坐标分量的取值范围限制在 $[−\beta h， \beta h]$ ，这里 $h$ 为最细的八分区的大小， $\beta$ 默认设置为1.5。我们还将 $r_{k,s}$ 限制在 $[l_{r}/ 2,2l_{r}]$ 内，其中 $l_{r} = \frac{h}{\sqrt{s}}$ 。这些约束是通过使用tanh激活网络输出来实现的，并通过其范围缩放值。</p>
<h3 id="Network-structure"><a href="#Network-structure" class="headerlink" title="Network structure"></a>Network structure</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409191356.png" alt=""></p>
<p>论文使用类似 U-Net 的 O-CNN 自动编码器，其中包含 O-CNN ResNet 块和输出引导的跳过连接。对于给定的无方向点云，论文提出为其构建一个深度八叉树。在每个最细的八分圆中，通过将八分圆内输入点的平均位置的偏移量与带有二进制标量的八分圆中心的偏移量与=连接来设置输入 4 维信号，该二进制标量指示八分圆是否为空。</p>
<p>Resblock(n, c) 表示一个 n 层基于 O-CNN 的残差块，通道编号为 c。Downsample(c) 和 Upsample(c) 是基于八叉树的卷积和反卷积算子 [49]，然后是批量归一化和 ReLU。对于第一个 Resblock，c 设置为 64，并且在每个 Downsample 算子之后增加 2 倍，并且在每个 Upsample 算子之后除以 2。在论文的实验中，论文设置 n = 3。隐藏层 MLP 用于预测八分圆是否为空。</p>
<h3 id="Loss-function-design"><a href="#Loss-function-design" class="headerlink" title="Loss function design"></a>Loss function design</h3><h4 id="Octree-structure-loss"><a href="#Octree-structure-loss" class="headerlink" title="Octree structure loss"></a>Octree structure loss</h4><p>八分圆状态的确定是一个二元分类问题：0 代表空，1 代表非空。 论文使用 O 的每个八分圆处的 sigmoid 交叉熵损失的加权求和来定义八叉树结构损失。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192717.png" alt=""></p>
<h4 id="SDF-loss"><a href="#SDF-loss" class="headerlink" title="SDF loss"></a>SDF loss</h4><p>IMLS曲面的预测值和真实值之间的差异用SDF损失表示</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192809.png" alt=""></p>
<p>这里 F 的梯度可以近似为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192845.png" alt=""></p>
<h4 id="MLS-point-repulsion-loss"><a href="#MLS-point-repulsion-loss" class="headerlink" title="MLS point repulsion loss"></a>MLS point repulsion loss</h4><p>用于改善生成的 MLS 点的局部规律性。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192956.png" alt=""></p>
<p>其中 $||p_{i}-p_{j}||_{proj}=||(T-n_{i}n_{i}^{T})(p_{i}-p_{j})||$ 是 $p_{i}-p_{j}$ 在 $p_{i}$ 处的切平面上的投影长度， $w_{ij}$ 是关于两个 MLS 点差和法向差的双边权重，定义如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193039.png" alt=""></p>
<p>上述设计将 $p_{j}$ 推离 $p_{i}$ ，尤其是当他们的法线和他们的位置是相似的。</p>
<h4 id="Projection-smoothness-loss"><a href="#Projection-smoothness-loss" class="headerlink" title="Projection smoothness loss"></a>Projection smoothness loss</h4><p>为了实现局部表面平滑度，论文鼓励 MLS 点靠近其相邻 MLS 点的切平面。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193200.png" alt=""></p>
<h4 id="Radius-smoothness-loss"><a href="#Radius-smoothness-loss" class="headerlink" title="Radius smoothness loss"></a>Radius smoothness loss</h4><p>同样，为了提高表面平滑度，相邻 MLS 点的半径变化通过对半径进行加权拉普拉斯平滑来惩罚</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193248.png" alt=""></p>
<h4 id="Weight-decay"><a href="#Weight-decay" class="headerlink" title="Weight decay"></a>Weight decay</h4><p>在损失函数中加入一项小的权重衰减项，系数为$\lambda_{w}$</p>
<h1 id="Efficient-Training-of-Physics-Informed-Neural-Networks-via-Importance-Sampling"><a href="#Efficient-Training-of-Physics-Informed-Neural-Networks-via-Importance-Sampling" class="headerlink" title="Efficient Training of Physics-Informed Neural Networks via Importance Sampling"></a>Efficient Training of Physics-Informed Neural Networks via Importance Sampling</h1><h2 id="Abstract-2"><a href="#Abstract-2" class="headerlink" title="Abstract"></a>Abstract</h2><p>PINN训练只需要问题描述，定义域，初始/边界条件，这种训练通常涉及使用随机梯度下降法的变体来解决一个非凸优化问题，将损失函数的梯度近似于一批配点中，在每次迭代中按均匀分布随机选取。在每次训练迭代中，按照与损失函数成正比的分布对搭配点进行采样，将改善PINNs训练的收敛行为。</p>
<h2 id="Introduction-5"><a href="#Introduction-5" class="headerlink" title="Introduction"></a>Introduction</h2><p>由于计算资源和优化算法的限制，PINN没有得到太多的关注。PINN网络的训练通常涉及到使用迭代法求解非凸优化问题。在给定的迭代中，这种批量选择可能会导致在一些配置点上计算梯度，在这些配置点上，近似解相对于其他点已经满足了微分算子的一个令人满意的程度。因此，得到的梯度信息很少或根本没有，从而延缓了收敛速度。或者，通过采用重要采样方案，在每次迭代中，我们可以选择一批能提供更多梯度信息的配点，以加速收敛。</p>
<p>首先，我们借鉴文献的理论发现，提出了一种基于重要度抽样的PINN网络加速训练方法。据作者所知，这是第一次使用重要抽样方案对pin网络进行训练。其次，我们展示了如何使用最近邻搜索或Voronoi分布来逼近建议分布，以进一步改善PINN训练的收敛行为。提出的重要度抽样方法简单明了，易于应用于现有的重要度抽样方法通过修改代码的几行PINN代码。此外，该方法没有引入新的超参数。</p>
<h2 id="Deep-Learning-of-Differential-Equations"><a href="#Deep-Learning-of-Differential-Equations" class="headerlink" title="Deep Learning of Differential Equations"></a>Deep Learning of Differential Equations</h2><p>PINNs基础知识</p>
<h2 id="Importance-Sampling-for-Training-of-PINNs"><a href="#Importance-Sampling-for-Training-of-PINNs" class="headerlink" title="Importance Sampling for Training of PINNs"></a>Importance Sampling for Training of PINNs</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418100747.png" alt=""></p>
<p>$f(x)$ 是训练点的采样分布，一种典型的采样分布是定义域上的均匀分布。在一种重要抽样方法中，我们寻求从一个备选抽样分布（用 $q(x)$ 表示）中提取训练样本，并根据如下更新网络参数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418101053.png" alt=""></p>
<p>在本工作中，我们有效地实现了一种离散采样方案，将连续域 $D$ 转化为 $N$  个采样点在 $D$ 上均匀选取的离散集合，其中 $N&gt;&gt; 1$ 。因此，我们将分别处理离散分布 $\{f_{j}\}_{j=1}^{N}$ 和 $\{ q_{j} \}_{j=1}^{N}$ ，而不是采样密度函数 $f(x_{j})$ 和 $q(x_{j})$，在任意候选点 $j$ 处 $f_{j} = \frac{1}{N}$ 。</p>
<p>为了构建相应的SGD，为了简洁起见，我们先考虑no mini batch，即 $m = 1$ ，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418102832.png" alt=""></p>
<p>在这项工作中，我们的目标是设计一个具有抽样分布 $q$ 的训练方案，它可以加速Eq. 12的收敛。[32]中的作者考虑了以下关于收敛速度的定义</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418103015.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418103050.png" alt=""></p>
<p>然后得出结论，通过从一个最小的分布 $Tr(\mathbb{V}_{P}[G^{(i)}])$ 中采样输入变量，可以加速收敛。如[32,34]所示，如果根据 $q^{\star}\propto||\triangledown_{\theta}J(\theta^{(i)})||_{2}$ 选择训练样本，则这一项可以被最小化。对于批量大小为m的小批量SGD，这个目标可以有效地被实现通过计算抽样分布</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418104326.png" alt=""></p>
<p>通过从概率为 $p^{(i)} = \{q_{1}^{(i)},\dots,q_{N}^{(i)}\}$ 的多项式中抽样 $M$ 个指标，选择小批量样本集 $M^{(i)}$ 。为了得到梯度 $\triangledown_{\theta}J(\theta)$ 的无偏估计，则根据式8，11给出的小批量梯度下降更新规则</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418104941.png" alt=""></p>
<p>这一推导提供了一个理论证据，即使用重要抽样方法可以加速PINN网络的训练，其中训练样本是根据与模型参数相关的损失函数梯度的2-范数成比例的分布获得的。然而，在每次迭代中为所有的并置点计算这个梯度的2-范数需要通过计算图进行额外的反向传播，这在计算上可能非常昂贵。为了缓解这一问题，在[33]中从理论上和数值上表明，在训练示例中损耗值的线性变换总是大于该示例中损耗梯度的2-范数，配点的梯度范数排序与损失值排序是一致的。因此，可以使用损失值代替梯度值作为重要性度量</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418105440.png" alt=""></p>
<p>具体来说，利用该proposal分布，可以选择前面解释的m个小批量样本，并结合公式16中的梯度下降规则来更新模型参数。</p>
<p>虽然与梯度计算相比，损失函数的计算成本较低，但在每次迭代中对整个配置点集进行这样的计算仍然非常昂贵。为了缓解这种情况，我们提出了一个分段常数近似的损失函数。也就是说，我们不是在每个配置点上计算损失函数，而是只在一个点子集上计算损失，以下称为”种子”，用 $\{x_{s}\}_{s=1}^{N}$ 表示， $S&lt;N$ 。然后，利用最近邻搜索算法，对每个配点 $j$ ，求出最接近的种子 $s = \rho(j)$，并设置该搭配点的损失值等于最接近种子的损失，即 $J(\cdot;x_{j}):=J(\cdot;x_{\rho(j)})$ 。这相当于使用种子生成Voronoi镶嵌，并在每个Voronoi单元中使用一个常数近似的损失。在数值例子中可以看出，与对整个配点求损函数的情况相比，这种分段常数近似提供了更高的计算效率。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418112136.png" alt=""></p>
<h1 id="PAGP-A-physics-assisted-Gaussian-process-framework-with-active-learning-for-forward-and-inverse-problems-of-partial-differential-equations"><a href="#PAGP-A-physics-assisted-Gaussian-process-framework-with-active-learning-for-forward-and-inverse-problems-of-partial-differential-equations" class="headerlink" title="PAGP: A physics-assisted Gaussian process framework with active learning for forward and inverse problems of partial differential equations"></a>PAGP: A physics-assisted Gaussian process framework with active learning for forward and inverse problems of partial differential equations</h1><h2 id="Abstract-3"><a href="#Abstract-3" class="headerlink" title="Abstract"></a>Abstract</h2><p>在这项工作中，建立了一个在偏微分方程(PDEs)中包含给定物理信息的高斯过程回归(GPR)模型:物理辅助高斯过程(PAGP)。该模型的目标可分为两类问题:给定偏微分方程的初始条件和边界条件的解或未知系数的发现。给定的物理信息被集成到高斯过程模型通过我们设计的GP损失函数。基于两种不同的训练标准GP模型的方法，本文给出了三种类型的损失函数。本文的第一部分介绍了连续时间模型，该模型将时域和空间域等同看待。已知的未知系数通过最小化设计的损失函数，偏微分方程可以与GP超参数联合学习。在离散时间模型中，我们首先选择一种时间离散方案来离散时域。然后在每个时间步上应用PAGP模型和该方案来近似最后时刻给定测试点的偏微分方程解。为了在这种情况下发现未知系数，需要两个特定时间的观测数据，并构造一个混合均方误差函数来获得最优系数。最后，提出了一种新的连续时间和离散时间混合模型。它融合了连续时间模型的灵活性和离散时间模型的精确性。讨论了采用不同GP损失函数选择不同模型的性能。建议的有效性PAGP方法在我们的数值部分进行了说明。</p>
<h2 id="Introduction-6"><a href="#Introduction-6" class="headerlink" title="Introduction"></a>Introduction</h2><p>如今，数据驱动的机器学习(ML)模型在科学计算和许多学科的发现中取得了巨大的成功。然而，仅仅将ML模型作为黑盒函数使用可能会由于忽略现有的物理规律或其他领域专业知识而导致性能较差。此外，目前大多数黑盒ML模型往往需要大量的数据和有限的泛化属性。因此，将ML模型与通常以偏微分方程(PDEs)形式存在的物理规律相结合就成为一个自然的热门话题。在所有数据驱动的ML模型中，高斯过程回归(GPR)，又称地质统计学中的克里格(Kriging)，是一种应用广泛的非参数模型贝叶斯模型构建一个廉价的代理复杂的科学和工程问题。高斯过程是唯一由其规定形式的均值和协方差函数决定的。它具有一个概率工作流，具有分析的易处理性，并从其后验分布返回稳健的方差估计。这也自然地量化了模型的不确定性。本文旨在将偏微分方程中包含的物理信息与GPR模型结合起来，解决正问题，即求解给定偏微分方程的解，以及反问题，即发现给定偏微分方程的未知系数。</p>
<p>简要介绍以前处理这类问题的两篇著作。</p>
<p>本文提出了一种将物理原理引入高斯过程回归模型的新方法。在标准GP中，均值函数和协方差函数的最优超参数可以通过两种不同的方式进行优化，即最小化负对数边际似然(NLML)或使用交叉验证的方法。在PAGP模型中，基于这两种方法构造了三种类型的损失函数。对于第一种方法，我们应用留一交叉验证(LOO-CV)构造一个损失函数。验证密度的对数作为拟合的交叉验证测度。根据惩罚GPR的思想，在这个损失函数中增加了一个额外的惩罚条款。这一项实际上是由配置点集上的PDE残差的绝对误差之和组成。第二个损失函数是相似的，除了对LOO-CV的拟合度的衡量是平方误差。对于最后一个，在原来的NLML函数中增加了一个相同的惩罚项。此外，还提出了一种自适应权值选择方法，以确定与惩罚项相乘的权值系数，使损失函数具有意义。在GP训练过程中，惩罚期限需要根据预先设定的配点来计算。因此，首先需要推导GP预测对时间t和空间位置x的导数。我们根据不同的问题设置开发连续时间模型和离散时间模型。对于连续时间模型，我们遵循中的步骤，直接使用GP预测公式，根据给定推导出关于t和x的n阶导数的解析表达式PDEs。对于离散时间模型，可以用类似的方法计算GP对x的导数。但是GP对t的导数需要用不同的方法计算。这里采用有限差分法进行计算。此外，还提出了一种新的两步混合模型，将连续时间模型和离散时间模型结合在一起。第一步遵循离散时间模型，但具有较大的时间步长。每一项的预测时间步长，和根据给定的初始条件和边界条件抽取的样本一起构成了偏微分方程第二步训练的数据集。然后利用连续时间模型对整个域的测试点进行预测。</p>
<h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>本文的目的是利用包含物理信息的GP来求解偏微分方程的正问题和反问题。在这项工作中，我们考虑一般形式的参数化偏微分方程</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418171923.png" alt=""></p>
<p>边界条件</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418172009.png" alt=""></p>
<p>初值条件</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418172045.png" alt=""></p>
<p>其中 $\mathcal{T}_{x}^{\lambda}$ 是一个一般的微分算子，可以是线性的，也可以是非线性的。下标表示操作符 $\mathcal{T}$ 作用的空间位置 $x$ 。上标表示只能部分知道的参数 $\lambda$ 。 $\Omega$ 是 $\mathbb{R}^{d}$ 的一个子集，$\Gamma$ 是 $\Omega$ 的边界。例如，考虑一维热方程： $u_{t}-\lambda u_{xx}=0$ 。这里，微分算子是 $\mathcal{T}_{x}^{\lambda}=\lambda \frac{\partial^{2}}{\partial x^{2}}$ 并且 $\lambda$ 是位置参数。在这种情况下我们考虑的正问题是找出解 $u(x,t)$ 给定特定边界条件 $g(x,t)$ ，初始条件 $h(x)$ 和系数 $\lambda$ ，而反问题是在偏微分方程中恢复未知系数 $\lambda$ 。注意，对于这两种类型的问题，偏微分方程的边界和初始条件也可以用可能被噪声污染的观测值来代替。</p>
<h3 id="Gaussian-process-regression"><a href="#Gaussian-process-regression" class="headerlink" title="Gaussian process regression"></a>Gaussian process regression</h3><p>略</p>
<h3 id="Derivatives-of-Gaussian-process-regression"><a href="#Derivatives-of-Gaussian-process-regression" class="headerlink" title="Derivatives of Gaussian process regression"></a>Derivatives of Gaussian process regression</h3><p>略</p>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><p>连续模型、离散模型、混合模型</p>
<h3 id="Active-Learning"><a href="#Active-Learning" class="headerlink" title="Active Learning"></a>Active Learning</h3><p>假设训练数据集D由N个样本组成。这代表了知识的当前状态，给定PDE域中信息量最大的样本是通过最大化获取函数 $a_{N}(x)$ 来选择的</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419144543.png" alt=""></p>
<p>获取功能实际上量化了我们可以获得多少信息来评估或在这个数据站点上执行一个昂贵的实验。然后 $(x_{N+1},y_{N+1})$ 加到原始训练数据集D中，此时如果达到了预先设定的条件，则停止处理。否则，该过程重复迭代，直到满足停止条件或达到最大迭代次数。在我们的PAGP模型中，采集函数被选择为后验分布的方差:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419144750.png" alt=""></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>这篇文章主要就是在训练GPR时通过对不同问题模型的设定设置不同的损失函数，然后在新一轮选点时采用后验方差大的点。</p>
<h1 id="Breaking-the-Dilemma-of-Medical-Image-to-image-Translation"><a href="#Breaking-the-Dilemma-of-Medical-Image-to-image-Translation" class="headerlink" title="Breaking the Dilemma of Medical Image-to-image Translation"></a>Breaking the Dilemma of Medical Image-to-image Translation</h1><h2 id="Abstract-4"><a href="#Abstract-4" class="headerlink" title="Abstract"></a>Abstract</h2><p>有监督的Pix2Pix和无监督的Cycle-consistency两种模式在医学图像到图像的转换中占主导地位。然而，这两种模式都不是理想的。Pix2Pix模式具有出色的性能。但它需要成对和像素对齐的图像，这可能不总是可以实现，因为在获得成对图像期间，呼吸运动或解剖变化。循环一致性模式对训练数据不太严格，对未配对或错位的图像也能很好地工作。但它的性能可能不是最优的。为了打破现有模式的困境，我们提出了一种新的无监督模式RegGAN用于医学图像到图像的转换。它基于“损失校正”理论。在RegGAN算法中，将失调的目标图像作为噪声标签，利用附加的配准网络对生成器进行训练，自适应地拟合失调的噪声分布。目标是搜索图像之间的转换和配准任务的共同最优解。我们将RegGAN合并到一些最先进的图像到图像的转换方法中，并证明RegGAN可以很容易地与这些方法结合起来，以提高它们的性能。例如，在我们的模式中，简单的CycleGAN超过了最新的NICEGAN，即使使用更少的网络参数。根据我们的结果，RegGAN在对齐数据上优于Pix2Pix，在未对齐或未配对的数据上优于Cycle-consistency。RegGAN对噪声不敏感，这使得它在很多情况下都是更好的选择，特别是在无法获得像素级对齐数据的医学图像到图像转换任务中。</p>
<h2 id="Introduction-7"><a href="#Introduction-7" class="headerlink" title="Introduction"></a>Introduction</h2><p>生成对抗网络(GANs)是一个通过对抗过程同时训练生成器G和鉴别器D的框架。该生成器用于将源域图像X的分布转换为目标域图像Y的分布。判别器用于确定目标域图像可能来自生成器还是来自真实数据。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210104.png" alt=""></p>
<p>Pix2Pix更新生成器 $(G:X \rightarrow Y)$ ，使源图像x和目标图像Y之间的像素级L1损失最小。因此，它要求对齐良好的成对图像，其中每个像素都有对应的标签。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210302.png" alt=""></p>
<p>然而，在现实场景中，对齐良好的成对图像并不总是可用的。为了解决图像不对齐所带来的挑战，我们开发了循环一致性算法，该算法基于这样的假设:从源域X到目标域Y $(G:X \rightarrow Y)$ 是生成器F从Y到X的反向 $(F:Y \rightarrow X)$ .与Pix2Pix模式相比，循环一致性模式在不对齐或未配对的图像上工作得更好。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210602.png" alt=""></p>
<p>然而，Cycle-consistency模式有其局限性。在医学图像到图像的转换中，不仅需要图像域之间的风格转换，还需要特定图像对之间的转换。最佳解决方案应该是唯一的。例如，翻译后的图像应尽可能保持原图像的解剖特征。众所周知，Cycle-consistency模式可能会产生多个解，这意味着训练过程可能比较混乱，结果可能不准确。Pix2Pix模式也不理想。即使它有唯一的解决方案，也很难满足成对图像对齐的要求。对于错位的图像，误差通过Pix2Pix模式，可能导致最终的平移图像不合理的位移。</p>
<p>到目前为止，还没有一种图像到图像的转换模式可以在对齐数据上优于Pix2Pix模式，在未对齐或未配对数据上优于Cycle-consistency模式。受[6-10]的启发，我们将失调的目标图像视为有噪声的标签，这意味着我们将存在的问题视为带噪声标签的监督学习。</p>
<h2 id="Methodology-1"><a href="#Methodology-1" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Theoretical-Motivation"><a href="#Theoretical-Motivation" class="headerlink" title="Theoretical Motivation"></a>Theoretical Motivation</h3><p>如果我们将失调的目标图像视为有噪声的标签，那么图像到图像的翻译训练就变成了一个有噪声标签的监督学习过程。给定一个训练数据集 $\{ (x_{n},\widetilde{y}_{n}) \}_{n=1}^{N}$ ，有n个噪声标签，其中 $x_{n}$, $\widetilde{y}_{n}$ 是来自两种模式的图像，假设 $y_{n}$ 是 $x_{n}$ 的正确标签，但在现实场景中是未知的。我们的目标是使用数据集 $\{ (x_{n},\widetilde{y}_{n}) \}_{n=1}^{N}$ 带噪声的标签，其性能相当于在干净数据集 $\{ (x_{n},y_{n}) \}_{n=1}^{N}$ 尽可能多。基于方程4的直接优化通常是无效的，并且会导致不好的结果，因为发生器不能挤出噪声的影响。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419212746.png" alt=""></p>
<p>为了解决噪声问题，我们提出了一个基于“损耗校正”的解决方案，如方程5所示。我们的解决方案通过建模噪声转移 $\phi$ 来匹配噪声分布来校正生成器 $G(x_{n})$ 的输出。之前，Patrini et al从数学上证明了用噪声标签训练的模型可以等价于用干净标签训练的模型，只要噪声发生转移 $\phi$ 匹配噪声分布。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419213250.png" alt=""></p>
<p>为此，Goldberger等提出将正确的标签视为潜在的随机变量，并将标签噪声显式建模为网络结构的一部分，记为 $R$ 。方程5可以改写为对数似然的形式，将对数似然作为神经网络训练的损失函数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419213846.png" alt=""></p>
<h3 id="RegGAN"><a href="#RegGAN" class="headerlink" title="RegGAN"></a>RegGAN</h3><p>与现有的使用的求解方程6的方法例如最大化期望，全连通层、锚点估计和Drichlet分布比较。在我们的问题中，噪声分布的类型更清楚，它可以表示为位移误差: $\widetilde{y}=y\circ T$ 。这里T表示为一个随机变形场，它为每个像素产生随机位移。因此，我们采用生成器G后的配准网络R作为标签噪声模型对结果进行校正。修正损失如式7所示</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419214445.png" alt=""></p>
<p>式中 $R(G(x), \widetilde{y})$ 为变形场， $\circ$ 代表重采样操作。注册网络基于U-Net。在式8中定义了平滑损失来评价变形场的平滑性，使变形场的梯度最小。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419214930.png" alt=""></p>
<p>最后，将产生器与鉴别器之间的平均损耗相加(式1)，总损耗如式9所示</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419215013.png" alt=""></p>
<h1 id="Characterizing-possible-failure-modes-in-physics-informed-neural-networks"><a href="#Characterizing-possible-failure-modes-in-physics-informed-neural-networks" class="headerlink" title="Characterizing possible failure modes in physics-informed neural networks"></a>Characterizing possible failure modes in physics-informed neural networks</h1><h2 id="Abstract-5"><a href="#Abstract-5" class="headerlink" title="Abstract"></a>Abstract</h2><p>我们证明，虽然现有的PINN方法可以学习相对次要问题的良好模型，但它们很容易无法学习相关的物理现象，即使是稍微复杂一点的问题。特别地，我们分析了几个不同的情况，广泛的物理兴趣，包括学习微分方程的对流，反应和扩散算子。我们提供证据，软正则化的PINN，其中涉及到基于偏微分算子，可以引入许多微妙的问题，包括使问题更病态。重要的是，我们表明，这些可能的失效模式不是由于缺乏神经网络结构的表现力，而是PINN的设置使损失景观非常难以优化。然后，我们描述了解决这些故障模式的两个有希望的解决方案。第一种方法是使用课程正则化，其中PINN的损失项从一个简单的PDE正则化开始，并随着NN的训练逐渐变得更加复杂。第二种方法是将问题作为一个顺序对顺序的学习任务，而不是学习一次性预测整个时空。大量的测试表明，与常规的PINN训练相比，我们可以实现高达1-2个数量级的误差。</p>
<h2 id="Introduction-8"><a href="#Introduction-8" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Problem-overview"><a href="#Problem-overview" class="headerlink" title="Problem overview"></a>Problem overview</h3><p>PINN 相关知识</p>
<h3 id="Main-contributions-1"><a href="#Main-contributions-1" class="headerlink" title="Main contributions"></a>Main contributions</h3><ul>
<li>我们分析了简单但物理相关的对流、反应和反应扩散问题的PINN模型。我们发现，普通/常规的PINN方法只适用于非常简单的参数体系。</li>
<li>我们分析了训练过的PINN模型的损失情况，发现增加基于pde的软约束正则化使其更加复杂和难以优化，特别是对于具有非平凡系数的情况。</li>
<li>我们证明了 NN 架构有能力/表现力来找到一个好的解，从而表明这些问题不是由于NN网格结构的容量有限引起的。相反，我们认为失败是由于相关的优化困难使用 PINN 的软 PDE 约束。</li>
<li>我们提出了解决这些失败模式的两种途径:(i)课程正规化(ii)将学习问题作为一个序列对序列的学习任务。</li>
</ul>
<h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><p>一些关于机器学习和PDE结合的工作</p>
<h2 id="Possible-failure-modes-for-physics-informed-neural-networks"><a href="#Possible-failure-modes-for-physics-informed-neural-networks" class="headerlink" title="Possible failure modes for physics-informed neural networks"></a>Possible failure modes for physics-informed neural networks</h2><h3 id="Experiment-setup"><a href="#Experiment-setup" class="headerlink" title="Experiment setup."></a>Experiment setup.</h3><p>4-layer fully-connected NN with 50 neurons per layer; tangent activation function; randomly sample collocation points on the domain; measure relative error and absolute error</p>
<h3 id="convection、reaction-diffusion"><a href="#convection、reaction-diffusion" class="headerlink" title="convection、reaction-diffusion"></a>convection、reaction-diffusion</h3><p> we can see that the PINN also fails to learn advection and reaction-diffusion.  </p>
<h2 id="Diagnosing-possible-failure-modes-for-physics-informed-NNs"><a href="#Diagnosing-possible-failure-modes-for-physics-informed-NNs" class="headerlink" title="Diagnosing possible failure modes for physics-informed NNs"></a>Diagnosing possible failure modes for physics-informed NNs</h2><h3 id="Soft-PDE-regularization-and-optimization-difficulties"><a href="#Soft-PDE-regularization-and-optimization-difficulties" class="headerlink" title="Soft PDE regularization and optimization difficulties"></a>Soft PDE regularization and optimization difficulties</h3><p>我们表明，添加软正则化实际上可以使问题更难优化，即正则化导致更不平滑的损失景观。</p>
<p>最后，我们研究了改变软正则化项的权重/乘子的影响，这可能与提高PINN性能有关。虽然我们发现调谐λ可以帮助改变误差，但它不能解决问题。</p>
<h2 id="Expressivity-versus-optimization-difficulty"><a href="#Expressivity-versus-optimization-difficulty" class="headerlink" title="Expressivity versus optimization difficulty"></a>Expressivity versus optimization difficulty</h2><h3 id="Curriculum-PINN-Regularization"><a href="#Curriculum-PINN-Regularization" class="headerlink" title="Curriculum PINN Regularization"></a>Curriculum PINN Regularization</h3><p>我们设计了一个“课程正则化”，方法通过为权值找到一个好的初始化值来热启动神经网络训练。对于$\beta/\rho$较高的情况，我们不是训练PINN立即学习解，而是先在较低的$\beta/\rho$上训练PINN(对PINN来说更容易学习)，然后逐渐分别在较高的$\beta/\rho$上训练PINN。</p>
<h3 id="Sequence-to-sequence-learning-vs-learning-the-entire-space-time-solution"><a href="#Sequence-to-sequence-learning-vs-learning-the-entire-space-time-solution" class="headerlink" title="Sequence-to-sequence learning vs learning the entire space-time solution"></a>Sequence-to-sequence learning vs learning the entire space-time solution</h3><p>在这里，我们证明，将问题作为一个序列对序列(seq2seq)学习任务可能更好，其中神经网络学习预测下一个时间步骤的解决方案，而不是一直预测。这样，我们就可以使用时间推进方案来预测不同的序列/时间点。注意，这里唯一可用的数据来自PDE本身，也就是说，只有初始条件。我们取在$t=\Delta t$处的预测，以此作为在$t=2\Delta t$处的预测的初始条件，依此类推。</p>
<h1 id="Uncertainty-Quantification-in-Scientific-Machine-Learning-Methods-Metrics-and-Comparisons"><a href="#Uncertainty-Quantification-in-Scientific-Machine-Learning-Methods-Metrics-and-Comparisons" class="headerlink" title="Uncertainty Quantification in Scientific Machine Learning:Methods, Metrics, and Comparisons"></a>Uncertainty Quantification in Scientific Machine Learning:Methods, Metrics, and Comparisons</h1><h2 id="Abstract-6"><a href="#Abstract-6" class="headerlink" title="Abstract"></a>Abstract</h2><p>神经网络在如何将数据和物理工程方面的数学定理融合方面正在改变新的计算范式。然而，在基于神经网络的推理中，对误差和不确定性的量化比传统方法更加复杂。这是因为除了与噪声数据相关的任意不确定性外，还存在数据有限的不确定性，还有神经网络超参数、过度参数化、优化和采样误差以及模型误规范等。在这项工作中，我们提出了一个全面的框架，包括不确定性建模、新的和现有的解决方法，以及评估指标和事后改进方法。为了证明我们的框架的适用性和可靠性，我们提出了一个广泛的比较研究，其中各种方法在原型问题上进行了测试，包括混合输入输出数据问题和高维随机问题。</p>
<h2 id="Introduction-9"><a href="#Introduction-9" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Novel-contributions-of-this-work"><a href="#Novel-contributions-of-this-work" class="headerlink" title="Novel contributions of this work"></a>Novel contributions of this work</h3><ol>
<li>我们测试并将各种用于后验推理、先验学习、数据噪声建模以及训练后校准的方法集成到物理信息神经网络、神经算子和SPDE求解器中。</li>
<li>我们演示了如何使用函数先验来解决具有异方差噪声的历史数据的函数逼近问题。</li>
<li>将高斯过程回归和生成式对抗网络相结合，提出了一种解决确定性正向偏微分方程问题的新方法，并与现有方法进行了比较。</li>
<li>我们求解源项、问题参数和解数据中含有异方差噪声的混合偏微分方程问题。</li>
<li>我们解决了带有噪声的随机实现的混合SPDE问题，并提出了一种新的神经网络结构，用于使用多项式混沌量化不确定性。</li>
<li>我们演示了如何处理有噪声和不完整的推断数据给出一个预先训练的神经算子对干净的数据。</li>
<li>我们提出了检测神经算子外分布数据的方法，这对风险相关的应用是至关重要的。</li>
<li>我们提出了一个统一的UQ框架，通过无缝地将物理与可能被各种类型的噪声污染的新数据和历史数据结合起来，解决科学机器学习中的各种问题。</li>
</ol>
<h2 id="Neural-PDEs-and-neural-operators"><a href="#Neural-PDEs-and-neural-operators" class="headerlink" title="Neural PDEs and neural operators"></a>Neural PDEs and neural operators</h2><h3 id="Solving-forward-and-mixed-PDE-problems-Overview-of-PINN-method"><a href="#Solving-forward-and-mixed-PDE-problems-Overview-of-PINN-method" class="headerlink" title="Solving forward and mixed PDE problems: Overview of PINN method"></a>Solving forward and mixed PDE problems: Overview of PINN method</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506153709.png" alt=""></p>
<h3 id="Learning-operator-mappings-Overview-of-DeepONet-method"><a href="#Learning-operator-mappings-Overview-of-DeepONet-method" class="headerlink" title="Learning operator mappings: Overview of DeepONet method"></a>Learning operator mappings: Overview of DeepONet method</h3><p>DeepONet方法通过构造一个以 $\theta$ 为参数的神经网络逼近器来处理算子学习问题，来对 $u(x;\xi)$ 。</p>
<h2 id="Modeling-total-uncertainty"><a href="#Modeling-total-uncertainty" class="headerlink" title="Modeling total uncertainty"></a>Modeling total uncertainty</h2><h3 id="Uncertainty-in-function-approximation"><a href="#Uncertainty-in-function-approximation" class="headerlink" title="Uncertainty in function approximation"></a>Uncertainty in function approximation</h3><p>为了定义 $p(u|x,\theta)$ ，我们构建一个模型 $u_{\theta}(x)$ 在一些 $x$ 点来捕捉 $u(x)$ 的确定性部分并且为噪声假定一个模型。例如，因式高斯似然函数，通过如下式子给出</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506161343.png" alt=""></p>
<p>下标 $d$ 表示 $u$ 的每个 $D_{u}$ 维，通常用于多维函数逼近问题。在公式(4)中，输出向量 $u_{\theta}(x)$ 是假设 $u$ 在位置 $x$ 处的高斯分布的均值， $diag(\Sigma^{2}_{u})$ 是一个对角协方差矩阵 $\Sigma_{u}^{2} = [\sigma_{u}^{2},\dots,\sigma_{u}^{2}]$ 可以是已知的，也可以是假设的，也可以是从数据推断出来的。</p>
<p>在给定数据 $\mathcal{D}$ 的情况下， $x$ 位置 $u$ 的值是一个随机变量，表示为 $(u|x,\mathcal{D})$。为了求 $(u|x;\mathcal{D})$ 积分出模型参数 $\theta$，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506163025.png" alt=""></p>
<p>利用贝叶斯规则，后验 $p(\theta|\mathcal{D})$ 可以通过下式获得</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506185405.png" alt=""></p>
<p>式(6)中， $p(\mathcal{D}|\theta)$ 是数据的似然，即 $p(\mathcal{D}|\theta) = \prod_{i=1}^{N}p(u_{i}|x_{i},\theta)$ 为独立同分布(i.i.d.)数据； $p(\theta)$为模型 $\mathcal{H}$ 定义的参数 $\theta$ 的先验概率；而 $p(\mathcal{D})$ 被称为边际可能性或证据，因为它代表了在所有由 $\mathcal{H}$ 建模的可能数据集中，我们观察到 $\mathcal{D}$ 发生的概率。证据 $p(\mathcal{D})$ 给出如下</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506190851.png" alt=""></p>
<p>即，给定从先验 $p(\theta)$ 中抽取的随机样本，然后与似然函数结合使用， $p(\mathcal{D})$ 表示数据集 $\mathcal{D}$ 产生的概率。</p>
<p>后验推断阶段之后，Eq.(5)的BMA可以用蒙特卡罗(MC)来近似。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506191803.png" alt=""></p>
<p>这个方程提供了 $(u|x,\mathcal{D})$ 以预测PDF $\overline{p}(\mu|x)$ 的形式。 $(\mu|x,\mathcal{D})$ 通过 $\hat{u}(x) = E[\mu|x]$ 建模并且用 $\overline{\mu}(x)$近似表示为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506193734.png" alt=""></p>
<p>其中 $\{\mu_{\hat{\theta}_{j}}(x)\}_{j=1}^{M}$ 是样本 $\{\hat{\theta}_{j} \}_{j=1}^{M}$ 对应的NN预测集。求 $(u|x,\mathcal{D})$ ，将式(4)的高斯似然值代入式(8)，得到高斯混合协方差矩阵的对角线部分由下式给出</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506195407.png" alt=""></p>
<h3 id="Uncertainty-in-PINNs"><a href="#Uncertainty-in-PINNs" class="headerlink" title="Uncertainty in PINNs"></a>Uncertainty in PINNs</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922185741.png" alt=""></p>
<h3 id="Uncertainty-in-DeepONets"><a href="#Uncertainty-in-DeepONets" class="headerlink" title="Uncertainty in DeepONets"></a>Uncertainty in DeepONets</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922190052.png" alt=""></p>
<h2 id="Methods-for-uncertainty-quantification"><a href="#Methods-for-uncertainty-quantification" class="headerlink" title="Methods for uncertainty quantification"></a>Methods for uncertainty quantification</h2><ul>
<li>Bayesian methods</li>
<li>Ensembles</li>
<li>Functional priors (FPs)</li>
<li>Solving stochastic PDEs (SPDEs)</li>
<li>Towards a unified view of the presented methods</li>
</ul>
<h1 id="Multi-Objective-Loss-Balancing-for-Physics-Informed-Deep-Learning"><a href="#Multi-Objective-Loss-Balancing-for-Physics-Informed-Deep-Learning" class="headerlink" title="Multi-Objective Loss Balancing for Physics-Informed Deep Learning"></a>Multi-Objective Loss Balancing for Physics-Informed Deep Learning</h1><h2 id="Abstract-7"><a href="#Abstract-7" class="headerlink" title="Abstract"></a>Abstract</h2><p>在这项工作中，我们观察到对多个竞争损失函数组合进行正确加权对有效训练PINN的重要作用。为此，我们实现并评估了不同的方法，旨在平衡PINN损失函数的多个项及其梯度的贡献。我们提出了一种新的自适应损失平衡称为ReLoBRaLo(相对随机回看的损失平衡)。我们的模拟研究证明了这一点与使用其他平衡方法训练PINN相比，ReLoBRaLo训练速度更快，准确率更高，因此非常有效，并增加了PINN算法的可持续性。</p>
<h2 id="Introduction-10"><a href="#Introduction-10" class="headerlink" title="Introduction"></a>Introduction</h2><p>物理信息神经网络的出现引起了人们对经常面临低数据系统问题的领域的极大兴趣。通过利用已知的物理定律，并将其作为隐式先验并入深度学习管道，PINN被证明需要很少或不需要数据，以近似不同复杂度的偏微分方程(PDE)。</p>
<h2 id="Physics-Informed-Neural-Networks-PINNs"><a href="#Physics-Informed-Neural-Networks-PINNs" class="headerlink" title="Physics-Informed Neural Networks (PINNs)"></a>Physics-Informed Neural Networks (PINNs)</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922182417.png" alt=""></p>
<p>然而，PINN训练的效率、收敛性和准确性仍面临严峻挑战。目前的研究可分为四种主要方法:修改神经网络的结构、分治/区域分解、参数初始化和损失平衡。</p>
<p>根据文献综述，自适应PINN训练过程可以被视为PDE约束的优化问题。本文关注的是对竞争力和适应性的仔细考虑，并从跨机器学习的几个领域提出的损失平衡技术中寻求灵感。</p>
<h2 id="Methodology-2"><a href="#Methodology-2" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Multi-Objective-Optimisation"><a href="#Multi-Objective-Optimisation" class="headerlink" title="Multi-Objective Optimisation"></a>Multi-Objective Optimisation</h3><p>多目标优化可以通过线性扩展转化为单一目标：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183152.png" alt=""></p>
<h3 id="Adaptive-Loss-Balancing-Methods"><a href="#Adaptive-Loss-Balancing-Methods" class="headerlink" title="Adaptive Loss Balancing Methods"></a>Adaptive Loss Balancing Methods</h3><h4 id="Learning-Rate-Annealing"><a href="#Learning-Rate-Annealing" class="headerlink" title="Learning Rate Annealing"></a>Learning Rate Annealing</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183302.png" alt=""></p>
<h4 id="GradNorm"><a href="#GradNorm" class="headerlink" title="GradNorm"></a>GradNorm</h4><p>更新内部刻度的损失GradNorm的计算方法如下:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183445.png" alt=""></p>
<p>更新网络参数的最终损失只是使用之前更新的缩放值进行线性扩展：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183525.png" alt=""></p>
<h4 id="SoftAdapt"><a href="#SoftAdapt" class="headerlink" title="SoftAdapt"></a>SoftAdapt</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183605.png" alt=""></p>
<h2 id="Relative-Loss-Balancing-with-Random-Lookback-ReLoBRaLo"><a href="#Relative-Loss-Balancing-with-Random-Lookback-ReLoBRaLo" class="headerlink" title="Relative Loss Balancing with Random Lookback (ReLoBRaLo)"></a>Relative Loss Balancing with Random Lookback (ReLoBRaLo)</h2><p>从现有平衡技术中汲取灵感，我们提出了一种新的方法和实现，用于平衡扩展MOO损失函数中的多个项，用于训练PINN：</p>
<ul>
<li>采用SoftAdapt的平衡方法，利用连续训练步骤之间的变化率，并通过softmax函数进行归一化。</li>
<li>与学习率退火类似，为了利用过去不止一个训练步骤的损失统计数据，使用指数衰减来更新标量。</li>
<li>此外，在指数衰减中引入了一个随机回看(称为saudade $\rho$)，它决定是使用穿透步骤的损失统计来计算缩放，还是一直回看直到训练$\mathcal{L}_{i}^{(0)}$开始。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922184617.png" alt=""></p>
<h2 id="Hyperparameter-Tuning-and-Meta-Learning"><a href="#Hyperparameter-Tuning-and-Meta-Learning" class="headerlink" title="Hyperparameter Tuning and Meta Learning"></a>Hyperparameter Tuning and Meta Learning</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922184701.png" alt=""></p>
<h1 id="A-Unified-Hard-Constraint-Framework-for-Solving-Geometrically-Complex-PDEs"><a href="#A-Unified-Hard-Constraint-Framework-for-Solving-Geometrically-Complex-PDEs" class="headerlink" title="A Unified Hard-Constraint Framework for Solving Geometrically Complex PDEs"></a>A Unified Hard-Constraint Framework for Solving Geometrically Complex PDEs</h1><h2 id="Abstract-8"><a href="#Abstract-8" class="headerlink" title="Abstract"></a>Abstract</h2><p>a unified hard-constraint framework  $\rightarrow$ geometrically complex PDEs</p>
<p>introduce the “extra fields” $\rightarrow$ reformulate the PDEs so as to equivalently transform the three types of BCs into linear forms.  </p>
<p>derive the general solutions of the BCs analytically</p>
<h2 id="Introduction-11"><a href="#Introduction-11" class="headerlink" title="Introduction"></a>Introduction</h2><p>Among all types of BCs, Dirichlet, Neumann, and Robin are the most commonly used</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018145545.png" alt=""></p>
<p>in practical problems, physical systems can be very geometrically complex, there exists an unbalanced competition between the<br>terms of PDEs and BCs, limiting the application of PINNs to geometrically complex problems. There are some imroved methods. Nevertheless, these methods are only applicable to specific BCs (e.g., Dirichlet BCs, homogeneous BCs, etc) or geometrically simple PDEs.</p>
<h3 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h3><ul>
<li>a unified hard-constraint framework for all the three most commonly used BCs</li>
<li>introduce the extra fields, substitutes the gradient of a physical quantity with new variables, allowing the BCs to be reformulated as linear equations. </li>
<li>summarize a paradigm for constructing the hard-constraint ansatz under time-dependent, multiboundary, and high-dimensional cases </li>
</ul>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Physics-Informed-Neural-Networks"><a href="#Physics-Informed-Neural-Networks" class="headerlink" title="Physics-Informed Neural Networks"></a>Physics-Informed Neural Networks</h3><p>basic introduction to PINNs</p>
<h3 id="Hard-Constraint-Methods"><a href="#Hard-Constraint-Methods" class="headerlink" title="Hard-Constraint Methods"></a>Hard-Constraint Methods</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018154155.png" alt=""></p>
<p>where $x$ is the coordinate, $\Omega$ is the domain of interest, $u^{\partial\Omega}(x)$ is the general solution at the boundary $\partial\Omega$, and $l^{\partial\Omega}(x)$ is an extended distance function which satisfies</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018154550.png" alt=""></p>
<p>However, it is hard to directly extend this method to more general cases of Robin BCs (see Eq. (7)), since we cannot obtain the general solution $u^{\partial\Omega}(x)$ analytically. </p>
<h2 id="Methodology-3"><a href="#Methodology-3" class="headerlink" title="Methodology"></a>Methodology</h2>]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>论文</tag>
      </tags>
  </entry>
</search>
