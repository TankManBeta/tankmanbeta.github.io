<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CloseAirCombat使用总结</title>
    <url>/2024/11/03/CloseAirCombat%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><code>CloseAirCombat</code>为红蓝飞机游戏提供了一个竞技环境，包括单一控制设置、<code>1V1</code>设置和<code>2V2</code>设置。飞行动力学基于<code>JSBSIM</code>，导弹动力学基于我们实现的比例制导。 同时，<code>CloseAirCombat</code>还提供了<code>ppo</code>和<code>mappo</code>的实现，用于自博弈或基线对比训练。</p>
<a id="more"></a>
<h1 id="具体用法"><a href="#具体用法" class="headerlink" title="具体用法"></a>具体用法</h1><p>以<code>heading</code>任务为例，解读一下<code>CloseAirCombat</code>的使用全流程。</p>
<h2 id="启动训练"><a href="#启动训练" class="headerlink" title="启动训练"></a>启动训练</h2><p>训练的启动脚本为<code>scripts/train_heading.sh</code>，<code>train_heading.sh</code>的内容如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031826956.png" style="zoom:150%;" /></p>
<h2 id="训练主脚本解读"><a href="#训练主脚本解读" class="headerlink" title="训练主脚本解读"></a>训练主脚本解读</h2><p>从上面的<code>.sh</code>脚本中，我们可以看出训练的主脚本为<code>scripts/train/train_jsbsim.py</code>，同时声明了一些命令行参数。</p>
<p><code>main</code>函数首先获取到所有的命令行参数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031830733.png" style="zoom:150%;" /></p>
<p>接着设置使用<code>GPU</code>还是<code>CPU</code>：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031831490.png" style="zoom:150%;" /></p>
<p>接着配置训练存储的路径：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031837005.png" style="zoom:150%;" /></p>
<p>接着设置是否使用<code>wandb</code>，默认为<code>False</code>：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031842114.png" style="zoom:150%;" /></p>
<p>接着设置多进程的名称：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031848914.png" style="zoom:150%;" /></p>
<p>接着设置初始化环境：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031851816.png" style="zoom:150%;" /></p>
<p>其中，<code>make_train_env</code>函数根据<code>env_name</code>和<code>n_rollout_threads</code>设置相对应的环境，<code>make_eval_env</code>函数也是同理：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031854959.png" style="zoom:150%;" /></p>
<p>其中的涉及很多环境类，例如<code>ShareDummyVecEnv</code>、<code>ShareSubprocVecEnv</code>等，以用于多智能体训练任务的<code>ShareSubprocVecEnv</code>类为例，该类继承自<code>SubprocVecEnv</code>和<code>ShareVecEnv</code>，该类在初始化时，使用<code>multiprocessing.Process</code> 创建子进程，每个子进程运行<code>shareworker</code>函数，该函数负责管理环境实例并与主进程通信。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503141514581.png" alt=""></p>
<p>通过进程间通信的方式可以完成<code>step</code>、<code>reset</code>、<code>close</code>等功能：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503141530436.png" alt=""></p>
<p>值得注意的是，在执行<code>step</code>命令的时候，如果<code>done</code>的状态为<code>True</code>，会自动执行<code>reset</code>函数重置环境。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503141553496.png" alt=""></p>
<p>接着开始训练：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031859833.png" style="zoom:150%;" /></p>
<p>其中，程序首先根据参数选择对应的<code>Runner</code>，然后通过<code>runner.run()</code>进行算法的训练，<code>JSBSimRunner</code>中<code>load</code>函数是初始化时就调用的函数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031913185.png" style="zoom:150%;" /></p>
<p><code>run</code>函数首先设置<code>total_num_steps</code>和<code>episodes</code>的值：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031915381.png" style="zoom:150%;" /></p>
<p>然后收集数据，更新算法，输出日志，评估，保存模型：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031919353.png" style="zoom: 150%;" /></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031919240.png" style="zoom: 150%;" /></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411031922933.png" style="zoom:150%;" /></p>
<p>其中，<code>self.collect</code>函数负责收集当前步的数据，获取到数据之后，让环境执行当前的<code>action</code>获得新的<code>obs</code>。<code>step</code>函数是环境类的基类<code>VecEnv</code>中实现的函数，该函数调用了<code>step_async</code>函数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503141537783.png" alt=""></p>
<p><code>step_async</code>是一个用于同步数据的抽象方法，其具体实现在子类<code>SubproVecEnv</code>中，同上面一样，通过进程间通信发送<code>step</code>命令的方式让环境推进。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503141543166.png" alt=""></p>
<p><code>step_async</code>函数执行完毕后，还需要再执行<code>step_wait</code>函数用于数据同步，<code>step_wait</code>函数也是抽象方法，虽然<code>SubprocVecEnv</code>虽然实现了这个抽象方法，但是由于子类<code>ShareSubprocVecEnv</code>也实现了该方法，根据动态绑定的性质，最终调用的是该类中的方法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503141550934.png" alt=""></p>
]]></content>
      <categories>
        <category>CloseAirCombat</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>CloseAirCombat</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker使用总结</title>
    <url>/2024/05/11/Docker%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下使用<code>Docker</code>过程中遇到的问题。</p>
<a id="more"></a>
<h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><p><code>Docker image</code>本质上是一个<code>read-only</code>只读文件， 这个文件包含了文件系统、源码、库文件、依赖、工具等一些运行<code>application</code>所必须的文件。因此，可以把<code>Docker image</code>理解成一个模板， 可以通过这个模板实例化出来很多容器。</p>
<h2 id="容器-Container"><a href="#容器-Container" class="headerlink" title="容器(Container)"></a>容器(<code>Container</code>)</h2><ul>
<li>容器是<code>Docker</code>的运行实例，它包含了所有的应用文件，环境变量，进程等。</li>
<li>每个容器都是隔离的，运行在自己的命名空间内。</li>
<li>容器可以启动、开始、停止、删除，每个容器都是静态的，除非你保存它的当前状态作为新的镜像。</li>
</ul>
<h2 id="镜像-Image"><a href="#镜像-Image" class="headerlink" title="镜像(Image)"></a>镜像(<code>Image</code>)</h2><ul>
<li>镜像是一个只读的模板，用来创建<code>Docker</code>容器。</li>
<li>镜像可以包含一些基本配置，例如环境变量、用户等。</li>
<li>镜像是创建容器的模板，你不能在镜像上运行应用或者进程。</li>
<li>镜像可以通过<code>Dockerfile</code>构建，也可以从<code>Docker Hub</code>或其他镜像仓库下载。</li>
</ul>
<h1 id="具体用法"><a href="#具体用法" class="headerlink" title="具体用法"></a>具体用法</h1><h2 id="查看镜像"><a href="#查看镜像" class="headerlink" title="查看镜像"></a>查看镜像</h2><ul>
<li><code>docker images</code>：列出所有本地镜像。</li>
</ul>
<h2 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h2><ul>
<li><code>docker rmi [IMAGE_ID]</code>：删除指定的镜像。</li>
</ul>
<h2 id="创建镜像"><a href="#创建镜像" class="headerlink" title="创建镜像"></a>创建镜像</h2><ul>
<li><code>docker build -t IMAGE_NAME:IMAGE_TAG .</code>：基于<code>Dockerfile</code>创建镜像。</li>
</ul>
<h2 id="提交镜像"><a href="#提交镜像" class="headerlink" title="提交镜像"></a>提交镜像</h2><ul>
<li><code>docker commit -a &quot;xxx&quot; -m &quot;xxx&quot; CONTAINER_ID NEW_IMAGE_NAME:NEW_IMAGE_TAG</code>命令根据<code>Docker</code>容器的更改创建一个新的镜像。</li>
</ul>
<h2 id="运行容器"><a href="#运行容器" class="headerlink" title="运行容器"></a>运行容器</h2><ul>
<li><code>docker run -v &lt;HOST_PATH1&gt;:&lt;CONTAINER_PATH1&gt; -v &lt;HOST_PATH2&gt;:&lt;CONTAINER_PATH2&gt; IMAGE_NAME</code>命令运行一个容器，同时通过<code>-v</code>参数进行卷的挂载。</li>
</ul>
<h2 id="查看正在运行的容器"><a href="#查看正在运行的容器" class="headerlink" title="查看正在运行的容器"></a>查看正在运行的容器</h2><ul>
<li><code>docker ps</code>：显示当前正在运行的容器。</li>
</ul>
<h2 id="查看所有状态的容器"><a href="#查看所有状态的容器" class="headerlink" title="查看所有状态的容器"></a>查看所有状态的容器</h2><ul>
<li><code>docker ps -a</code>：显示所有状态的容器。容器的状态共有<code>7</code>种：<code>created|restarting|running|removing|paused|exited|dead</code>。</li>
</ul>
<h2 id="启动已经停止运行的容器"><a href="#启动已经停止运行的容器" class="headerlink" title="启动已经停止运行的容器"></a>启动已经停止运行的容器</h2><ul>
<li><code>docker start [CONTAINER_ID]</code>：启动已经停止运行的容器。</li>
</ul>
<h2 id="重新启动容器"><a href="#重新启动容器" class="headerlink" title="重新启动容器"></a>重新启动容器</h2><ul>
<li><code>docker restart [CONTAINER_ID]</code>：重启容器。</li>
</ul>
<h2 id="停止正在运行的容器"><a href="#停止正在运行的容器" class="headerlink" title="停止正在运行的容器"></a>停止正在运行的容器</h2><ul>
<li><code>docker stop [CONTAINER_ID]</code>：停止正在运行的容器。</li>
</ul>
<h2 id="强制停止正在运行的容器"><a href="#强制停止正在运行的容器" class="headerlink" title="强制停止正在运行的容器"></a>强制停止正在运行的容器</h2><ul>
<li><code>docker kill [CONTAINER_ID]</code>：强制停止正在运行的容器。</li>
</ul>
<h2 id="删除已经停止运行的容器"><a href="#删除已经停止运行的容器" class="headerlink" title="删除已经停止运行的容器"></a>删除已经停止运行的容器</h2><ul>
<li><code>docker rm [CONTAINER_ID]</code>：删除已经停止运行的容器。</li>
</ul>
<h2 id="强制删除容器"><a href="#强制删除容器" class="headerlink" title="强制删除容器"></a>强制删除容器</h2><ul>
<li><code>docker rm -f [CONTAINER_ID]</code>：强制删除容器。</li>
</ul>
<h2 id="删除多个容器"><a href="#删除多个容器" class="headerlink" title="删除多个容器"></a>删除多个容器</h2><ul>
<li><code>docker rm -f $(docker ps -aq)</code>：一次性删除多个容器。</li>
</ul>
<h2 id="进入正在运行的容器并交互"><a href="#进入正在运行的容器并交互" class="headerlink" title="进入正在运行的容器并交互"></a>进入正在运行的容器并交互</h2><ul>
<li><code>docker exec -it CONTAINER_ID/CONTAINER_NAME /bin/bash</code>：进入正在运行的容器内部，使用<code>exit</code>命令退出容器后，容器不会停止运行。</li>
<li><code>docker attach CONTAINER_ID/CONTAINER_NAME</code>：进入正在运行的容器内部，使用<code>exit</code>命令退出容器后，容器停止运行。</li>
</ul>
<h2 id="数据拷贝"><a href="#数据拷贝" class="headerlink" title="数据拷贝"></a>数据拷贝</h2><ul>
<li><code>docker cp SOURCE_PATH TARGET_PATH</code>：进行主机（容器）和容器（主机）之间的数据拷贝，其中容器的路径格式为<code>COTAINER_ID:/xxx</code>。</li>
</ul>
<h2 id="镜像归档"><a href="#镜像归档" class="headerlink" title="镜像归档"></a>镜像归档</h2><ul>
<li><code>docker save -o FILE_PATH IMAGE1:TAG1 IMAGE2:TAG2</code>：将一个或多个镜像保存到一个<code>tar</code>归档文件中，以便在其他环境中分发或备份。</li>
</ul>
<h2 id="镜像加载"><a href="#镜像加载" class="headerlink" title="镜像加载"></a>镜像加载</h2><ul>
<li><code>docker load -i myimage.tar</code>：从由<code>docker save</code>命令生成的<code>tar</code>文件中加载<code>Docker</code>镜像。它可以将存档中的镜像和所有层加载到<code>Docker</code>中，使其可以在新环境中使用。</li>
</ul>
<h2 id="查看容器在宿主机的id"><a href="#查看容器在宿主机的id" class="headerlink" title="查看容器在宿主机的id"></a>查看容器在宿主机的<code>id</code></h2><ul>
<li><code>docker inspect -f &#39;&#123;&#123;.State.Pid&#125;&#125;&#39; CONTAINER_ID/CONTAINER_NAME</code>：以<code>json</code>格式得到容器的元数据，通过<code>-f</code>参数用<code>Go</code>模板语法获取<code>Pid</code>。</li>
</ul>
<h1 id="报错解决"><a href="#报错解决" class="headerlink" title="报错解决"></a>报错解决</h1><h2 id="删除镜像-1"><a href="#删除镜像-1" class="headerlink" title="删除镜像"></a>删除镜像</h2><p><strong>问题：</strong>想要删除某个不用的镜像，执行<code>docker rmi ubuntu:latest</code>后报错：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202405111428042.png" alt=""></p>
<p><strong>解决思路：</strong>根据报错内容我们可以看到，是由于我们要删除的镜像正在被一个容器使用，解决办法是先把容器删了，然后再删除镜像。</p>
<p>首先执行<code>docker ps –a</code>查看所有的容器</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202405111431575.png" alt=""></p>
<p>接着执行<code>docker rm d8fd3c8642c8</code>删除该容器</p>
<p>最后再执行<code>docker rmi ubuntu:latest</code>即可成功</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202405111434050.png" alt=""></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux使用总结</title>
    <url>/2023/06/14/Linux%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下使用<code>Linux</code>系统过程中遇到的知识点。</p>
<a id="more"></a>
<h1 id="服务器连接"><a href="#服务器连接" class="headerlink" title="服务器连接"></a>服务器连接</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -p &lt;port&gt; &lt;username&gt;@&lt;remote_ip&gt;</span><br></pre></td></tr></table></figure>
<h1 id="修改密码"><a href="#修改密码" class="headerlink" title="修改密码"></a>修改密码</h1><p>修改当前用户密码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">passwd</span><br></pre></td></tr></table></figure>
<h1 id="快捷补全"><a href="#快捷补全" class="headerlink" title="快捷补全"></a>快捷补全</h1><p>按<code>Tab</code>键即可快捷补全。</p>
<h1 id="切换目录"><a href="#切换目录" class="headerlink" title="切换目录"></a>切换目录</h1><p>切换到<code>xxx</code>目录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd xxx</span><br></pre></td></tr></table></figure>
<h1 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h1><p>创建一个名为<code>Environment</code>的目录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir Environment</span><br></pre></td></tr></table></figure>
<p><code>-p</code>选项允许创建一个目录和它不存在的父目录。也就是说，<code>-p</code>选项确保了指定的整个目录路径都会被创建。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p files&#x2F;images&#x2F;jpg</span><br></pre></td></tr></table></figure>
<h1 id="命令行参数"><a href="#命令行参数" class="headerlink" title="命令行参数"></a>命令行参数</h1><p><code>-</code>和<code>--</code>是两种不同的命令行选项的风格。前者是传统的<code>Unix</code>风格，后者是<code>GNU</code>风格。</p>
<p>起初<code>Unix</code>设计命令行程序时，需要将一个命令的选项（<code>Options</code>）和参数（<code>Arguments</code>）区分开来，就引入了<code>-</code>。</p>
<p>凡是以<code>-</code>开头的，就是选项。选项用一个单独的字母作为标志，通常也是一个选项英语的缩写。例如，<code>-a</code>表示所有，<code>-c</code>表示命令，<code>-f</code>表示文件，<code>-V</code>表示版本。</p>
<p>但是，单独字母的数量毕竟有限，会不够用，而且表达的意思不够明确。于是就有了之后的<code>GNU</code>风格来完善上述的不足，使用<code>--</code>作为前缀，后面可以跟一串单词，如<code>--version</code>，<code>--all</code>。</p>
<h1 id="查看工作目录下的内容"><a href="#查看工作目录下的内容" class="headerlink" title="查看工作目录下的内容"></a>查看工作目录下的内容</h1><p>以长格式的形式查看当前目录下所有可见文件的详细属性：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -l</span><br></pre></td></tr></table></figure>
<p>显示当前目录中的所有文件和目录（包括隐藏文件）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -a</span><br></pre></td></tr></table></figure>
<h1 id="获取当前目录的完整路径"><a href="#获取当前目录的完整路径" class="headerlink" title="获取当前目录的完整路径"></a>获取当前目录的完整路径</h1><p>获取当前目录的完整路径（绝对路径）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pwd</span><br></pre></td></tr></table></figure>
<h1 id="获取文件的绝对路径"><a href="#获取文件的绝对路径" class="headerlink" title="获取文件的绝对路径"></a>获取文件的绝对路径</h1><p><code>readlink</code>的最初用途是解析符号链接，不过我们可以用它来显示文件的完整路径，如下为其语法结构：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">readlink -f sample.txt</span><br></pre></td></tr></table></figure>
<p><code>realpath</code>原用于解析绝对文件名，在这里我们也可以用它来显示文件的完整路径，如果使用符号链接，它将显示原始文件的实际路径：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">realpath sample.txt</span><br></pre></td></tr></table></figure>
<p>可以强制它不跟随符号链接（即显示当前文件的路径）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">realpath -s sample.txt</span><br></pre></td></tr></table></figure>
<h1 id="友好显示文件大小"><a href="#友好显示文件大小" class="headerlink" title="友好显示文件大小"></a>友好显示文件大小</h1><p>查看文件/目录的大小并且输出我们看得懂的单位（例如<code>K</code>，<code>M</code>，<code>G</code>），<code>-h</code>是<code>--human-readable</code>的意思：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ll -h</span><br></pre></td></tr></table></figure>
<h1 id="拷贝文件-文件夹"><a href="#拷贝文件-文件夹" class="headerlink" title="拷贝文件/文件夹"></a>拷贝文件/文件夹</h1><p>将<code>test-3ddata</code>目录拷贝到上层<code>Data</code>目录下，<code>-r</code>选项是递归复制，用于目录的复制操作：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp test-3ddata/ ../Data -r</span><br></pre></td></tr></table></figure>
<h1 id="移动文件-文件夹"><a href="#移动文件-文件夹" class="headerlink" title="移动文件/文件夹"></a>移动文件/文件夹</h1><p>将<code>test-3ddata</code>目录移动到上层<code>Data</code>目录下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv test-3ddata/ ../Data/</span><br></pre></td></tr></table></figure>
<h1 id="重命名文件-文件夹"><a href="#重命名文件-文件夹" class="headerlink" title="重命名文件/文件夹"></a>重命名文件/文件夹</h1><p>将<code>test-3ddata</code>目录重命名为<code>test-3d</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv test-3ddata test-3d</span><br></pre></td></tr></table></figure>
<h1 id="删除文件-文件夹"><a href="#删除文件-文件夹" class="headerlink" title="删除文件/文件夹"></a>删除文件/文件夹</h1><p>删除名为<code>gtc-input-f6cab9.lua</code>和<code>gtcv3-f6cab9.converted.npz</code>的文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm -f gtc-input-f6cab9.lua gtcv3-f6cab9.converted.npz</span><br></pre></td></tr></table></figure>
<p>删除名为<code>aaa</code>的目录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm -rf aaa</span><br></pre></td></tr></table></figure>
<h1 id="输出文本"><a href="#输出文本" class="headerlink" title="输出文本"></a>输出文本</h1><p><code>echo</code>命令是<code>Linux</code>和<code>Unix</code>系统中常用的一个命令行工具，它的主要功能是显示一行文本或将文本重定向到文件。<code>echo</code>命令的语法非常简单，基本上只需要在命令行中输入<code>echo</code>后面跟上要输出的文本即可。</p>
<p>使用<code>echo</code>命令输出各种文本信息：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo &quot;Hello!&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> Hello!</span></span><br></pre></td></tr></table></figure>
<p>使用<code>echo</code>命令输出变量的值：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">name=&quot;xxx&quot;</span><br><span class="line">echo &quot;Hello, $name!&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> Hello, xxx!</span></span><br></pre></td></tr></table></figure>
<p>使用<code>-e</code>选项可以启用转义字符的解释，例如输出换行符：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo -e &quot;Line 1\nLine 2&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> Line 1</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Line 2</span></span><br></pre></td></tr></table></figure>
<p><code>echo</code>命令还可以将文本重定向到文件中，通过使用重定向操作符<code>&gt;</code>或<code>&gt;&gt;</code>来实现：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo &quot;This is some text&quot; &gt; file.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建一个名为file.txt的文件，并将<span class="string">&quot;This is some text&quot;</span>写入文件中。如果文件已经存在，则内容会被覆盖。</span></span><br><span class="line">echo &quot;Another line of text&quot; &gt;&gt; file.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在file.txt文件的末尾追加<span class="string">&quot;Another line of text&quot;</span>。</span></span><br></pre></td></tr></table></figure>
<h1 id="从文件读取和执行命令"><a href="#从文件读取和执行命令" class="headerlink" title="从文件读取和执行命令"></a>从文件读取和执行命令</h1><p><code>source</code>命令是一个内置的<code>shell</code>命令，用于从当前<code>shell</code>会话中的文件读取和执行命令，更常见的简写方式是使用点号<code>.</code>。<code>source</code>命令通常用于保留、更改当前<code>shell</code>中的环境变量。当使用<code>source</code>命令运行一个脚本时，该脚本中的变量、函数和其他<code>shell</code>特性都会在当前<code>shell</code>会话中生效，而不仅仅是在子<code>shell</code>中。</p>
<p>假设有一个名为<code>test_source.sh</code>的脚本，内容如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">MY_VAR=<span class="string">&quot;xxx&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello, <span class="variable">$MY_VAR</span>.&quot;</span></span><br></pre></td></tr></table></figure>
<p>使用<code>sh/bash</code>命令的执行结果和<code>source/.</code>命令的执行结果对比：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sh test_source.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> Hello, xxx.</span></span><br><span class="line">echo &quot;$MY_VAR&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line"></span><br><span class="line">bash test_source.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> Hello, xxx.</span></span><br><span class="line">echo &quot;$MY_VAR&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line"></span><br><span class="line">source test_source.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> Hello, xxx.</span></span><br><span class="line">echo &quot;$MY_VAR&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> xxx</span></span><br><span class="line"></span><br><span class="line">. test_source.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> Hello, xxx.</span></span><br><span class="line">echo &quot;$MY_VAR&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> xxx</span></span><br></pre></td></tr></table></figure>
<h1 id="更改文件权限"><a href="#更改文件权限" class="headerlink" title="更改文件权限"></a>更改文件权限</h1><p>在<code>Linux</code>文件系统当中，每个文件都与一个特定的所有者相关联，并且对不同的用户具有访问权限。</p>
<p>用户类别可以是：</p>
<ul>
<li>所有者</li>
<li>小组成员</li>
<li>其他人（其他所有人）</li>
</ul>
<p><code>Linux</code>中的文件权限是以下三种类型：</p>
<ul>
<li>阅读(<code>r-4</code>)</li>
<li>写(<code>w-2</code>)</li>
<li>执行(<code>x-1</code>)</li>
</ul>
<p><code>chmod</code>命令的基本语法如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod &lt;options&gt; &lt;permissions&gt; &lt;file name&gt;</span><br></pre></td></tr></table></figure>
<p>权限设定字串的格式为：<code>[ugoa...][[+-=][rwx]...][,...]</code>。所有者<code>User</code>，简称<code>u</code>；所属组<code>Group</code>，简称<code>g</code>；其他用户<code>Other</code>，简称<code>o</code>。</p>
<h2 id="数字表示法"><a href="#数字表示法" class="headerlink" title="数字表示法"></a>数字表示法</h2><p>要给用户完全权限（读+写+执行），为组提供读和执行权限（<code>4+1=5</code>），为其他人提供只读权限（<code>4</code>），可以使用以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod 754 file_name</span><br></pre></td></tr></table></figure>
<p>递归修改目录及其子目录和文件的权限，可以使用<code>-R</code>选项，递归地给目录及其所有子目录和文件的用户完整权限：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod -R 777 directory_name</span><br></pre></td></tr></table></figure>
<h2 id="符号表示法"><a href="#符号表示法" class="headerlink" title="符号表示法"></a>符号表示法</h2><p>给用户添加执行权限：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod u+x file_name</span><br></pre></td></tr></table></figure>
<p>移除组的写权限：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod g-w file_name</span><br></pre></td></tr></table></figure>
<p>设置所有人的权限为读+写+执行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod a+rwx file_name</span><br></pre></td></tr></table></figure>
<h1 id="查看可执行文件或共享库的依赖"><a href="#查看可执行文件或共享库的依赖" class="headerlink" title="查看可执行文件或共享库的依赖"></a>查看可执行文件或共享库的依赖</h1><p><code>ldd</code>是一个用于查看可执行文件或共享库所依赖的共享库的命令。该命令可以帮助用户了解可执行文件或库与系统上安装的共享库之间的依赖关系。基本语法为：<code>ldd [options] file</code>。</p>
<p>下面的命令会输出<code>libpython3.8.so</code>共享库的依赖关系，输出内容主要包括：共享库的名称、共享库的版本、是否为调试符号、共享库的路径。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ldd libpython3.8.so</span><br></pre></td></tr></table></figure>
<h2 id="共享库文件"><a href="#共享库文件" class="headerlink" title="共享库文件"></a>共享库文件</h2><p>共享库文件<code>(Shared Object)</code>通常用于<code>Linux</code>和类<code>Unix</code>操作系统中。它是一个包含可执行代码的文件，多个程序可以共享同一个<code>.so</code>文件中的代码，从而节省内存和磁盘空间。<code>.so</code>文件相当于<code>Windows</code>系统中的动态链接库<code>(DLL)</code>文件。</p>
<p><code>.so</code>文件的特点：</p>
<ul>
<li>共享性：多个程序可以同时使用同一个<code>.so</code>文件，操作系统会在程序运行时加载共享库中的代码。这样，当多个程序需要使用相同的功能时，它们不需要各自复制一份代码，而是直接共享这部分内存。</li>
<li>动态链接：<code>.so</code>文件通常是在程序运行时被加载的，而不是在编译时就被静态链接到程序中。这样，程序在启动时可以动态地加载所需要的共享库文件。</li>
<li>内存节省：由于多个程序可以共享同一个<code>.so</code>文件，因此相同的代码只会加载一次，从而减少了内存的占用。</li>
<li>版本控制：<code>.so</code>文件也支持版本控制，可以更新共享库，而不需要重新编译依赖它的程序，只要接口没有变化，程序就可以继续正常运行。</li>
</ul>
<h1 id="从二进制文件提取字符序列"><a href="#从二进制文件提取字符序列" class="headerlink" title="从二进制文件提取字符序列"></a>从二进制文件提取字符序列</h1><p><code>strings</code>命令从二进制文件中提取可打印的字符序列。这些字符序列通常包括变量名、函数名、注释或任何嵌入的文本信息，对于文件分析和调试具有重要意义。</p>
<p>查找并显示文件中的可打印字符串：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">strings /bin/ls</span><br></pre></td></tr></table></figure>
<p>设置最小字符串长度：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">strings -n 6 /usr/bin/uptime</span><br></pre></td></tr></table></figure>
<h1 id="查看所有打开的文件和关联进程"><a href="#查看所有打开的文件和关联进程" class="headerlink" title="查看所有打开的文件和关联进程"></a>查看所有打开的文件和关联进程</h1><p> <code>lsof(List Open Files)</code>命令在<code>Linux</code>系统中用于查看当前系统上所有打开的文件和与之关联的进程。每个进程在系统中都有文件描述符，用于指向打开的文件，这些文件可以是磁盘文件、网络套接字、管道等。</p>
<p>查看所有网络连接：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -i</span><br></pre></td></tr></table></figure>
<p>查看特定用户打开的文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -u &lt;user&gt;</span><br><span class="line">lsof -u ubuntu</span><br></pre></td></tr></table></figure>
<p>列出某个程序打开的文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -c &lt;app_name&gt;</span><br><span class="line">lsof -c containerd</span><br></pre></td></tr></table></figure>
<p>查看指定进程打开的文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -p &lt;pid&gt;</span><br><span class="line">lsof -p 859</span><br></pre></td></tr></table></figure>
<p>查找监听特定端口的进程：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -i :&lt;port&gt;</span><br><span class="line">lsof -i :</span><br></pre></td></tr></table></figure>
<p>查看所有处于监听状态的<code>TCP</code>连接：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -i -sTCP:LISTEN</span><br></pre></td></tr></table></figure>
<p> 查看所有处于建立好连接的<code>TCP</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -i -sTCP:ESTABLISHED</span><br></pre></td></tr></table></figure>
<p>查看指定进程监听的端口：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -i -a -p &lt;pid&gt;</span><br></pre></td></tr></table></figure>
<p>查看指定命令监听的端口：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -i -a -c &lt;command&gt;</span><br></pre></td></tr></table></figure>
<p>查看所有<code>TCP</code>连接：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -i tcp</span><br></pre></td></tr></table></figure>
<p>查看所有<code>UDP</code>连接：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -i udp</span><br></pre></td></tr></table></figure>
<p>查找使用特定文件的进程：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof &lt;file&gt;</span><br></pre></td></tr></table></figure>
<p>查找使用特定目录的进程：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof +D &lt;dir&gt;</span><br></pre></td></tr></table></figure>
<h1 id="查看文件中的符号信息"><a href="#查看文件中的符号信息" class="headerlink" title="查看文件中的符号信息"></a>查看文件中的符号信息</h1><p><code>nm</code>是<code>names</code>的缩写，<code>nm</code>命令主要是用来查看文件中的符号信息。可以查看的文件包括：库文件、目标文件（<code>main.o</code>）、可执行文件等。基本语法为：<code>nm [-option] file</code>。</p>
<p>列出二进制文件中的所有符号：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nm &lt;program&gt;</span><br></pre></td></tr></table></figure>
<p>仅列出已定义的函数符号：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nm -t f --defined-only &lt;program&gt;</span><br></pre></td></tr></table></figure>
<p>以长格式输出符号信息，并显示其十六进制地址：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nm -ln &lt;program&gt;</span><br></pre></td></tr></table></figure>
<h1 id="软链接和硬链接"><a href="#软链接和硬链接" class="headerlink" title="软链接和硬链接"></a>软链接和硬链接</h1><h2 id="软链接"><a href="#软链接" class="headerlink" title="软链接"></a>软链接</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul>
<li>软链接是一种特殊类型的文件，它包含了另一个文件或目录的路径名。当访问软链接时，系统会通过该路径名找到并访问源文件或目录。</li>
<li>软链接类似于Windows系统中的快捷方式，它存储的是源文件的路径，而不是文件本身的数据。这意味着如果源文件被移动、重命名或删除，软链接将会失效。</li>
</ul>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li>独立性：软链接是一个独立的文件，它有自己的<code>inode</code>号，并占用少量的存储空间（通常只有几个字节）。</li>
<li>可跨文件系统：软链接可以跨越不同的文件系统，将一个文件或目录链接到另一个文件系统中。</li>
<li>可链接目录：与硬链接不同，软链接可以链接到目录。</li>
<li>源文件依赖性：如果源文件或目录被移动、重命名或删除，软链接将会失效，成为“死链接”。</li>
</ul>
<h3 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h3><ul>
<li>快捷方式：软链接可以创建桌面或文件夹中的快捷方式，方便用户快速访问源文件或目录。</li>
<li>软件安装：在某些操作系统中，软链接常用于指向已安装软件的可执行文件，简化软件的升级和管理。</li>
</ul>
<h3 id="创建方式"><a href="#创建方式" class="headerlink" title="创建方式"></a>创建方式</h3><p>软链接是通过<code>ln</code>命令结合<code>-s</code>选项来创建的。其基本语法为：<code>ln -s [SOURCE_FILE/SOURCE_DIR] [TARGET_FILE/TARGET_DIR]</code>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503172007916.png" alt=""></p>
<h2 id="硬链接"><a href="#硬链接" class="headerlink" title="硬链接"></a>硬链接</h2><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><ul>
<li>共享<code>inode</code>：硬链接直接指向文件的数据所在的位置，而不是文件名。多个硬链接实际上是共享同一存储空间的文件名，它们具有相同的<code>inode</code>号。</li>
<li>文件系统限制：硬链接只能在同一个文件系统中创建，不能跨文件系统。</li>
</ul>
<h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><ul>
<li>无独立性：硬链接并不是独立的文件，它不会增加源文件的<code>inode</code>数或存储空间占用。</li>
<li>不可跨文件系统：硬链接不能跨越不同的文件系统，因为每个文件系统都有自己独立的<code>inode</code>空间。</li>
<li>不可链接目录：在大多数<code>Unix-like</code>系统中，不能为目录创建硬链接。</li>
<li>源文件无关性：删除具有多个硬链接的文件（即其链接数大于1的文件）只会减少其链接数，而不会从文件系统中删除该文件，直到其链接数减至0为止。</li>
</ul>
<h3 id="用途-1"><a href="#用途-1" class="headerlink" title="用途"></a>用途</h3><ul>
<li>共享文件：多个用户或进程可以使用硬链接来共享同一个文件，节省存储空间。</li>
<li>备份文件：硬链接可以用于文件备份，因为它们不会占用额外的磁盘空间（除了链接文件本身的<code>inode</code>和文件名信息）。</li>
<li>系统文件管理：一些系统文件经常需要在不同位置进行引用，通过创建硬链接可以简化管理和维护。</li>
<li>防止误删：通过创建多个硬链接，可以确保即使删除了一个链接，文件本身也不会被删除，从而防止误删。</li>
</ul>
<h3 id="创建方式-1"><a href="#创建方式-1" class="headerlink" title="创建方式"></a>创建方式</h3><p>硬链接是通过<code>ln</code>命令（不带<code>-s</code>选项）来创建的。其基本语法为：<code>ln [SOURCE_FILE] [TARGET_FILE]</code>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503172007453.png" alt=""></p>
<h2 id="删除原理"><a href="#删除原理" class="headerlink" title="删除原理"></a>删除原理</h2><p>在<code>Linux</code>文件系统中，每个文件都有一个唯一的<code>inode</code>（索引节点），用于存储文件的元数据（如权限、大小、时间戳等）以及指向文件数据块的指针。文件名只是指向<code>inode</code>的链接，而不是文件数据本身。</p>
<p>每个<code>inode</code>中都有一个 链接计数（<code>link count</code>），表示有多少个文件名指向该<code>inode</code>。创建硬链接时，链接计数加<code>1</code>。删除文件时，链接计数减<code>1</code>。只有当链接计数变为<code>0</code>时，文件系统才会释放<code>inode</code>和数据块。</p>
<h1 id="跟踪进程执行时的系统调用和所接收的信号"><a href="#跟踪进程执行时的系统调用和所接收的信号" class="headerlink" title="跟踪进程执行时的系统调用和所接收的信号"></a>跟踪进程执行时的系统调用和所接收的信号</h1><p><code>strace</code>命令常用来跟踪进程执行时的系统调用和所接收的信号。 在<code>Linux</code>世界，进程不能直接访问硬件设备，当进程需要访问硬件设备（比如读取磁盘文件，接收网络数据等等）时，必须由用户态模式切换至内核态模式，通过系统调用访问硬件设备。<code>strace</code>可以跟踪到一个进程产生的系统调用,包括参数，返回值，执行消耗的时间。</p>
<p>追踪<code>df</code>命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">strace df -h</span><br></pre></td></tr></table></figure>
<p>追踪特定的系统调用：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo strace -e trace=write df -h</span><br></pre></td></tr></table></figure>
<p>针对文件系统调用的追踪：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo strace -q  -e trace=file df -h</span><br></pre></td></tr></table></figure>
<p>针对内存的追踪：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo strace -q -e trace=memory df -h</span><br></pre></td></tr></table></figure>
<p>针对网络的追踪：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo strace -e trace=network df -h</span><br></pre></td></tr></table></figure>
<p>根据进程<code>PID</code>进行追踪：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo strace -p &lt;pid&gt;</span><br></pre></td></tr></table></figure>
<p>得到进程的汇总信息：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo strace -c -p &lt;pid&gt;</span><br></pre></td></tr></table></figure>
<p>打印指令指针：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo strace -i df -h</span><br></pre></td></tr></table></figure>
<p>显示调用时间：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">strace -t df -h</span><br></pre></td></tr></table></figure>
<p>显示系统调用的耗时：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">strace -T df -h</span><br></pre></td></tr></table></figure>
<p>将追踪结果写入到文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">strace -o df_debug.txt df -h</span><br></pre></td></tr></table></figure>
<h1 id="反汇编可执行文件"><a href="#反汇编可执行文件" class="headerlink" title="反汇编可执行文件"></a>反汇编可执行文件</h1><p><code>objdump</code>命令是<code>GNUBinutils</code>工具集中的一个重要组成部分，它可以用于反汇编可执行文件，显示可执行文件的各个节的内容。</p>
<p>显示可执行文件的节表信息：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">objdump -h &lt;executable&gt;</span><br></pre></td></tr></table></figure>
<p>显示可执行文件的源代码和汇编代码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">onjdump -S &lt;executable&gt;</span><br></pre></td></tr></table></figure>
<p>显示可执行文件的符号表：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">objdump -t &lt;executable&gt;</span><br></pre></td></tr></table></figure>
<h1 id="查找命令"><a href="#查找命令" class="headerlink" title="查找命令"></a>查找命令</h1><p><code>find</code>命令用于在文件树中查找文件，并作出相应的处理。基本语法为：<code>find [path] [expression]</code>。</p>
<p>获取<code>/etc/</code>中以<code>.conf</code>结尾的文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /etc/ -type f -name &quot;*.conf&quot;</span><br></pre></td></tr></table></figure>
<p>搜索当前目录及子目录下所有<code>.txt</code>文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -name &quot;*.txt&quot; -type f</span><br></pre></td></tr></table></figure>
<p>搜索<code>/var/log</code>目录下修改时间在<code>7</code>天前的文件并删除它们：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /var/log -type f -mtime +7 -exec rm &#123;&#125; \;</span><br></pre></td></tr></table></figure>
<p>搜索<code>/usr/bin</code>目录下所有可执行文件，并打印它们的权限，<code>\;</code>告诉<code>find</code>命令<code>-exec</code>选项的命令序列在哪里结束：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /usr/bin -type f -executable -exec ls -l &#123;&#125; \;</span><br></pre></td></tr></table></figure>
<h1 id="设置或显示环境变量"><a href="#设置或显示环境变量" class="headerlink" title="设置或显示环境变量"></a>设置或显示环境变量</h1><p><code>export</code>命令用于设置和显示环境变量。基本语法为：<code>export [-fn] [NAME[=WORD]]...</code>。</p>
<p>定义环境变量并赋值：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export MYNEWV=8</span><br></pre></td></tr></table></figure>
<p>在保留原来<code>LD_LIBRARY_PATH</code>值的基础上添加当前工作路径。<code>.</code>代表当前工作目录，放在<code>LD_LIBRARY_PATH</code>的最前面，意味着动态链接器在搜索共享库时会首先查看当前目录，<code>:</code>作为路径分隔符：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=.:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>
<p>永久性设置环境变量：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo &#x27;export MY_VARIABLE=&quot;HelloWorld&quot;&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>
<h1 id="文件压缩与解压"><a href="#文件压缩与解压" class="headerlink" title="文件压缩与解压"></a>文件压缩与解压</h1><p>主要介绍<code>tar</code>命令，其比较常用的格式为<code>tar [option] [file]</code>。其中<code>file</code>参数通常是我们要操作的文件名。而<code>option</code>参数一般是我们要对该文件进行的操作，它可以简单地分为操作选项和附加选项。</p>
<h2 id="操作选项"><a href="#操作选项" class="headerlink" title="操作选项"></a>操作选项</h2><p>需要注意的是，操作选项之间互相独立，一般不可同时使用，但可以和附加选项参数配合使用。（为了方便理解，我们一般会操作选项参数放在附加选项参数之前。）</p>
<ul>
<li><code>-c</code>：创建压缩文件</li>
<li><code>-x</code>：对文件进行解压</li>
<li><code>-t</code>：查看压缩包内容</li>
<li><code>-r</code>：向压缩归档文件末尾追加文件</li>
<li><code>-u</code>：更新原压缩包中的文件</li>
<li><code>-d</code>：将压缩文件和文件系统上的文件进行对比</li>
</ul>
<h2 id="附加选项"><a href="#附加选项" class="headerlink" title="附加选项"></a>附加选项</h2><p>这些参数是根据压缩或者解压缩需要选择的，使用时放在操作选项参数的后面。</p>
<ul>
<li><code>-z</code>：文件有<code>gzip</code>属性</li>
<li><code>-j</code>：文件有<code>bz2</code>属性</li>
<li><code>-Z</code>：文件有<code>compress</code>属性</li>
<li><code>-v</code>：详细列出所有处理过程</li>
<li><code>-C</code>：指定工作目录（因为该参数后必须紧跟文件目录，故一般放在<code>option</code>参数的最后或单独使用）</li>
<li><code>-f</code>：指定归档文件名（因为该参数后必须紧跟文件名，故一般放在<code>option</code>参数的最后或单独使用）</li>
</ul>
<h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><h3 id="压缩文件"><a href="#压缩文件" class="headerlink" title="压缩文件"></a>压缩文件</h3><p>将当前目录里所有以<code>demo_d01_</code>开头的文件打包成<code>demo.tar</code>，并详细显示压缩过程：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -cvf demo.tar demo_d01_*</span><br></pre></td></tr></table></figure>
<p>将当前目录里所有以<code>demo_d01_</code>开头的文件打包成<code>demo.tar</code>后，并将其用<code>gzip</code>进行压缩，生成一个<code>gzip</code>压缩过的包，命名为<code>demo.tar.gz</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -czf demo.tar.gz demo_d01_*</span><br></pre></td></tr></table></figure>
<p>将当前目录里所有以<code>demo_d01_</code>开头的文件打包成<code>demo.tar</code>后，并将其用<code>bzip2</code>压缩，生成一个<code>bzip2</code>压缩过的包，命名为<code>demo.tar.bz2</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -cjf demo.tar.bz2 demo_d01_*</span><br></pre></td></tr></table></figure>
<p>将当前目录里所有以<code>demo_d01_</code>开头的文件打包成<code>demo.tar</code>后，并将其用<code>compress</code>压缩，生成一个<code>compress</code>压缩过的包，命名为<code>demo.tar.Z</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -cZf demo.tar.Z demo_d01_*</span><br></pre></td></tr></table></figure>
<p>将当前目录里所有以<code>demo_d01_</code>开头的文件打包成<code>demo.tar</code>存放在上一级目录中，并详细显示压缩过程：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -cvf ../demo.tar demo_d01_*</span><br></pre></td></tr></table></figure>
<h3 id="解压文件"><a href="#解压文件" class="headerlink" title="解压文件"></a>解压文件</h3><p>对于<code>.zip</code>文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">unzip filename.zip</span><br></pre></td></tr></table></figure>
<p>对于<code>.tar.gz</code>文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -xzf filename.tar.gz</span><br></pre></td></tr></table></figure>
<p>对于<code>.tar.bz2</code>文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xjf filename.tar.bz2</span><br></pre></td></tr></table></figure>
<p>对与<code>.tar</code>文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf filename.tar</span><br></pre></td></tr></table></figure>
<p>对于<code>.rar</code>文件（需要先安装<code>unrar</code>）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install unrar</span><br><span class="line">unrar x filename.rar</span><br></pre></td></tr></table></figure>
<p>对于<code>.7z</code>文件（需要先安装<code>p7zip-full</code>）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install p7zip-full</span><br><span class="line">7z x filename.7z</span><br></pre></td></tr></table></figure>
<h1 id="不同机器之间文件传输"><a href="#不同机器之间文件传输" class="headerlink" title="不同机器之间文件传输"></a>不同机器之间文件传输</h1><p><code>SCP</code>是一种命令行实用程序，允许你通过网络在两个主机之间安全地传输文件。它使用<code>SSH</code>进行身份验证和加密，确保传输的数据安全。<code>SCP</code>命令的基本语法为：<code>scp [option] [source_path] [target_path]</code>。</p>
<p><strong>将文件从本地系统复制到远程系统：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp /path/to/local/file username@remote_host:/path/to/remote/directory</span><br></pre></td></tr></table></figure>
<p><strong>将文件从远程系统复制到本地系统：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp username@remote_host:/path/to/remote/file /path/to/local/directory</span><br></pre></td></tr></table></figure>
<p><strong>将目录从本地系统复制到远程系统：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r /path/to/local/directory username@remote_host:/path/to/remote/directory</span><br></pre></td></tr></table></figure>
<p><strong>将目录从远程系统复制到本地系统：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r username@remote_host:/path/to/remote/directory /path/to/local/directory</span><br></pre></td></tr></table></figure>
<h1 id="清屏命令"><a href="#清屏命令" class="headerlink" title="清屏命令"></a>清屏命令</h1><p>刷新屏幕（本质上只是让终端显示页向后翻了一页，如果向上滚动屏幕还可以看到之前的操作信息）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">clear</span><br></pre></td></tr></table></figure>
<p>完全刷新终端屏幕（之前的终端输入操作信息将都会被清空，整个命令过程速度有点慢，使用较少）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">reset</span><br></pre></td></tr></table></figure>
<h1 id="监控GPU命令"><a href="#监控GPU命令" class="headerlink" title="监控GPU命令"></a>监控<code>GPU</code>命令</h1><p>监控<code>GPU</code>的使用情况：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
<h1 id="退出"><a href="#退出" class="headerlink" title="退出"></a>退出</h1><p>终端翻阅到最后出现退出<code>(END)</code>，按<code>q</code>键即可退出</p>
<h1 id="周期性执行命令"><a href="#周期性执行命令" class="headerlink" title="周期性执行命令"></a>周期性执行命令</h1><p>每隔<code>10</code>秒执行监控<code>GPU</code>的使用情况：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">watch -n 10 nvidia-smi</span><br></pre></td></tr></table></figure>
<h1 id="杀死进程"><a href="#杀死进程" class="headerlink" title="杀死进程"></a>杀死进程</h1><p>杀死<code>pid</code>为<code>88888</code>的进程</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kill -9 88888</span><br></pre></td></tr></table></figure>
<h1 id="挂起进程"><a href="#挂起进程" class="headerlink" title="挂起进程"></a>挂起进程</h1><p>如何挂起正在执行的进程：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Ctrl+z</span><br></pre></td></tr></table></figure>
<p>查看被挂起的进程：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jobs</span><br></pre></td></tr></table></figure>
<p>重新启动前台被中断的任务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">fg [job_id]</span><br></pre></td></tr></table></figure>
<p>把被中断的任务放在后台执行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bg [job_id]</span><br></pre></td></tr></table></figure>
<h1 id="查看进程信息"><a href="#查看进程信息" class="headerlink" title="查看进程信息"></a>查看进程信息</h1><p>在<code>Linux</code>中，<code>ps -aux</code>是一个常见的用于查看系统进程信息的命令。<code>-a</code>选项用于显示所有用户的进程，而不仅仅是当前用户的。<code>-u</code>选项用于显示详细的用户/拥有者信息。<code>-x</code>选项用于显示没有控制终端的进程。请注意，<code>ps -aux</code>的写法在一些操作系统中可能已经过时，更推荐使用<code>ps aux</code>。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ps -aux | grep python</span><br></pre></td></tr></table></figure>
<h1 id="系统服务管理"><a href="#系统服务管理" class="headerlink" title="系统服务管理"></a>系统服务管理</h1><p><code>systemctl</code>是一个系统服务管理工具，可以用来管理和控制系统的服务。在<code>Ubuntu</code>中，可以使用<code>systemctl</code>命令来启动、停止、重启、禁用和启用系统服务。</p>
<p>启动一个服务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl start service_name</span><br></pre></td></tr></table></figure>
<p>停止一个服务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl stop service_name</span><br></pre></td></tr></table></figure>
<p>重启一个服务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl restart service_name</span><br></pre></td></tr></table></figure>
<p>禁用一个服务（在系统启动时不自动启动）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl disable service_name</span><br></pre></td></tr></table></figure>
<p>启用一个服务（在系统启动时自动启动）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl enable service_name</span><br></pre></td></tr></table></figure>
<p>查看服务状态：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl status service_name</span><br></pre></td></tr></table></figure>
<p>查看所有已启动的服务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl list-units --type=service</span><br></pre></td></tr></table></figure>
<p>查看所有已启用的服务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl list-unit-files --type=service</span><br></pre></td></tr></table></figure>
<h1 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a>命名空间</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p><code>Linux</code>命名空间是一种内核级特性，它用于隔离系统资源，如进程<code>ID</code>、主机名、用户<code>ID</code>、网络接口等。这使得容器（如<code>Docker</code>或<code>LXC</code>）能够在单个<code>Linux</code>内核上运行多个相互隔离的系统。改变一个<code>namespace</code>中的系统资源只会影响当前<code>namespace</code>里的进程，对其他<code>namespace</code>中的进程没有影响。</p>
<h2 id="命名空间类型"><a href="#命名空间类型" class="headerlink" title="命名空间类型"></a>命名空间类型</h2><div class="table-container">
<table>
<thead>
<tr>
<th><code>Namespace</code>类型</th>
<th>系统调用参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Mount Namespace(mnt)</code></td>
<td><code>CLONE_NEWNS</code></td>
<td>隔离每个进程的挂载点视图</td>
</tr>
<tr>
<td><code>UTS Namespace(uts)</code></td>
<td><code>CLONE_NEWUTS</code></td>
<td>隔离<code>NodeName</code>和<code>DomainName</code></td>
</tr>
<tr>
<td><code>PID Namespace(pid)</code></td>
<td><code>CLONE_NEWPID</code></td>
<td>隔离进程<code>ID</code></td>
</tr>
<tr>
<td><code>Network Namespace(net)</code></td>
<td><code>CLONE_NEWNET</code></td>
<td>隔离网络设备</td>
</tr>
<tr>
<td><code>IPC Namespace(ipc)</code></td>
<td><code>CLONE_NEWIPC</code></td>
<td>隔离<code>System V IPC(Inter-Process Communication)</code>和<code>POSIX</code>消息队列，包括共享内存、信号量、消息队列等</td>
</tr>
<tr>
<td><code>User Namespace(user)</code></td>
<td><code>CLONE_NEWUSER</code></td>
<td>隔离用户和用户组<code>ID</code></td>
</tr>
<tr>
<td><code>Cgroup Namespace(cgroup)</code></td>
<td><code>CLONE_NEWCGROUP</code></td>
<td>隔离<code>Cgroup</code>根目录</td>
</tr>
</tbody>
</table>
</div>
<h3 id="PID命名空间"><a href="#PID命名空间" class="headerlink" title="PID命名空间"></a><code>PID</code>命名空间</h3><p><code>Linux PID</code>命名空间是<code>Linux Namespace</code>的一种类型，用于隔离进程<code>ID</code>。在一个<code>PID</code>命名空间中，每个进程拥有独立的进程<code>ID</code>，这样在不同的命名空间中可以有相同的进程<code>ID</code>，而不会产生冲突。每个子<code>PID</code>命名空间中都有<code>PID</code>为<code>1</code>的<code>init</code>进程，对应父命名空间中的进程，父命名空间对子命名空间运行状态是不隔离的，但是每一个子命名空间是互相隔离的。</p>
<h3 id="UTS命名空间"><a href="#UTS命名空间" class="headerlink" title="UTS命名空间"></a><code>UTS</code>命名空间</h3><p><code>Linux UTS</code>命名空间用于隔离主机名和域名。在<code>UTS</code>命名空间中，每个进程可以拥有独立的主机名（<code>Nodename</code>）和域名（<code>Domainname</code>），这样可以在不同的命名空间中拥有不同的标识，从而实现了主机名和域名的隔离。</p>
<p><code>Nodename</code>：是用于标识主机的独特名称，通常也被称为主机名。它用于在网络中唯一地标识一台计算机<br><code>Domainname</code>： 是主机的域名部分，通常用于标识所属的网络域。域名通常由多个部分组成，按照从右到左的顺序，每个部分之间用点号<code>.</code>分隔。域名用于将主机名与特定的网络域关联起来，从而帮助在全球范围内定位和访问计算机。</p>
<h3 id="Mount命名空间"><a href="#Mount命名空间" class="headerlink" title="Mount命名空间"></a><code>Mount</code>命名空间</h3><p><code>Linux Mount</code>命名空间用于隔离文件系统挂载点。通过<code>Mount Namespace</code>，不同的进程可以在不同的挂载点上看到不同的文件系统层次结构，即使在同一台主机上运行。这种隔离使得进程在一个<code>Mount Namespace</code>中的挂载操作对其他<code>Mount Namespace</code>中的进程不可见，从而实现了文件系统层面的隔离。</p>
<p>在容器技术中，利用<code>Mount Namespace</code>隔离后，容器内部的文件系统挂载与宿主系统和其他容器相互隔离。这样，每个容器可以拥有独立的文件系统视图，容器内的进程只能访问自己的文件系统层次结构，而无法访问其他容器或宿主系统的文件系统。</p>
<h3 id="Network命名空间"><a href="#Network命名空间" class="headerlink" title="Network命名空间"></a><code>Network</code>命名空间</h3><p><code>Linux Network</code>命名空间用于隔离网络栈。通过<code>Network Namespace</code>，不同的进程可以拥有独立的网络设备、<code>IP</code>地址、路由表、网络连接和网络命名空间中的其他网络资源。这种隔离使得进程在一个<code>Network Namespace</code>中的网络配置和状态对其他<code>Network Namespace</code>中的进程不可见，从而实现了网络层面的隔离。</p>
<p>在容器技术中，利用<code>Network Namespace</code>隔离后，容器内部的进程拥有独立的网络环境，从而使得容器在网络上彼此隔离。每个容器可以有自己的网络设备、<code>IP</code>地址、路由表和网络连接，容器之间不会干扰彼此，也不会干扰宿主系统。</p>
<h3 id="User命名空间"><a href="#User命名空间" class="headerlink" title="User命名空间"></a><code>User</code>命名空间</h3><p><code>Linux User</code>命名空间用于隔离用户和用户组<code>ID</code>。通过<code>User Namespace</code>，不同的进程可以拥有独立的用户和用户组<code>ID</code>，这样可以在不同的命名空间中拥有不同的身份标识，从而实现了用户和用户组的隔离。</p>
<p>在容器技术中，利用<code>User Namespace</code>隔离后，容器内的进程可以拥有独立的用户和用户组<code>ID</code>，而不会与宿主系统或其他容器中的用户产生冲突。这样，容器内的应用程序可以以普通用户身份运行，而不需要在宿主系统中创建相同的用户账号。</p>
<h3 id="IPC命名空间"><a href="#IPC命名空间" class="headerlink" title="IPC命名空间"></a><code>IPC</code>命名空间</h3><p><code>Linux IPC</code>命名空间用于隔离进程间通信资源。在<code>IPC</code>命名空间中，每个命名空间都有独立的<code>IPC</code>资源，如消息队列、信号量和共享内存，使得不同命名空间中的进程无法直接访问其他命名空间的<code>IPC</code>资源，从而实现了<code>IPC</code>资源的隔离。</p>
<p>在容器技术中，利用<code>IPC Namespace</code>隔离后，容器内的进程拥有独立的<code>IPC</code>资源，从而避免不同容器之间的进程干扰和资源冲突。每个容器都可以有自己的<code>IPC</code>命名空间，使得容器内的进程在进行进程间通信时只能访问属于同一命名空间的<code>IPC</code>资源，而无法直接访问其他容器的<code>IPC</code>资源。</p>
<h3 id="Cgroup命名空间"><a href="#Cgroup命名空间" class="headerlink" title="Cgroup命名空间"></a><code>Cgroup</code>命名空间</h3><p><code>Cgroup</code>是对进程的<code>cgroup</code>视图虚拟化。 每个<code>cgroup</code>命名空间都有自己的一组<code>cgroup</code>根目录。<code>Linux 4.6</code>开始支持。</p>
<p><code>cgroup</code>命名空间提供的虚拟化有多种用途：</p>
<ul>
<li>防止信息泄漏。否则容器外的<code>cgroup</code>目录路径对容器中的进程可见。</li>
<li>简化了容器迁移等任务。</li>
<li>允许更好地限制容器化进程。可以挂载容器的<code>cgroup</code>文件系统，这样容器无需访问主机<code>cgroup</code>目录。</li>
</ul>
<h1 id="Cgroup"><a href="#Cgroup" class="headerlink" title="Cgroup"></a><code>Cgroup</code></h1><p>当我们要运行一个容器时，<code>Docker</code>等应用会为该容器创建一组<code>namespace</code>，对操作系统而言可以理解为一组进程。这下我们完成了“权利”的集中，但是“权利越大，责任也大”，我们不能放任这组“大权“不管，所以又有了<code>Cgroup(Linux Control Group)</code>这个东西。</p>
<p><code>Cgroup</code>最主要的作用，就是限制一个进程组能够使用的资源上限，包括<code>CPU</code>、内存、磁盘、网络带宽等等。</p>
<p><code>cgroups</code>框架提供了以下内容：</p>
<ul>
<li>资源限制：可以为我们的进程组配置内存限制或<code>CPU</code>个数限制又或者仅限于某个特定外围设备。</li>
<li>优先级：一个或多个组可以配置为优先占用<code>CPU</code>或磁盘<code>I/O</code>吞吐量。</li>
<li>资源记录：监视和测量组的资源使用情况。</li>
<li>控制：可以冻结或停止和重新启动进程组。</li>
</ul>
<h1 id="如何查询Python安装路径"><a href="#如何查询Python安装路径" class="headerlink" title="如何查询Python安装路径"></a>如何查询<code>Python</code>安装路径</h1><p>查看所有<code>Python</code>的安装目录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">whereis python</span><br></pre></td></tr></table></figure>
<p>查看当前使用的<code>python</code>的安装目录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">which python</span><br></pre></td></tr></table></figure>
<h1 id="虚拟环境管理"><a href="#虚拟环境管理" class="headerlink" title="虚拟环境管理"></a>虚拟环境管理</h1><h2 id="virtualenv"><a href="#virtualenv" class="headerlink" title="virtualenv"></a><code>virtualenv</code></h2><h3 id="创建虚拟环境"><a href="#创建虚拟环境" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h3><p>创建一个名为<code>env1</code>的虚拟环境目录（<code>/usr/local/bin/python</code>是<code>Python</code>的安装路径，创建的虚拟环境中的<code>Python</code>版本与路径中的<code>Python</code>版本一致）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">virtualenv -p /usr/local/bin/python env1</span><br></pre></td></tr></table></figure>
<h3 id="激活虚拟环境"><a href="#激活虚拟环境" class="headerlink" title="激活虚拟环境"></a>激活虚拟环境</h3><p>激活虚拟环境（激活成功之后命令行前面会出现<code>(env1)</code>）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source env1/bin/activate</span><br></pre></td></tr></table></figure>
<h3 id="退出虚拟环境"><a href="#退出虚拟环境" class="headerlink" title="退出虚拟环境"></a>退出虚拟环境</h3><p>退出虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure>
<h3 id="删除虚拟环境"><a href="#删除虚拟环境" class="headerlink" title="删除虚拟环境"></a>删除虚拟环境</h3><p>删除名为<code>env1</code>的虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm -rf env1</span><br></pre></td></tr></table></figure>
<h2 id="miniconda"><a href="#miniconda" class="headerlink" title="miniconda"></a><code>miniconda</code></h2><h3 id="下载miniconda安装包"><a href="#下载miniconda安装包" class="headerlink" title="下载miniconda安装包"></a>下载<code>miniconda</code>安装包</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://mirrors.bfsu.edu.cn/anaconda/miniconda/Miniconda3-py37_23.1.0-1-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>
<h3 id="安装miniconda"><a href="#安装miniconda" class="headerlink" title="安装miniconda"></a>安装<code>miniconda</code></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bash Miniconda3-py37_23.1.0-1-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>
<h3 id="查看所有虚拟环境"><a href="#查看所有虚拟环境" class="headerlink" title="查看所有虚拟环境"></a>查看所有虚拟环境</h3><p>查看已经安装的所有虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda info --envs</span><br></pre></td></tr></table></figure>
<h3 id="创建虚拟环境-1"><a href="#创建虚拟环境-1" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h3><p>创建一个虚拟环境名为<code>venv</code>，<code>python</code>版本为<code>3.7</code>的虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda create --name venv python=3.7</span><br></pre></td></tr></table></figure>
<p>在指定位置创建名为<code>venv</code>的虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda create --prefix=/home/jeeby/Environment/venv python=3.7</span><br></pre></td></tr></table></figure>
<p>注意此时<code>conda activate venv</code>会报错，因为虚拟环境虽然创建成功，但是没有名字，我们需要将新建立的环境目录加入：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda config --append envs_dirs /home/jeeby/Environment/</span><br></pre></td></tr></table></figure>
<h3 id="激活虚拟环境-1"><a href="#激活虚拟环境-1" class="headerlink" title="激活虚拟环境"></a>激活虚拟环境</h3><p>激活名为<code>venv</code>的虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda activate venv</span><br></pre></td></tr></table></figure>
<h3 id="退出虚拟环境-1"><a href="#退出虚拟环境-1" class="headerlink" title="退出虚拟环境"></a>退出虚拟环境</h3><p>退出当前虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></table></figure>
<h3 id="删除虚拟环境-1"><a href="#删除虚拟环境-1" class="headerlink" title="删除虚拟环境"></a>删除虚拟环境</h3><p>删除名为<code>venv</code>的虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda remove -n venv --all</span><br></pre></td></tr></table></figure>
<h1 id="安装GPU版本的PyTorch"><a href="#安装GPU版本的PyTorch" class="headerlink" title="安装GPU版本的PyTorch"></a>安装<code>GPU</code>版本的<code>PyTorch</code></h1><p>建议先进入<code>torch</code>的<code>wheel</code><a href="https://download.pytorch.org/whl/torch_stable.html">下载网站</a>查看版本对应的情况。</p>
<p>拿我自己举例，服务器下安装的<code>CUDA</code>的版本是<code>12.1</code>，但是<code>PyTorch</code>的<a href="https://pytorch.org/get-started/locally/">官网</a>上显示目前支持的<code>CUDA</code>版本为<code>11.7</code>和<code>11.8</code>，秉持着用新不用旧的原则，就运行了官网提供的<code>CUDA 11.8</code>的<code>Command</code>，但是没有安装成功，然后找了半天发现自己的<code>python</code>版本是<code>3.7</code>，在上面<code>wheel</code>网站里发现<code>3.7</code>版本的<code>python</code>最高支持的<code>CUDA</code>版本为<code>11.7</code>，于是在官网中的<code>Compute Platform</code>这一项选择了<code>CUDA 11.7</code>，然后在运行官网提供的新<code>Command</code>，待安装完成之后执行<code>torch.cuda.is_available()</code>，返回<code>True</code>。</p>
<h1 id="多个项目使用同一个数据集"><a href="#多个项目使用同一个数据集" class="headerlink" title="多个项目使用同一个数据集"></a>多个项目使用同一个数据集</h1><p>在训练深度学习模型时，很多模型需要用到同一个数据集，而很多模型都要求在当前算法文件夹中存放数据集，为了减少内存浪费，可以在当前文件夹下使用软连接来连接到数据集源文件，就可以不需要复制多个数据集了。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ln -s source_file link_file</span><br></pre></td></tr></table></figure>
<h1 id="连接中断的恢复"><a href="#连接中断的恢复" class="headerlink" title="连接中断的恢复"></a>连接中断的恢复</h1><ol>
<li><p>第一次连接的时候使用<code>screen -S</code>命令对<code>session</code>进行记录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -S test</span><br></pre></td></tr></table></figure></li>
<li><p>在要执行的命令后加<code>&amp;</code>，让命令放到服务器端后台运行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python main.py &amp;</span><br></pre></td></tr></table></figure></li>
<li><p>如果连接中断，则使用<code>screen</code>命令恢复上次的会话，继续监控命令执行的情况：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -r test</span><br></pre></td></tr></table></figure></li>
<li><p>查看所有<code>session</code>的<code>id</code>，名称以及状态：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -ls</span><br></pre></td></tr></table></figure></li>
<li><p>删除名称为<code>test</code>的<code>session</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -S test -X quit</span><br></pre></td></tr></table></figure></li>
<li><p>进入名称<code>jeeby</code>的<code>session</code>，若<code>session</code>不存在则新建：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -R jeeby</span><br></pre></td></tr></table></figure>
<h1 id="PyCharm远程连接服务器"><a href="#PyCharm远程连接服务器" class="headerlink" title="PyCharm远程连接服务器"></a><code>PyCharm</code>远程连接服务器</h1></li>
</ol>
<ul>
<li>确保自己的<code>PyCharm</code>版本为<code>professional</code>版本</li>
<li>创建远程连接：<code>Tools</code>—&gt;<code>Deployment</code>—&gt;<code>Configuration</code>—&gt;<code>SFTP</code>协议—&gt;配置服务器的<code>IP</code>、端口、用户名、密码等相关信息</li>
<li>进行本地项目与远程项目之间的文件夹路径映射：在刚才的<code>SFTP</code>协议中选择<code>Mappings</code>添加映射，例如我们将本地的<code>D:\workspace\PyCharmProjects\Code</code>路径映射到远端的<code>/home/jeeby/Code</code>路径</li>
<li>设置文件自动上传（可选）：<code>Tools</code>—&gt;<code>Deployment</code>—&gt;<code>Automatic Upload</code>，默认是有修改就自动上传，可以在<code>Tools</code>—&gt;<code>Deployment</code>—&gt;<code>Options</code>中设置按了<code>ctrl+s</code>上传</li>
<li>验证是否连接成功：<code>Tools</code>—&gt;<code>Deployment</code>—&gt;<code>Browse Remote Host</code>，如果能打开服务器文件目录说明连接成功</li>
<li>配置<code>Python</code>解释器<ul>
<li>查询服务器中所使用的<code>Python</code>解释器路径：<code>which python</code>命令，注意虚拟环境的话需要先进入虚拟环境再使用前述命令</li>
<li>本地<code>PyCharm</code>中配置<code>Python</code>解释器：<code>File</code>—&gt;<code>Settings</code>—&gt;<code>Project</code>—&gt;<code>Project Interpreter</code>—&gt;右上角设置图标<code>Add</code>—&gt;<code>SSH Interpreter</code>—&gt;<code>Existing server configuration</code>—&gt;<code>Move</code>—&gt;配置<code>Interpreter</code>和<code>Sync folders</code>（和前面配置的文件夹路径映射一致即可）</li>
</ul>
</li>
<li>本地启动服务器终端：<code>Tools</code>—&gt;<code>Start SSH session</code></li>
</ul>
<h1 id="VIM编辑器使用"><a href="#VIM编辑器使用" class="headerlink" title="VIM编辑器使用"></a><code>VIM</code>编辑器使用</h1><ul>
<li>使用<code>vim</code>命令进入编辑器，例如编辑<code>vim main.py</code>来编辑<code>main.py</code>文件</li>
<li>进入编辑器之后按<code>i</code>切换到插入状态</li>
<li>退出编辑器<ul>
<li>首先按<code>Esc</code>退出插入状态</li>
<li>输入<code>:</code>，系统会等待输入命令</li>
<li>输入相应的命令：<code>wq</code>（保存退出，可以直接用<code>x</code>代替）；<code>q</code>（直接退出）；<code>!q</code>（不保存退出）；<code>!</code>（强制退出）</li>
</ul>
</li>
</ul>
<p><code>Tips</code>：可以在按了<code>Esc</code>键之后，按<code>shift+zz</code>直接退出，这是最便捷的方式</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S使用总结</title>
    <url>/2024/10/31/K8S%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><code>Kubernetes</code>（通常称为<code>K8S</code>）是来自<code>Google</code>云平台的开源容器集群管理系统，用于自动部署、扩展和管理容器化应用程序。该系统基于<code>Docker</code>构建一个容器的调度服务。</p>
<a id="more"></a>
<h1 id="具体用法"><a href="#具体用法" class="headerlink" title="具体用法"></a>具体用法</h1><h2 id="查看命令"><a href="#查看命令" class="headerlink" title="查看命令"></a>查看命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看当前命名空间下的pod</span></span><br><span class="line">kubectl get pods</span><br><span class="line">kubectl get pod</span><br><span class="line">kubectl get po</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看所有命名空间的pod</span></span><br><span class="line">kubectl get pod -A</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看指定命名空间下的pod</span></span><br><span class="line">kubectl get pod -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看某个指定pod的信息</span></span><br><span class="line">kubectl get pod &lt;pod-name&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看某个指定命名空间下的指定pod</span></span><br><span class="line">kubectl get pod &lt;pod-name&gt; -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 以指定输出格式查看pod的结果</span></span><br><span class="line">kubectl get pod &lt;pod-name&gt; -n &lt;namespace&gt; -o yaml</span><br><span class="line">kubectl get pod &lt;pod-name&gt; -n &lt;namespace&gt; -o json</span><br><span class="line">kubectl get pod &lt;pod-name&gt; -n &lt;namespace&gt; -o wide</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看所有的命名空间</span></span><br><span class="line">kubectl get namespaces</span><br><span class="line">kubectl get namespace</span><br><span class="line">kubectl get ns</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看资源版本标签</span></span><br><span class="line">kubectl api-versions</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看集群状态</span></span><br><span class="line">kubectl get componentstatuses</span><br><span class="line">kubectl get componentstatus</span><br><span class="line">kubectl get cs</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看集群节点信息</span></span><br><span class="line">kubectl get nodes</span><br><span class="line">kubectl get node</span><br><span class="line">kubectl get no</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看部署</span></span><br><span class="line">kubectl get deployments</span><br><span class="line">kubectl get deployment</span><br><span class="line">kubectl get deploy</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看端口映射</span></span><br><span class="line">kubectl get services</span><br><span class="line">kubectl get service</span><br><span class="line">kubectl get svc</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看指定命名空间的服务</span></span><br><span class="line">kubectl get svc -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure>
<h2 id="删除命令"><a href="#删除命令" class="headerlink" title="删除命令"></a>删除命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 基于pod.yaml定义的名称删除pod</span></span><br><span class="line">kubectl delete -f pod.yaml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除所有pod</span></span><br><span class="line">kubectl delete pods --all</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除指定名称的pod</span></span><br><span class="line">kubectl delete pod my_pod</span><br></pre></td></tr></table></figure>
<h2 id="执行命令"><a href="#执行命令" class="headerlink" title="执行命令"></a>执行命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 执行pod的date命令</span></span><br><span class="line">kubectl exec &lt;pod-name&gt; date</span><br><span class="line">kubectl exec &lt;pod-name&gt; -- date</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定pod中某个容器执行date命令</span></span><br><span class="line">kubectl exec &lt;pod-name&gt; -c &lt;container-name&gt; date</span><br><span class="line">kubectl exec &lt;pod-name&gt; -c &lt;container-name&gt; -- date</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过bash进入容器</span></span><br><span class="line">kubectl exec -it &lt;pod-name&gt; -c &lt;container-name&gt; /bin/bash</span><br><span class="line">kubectl exec -it &lt;pod-name&gt; -c &lt;container-name&gt; -- /bin/bash</span><br></pre></td></tr></table></figure>
<h2 id="描述命令"><a href="#描述命令" class="headerlink" title="描述命令"></a>描述命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 显示node的详细信息</span></span><br><span class="line">kubectl describe nodes &lt;node-name&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 显示pod的详细信息</span></span><br><span class="line">kubectl describe pods &lt;pod-name&gt;</span><br></pre></td></tr></table></figure>
<h2 id="应用命令"><a href="#应用命令" class="headerlink" title="应用命令"></a>应用命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 应用配置文件</span></span><br><span class="line">kubectl apply -f pod.yaml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 应用目录</span></span><br><span class="line">kubectl apply -f ./configurations/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 应用更新</span></span><br><span class="line">kubectl apply -f pod-v2.yaml</span><br></pre></td></tr></table></figure>
<h2 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h2><p>要将本地文件夹传输到<code>K8S</code>中某个命名空间下的<code>PVC</code>，通常按照以下步骤进行：</p>
<ol>
<li><p>创建<code>pod.yaml</code>文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">temp-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">xxx</span>  <span class="comment"># 指定命名空间</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">temp-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">docker.m.daocloud.io/busybox</span></span><br><span class="line">      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;sleep 3600&#x27;</span>]  <span class="comment"># 让pod运行一段时间</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/mnt/data</span>  <span class="comment"># 挂载路径</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">my-pvc-volume</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-pvc-volume</span></span><br><span class="line">      <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">        <span class="attr">claimName:</span> <span class="string">xxx</span>  <span class="comment"># pvc的名称</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure></li>
<li><p>应用<code>pod.yaml</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f pod.yaml</span><br></pre></td></tr></table></figure></li>
<li><p>使用<code>kubectl cp</code>复制文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl cp &lt;source-path&gt; &lt;target-path&gt; -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>删除临时<code>pod</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl delete pod &lt;pod-name&gt; -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure>
<h2 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h2></li>
</ol>
<p>假设要在<code>K8S</code>中以<code>host</code>模式启动容器，并将<code>pod</code>挂载到指定<code>node</code>节点并挂载文件，同时运行在特定的命名空间下，可以使用<code>nodeSelector</code>来指定节点，以及使用<code>volume</code>和<code>volumeMounts</code>来挂载文件。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">&lt;pod-name&gt;</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">&lt;namespace&gt;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">kubernetes.io/hostname:</span> <span class="string">&lt;node-name&gt;</span>  <span class="comment"># 指定节点名称</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&lt;container-name&gt;</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&lt;image-name&gt;</span></span><br><span class="line">    <span class="attr">securityContext:</span></span><br><span class="line">      <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&lt;volume-name&gt;</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&lt;mount-path1&gt;</span></span><br><span class="line">      <span class="attr">subPath:</span> <span class="string">&lt;sub-path1&gt;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&lt;volume-name&gt;</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&lt;mount-path2&gt;</span></span><br><span class="line">      <span class="attr">subPath:</span> <span class="string">&lt;sub-path2&gt;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&lt;volume-name&gt;</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&lt;mount-path3&gt;</span></span><br><span class="line">      <span class="attr">subPath:</span> <span class="string">&lt;sub-path3&gt;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&lt;volume-name&gt;</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&lt;mount-path4&gt;</span></span><br><span class="line">      <span class="attr">subPath:</span> <span class="string">&lt;sub-path4&gt;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&lt;volume-name&gt;</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&lt;mount-path5&gt;</span></span><br><span class="line">      <span class="attr">subPath:</span> <span class="string">&lt;sub-path5&gt;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&lt;volume-name&gt;</span></span><br><span class="line">    <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">      <span class="attr">claimName:</span> <span class="string">&lt;pvc-name&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>K8S</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>Git使用总结</title>
    <url>/2022/02/25/Git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下使用<code>Git</code>过程中遇到的问题</p>
<a id="more"></a>
<p>大体框架如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305141244969.png" alt=""></p>
<h1 id="提交项目至GitHub仓库"><a href="#提交项目至GitHub仓库" class="headerlink" title="提交项目至GitHub仓库"></a>提交项目至<code>GitHub</code>仓库</h1><ol>
<li><p>新建仓库，会出现仓库地址，例如：<a href="https://github.com/TankManBeta/xxx.git">https://github.com/TankManBeta/xxx.git</a></p>
</li>
<li><p>本地项目文件夹，打开根目录命令行窗口，输入以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建说明文档</span></span><br><span class="line">git touch README.md</span><br><span class="line"><span class="meta">#</span><span class="bash"> 初始化本地仓库</span></span><br><span class="line">git init</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加全部已修改的文件，效果等同于git add -A</span></span><br><span class="line">git add .</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改后为文件提交到本地仓库</span></span><br><span class="line">git commit -m &quot;first commit&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 强制修改分支名</span></span><br><span class="line">git branch -M main</span><br><span class="line"><span class="meta">#</span><span class="bash"> 连接到远程仓库并为该仓库创建别名，别名为origin；远程仓库地址就是新建的仓库的地址</span></span><br><span class="line">git remote add origin https://github.com/TankManBeta/xxx.git</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建一个upSrtream，并将本地代码通过这个upStream推送到别名为origin的仓库中的main分支上</span></span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure></li>
<li>本地项目上传至<code>GitHub</code>仓库成功</li>
</ol>
<h1 id="克隆项目"><a href="#克隆项目" class="headerlink" title="克隆项目"></a>克隆项目</h1><ol>
<li>新建一个文件夹</li>
<li>打开<code>CMD</code>或者右键<code>Git Bash Here</code></li>
<li>命令行中输入<code>git init</code>，此时刚创建的文件夹中出现一个<code>.git</code>文件夹</li>
<li>先在<code>GitHub</code>中复制<code>URL</code>，然后命令行窗口中输入<code>git clone [URL] [需要新建的文件夹名]</code>，回车，等待下载完成即可</li>
</ol>
<h1 id="Fork项目"><a href="#Fork项目" class="headerlink" title="Fork项目"></a>Fork项目</h1><ol>
<li>点击想要<code>fork</code>的<strong>原仓库的</strong><code>fork</code>按钮，执行完这个操作后会将原仓库的文件、提交历史、<code>issues</code>和其余内容复制到自己的<code>github</code>仓库中；</li>
<li>采用<code>git clone</code>命令在本地工作区克隆<strong>原仓库的</strong>代码；</li>
<li>采用<code>git remote add &lt;remote_name&gt; &lt;remote_url&gt;</code>向当前仓库中添加<strong>自己的</strong>远程仓库；</li>
<li>后续更改任何东西都可以在本地完成，如<code>add</code>、<code>commit</code>一系列的操作，然后通过<code>push</code>命令推到<strong>自己的</strong>远程仓库；</li>
<li>如果希望对方接受你的修改，可以通过发送<code>pull requests</code>给对方。如果对方接受，则会将你的修改内容更新到仓库中。</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306271006689.jpg" alt=""></p>
<h1 id="每次上传需要登陆"><a href="#每次上传需要登陆" class="headerlink" title="每次上传需要登陆"></a>每次上传需要登陆</h1><p><code>git</code>使用<code>https</code>协议，每次<code>pull</code>, <code>push</code>都要输入密码。使用<code>git</code>协议，然后使用<code>SSH</code>密钥，可以不用每次都输密码。</p>
<ol>
<li><p>生成<code>SSH</code></p>
<ol>
<li><p>打开<code>Git</code>，输入：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen</span><br></pre></td></tr></table></figure></li>
<li><p>设定保存<code>key</code>的文件名</p>
</li>
<li><p>设定密码</p>
</li>
</ol>
</li>
<li><p><code>GitHub</code>主页添加<code>SSH</code>： <code>Settings</code> —&gt; <code>SSH and GPG keys</code> —&gt; <code>New SSH key</code> —&gt; 输入自定义标题和刚刚生成的<code>pub</code>文件 —&gt; <code>Add SSH key</code></p>
</li>
<li><p>本地登陆<code>SSH</code></p>
<ol>
<li><p>添加<code>Key</code>到<code>ssh</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-add  ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-add  ~/.ssh/你的私钥名</span><br></pre></td></tr></table></figure></li>
<li><p><code>Git</code>输入命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -T -i 你的私钥名 git@github.com</span><br></pre></td></tr></table></figure>
<p><strong>注：设置了自定义名字的<code>SSH</code>密钥后，还需要再设置一下<code>SSH</code>的配置文件，否则会导致拒绝连接。</strong></p>
</li>
</ol>
</li>
<li><p>移除旧的提交方式：</p>
<ol>
<li><p>查看项目采用的提交方式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure></li>
<li><p>删除旧的提交方式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote rm origin</span><br></pre></td></tr></table></figure></li>
<li><p>修改提交方式</p>
<ol>
<li><p><code>GitHub</code>仓库 —&gt; <code>Clone or download</code> —&gt; <code>User SSH</code>，获取<code>SSH</code>链接</p>
</li>
<li><p>添加新的<code>SSH</code>提交方式</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote add origin git@github.com:TankManBeta/xxx.git</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li>提交新代码，不再需要输入账号密码</li>
</ol>
<h1 id="多人协作开发"><a href="#多人协作开发" class="headerlink" title="多人协作开发"></a>多人协作开发</h1><p>如果是多人协作开发的话，一定要先<code>pull</code>，将最新版本的代码拉取到本地</p>
<h1 id="多个远程仓库或多个分支"><a href="#多个远程仓库或多个分支" class="headerlink" title="多个远程仓库或多个分支"></a>多个远程仓库或多个分支</h1><p>如果有多个远程仓库或者多个分支，并且需要将当前分支代码推送到指定仓库的指定分支上，那么在<code>pull</code>或<code>push</code>的时候，就需要按照下面的格式书写：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git pull 仓库别名 仓库分支名</span><br><span class="line">git push 仓库别名 仓库分支名</span><br></pre></td></tr></table></figure>
<h1 id="关于-idea文件夹"><a href="#关于-idea文件夹" class="headerlink" title="关于.idea文件夹"></a>关于.idea文件夹</h1><p><code>.idea</code>文件夹是<code>Pycharm</code>等<code>IDE</code>生成的项目配置文件。</p>
<ol>
<li><p>如果<code>.idea</code>文件夹为提交至仓库，则在项目中添加<code>.gitignore</code>文件，在其中设置需要忽略的文件或文件夹，然后再<code>push</code>即可</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">.idea/</span><br></pre></td></tr></table></figure></li>
<li><p>如果已经把<code>.idea</code>已经提交了，则需要先将远端的文件给删掉，然后再同第一步进行相同的设置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git rm -r --cached .idea</span><br></pre></td></tr></table></figure>
<h1 id="修改Github仓库名后的操作"><a href="#修改Github仓库名后的操作" class="headerlink" title="修改Github仓库名后的操作"></a>修改<code>Github</code>仓库名后的操作</h1></li>
</ol>
<p>在<code>Github</code>上修改完仓库名之后，再<code>push</code>会报错，需要采取如下措施</p>
<ul>
<li><p>首先查看本地仓库对应的远程仓库名</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure></li>
<li><p>修改链接</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote set-url origin xxx.git</span><br></pre></td></tr></table></figure></li>
<li>再次<code>push</code>也可能报错，需要输入用户名密码（由于我配置过<code>ssh</code>私钥，所以未出现这种情况）</li>
</ul>
<h1 id="配置用户名和邮箱"><a href="#配置用户名和邮箱" class="headerlink" title="配置用户名和邮箱"></a>配置用户名和邮箱</h1><p>修改全局配置：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --global user.email &quot;邮箱&quot;</span><br><span class="line">git config --global user.name &quot;名称&quot;</span><br></pre></td></tr></table></figure>
<p>修改某个仓库的配置：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config user.name xxx</span><br><span class="line">git config user.email xxx@xxxx.com</span><br></pre></td></tr></table></figure>
<h1 id="修改远程源"><a href="#修改远程源" class="headerlink" title="修改远程源"></a>修改远程源</h1><p>首先查看远程信息：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure>
<p>删除关联的<code>origin</code>的远程仓库：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote remove origin</span><br></pre></td></tr></table></figure>
<p>添加远程仓库：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote add origin git@github.com:xxx/xxx.git</span><br></pre></td></tr></table></figure>
<h1 id="自己的仓库中包含其他仓库的提交方式"><a href="#自己的仓库中包含其他仓库的提交方式" class="headerlink" title="自己的仓库中包含其他仓库的提交方式"></a>自己的仓库中包含其他仓库的提交方式</h1><p>一个仓库有时候会需要引用另一个仓库，来确保能跟踪到仓库的更新。此时提交代码会报错<code>warning: adding embedded git repository: research-contributions</code>，大概就是说仓库会有嵌套，具体解决方案是采用<code>submodule</code>：</p>
<p>首先删除仓库索引，如果执行之后出现<code>error: the following file has staged content different from both the file and the HEAD:</code>报错，则需要加上<code>-f</code>命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 如果是文件</span></span><br><span class="line">git rm --cached research-contributions</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果是文件夹</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> git rm -r --cached research-contributions</span></span><br><span class="line">git rm -r -f --cached research-contributions</span><br></pre></td></tr></table></figure>
<p>接着添加仓库索引：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git submodule add &lt;url&gt; project</span><br><span class="line"><span class="meta">#</span><span class="bash"> example(https)</span></span><br><span class="line">git submodule add https://github.com/Project-MONAI/research-contributions.git research-contributions</span><br><span class="line"><span class="meta">#</span><span class="bash"> example(ssh)</span></span><br><span class="line">git submodule add git@github.com:Project-MONAI/research-contributions.git research-contributions</span><br></pre></td></tr></table></figure>
<h1 id="子模块详解"><a href="#子模块详解" class="headerlink" title="子模块详解"></a>子模块详解</h1><p><code>git submodule</code>命令用于管理包含其他<code>Git</code>仓库的项目。<code>git submodule</code>命令对于大型项目或需要将外部库集成到项目中的情况非常有用。 通过使用子模块，你可以将外部库作为你的项目的一部分来管理，而不必将其直接合并到主仓库中。</p>
<p>初始化子模块，<code>git submodule init</code>命令会初始化配置文件中的所有子模块。它会根据<code>.gitmodules</code>文件中的信息设置子模块的<code>URL</code>和路径，但不会下载子模块的内容。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git submodule init</span><br></pre></td></tr></table></figure>
<p><code>git submodule update</code>命令会从子模块的远程仓库中拉取子模块的内容，并将其更新到<code>.gitmodules</code>文件中指定的提交。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git submodule update</span><br></pre></td></tr></table></figure>
<p><code>git submodule add &lt;repo-url&gt; [&lt;path&gt;]</code>命令会将指定的<code>Git</code>仓库作为子模块添加到当前仓库中。<code>&lt;repo-url&gt;</code> 是子模块的仓库地址，<code>&lt;path&gt;</code> 是子模块在主仓库中的路径（可选，如果不指定，默认使用子模块仓库的名称作为路径）。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git submodule add https://github.com/example/libfoo.git libfoo</span><br></pre></td></tr></table></figure>
<p><code>git submodule deinit &lt;path&gt;</code>命令将子模块从<code>.git/config</code>文件中移除，并删除子模块目录中的文件。<code>git rm &lt;path&gt;</code>命令将子模块的引用从主仓库中删除，并提交更改。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git submodule deinit libfoo</span><br><span class="line">git rm libfoo</span><br><span class="line">rm -rf .git/modules/libfoo</span><br></pre></td></tr></table></figure>
<p><code>git submodule</code>命令列出当前仓库中的所有子模块，以及它们的提交哈希和路径。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git submodule</span><br></pre></td></tr></table></figure>
<p><code>git submodule update --recursive --remote</code>命令更新所有子模块。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git submodule update --recursive --remote</span><br></pre></td></tr></table></figure>
<p><code>git submodule status</code>命令显示子模块的当前状态，包括当前的提交哈希和路径，是否有未提交的更改。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git submodule status</span><br></pre></td></tr></table></figure>
<h1 id="查看日志信息"><a href="#查看日志信息" class="headerlink" title="查看日志信息"></a>查看日志信息</h1><p><code>git log</code>用于查询版本的历史，会列出所有历史记录，最近的排在最上方，显示提交对象的哈希值，作者、提交日期和提交说明：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git log</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305141215648.png" alt=""></p>
<h1 id="查看commit的操作"><a href="#查看commit的操作" class="headerlink" title="查看commit的操作"></a>查看<code>commit</code>的操作</h1><p>采用<code>git show</code>查看某次提交具体做了哪些操作：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git show 2f6431b1886845d8754fdb1a78dc65a0412cd03c</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305141234277.png" alt=""></p>
<h1 id="查看状态"><a href="#查看状态" class="headerlink" title="查看状态"></a>查看状态</h1><p><code>git status</code>是一个用于查看<code>Git</code>仓库当前状态的命令，可以查看在你上次提交之后是否有对文件进行再次修改。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305141236671.png" alt=""></p>
<h1 id="回滚提交"><a href="#回滚提交" class="headerlink" title="回滚提交"></a>回滚提交</h1><p><code>git reset</code>命令用于回退版本，可以指定退回某一次提交的版本。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git reset 2f6431b1886845d8754fdb1a78dc65a0412cd03c</span><br></pre></td></tr></table></figure>
<h1 id="检出文件"><a href="#检出文件" class="headerlink" title="检出文件"></a>检出文件</h1><p><code>git checkout</code>可以将工作区指定文件恢复到最近一次提交时的状态，丢弃所有未提交的更改，这对于撤销不需要的更改非常有用：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout -- &lt;file&gt;</span><br></pre></td></tr></table></figure>
<p><strong>注：<code>git checkout -- &lt;file&gt;</code>指令应该是从先从缓存区中拉取版本还原，如果没有再到版本库中拉取还原。</strong></p>
<h1 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h1><p>查看所有分支：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 只显示本地分支</span></span><br><span class="line">git branch</span><br><span class="line"><span class="meta">#</span><span class="bash"> 显示本地和远端分支</span></span><br><span class="line">git branch -a</span><br></pre></td></tr></table></figure>
<p>创建本地分支：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch dev</span><br><span class="line">git checkout dev</span><br><span class="line"><span class="meta">#</span><span class="bash"> 上面两个命令合并操作</span></span><br><span class="line">git checkout -b dev</span><br></pre></td></tr></table></figure>
<p>关联远端分支：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1. 本地、远程都没有分支</span><br><span class="line">git branch -a</span><br><span class="line">git checkout -b v1.0.0</span><br><span class="line">git push --set-upstream origin v1.0.0</span><br><span class="line">git branch -a</span><br><span class="line">git branch -vv</span><br><span class="line"></span><br><span class="line">2. 本地有分支，远程没有分支</span><br><span class="line">git branch -a</span><br><span class="line">git push --set-upstream origin v1.0.0</span><br><span class="line">git branch -a</span><br><span class="line">git branch -vv</span><br><span class="line"></span><br><span class="line">3. 本地没有分支，远程已存在分支</span><br><span class="line">git branch -a</span><br><span class="line">git pull</span><br><span class="line">git checkout -b v1.0.1 origin/v1.0.1</span><br><span class="line">git branch -a</span><br><span class="line">git branch -vv</span><br><span class="line"></span><br><span class="line">4. 本地有分支，远程有分支，但还未关联，需要进行关联</span><br><span class="line">git branch --set-upstream-to=origin/master</span><br></pre></td></tr></table></figure>
<p>合并不同的分支，合并出现冲突时，可以使用<code>IDE</code>解决冲突更为方便：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git pull</span><br><span class="line">git merge dev</span><br><span class="line">git push</span><br></pre></td></tr></table></figure>
<p>删除本地分支：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch -d dev</span><br></pre></td></tr></table></figure>
<p>强制删除未合并的分支：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch -D &lt;branch_name&gt;</span><br></pre></td></tr></table></figure>
<p>删除远程分支：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git push origin --delete &lt;branch_name&gt;</span><br></pre></td></tr></table></figure>
<h1 id="忽略已上传的文件"><a href="#忽略已上传的文件" class="headerlink" title="忽略已上传的文件"></a>忽略已上传的文件</h1><ol>
<li>在<code>.gitignore</code>中添加这次需要忽略的文件/文件夹；</li>
<li>清除缓存，具体命令为<code>git rm -r --cached .</code>；</li>
<li>提交代码到暂存区，具体命令为<code>git add .</code>；</li>
<li>提交到本地仓库，具体命令为<code>git commit -m &quot;xxxx&quot;</code>；</li>
<li>推送到远程仓库，具体命令为<code>git push origin main</code>。</li>
</ol>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper Ideas</title>
    <url>/2021/11/02/Paper-Ideas/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下读过论文的idea</p>
<a id="more"></a>
<h1 id="Physics-Coupled-Spatio-Temporal-Active-Learning-for-Dynamical-Systems"><a href="#Physics-Coupled-Spatio-Temporal-Active-Learning-for-Dynamical-Systems" class="headerlink" title="Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems"></a>Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems</h1><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104195000.png" alt="framework"></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104195040.png" alt="FN-PN"></p>
<ul>
<li>初始化<ul>
<li>选定 $n$ 个点 $\longrightarrow$ $\Omega^{n}_{temp}$</li>
<li>创建训练数据 $\longrightarrow$ $D_{temp}$ （选定 $n$ 个点都取 $T_{\omega}$ 时长的数据）</li>
</ul>
</li>
<li>训练<ul>
<li>learn $\lambda$ $\longleftarrow$ 最小化 $E_{q}$ ，偏微分方程</li>
<li>train ST-PCNN $\longleftarrow$ $\lambda$</li>
<li>predict $[\hat{s}]$ $\longleftarrow$ at all locations</li>
<li>$\Omega_{Kriging}^{n}$ $\longleftarrow$ $n$ 个：largest estimate error</li>
<li>$D_{Kriging}$ $\longleftarrow$ 上一步新选出的 $n$ 个，选取 $T_{\omega}$ 时长数据</li>
<li>更新 $D$</li>
</ul>
</li>
</ul>
<h1 id="ACTIVE-LEARNING-OF-DEEP-SURROGATES-FOR-PDES"><a href="#ACTIVE-LEARNING-OF-DEEP-SURROGATES-FOR-PDES" class="headerlink" title="ACTIVE LEARNING OF DEEP SURROGATES FOR PDES"></a>ACTIVE LEARNING OF DEEP SURROGATES FOR PDES</h1><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211104203300.png" alt="model"></p>
<p>algorithm: reduce number of training points(selected based on error measure)</p>
<p>AL: adding the most uncertain points</p>
<ul>
<li><p>Initialize:</p>
<p>random choose $n_{init}$ train 50 epochs $\longrightarrow$ $\widetilde{t^{0}}(p)$</p>
</li>
<li><p>Do T times:</p>
<ul>
<li>evaluate $\widetilde{t^{i}}(p)$ at $M×K$ points</li>
<li>choose $K$ points(largest $\sigma_{*}^{2}$ )</li>
<li>put the $K$ points into training set</li>
</ul>
</li>
</ul>
<h1 id="Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows"><a href="#Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows" class="headerlink" title="Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"></a>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</h1><p>Application：language $\longrightarrow$ vision</p>
<p>Challenges:</p>
<ul>
<li>scale（视觉实体的区别尺度区别很大，例如车辆和人）</li>
<li>high resolution of pixels(计算复杂度： $n^{2}$ )</li>
</ul>
<p>Advantages：</p>
<ul>
<li>通过限制在局部窗口内使用自注意力，带来了更高的效率</li>
<li>通过移动，使得相邻两个窗口之间有了交互，上下层之间也有了跨窗口连接，从而变相达到了一种全局建模的效果</li>
<li>层级式的结构不仅非常灵活地去建模各个尺度的信息并且计算复杂度随着图像大小线性增长</li>
</ul>
<p>Key point:</p>
<ul>
<li>小批量开始 $\longrightarrow$ 逐渐合并邻居</li>
<li>如何实现线性复杂度：在无重叠窗口计算自注意力<ul>
<li>standard transformer architecture: global self-attention $\longrightarrow$ quadratic complexity</li>
<li>Swin Transformer: local self-attention $\longrightarrow$ linear complexity</li>
</ul>
</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>CNNs在计算机视觉中发挥了重要作用；在NLP领域，Transformer已经成为了主流模型，得益于注意力机制的使用，Transformer对长期依赖建模非常有效。</p>
<ul>
<li>为了解决多尺度问题，Swin-Transformer采用了层级式的结构，从小patch开始逐渐合并邻居patch。</li>
<li>为了实现线性计算复杂度，Swin-Transformer在不重叠的局部窗口计算自注意力。</li>
<li>移动窗口，新窗口中的注意力计算跨越先前窗口的边界，提供它们之间的连接。</li>
</ul>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><ul>
<li><p>Overall Framework：具体地，我们一开始的patch大小为 $4 \times 4$ ，原始的图像大小为 $224 \times 224$ ，窗口大小为 $7 \times 7$ ，这里的窗口大小指的是patch的数目，也就是说我们可以得到 $\frac{224}{4} \times \frac{224}{4} = 56 \times 56$ 个patch，又因为一个窗口的大小为 $7 \times 7$ ，因此我们的窗口数目为 $\frac{56}{7} \times \frac{56}{7} = 8 \times 8$ 个窗口。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/swin_1.png" alt=""></p>
</li>
<li><p>Two Successive Swin Transformer Blocks：这些block都是两个两个出现的，因为第二个block是在第一个block的基础之上做一个窗口的移动。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/swin_2.png" alt=""></p>
</li>
<li><p>Shifted window partitioning：SW-MSA紧接在W-MSA后面就是想让不同window之间也有信息传递。因此，最直接的想法就是将图片平移，但不是平移<code>window_size</code>，比如平移一半，再以跟之前相同的划分来切割，这样就会有上一轮本来不在同一个window里面的patch，现在出现在同一个window。但是，最简单的处理，比如像第一个图，会出现更多的window，有些window尺寸还不一样。一种修补方法是做padding补上一些块，但是会增大计算量。为此，这里采用cycling（rolling）的方法，即滚动，将图片向左、向上平移window一半的尺寸，比如window是7，这里就平移三个patch，左边的那些块移到右边，上边的那些块移到下边。然后采用mask的方式来计算每一块的自注意力。</p>
<ul>
<li><p>情况1，一左一右。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201617035.png" alt=""></p>
</li>
<li><p>情况2，一上一下。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201619762.png" alt=""></p>
</li>
<li><p>情况3，一个window内4个part。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201620069.png" alt=""></p>
</li>
</ul>
<p>首先将一个大特征图（图中为 $16 \times 16$ ）分为4个window，然后给每个区域打上编号。之后，对于每个window，就可以按之前的方式生成mask矩阵：1. 先展平；2. 如果x坐标，y坐标编号相同，那么就赋 $0$ （表示起作用的位置）；如果编号不同，就赋值$-100$，表示mask掉。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306201624545.png" alt=""></p>
</li>
</ul>
<h1 id="Adversarial-Sampling-for-Solving-Differential-Equations-with-Neural-Networks"><a href="#Adversarial-Sampling-for-Solving-Differential-Equations-with-Neural-Networks" class="headerlink" title="Adversarial Sampling for Solving Differential Equations with Neural Networks"></a>Adversarial Sampling for Solving Differential Equations with Neural Networks</h1><h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p>sample points adversarially to maximize the loss of the current solution estimate  </p>
<p>Advantages on using neural networks:</p>
<ul>
<li>instead of obtaining solution values at discretized points, we get a closed and differentiable solution function</li>
<li>it is more effective in solving high dimensional PDEs by faring better against the “curse of dimensionality” </li>
<li>numerical errors are not accumulated in each iteration</li>
<li>initial and boundary conditions are satisfied by construction</li>
</ul>
<p>Drawbacks  of using a predefined sampling scheme: agnostic to the equation being solved as well as our current estimate $\hat{y}$</p>
<h2 id="Key-Idea"><a href="#Key-Idea" class="headerlink" title="Key Idea"></a>Key Idea</h2><p>present a sampling scheme that is dependent on the current estimate $\hat{y}$, using a neural network to represent a variable sampling distribution.</p>
<p>In each iteration, the sampler is trained to <strong>produce points which maximize the loss of the solver (and a secondary loss). </strong></p>
<p>Thus, it competes with the solver whose weights are updated to minimize the loss at these very points.  </p>
<h2 id="Architecture-1"><a href="#Architecture-1" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/image-20211128164821263.png" alt=""></p>
<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>It is observed that if the sampler is purely optimized with the objective of maximizing $\hat{L}(\hat{y}; x)$(residual loss corresponding to the $DE$ at samples $x$), it tends to collapse all samples to one single point of high loss. </p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>Therefore, use <strong>an additional loss term $D_{k}$,</strong>Given points$\begin{Bmatrix}x_{1},x_{2},\dots,x_{n}\end{Bmatrix}$, we define $d_{k}(x_{i})$ to be the sum of distances of $x_{i}$ from its $k$ nearest neighbors.</p>
<h1 id="Machine-Learning-of-Linear-Differential-Equations-using-Gaussian-Processes"><a href="#Machine-Learning-of-Linear-Differential-Equations-using-Gaussian-Processes" class="headerlink" title="Machine Learning of Linear Differential Equations using Gaussian Processes"></a>Machine Learning of Linear Differential Equations using Gaussian Processes</h1><p>Gaussian process priors are modified according to the particular form of such operators and are employed to infer parameters of the linear equations from scarce and possibly noisy observations.  </p>
<p>optimal model parameters and hyper-parameters are all learned directly from the data by maximizing the joint marginal log-likelihood of the probabilistic model instead of being guessed or tuned manually by the user.  </p>
<h2 id="Priors"><a href="#Priors" class="headerlink" title="Priors"></a>Priors</h2><p>place the $GP$ prior on $u(x)$ instead of $f(x)$ </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/image-20211128222044474.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222142.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222208.png" alt=""></p>
<h2 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222342.png" alt=""></p>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>employing a $Quasi-Newton$ optimizer $L-BFGS$ to minimize the negative log marginal likelihood</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222510.png" alt=""></p>
<h2 id="Predictions"><a href="#Predictions" class="headerlink" title="Predictions"></a>Predictions</h2><p>one can predict the values $u(x)$ and $f(x)$ at a new test point $x$ by writing the posterior distributions</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20211128222753.png" alt=""></p>
<h1 id="Learning-Physics-Informed-Neural-Networks-without-Stacked-Back-propagation"><a href="#Learning-Physics-Informed-Neural-Networks-without-Stacked-Back-propagation" class="headerlink" title="Learning Physics-Informed Neural Networks without Stacked Back-propagation"></a>Learning Physics-Informed Neural Networks without Stacked Back-propagation</h1><h2 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h2><p>PINN training suffers from a significant scalability issue</p>
<h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ul>
<li>developing a novel approach to train the model without stacked back-propagation</li>
<li>parameterize the PDE solution $u(x; θ)$ as a Gaussian smoothed model, $u(x;\theta)=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}f(x+\delta,\theta)$, where $u$ transforms arbitrary base network $f$ by injecting Gaussian noise into input $x$. This transformation gives rise to a key property for $u$ where its derivatives to the input can be efficiently calculated <em>without back-propagation</em>.<ul>
<li>Such property is derived from the well-known Stein’s Identity that essentially tells that the derivatives of any Gaussian smoothed function $u$ can be reformulated as some expectation terms of the output of its base $f$, which can be estimated using Monte Carlo methods. </li>
</ul>
</li>
<li>given any PDE problem, we can replace the derivative terms in the PDE with Stein’s<br>derivative estimators.</li>
</ul>
<h2 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h2><ol>
<li>no longer need stacked back-propagation to compute the loss</li>
<li>parallelize the computation into distributed machines to further accelerate the training </li>
</ol>
<h2 id="Notice"><a href="#Notice" class="headerlink" title="Notice"></a>Notice</h2><p>for large $\sigma$, the induced Gaussian smoothed models may not be expressive enough to approximate functions (i.e., learn solutions) with a large Lipschitz constant. Therefore, using a small value of $\sigma$ is usually a better choice in practice. However, a small $\sigma$ will lead to high-variance Stein’s derivative estimation, which inevitably causes unstable training.  </p>
<h2 id="Two-Sources-of-Inefficiency-In-Computing-the-PINN-Loss"><a href="#Two-Sources-of-Inefficiency-In-Computing-the-PINN-Loss" class="headerlink" title="Two Sources of Inefficiency In Computing the PINN Loss"></a>Two Sources of Inefficiency In Computing the PINN Loss</h2><ol>
<li>different orders of derivatives can only be calculated sequentially  </li>
<li>the dimension-level inefficiency </li>
</ol>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="4-1-Back-propagation-free-Derivative-Estimators"><a href="#4-1-Back-propagation-free-Derivative-Estimators" class="headerlink" title="4.1 Back-propagation-free Derivative Estimators"></a>4.1 Back-propagation-free Derivative Estimators</h3><p>define $u(x)=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}f(x+\delta,\theta)$, then we have $\bigtriangledown_{x}u=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}[\frac{\delta}{\sigma^{2}}f(x+\delta)]$</p>
<h4 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_1.png" alt=""></p>
<p>From the above theorem, we can see that the first-order derivative rxu can be reformulated as an expectation term $E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}[\frac{\delta}{\sigma^{2}}f(x+\delta)]$, To calculate the value of the expectation, we can use Monte Carlo method to obtain an unbiased estimation from K.  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_2.png" alt=""></p>
<h3 id="4-2-Model-Capacity"><a href="#4-2-Model-Capacity" class="headerlink" title="4.2 Model Capacity"></a>4.2 Model Capacity</h3><p>For any measurable function $f : R^{d}\rightarrow R$, define $u(x)=E_{\delta\thicksim\mathcal{N}(0,\sigma^{2}\mathbf{I})}f(x+\delta,\theta)$, then<br>$u(x) $is $\frac{F}{\sigma}\sqrt{\frac{2}{\pi}}$-Lipschitz with respect to $l_{2}$-norm, where $F=sup_{x\in R^{d}}|f(x)|$.  </p>
<h4 id="Proof-1"><a href="#Proof-1" class="headerlink" title="Proof"></a>Proof</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_3.png" alt=""></p>
<h3 id="4-3-Variance-Reduced-Stein’s-Derivative-Estimators"><a href="#4-3-Variance-Reduced-Stein’s-Derivative-Estimators" class="headerlink" title="4.3 Variance-Reduced Stein’s Derivative Estimators"></a>4.3 Variance-Reduced Stein’s Derivative Estimators</h3><h4 id="The-control-variate-method"><a href="#The-control-variate-method" class="headerlink" title="The control variate method"></a>The control variate method</h4><p>One generic approach to reducing the variance of Monte Carlo estimates of integrals is to use an additive control variate, which is known as baseline.  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_4.png" alt=""></p>
<h4 id="Further-improvement-using-the-antithetic-variable-method"><a href="#Further-improvement-using-the-antithetic-variable-method" class="headerlink" title="Further improvement using the antithetic variable method"></a>Further improvement using the antithetic variable method</h4><p>The antithetic variable method is yet another powerful technique for variance reduction.  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220221_5.png" alt=""></p>
<h1 id="Neural-Galerkin-Scheme-with-Active-Learning-for-High-Dimensional-Evolution-Equations"><a href="#Neural-Galerkin-Scheme-with-Active-Learning-for-High-Dimensional-Evolution-Equations" class="headerlink" title="Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations"></a>Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><h3 id="problems"><a href="#problems" class="headerlink" title="problems"></a>problems</h3><ol>
<li>no data are available  </li>
<li>the principal aim is to gather insights from a known model  </li>
</ol>
<p>高维逼近问题需要一个完全不同的“离线”自适应概念来规避维数的诅咒。</p>
<h2 id="Introduction-2"><a href="#Introduction-2" class="headerlink" title="Introduction"></a>Introduction</h2><p>develop time-integrators for PDEs that use DNNs to represent the solution but update the parameters sequentially from one time slice to another rather than globally over the whole time-space domain.  </p>
<p>use the structural form of the PDEs, but no a priori data about their solution.</p>
<p>leverage adaptivity in both function approximation and data acquisition.   </p>
<h3 id="Main-contributions"><a href="#Main-contributions" class="headerlink" title="Main contributions"></a>Main contributions</h3><ol>
<li><p>derive a nonlinear evolution equation for the parameters. </p>
<p>This equation can then be integrated using standard solvers with different level of sophistication.   </p>
<p>the proposed approach takes larger time steps when possible and corrects to smaller time-step sizes if the dynamics of the solution require it.  </p>
</li>
<li><p>The evolution equations that we derive for the DNN parameters involve operators that require estimation via sampling in space.  propose a dynamical estimation of the loss.   </p>
</li>
<li><p>We illustrate the viability and usefulness of our approach on a series of test cases.  </p>
</li>
</ol>
<h3 id="Related-works"><a href="#Related-works" class="headerlink" title="Related works"></a>Related works</h3><ol>
<li>The need for adaptive data acquisition in the context of machine learning for problems<br>in science and engineering has been emphasized in previous works.</li>
<li>There also is a large body of work on numerically solving PDEs with DNN parametrization based on collocation over the spatio-temporal domain.   </li>
<li>There also is a range of surrogate-modeling methods based on nonlinear parametrizations.  </li>
</ol>
<h2 id="Neural-Galerkin-schemes"><a href="#Neural-Galerkin-schemes" class="headerlink" title="Neural Galerkin schemes"></a>Neural Galerkin schemes</h2><h3 id="Neural-Galerkin"><a href="#Neural-Galerkin" class="headerlink" title="Neural Galerkin"></a>Neural Galerkin</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309201020.png" alt=""></p>
<h4 id="Parametrizing-the-solution"><a href="#Parametrizing-the-solution" class="headerlink" title="Parametrizing the solution"></a>Parametrizing the solution</h4><p>use ansatz $u(t,x)=U(\theta(t),x)$ , It is important to emphasize that U may depend nonlinearly on $\theta (t)$ , which is in stark contrast to the majority of classical approximations in scientific computing that have a linear dependence on the parameter.</p>
<h4 id="Controlling-the-residual"><a href="#Controlling-the-residual" class="headerlink" title="Controlling the residual"></a>Controlling the residual</h4><p>Since we do not have access to the solution $u(t)$ , we will use the structure of the governing equation to control the approximation error. To this end, note that inserting the ansatz solution $U(\theta(t))$ in Eq. (1). assuming differentiability of $\theta(t)$ and using $\partial_{t}U(\theta(t))=\triangledown_{\theta}U(\theta)\cdot \dot{\theta}(t)$ , leads to the residual function r:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309201330.png" alt=""></p>
<p>we will opt for controlling the residual locally in time, which leads to an initial value problem that can be solved over arbitrary long times. Specifically, we will seek $\theta(t)$ such that for all $t &gt; 0$ it holds</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309202447.png" alt=""></p>
<p>where we define the objective function $J_{t}:\Theta \times \dot{\Theta} \rightarrow \mathbb{R}$</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309202721.png" alt=""></p>
<h4 id="Neural-Galerkin-equations"><a href="#Neural-Galerkin-equations" class="headerlink" title="Neural Galerkin equations"></a>Neural Galerkin equations</h4><p>Since $J_{t}(\theta(t); \eta)$ is quadratic in $\eta$ and positive semi-definite, its minimum is unique and its minimizers solve the Euler-Lagrange equation</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309204135.png" alt=""></p>
<p>Written explicitly, Eq. (6) is a system of ODEs for $\theta(t)$:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309204238.png" alt=""></p>
<p>where we defined</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220309210508.png" alt=""></p>
<p>in which $\bigotimes$ denotes the outer product.  The initial condition $\theta_{0}$ can be obtained via e.g. minimization of the least-squares loss between $u_{0}$ and $U(\theta_{0})$:  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310155509.png" alt=""></p>
<p>where ν is some user-prescribed measure with full support on $\mathcal{X}$ .  </p>
<h3 id="Estimating-M-theta-and-F-t-theta"><a href="#Estimating-M-theta-and-F-t-theta" class="headerlink" title="Estimating $M(\theta)$ and $F(t, \theta)$"></a>Estimating $M(\theta)$ and $F(t, \theta)$</h3><p>integrals in Eq. (8) do not admit a closed-form solution and so will need to be numerically estimated. In low dimensions,  we perform quadrature on a grid; in high dimensions, If $ν_{\theta}$<br>is a probability measure, we can consider using a vanilla Monte-Carlo estimator for each term,     </p>
<p>by drawing $n$ samples $\{x_{i}\}_{i=1}^{n}$ from $ν_{\theta}$ and replacing the expectations by empirical averages over these samples.  This estimator is efficient to approximate certain kernels uniformly over high-dimensional spaces, but not necessarily if the solution to the PDE develops spatially localized structures. Here are two options:</p>
<h4 id="Importance-sampling-with-a-fixed-measure"><a href="#Importance-sampling-with-a-fixed-measure" class="headerlink" title="Importance sampling with a fixed measure"></a>Importance sampling with a fixed measure</h4><p>importance sampling: <a href="https://zhuanlan.zhihu.com/p/41217212">重要性采样</a></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310165322.png" alt=""></p>
<h4 id="Direct-sampling-with-an-adaptive-measure"><a href="#Direct-sampling-with-an-adaptive-measure" class="headerlink" title="Direct sampling with an adaptive measure"></a>Direct sampling with an adaptive measure</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310170640.png" alt=""></p>
<h3 id="Discretization-in-time"><a href="#Discretization-in-time" class="headerlink" title="Discretization in time"></a>Discretization in time</h3><p>To update $\theta^{k}$, we can either use:  </p>
<h4 id="Explicit-integrators"><a href="#Explicit-integrators" class="headerlink" title="Explicit integrators"></a>Explicit integrators</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310171021.png" alt=""></p>
<h4 id="Implicit-integrators"><a href="#Implicit-integrators" class="headerlink" title="Implicit integrators"></a>Implicit integrators</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310171036.png" alt=""></p>
<h3 id="Neural-architectures"><a href="#Neural-architectures" class="headerlink" title="Neural architectures"></a>Neural architectures</h3><p>The first is a shallow (one-hidden-layer) network with m nodes given by</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180129.png" alt=""></p>
<p> The first is the Gaussian kernel, which we use when $\mathcal{X} = \mathbb{R}^{d}$</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180331.png" alt=""></p>
<p>the second is we use when $\mathcal{X} = L\mathbb{T}^{d}$ with L &gt; 0 and we need to enforce periodicity.</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310180732.png" alt=""></p>
<p>The other neural architecture that we use is a feedforward neural network with $l\in \mathbb{N}$ hidden layers and m nodes per layer:  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310182117.png" alt=""></p>
<p>$\varphi_{tanh}^{L}$ is the nonlinear unit</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220310182545.png" alt=""></p>
<h1 id="AUTOIP-A-UNITED-FRAMEWORK-TO-INTEGRATE-PHYSICS-INTO-GAUSSIAN-PROCESSES"><a href="#AUTOIP-A-UNITED-FRAMEWORK-TO-INTEGRATE-PHYSICS-INTO-GAUSSIAN-PROCESSES" class="headerlink" title="AUTOIP: A UNITED FRAMEWORK TO INTEGRATE PHYSICS INTO GAUSSIAN PROCESSES"></a>AUTOIP: A UNITED FRAMEWORK TO INTEGRATE PHYSICS INTO GAUSSIAN PROCESSES</h1><h2 id="Introduction-3"><a href="#Introduction-3" class="headerlink" title="Introduction"></a>Introduction</h2><p>To model a system, one usually writes down a set of partial differential equations (PDEs) and/or ordinary differential equations (ODEs) that characterize how the system runs according to physical laws.  Then, one identifies the boundary and/or initial conditions and solves the equations.</p>
<p>Machine learning and data science use a completely different paradigm. They estimate or reconstruct target functions from observed data rather than from solving the equations.</p>
<h3 id="Contribution-1"><a href="#Contribution-1" class="headerlink" title="Contribution"></a>Contribution</h3><p>consider incorporating physics knowledge into Gaussian processes (GPs). Not only flexible enough to learn various, complex functions from data, but also convenient to quantify the uncertainty due to their closed-form posterior distribution. </p>
<ol>
<li>联合采样目标函数在input的值，方程有关的微分的值，多元高斯分布在配点的潜在源. we couple the target function and its derivatives in a probabilistic framework, without the need for conducting differential operations on a nonlinear surrogate (like NNs).  </li>
<li>Next, we feed these samples to two likelihoods. One is to fit the training data. The other is a virtual Gaussian likelihood that encourages the conformity to the equation.</li>
<li>we use the whitening trick to parameterize the latent random variables with a standard Gaussian noise.       </li>
</ol>
<h2 id="Gaussian-Process-Regression"><a href="#Gaussian-Process-Regression" class="headerlink" title="Gaussian Process Regression"></a>Gaussian Process Regression</h2><p>Consider a training dataset $\mathcal{D}=(X,y)$, where $X = [x_{1},\dots,x_{N}]$, $y = [y_{1},\dots, y_{N}]$, each $x_{n}$ is an input, and $y_{n}$ is a noisy observation of $f(x_{n})$.  Then the function values at the training inputs, $f = [f(x_{1}),\dots,f(x_{N})]$, follow a multivariate Gaussian distribution, $p(f|X) = N(f|0,K)$ where each $[K]_{i,j} = κ(x_{i}, x_{j})$  </p>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>Specifically, we first construct a GP prior over $u$, $g$ and the equation-related derivatives, i.e., $\partial_{t}u$ and $\partial_{x}^{2}u$  , The covariance and cross-covariance among $u$ and its derivatives can be obtained outright from $κ_{u}$ via kernel differentiation   </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311161000.png" alt=""></p>
<p>Now, we can leverage the covariance functions in (4) and $k_{g}$ to construct a joint Gaussian prior over $f = [u; \hat{u}; \hat{u}_{t}; \hat{u}_{xx}; g]$ ,</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163413.png" alt=""></p>
<p>Given $f$ , we feed them to two data likelihoods. One is to fit the actual observations from a Gaussian noise model,  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163508.png" alt=""></p>
<p>The other is a virtual Gaussian likelihood that integrates the physics knowledge in the differential equation</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311163540.png" alt=""></p>
<h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><p> the virtual likelihood (7) couples the components of $f$ to reflect the equation. Hence, we develop a general variational inference algorithm to jointly estimate the posterior<br>of $f$ and kernel parameters, inverse noise variance $\beta$, $v$, etc. However, we found that a straightforward implementation to optimize the variational posterior $q(f)$ is often stuck at an inferior estimate.  </p>
<p>That is, we parameterize $f$ with a Gaussian noise,</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311164311.png" alt=""></p>
<p>where $\eta \thicksim N(0, I)$, and $A$ is the Cholesky decomposition of the covariance matrix $\Sigma$  i.e., $\Sigma = AA^{T}$ . Therefore, the joint probability of the model can be rewritten as</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311164651.png" alt=""></p>
<p>We then introduce a Gaussian variational posterior for the noise,  $q(\eta) = \mathcal{N}(\eta|\mu,LL^{T})$ where $L$ is a lower-triangular matrix to ensure the positive definiteness of the covariance matrix.   </p>
<p>We then construct a variational evidence lower bound,</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220311170307.png" alt=""></p>
<h1 id="RESPECTING-CAUSALITY-IS-ALL-YOU-NEED-FOR-TRAINING-PHYSICS-INFORMED-NEURAL-NETWORKS"><a href="#RESPECTING-CAUSALITY-IS-ALL-YOU-NEED-FOR-TRAINING-PHYSICS-INFORMED-NEURAL-NETWORKS" class="headerlink" title="RESPECTING CAUSALITY IS ALL YOU NEED FOR TRAINING PHYSICS-INFORMED NEURAL NETWORKS"></a>RESPECTING CAUSALITY IS ALL YOU NEED FOR TRAINING PHYSICS-INFORMED NEURAL NETWORKS</h1><h2 id="Introduction-4"><a href="#Introduction-4" class="headerlink" title="Introduction"></a>Introduction</h2><p>Extensions to enhance the accuracy and robustness of PINNs: novel optimization algorithms for adaptive training;  adaptive algorithms for selecting batches of training data; novel network architectures; domain decomposition strategies; new types of activation functions; sequential learning strategies.</p>
<p>notion of temporal dependence is absent in most continuous-time PINNs formulations   </p>
<p>Specific contributions can be summarized as:  </p>
<ul>
<li>We reveal an implicit bias suggesting that continuous-time PINNs models can violate causality, and hence are susceptible to converge towards erroneous solutions.  </li>
<li>We put forth a simple re-formulation of PINNs loss functions that allows us to explicitly respect the causal structure that characterizes the solution of general nonlinear PDEs. </li>
<li>Strikingly, we demonstrate that this simple modification alone is enough to introduce significant accuracy improvements, allowing us to tackle problems that have remained elusive to PINNs.  </li>
<li>We provide a practical quantitative criterion for assessing the training convergence of a PINNs model.  </li>
<li>We examine a collection of challenging benchmarks for which existing PINNs formulations fail, and demonstrate that the proposed causal training strategy leads to state-of-the-art results.  </li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317183104.png" alt=""></p>
<h2 id="Causal-training-for-physics-informed-neural-networks"><a href="#Causal-training-for-physics-informed-neural-networks" class="headerlink" title="Causal training for physics-informed neural networks"></a>Causal training for physics-informed neural networks</h2><p>To this end, we define a weighted residual loss as</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317184032.png" alt=""></p>
<p>We recognize that the weights $w_{i}$ should be large – and therefore allow the minimization of $\mathcal{L}_{r}(t_{i}, \theta)$ – only if all residuals $\{\mathcal{L}_{r}(t_{k}, \theta)\}^{i}_{k=1}$ before $t_{i}$ are minimized properly, and vice versa.   </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317184906.png" alt=""></p>
<p>As such, the weighted residual loss can be written as  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317185502.png" alt=""></p>
<p>$\mathcal{L}_{r}(t_{i}, \theta)$ will not be minimized unless all previous residuals $\{ \mathcal{L}_{r}(t_{k}, \theta) \}_{k=1}^{i-1}$ decrease to<br>some small value such that $w_{i}$ is large enough.</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220317192154.png" alt=""></p>
<h1 id="Deep-Implicit-Moving-Least-Squares-Functions-for-3D-Reconstruction"><a href="#Deep-Implicit-Moving-Least-Squares-Functions-for-3D-Reconstruction" class="headerlink" title="Deep Implicit Moving Least-Squares Functions for 3D Reconstruction"></a>Deep Implicit Moving Least-Squares Functions for 3D Reconstruction</h1><h2 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h2><p>点集因为其灵活和轻量级的表示被广泛应用于3D深度学习，但是它的离散特性限制了对连续和精细的几何图形的表示。这篇文章通过引入隐式最小二乘（IMLS）曲面公式，将离散的点集转化成光滑的曲面，定义了点集上的局部隐式函数。IMLSNet预测一个八叉树结构，作为再需要时生成MLS点的支架，并且用学到的先验知识来表征形状几何。同时，一旦MLS点被预测，隐式函数的评估将独立于神经网络，从而实现了快速运行时评估。</p>
<h2 id="Introduction-5"><a href="#Introduction-5" class="headerlink" title="Introduction"></a>Introduction</h2><p>与多边形网格和体积网格等其他3D表示相比，点集作为神经元被自然地嵌入DNN中，易于获取，拥有最小的额外结构，动态捕捉复杂的几何和拓扑，并且不会浪费自由空间区域的计算。事实上，点集已经被用于基于深度学习的不同任务的3D分析。在使用点集进行深度学习生成三维数据时，一方面可以灵活地建模变化的拓扑和复杂的表面，另一方面也会受到离散和粗糙几何的影响。</p>
<p>近年来的研究主要集中在以网格和多边形块的形式生成形状，但由于其离散性和非光滑性，其形状表达能力仍然受到限制。而深度隐式函数方法则在整个三维域上定义光滑函数，以保证结果的连续性，在高质量的三维重建中具有很好的应用前景。然而，隐式曲面生成是低效的，因为对于三维域中的每个点，在提取曲面之前，网络都必须单独评估。在本文中，我们结合了隐函数方法和点集方法的优点，在保留显式点集固有的灵活性和计算效率的同时，将点集表示方法扩展到隐式曲面模型中，以实现高质量的三维生成。</p>
<p>对于通过点集建模光滑曲面，我们采用点集曲面，并使用点的移动最小二乘插值来定义在点集的窄带区域内的局部隐函数。特别是对于本文使用的隐式MLS公式，对于狭窄区域内的任意空间点，采用隐式MLS函数将其映射到零水平集表面的有符号距离值，定义为附近点支持的有符号距离的定向平面的加权混合；然后将零水平集曲面提取为光滑连续的曲面，用于形状表示。</p>
<p>虽然MLS曲面在三维重建和绘制方面已经得到了很好的研究，但将其表示整合到深度学习框架中带来了新的挑战和机遇，这在现有的基于点集或隐式表示的方法中是看不到的。首先，当点足够密集且均匀分布于重构形状上时，才能最有效地定义隐式MLS曲面。然而大多数点生成方法固定点的数量并且消耗大量资源用于难以概括的密集点的预测,我们引入一个octree-based脚手架，只在需要时根据目标形状生成可变数量的MLS点，通过定制损失函数进一步调整点的分布。第二，为了度量训练监督和测试评估的预测隐函数，而现有的隐式方法必须在整个3D域上使用密集抽样，MLS表面自然地定位在生成点的窄带区域内，这促使我们只在八叉树节点上使用更简洁的抽样来进行监督和评估。此外，一旦所有的MLS点都嵌入到三维域中，评估就独立于网络，从而避免了其他隐式方法典型的点网络评估的代价。</p>
<p>我们使用广泛的消融试验来验证设计的选择。我们也通过三维物体的重建任务证明了我们的深度隐式MLS曲面方法比点集生成方法和其他全局或局部隐式函数方法都有更好的性能。</p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Deep-representations-for-3D-generation"><a href="#Deep-representations-for-3D-generation" class="headerlink" title="Deep representations for 3D generation"></a>Deep representations for 3D generation</h3><p>点集是许多著作中常用的表示方法。但由于通常指定了点的个数，其表示细节几何的能力受到限制，需要进一步的点上采样来提高点密度和形状质量。</p>
<p>密集的体素很好地表征了形状占用率，但其高昂的内存成本妨碍了其用于表示高分辨率3D内容。稀疏体素包括八叉树克服了这些问题，在内存和计算方面都有很大的效率。</p>
<p>网格表示和基于patch的表示是提高形状质量的方便的3D表示。然而，它们的能力受到预定义的网格拓扑和分辨率，或多个补丁的断开连接的限制。中间3D表示，如粗体素或形状骨架是进一步提高其质量的可能方法。中间3D表示，如粗体素或形状骨架是进一步提高其质量的可能方法。</p>
<p>基于基元的表示使用一组简单的几何对象，如平面和立方体来近似3D形状。基于结构的表示明确地将语义部件结构编码为长方体，并使用体素表示在每个长方体内重构部件。虽然它们适用于表征形状结构，但由于基元的简单性，它们的近似质量也受到限制。</p>
<p>最近出现了基于隐式表面的深度学习方法提供了一种平滑连续的3D表示，并在连续空间中实现函数评价。对于一个给定的点，网络预测它的占用率或从它到表面的符号距离。这些技术最近得到了进一步的改进，通过整合局部特征来建模更详细的形状几何。</p>
<p>我们的方法属于深度隐式类，通过对光滑、连续的隐式MLS曲面进行建模，同时具有显式点集生成的灵活性和效率；它是一种混合的3D深度学习表示，结合了点集和隐函数的优点。</p>
<h3 id="Surface-reconstruction-from-point-clouds"><a href="#Surface-reconstruction-from-point-clouds" class="headerlink" title="Surface reconstruction from point clouds"></a>Surface reconstruction from point clouds</h3><p>表面重建技术已经研究了几十年。其中，利用全局或局部平滑先验对点云进行高质量重建的方法包括：多层分割的单位云(MPU)、泊松重建、径向基函数和移动最小二乘曲面(MLS) 广泛用于点集曲面建模和绘制。</p>
<p>由于MLS的快速和局部评价特性，我们选择MLS表面作为我们的深层3D表示。MLS曲面可以分为两种类型：投影MLS曲面和隐式MLS曲面(IMLS)。前者通过迭代投影定义一组平稳点，后者直接定义隐函数。我们使用基于IMLS的带符号的距离监控，实现了快速的功能评估。</p>
<h2 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h2><h3 id="IMLS-surface"><a href="#IMLS-surface" class="headerlink" title="IMLS surface"></a>IMLS surface</h3><p>隐式MLS曲面定义如下: 表示 $\mathcal{P}=\{p_{i} \in \mathbb{R}^{3} \}_{i=1}^{N}$ 为三维点集，每个点都具有单位法向 $n_{i} \in \mathbb{R}^{3}$，控制半径 $r_{i} \in \mathbb{R}^{+}$ 。为了方便起见，我们称这些点为MLS点。</p>
<p>对于每个MLS点 $p_{i}$ 到其切平面的有符号距离函数定义为 $＜x-p_{i},n_{i}＞$ ，其中 $＜\cdot,\cdot＞$ 是内积。通过加权平均所有逐点带符号的距离函数，我们得到了一个隐函数 $F(x)$ 的零水平集定义了隐式曲面 $\mathcal{S}$ :</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409163226.png" alt=""></p>
<p>这里我们设权函数 $\theta(d,r)=exp(-d^{2}/r^{2})$ 。Kolluri证明了在均匀采样条件下IMLS曲面 $\mathcal{S}$ 是对 $\mathcal{P}$ 进行采样的原始曲面的几何和拓扑正确的近似，而IMLS函数 $F$ 是对原始曲面的有符号距离函数的紧密近似。</p>
<p>由于当 $x$ 远离 $p_{i}$ 时，权函数衰减，因此只考虑附近的MLS点可以加速 $F(x)$ 的求值。Eq.(1)可以修改为:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409163632.png" alt=""></p>
<p>其中 $\Omega(x)$ 表示以 $x$ 为中心，半径为 $r_{b}$ 的球内的MLS点集合。 $r_{b}$ 可由用户设置为截断点距离值。</p>
<p>由于上述公式，函数值为零 $F(x)$ 存在于IMLS点的窄带区域。通过对边界区域内的规则网格进行函数求值，通过移动立方体可以有效地将 $\mathcal{S}$ 显式地提取为三角形网格。</p>
<h3 id="Deep-IMLS-surface"><a href="#Deep-IMLS-surface" class="headerlink" title="Deep IMLS surface"></a>Deep IMLS surface</h3><p>在实际三维重建中，稀疏的、无方向的点云可能带有噪声和缺失区域，这是典型的输入，但传统方法无法很好地处理这些输入三维重建方法，比如泊松重建。为了处理这种不完美的数据，我们的目标是设计一个自编码的神经网络来生成IMLS曲面。</p>
<p>定义网络输出的一种简单方法是设置固定数量的IMLS点元组 $\{ p_{i},n_{i},r_{i} \}_{i=1}^{N}$ 。但是，它会限制IMLS的表示能力，不能很好地从数据中学习局部几何先验。我们引入了一个中间网络输出：基于八叉树的脚手架，以帮助生成需要的MLS点。基于八叉树的支架是一个 $d$ 深度的八叉树 $\mathcal{O}$ ，它在多分辨率下大致近似3D表面。对于每一个最细的非空八分位数 $o_{k}$ ，也就是八叉树中最小的非空体素，我们关联一个小集合的MLS点，这些点的位置靠近八分位数中心 $c_{k}$ 。具体来说与 $o_{k}$ 关联的MLS点定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409170339.png" alt=""></p>
<p>其中 $t_{k,l}\in \mathbb{R}^{3}$ 是 $p_{k,l}$ 到 $c_{k}$ 的偏移向量， $s$ 是一个预定义的点的数目。由于基于八叉树的支架的结构依赖于目标表面，因此需要自适应地确定MLS点的总数及其位置。</p>
<p>有了上面的设置，一个适合IMLS生成的网络应该输出：</p>
<p>（1）一个基于八叉树的脚手架 $\mathcal{O}$ </p>
<p>（2）一个最细的非空八分圆 $o_{k}$ 的MLS点偏移量、MLS点法线和控制半径</p>
<p>这里我们注意到，由输入噪声和稀疏点云创建的八叉树不能用作脚手架，因为它可能是不完整和不准确的，并且不同于目标形状。</p>
<h4 id="Scaffold-prediction"><a href="#Scaffold-prediction" class="headerlink" title="Scaffold prediction"></a>Scaffold prediction</h4><p>使用基于八叉树的卷积神经网络(O-CNN)自动编码器来生成支架。其编码器采用输入点云构建的深度 $d_{in}$ 八叉树作为输入，并仅在八叉树内进行CNN计算。它的解码器以4 × 4 × 4的单元格开始，预测每个单元格是否空，如果单元格不空，则将其细分为8个八边形。这个过程递归地对每个非空的八进制执行，直到达到最大输出八叉树深度 $d_{out}$ 。</p>
<h4 id="MLS-point-prediction"><a href="#MLS-point-prediction" class="headerlink" title="MLS point prediction"></a>MLS point prediction</h4><p>与之前工作不同，解码器在每个最细的非空八分圆处回归定向点或平面补丁以实现亚体素精度，我们通过一个具有如下隐含层的多层感知器(MLP)来预测MLS点元组，该元组的特征向量用 $f(o_{k})$ 表示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409190020.png" alt=""></p>
<p>注意，MLP预测了 $p_{k,l}$ 的局部坐标，即 $t_{k,l}$ ，因此它可以从数据中学习局部先验。为了保证 $p_{k,l}$ 接近 $c_{k}$ ， $t_{k,l}$ 的每个坐标分量的取值范围限制在 $[−\beta h， \beta h]$ ，这里 $h$ 为最细的八分区的大小， $\beta$ 默认设置为1.5。我们还将 $r_{k,s}$ 限制在 $[l_{r}/ 2,2l_{r}]$ 内，其中 $l_{r} = \frac{h}{\sqrt{s}}$ 。这些约束是通过使用tanh激活网络输出来实现的，并通过其范围缩放值。</p>
<h3 id="Network-structure"><a href="#Network-structure" class="headerlink" title="Network structure"></a>Network structure</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409191356.png" alt=""></p>
<p>论文使用类似 U-Net 的 O-CNN 自动编码器，其中包含 O-CNN ResNet 块和输出引导的跳过连接。对于给定的无方向点云，论文提出为其构建一个深度八叉树。在每个最细的八分圆中，通过将八分圆内输入点的平均位置的偏移量与带有二进制标量的八分圆中心的偏移量与=连接来设置输入 4 维信号，该二进制标量指示八分圆是否为空。</p>
<p>Resblock(n, c) 表示一个 n 层基于 O-CNN 的残差块，通道编号为 c。Downsample(c) 和 Upsample(c) 是基于八叉树的卷积和反卷积算子 [49]，然后是批量归一化和 ReLU。对于第一个 Resblock，c 设置为 64，并且在每个 Downsample 算子之后增加 2 倍，并且在每个 Upsample 算子之后除以 2。在论文的实验中，论文设置 n = 3。隐藏层 MLP 用于预测八分圆是否为空。</p>
<h3 id="Loss-function-design"><a href="#Loss-function-design" class="headerlink" title="Loss function design"></a>Loss function design</h3><h4 id="Octree-structure-loss"><a href="#Octree-structure-loss" class="headerlink" title="Octree structure loss"></a>Octree structure loss</h4><p>八分圆状态的确定是一个二元分类问题：0 代表空，1 代表非空。 论文使用 O 的每个八分圆处的 sigmoid 交叉熵损失的加权求和来定义八叉树结构损失。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192717.png" alt=""></p>
<h4 id="SDF-loss"><a href="#SDF-loss" class="headerlink" title="SDF loss"></a>SDF loss</h4><p>IMLS曲面的预测值和真实值之间的差异用SDF损失表示</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192809.png" alt=""></p>
<p>这里 F 的梯度可以近似为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192845.png" alt=""></p>
<h4 id="MLS-point-repulsion-loss"><a href="#MLS-point-repulsion-loss" class="headerlink" title="MLS point repulsion loss"></a>MLS point repulsion loss</h4><p>用于改善生成的 MLS 点的局部规律性。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409192956.png" alt=""></p>
<p>其中 $||p_{i}-p_{j}||_{proj}=||(T-n_{i}n_{i}^{T})(p_{i}-p_{j})||$ 是 $p_{i}-p_{j}$ 在 $p_{i}$ 处的切平面上的投影长度， $w_{ij}$ 是关于两个 MLS 点差和法向差的双边权重，定义如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193039.png" alt=""></p>
<p>上述设计将 $p_{j}$ 推离 $p_{i}$ ，尤其是当他们的法线和他们的位置是相似的。</p>
<h4 id="Projection-smoothness-loss"><a href="#Projection-smoothness-loss" class="headerlink" title="Projection smoothness loss"></a>Projection smoothness loss</h4><p>为了实现局部表面平滑度，论文鼓励 MLS 点靠近其相邻 MLS 点的切平面。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193200.png" alt=""></p>
<h4 id="Radius-smoothness-loss"><a href="#Radius-smoothness-loss" class="headerlink" title="Radius smoothness loss"></a>Radius smoothness loss</h4><p>同样，为了提高表面平滑度，相邻 MLS 点的半径变化通过对半径进行加权拉普拉斯平滑来惩罚</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220409193248.png" alt=""></p>
<h4 id="Weight-decay"><a href="#Weight-decay" class="headerlink" title="Weight decay"></a>Weight decay</h4><p>在损失函数中加入一项小的权重衰减项，系数为$\lambda_{w}$</p>
<h1 id="Efficient-Training-of-Physics-Informed-Neural-Networks-via-Importance-Sampling"><a href="#Efficient-Training-of-Physics-Informed-Neural-Networks-via-Importance-Sampling" class="headerlink" title="Efficient Training of Physics-Informed Neural Networks via Importance Sampling"></a>Efficient Training of Physics-Informed Neural Networks via Importance Sampling</h1><h2 id="Abstract-2"><a href="#Abstract-2" class="headerlink" title="Abstract"></a>Abstract</h2><p>PINN训练只需要问题描述，定义域，初始/边界条件，这种训练通常涉及使用随机梯度下降法的变体来解决一个非凸优化问题，将损失函数的梯度近似于一批配点中，在每次迭代中按均匀分布随机选取。在每次训练迭代中，按照与损失函数成正比的分布对搭配点进行采样，将改善PINNs训练的收敛行为。</p>
<h2 id="Introduction-6"><a href="#Introduction-6" class="headerlink" title="Introduction"></a>Introduction</h2><p>由于计算资源和优化算法的限制，PINN没有得到太多的关注。PINN网络的训练通常涉及到使用迭代法求解非凸优化问题。在给定的迭代中，这种批量选择可能会导致在一些配置点上计算梯度，在这些配置点上，近似解相对于其他点已经满足了微分算子的一个令人满意的程度。因此，得到的梯度信息很少或根本没有，从而延缓了收敛速度。或者，通过采用重要采样方案，在每次迭代中，我们可以选择一批能提供更多梯度信息的配点，以加速收敛。</p>
<p>首先，我们借鉴文献的理论发现，提出了一种基于重要度抽样的PINN网络加速训练方法。据作者所知，这是第一次使用重要抽样方案对pin网络进行训练。其次，我们展示了如何使用最近邻搜索或Voronoi分布来逼近建议分布，以进一步改善PINN训练的收敛行为。提出的重要度抽样方法简单明了，易于应用于现有的重要度抽样方法通过修改代码的几行PINN代码。此外，该方法没有引入新的超参数。</p>
<h2 id="Deep-Learning-of-Differential-Equations"><a href="#Deep-Learning-of-Differential-Equations" class="headerlink" title="Deep Learning of Differential Equations"></a>Deep Learning of Differential Equations</h2><p>PINNs基础知识</p>
<h2 id="Importance-Sampling-for-Training-of-PINNs"><a href="#Importance-Sampling-for-Training-of-PINNs" class="headerlink" title="Importance Sampling for Training of PINNs"></a>Importance Sampling for Training of PINNs</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418100747.png" alt=""></p>
<p>$f(x)$ 是训练点的采样分布，一种典型的采样分布是定义域上的均匀分布。在一种重要抽样方法中，我们寻求从一个备选抽样分布（用 $q(x)$ 表示）中提取训练样本，并根据如下更新网络参数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418101053.png" alt=""></p>
<p>在本工作中，我们有效地实现了一种离散采样方案，将连续域 $D$ 转化为 $N$  个采样点在 $D$ 上均匀选取的离散集合，其中 $N&gt;&gt; 1$ 。因此，我们将分别处理离散分布 $\{f_{j}\}_{j=1}^{N}$ 和 $\{ q_{j} \}_{j=1}^{N}$ ，而不是采样密度函数 $f(x_{j})$ 和 $q(x_{j})$，在任意候选点 $j$ 处 $f_{j} = \frac{1}{N}$ 。</p>
<p>为了构建相应的SGD，为了简洁起见，我们先考虑no mini batch，即 $m = 1$ ，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418102832.png" alt=""></p>
<p>在这项工作中，我们的目标是设计一个具有抽样分布 $q$ 的训练方案，它可以加速Eq. 12的收敛。[32]中的作者考虑了以下关于收敛速度的定义</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418103015.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418103050.png" alt=""></p>
<p>然后得出结论，通过从一个最小的分布 $Tr(\mathbb{V}_{P}[G^{(i)}])$ 中采样输入变量，可以加速收敛。如[32,34]所示，如果根据 $q^{\star}\propto||\triangledown_{\theta}J(\theta^{(i)})||_{2}$ 选择训练样本，则这一项可以被最小化。对于批量大小为m的小批量SGD，这个目标可以有效地被实现通过计算抽样分布</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418104326.png" alt=""></p>
<p>通过从概率为 $p^{(i)} = \{q_{1}^{(i)},\dots,q_{N}^{(i)}\}$ 的多项式中抽样 $M$ 个指标，选择小批量样本集 $M^{(i)}$ 。为了得到梯度 $\triangledown_{\theta}J(\theta)$ 的无偏估计，则根据式8，11给出的小批量梯度下降更新规则</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418104941.png" alt=""></p>
<p>这一推导提供了一个理论证据，即使用重要抽样方法可以加速PINN网络的训练，其中训练样本是根据与模型参数相关的损失函数梯度的2-范数成比例的分布获得的。然而，在每次迭代中为所有的并置点计算这个梯度的2-范数需要通过计算图进行额外的反向传播，这在计算上可能非常昂贵。为了缓解这一问题，在[33]中从理论上和数值上表明，在训练示例中损耗值的线性变换总是大于该示例中损耗梯度的2-范数，配点的梯度范数排序与损失值排序是一致的。因此，可以使用损失值代替梯度值作为重要性度量</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418105440.png" alt=""></p>
<p>具体来说，利用该proposal分布，可以选择前面解释的m个小批量样本，并结合公式16中的梯度下降规则来更新模型参数。</p>
<p>虽然与梯度计算相比，损失函数的计算成本较低，但在每次迭代中对整个配置点集进行这样的计算仍然非常昂贵。为了缓解这种情况，我们提出了一个分段常数近似的损失函数。也就是说，我们不是在每个配置点上计算损失函数，而是只在一个点子集上计算损失，以下称为”种子”，用 $\{x_{s}\}_{s=1}^{N}$ 表示， $S&lt;N$ 。然后，利用最近邻搜索算法，对每个配点 $j$ ，求出最接近的种子 $s = \rho(j)$，并设置该搭配点的损失值等于最接近种子的损失，即 $J(\cdot;x_{j}):=J(\cdot;x_{\rho(j)})$ 。这相当于使用种子生成Voronoi镶嵌，并在每个Voronoi单元中使用一个常数近似的损失。在数值例子中可以看出，与对整个配点求损函数的情况相比，这种分段常数近似提供了更高的计算效率。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418112136.png" alt=""></p>
<h1 id="PAGP-A-physics-assisted-Gaussian-process-framework-with-active-learning-for-forward-and-inverse-problems-of-partial-differential-equations"><a href="#PAGP-A-physics-assisted-Gaussian-process-framework-with-active-learning-for-forward-and-inverse-problems-of-partial-differential-equations" class="headerlink" title="PAGP: A physics-assisted Gaussian process framework with active learning for forward and inverse problems of partial differential equations"></a>PAGP: A physics-assisted Gaussian process framework with active learning for forward and inverse problems of partial differential equations</h1><h2 id="Abstract-3"><a href="#Abstract-3" class="headerlink" title="Abstract"></a>Abstract</h2><p>在这项工作中，建立了一个在偏微分方程(PDEs)中包含给定物理信息的高斯过程回归(GPR)模型:物理辅助高斯过程(PAGP)。该模型的目标可分为两类问题:给定偏微分方程的初始条件和边界条件的解或未知系数的发现。给定的物理信息被集成到高斯过程模型通过我们设计的GP损失函数。基于两种不同的训练标准GP模型的方法，本文给出了三种类型的损失函数。本文的第一部分介绍了连续时间模型，该模型将时域和空间域等同看待。已知的未知系数通过最小化设计的损失函数，偏微分方程可以与GP超参数联合学习。在离散时间模型中，我们首先选择一种时间离散方案来离散时域。然后在每个时间步上应用PAGP模型和该方案来近似最后时刻给定测试点的偏微分方程解。为了在这种情况下发现未知系数，需要两个特定时间的观测数据，并构造一个混合均方误差函数来获得最优系数。最后，提出了一种新的连续时间和离散时间混合模型。它融合了连续时间模型的灵活性和离散时间模型的精确性。讨论了采用不同GP损失函数选择不同模型的性能。建议的有效性PAGP方法在我们的数值部分进行了说明。</p>
<h2 id="Introduction-7"><a href="#Introduction-7" class="headerlink" title="Introduction"></a>Introduction</h2><p>如今，数据驱动的机器学习(ML)模型在科学计算和许多学科的发现中取得了巨大的成功。然而，仅仅将ML模型作为黑盒函数使用可能会由于忽略现有的物理规律或其他领域专业知识而导致性能较差。此外，目前大多数黑盒ML模型往往需要大量的数据和有限的泛化属性。因此，将ML模型与通常以偏微分方程(PDEs)形式存在的物理规律相结合就成为一个自然的热门话题。在所有数据驱动的ML模型中，高斯过程回归(GPR)，又称地质统计学中的克里格(Kriging)，是一种应用广泛的非参数模型贝叶斯模型构建一个廉价的代理复杂的科学和工程问题。高斯过程是唯一由其规定形式的均值和协方差函数决定的。它具有一个概率工作流，具有分析的易处理性，并从其后验分布返回稳健的方差估计。这也自然地量化了模型的不确定性。本文旨在将偏微分方程中包含的物理信息与GPR模型结合起来，解决正问题，即求解给定偏微分方程的解，以及反问题，即发现给定偏微分方程的未知系数。</p>
<p>简要介绍以前处理这类问题的两篇著作。</p>
<p>本文提出了一种将物理原理引入高斯过程回归模型的新方法。在标准GP中，均值函数和协方差函数的最优超参数可以通过两种不同的方式进行优化，即最小化负对数边际似然(NLML)或使用交叉验证的方法。在PAGP模型中，基于这两种方法构造了三种类型的损失函数。对于第一种方法，我们应用留一交叉验证(LOO-CV)构造一个损失函数。验证密度的对数作为拟合的交叉验证测度。根据惩罚GPR的思想，在这个损失函数中增加了一个额外的惩罚条款。这一项实际上是由配置点集上的PDE残差的绝对误差之和组成。第二个损失函数是相似的，除了对LOO-CV的拟合度的衡量是平方误差。对于最后一个，在原来的NLML函数中增加了一个相同的惩罚项。此外，还提出了一种自适应权值选择方法，以确定与惩罚项相乘的权值系数，使损失函数具有意义。在GP训练过程中，惩罚期限需要根据预先设定的配点来计算。因此，首先需要推导GP预测对时间t和空间位置x的导数。我们根据不同的问题设置开发连续时间模型和离散时间模型。对于连续时间模型，我们遵循中的步骤，直接使用GP预测公式，根据给定推导出关于t和x的n阶导数的解析表达式PDEs。对于离散时间模型，可以用类似的方法计算GP对x的导数。但是GP对t的导数需要用不同的方法计算。这里采用有限差分法进行计算。此外，还提出了一种新的两步混合模型，将连续时间模型和离散时间模型结合在一起。第一步遵循离散时间模型，但具有较大的时间步长。每一项的预测时间步长，和根据给定的初始条件和边界条件抽取的样本一起构成了偏微分方程第二步训练的数据集。然后利用连续时间模型对整个域的测试点进行预测。</p>
<h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>本文的目的是利用包含物理信息的GP来求解偏微分方程的正问题和反问题。在这项工作中，我们考虑一般形式的参数化偏微分方程</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418171923.png" alt=""></p>
<p>边界条件</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418172009.png" alt=""></p>
<p>初值条件</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418172045.png" alt=""></p>
<p>其中 $\mathcal{T}_{x}^{\lambda}$ 是一个一般的微分算子，可以是线性的，也可以是非线性的。下标表示操作符 $\mathcal{T}$ 作用的空间位置 $x$ 。上标表示只能部分知道的参数 $\lambda$ 。 $\Omega$ 是 $\mathbb{R}^{d}$ 的一个子集，$\Gamma$ 是 $\Omega$ 的边界。例如，考虑一维热方程： $u_{t}-\lambda u_{xx}=0$ 。这里，微分算子是 $\mathcal{T}_{x}^{\lambda}=\lambda \frac{\partial^{2}}{\partial x^{2}}$ 并且 $\lambda$ 是位置参数。在这种情况下我们考虑的正问题是找出解 $u(x,t)$ 给定特定边界条件 $g(x,t)$ ，初始条件 $h(x)$ 和系数 $\lambda$ ，而反问题是在偏微分方程中恢复未知系数 $\lambda$ 。注意，对于这两种类型的问题，偏微分方程的边界和初始条件也可以用可能被噪声污染的观测值来代替。</p>
<h3 id="Gaussian-process-regression"><a href="#Gaussian-process-regression" class="headerlink" title="Gaussian process regression"></a>Gaussian process regression</h3><p>略</p>
<h3 id="Derivatives-of-Gaussian-process-regression"><a href="#Derivatives-of-Gaussian-process-regression" class="headerlink" title="Derivatives of Gaussian process regression"></a>Derivatives of Gaussian process regression</h3><p>略</p>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><p>连续模型、离散模型、混合模型</p>
<h3 id="Active-Learning"><a href="#Active-Learning" class="headerlink" title="Active Learning"></a>Active Learning</h3><p>假设训练数据集D由N个样本组成。这代表了知识的当前状态，给定PDE域中信息量最大的样本是通过最大化获取函数 $a_{N}(x)$ 来选择的</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419144543.png" alt=""></p>
<p>获取功能实际上量化了我们可以获得多少信息来评估或在这个数据站点上执行一个昂贵的实验。然后 $(x_{N+1},y_{N+1})$ 加到原始训练数据集D中，此时如果达到了预先设定的条件，则停止处理。否则，该过程重复迭代，直到满足停止条件或达到最大迭代次数。在我们的PAGP模型中，采集函数被选择为后验分布的方差:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419144750.png" alt=""></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>这篇文章主要就是在训练GPR时通过对不同问题模型的设定设置不同的损失函数，然后在新一轮选点时采用后验方差大的点。</p>
<h1 id="Breaking-the-Dilemma-of-Medical-Image-to-image-Translation"><a href="#Breaking-the-Dilemma-of-Medical-Image-to-image-Translation" class="headerlink" title="Breaking the Dilemma of Medical Image-to-image Translation"></a>Breaking the Dilemma of Medical Image-to-image Translation</h1><h2 id="Abstract-4"><a href="#Abstract-4" class="headerlink" title="Abstract"></a>Abstract</h2><p>有监督的Pix2Pix和无监督的Cycle-consistency两种模式在医学图像到图像的转换中占主导地位。然而，这两种模式都不是理想的。Pix2Pix模式具有出色的性能。但它需要成对和像素对齐的图像，这可能不总是可以实现，因为在获得成对图像期间，呼吸运动或解剖变化。循环一致性模式对训练数据不太严格，对未配对或错位的图像也能很好地工作。但它的性能可能不是最优的。为了打破现有模式的困境，我们提出了一种新的无监督模式RegGAN用于医学图像到图像的转换。它基于“损失校正”理论。在RegGAN算法中，将失调的目标图像作为噪声标签，利用附加的配准网络对生成器进行训练，自适应地拟合失调的噪声分布。目标是搜索图像之间的转换和配准任务的共同最优解。我们将RegGAN合并到一些最先进的图像到图像的转换方法中，并证明RegGAN可以很容易地与这些方法结合起来，以提高它们的性能。例如，在我们的模式中，简单的CycleGAN超过了最新的NICEGAN，即使使用更少的网络参数。根据我们的结果，RegGAN在对齐数据上优于Pix2Pix，在未对齐或未配对的数据上优于Cycle-consistency。RegGAN对噪声不敏感，这使得它在很多情况下都是更好的选择，特别是在无法获得像素级对齐数据的医学图像到图像转换任务中。</p>
<h2 id="Introduction-8"><a href="#Introduction-8" class="headerlink" title="Introduction"></a>Introduction</h2><p>生成对抗网络(GANs)是一个通过对抗过程同时训练生成器G和鉴别器D的框架。该生成器用于将源域图像X的分布转换为目标域图像Y的分布。判别器用于确定目标域图像可能来自生成器还是来自真实数据。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210104.png" alt=""></p>
<p>Pix2Pix更新生成器 $(G:X \rightarrow Y)$ ，使源图像x和目标图像Y之间的像素级L1损失最小。因此，它要求对齐良好的成对图像，其中每个像素都有对应的标签。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210302.png" alt=""></p>
<p>然而，在现实场景中，对齐良好的成对图像并不总是可用的。为了解决图像不对齐所带来的挑战，我们开发了循环一致性算法，该算法基于这样的假设:从源域X到目标域Y $(G:X \rightarrow Y)$ 是生成器F从Y到X的反向 $(F:Y \rightarrow X)$ .与Pix2Pix模式相比，循环一致性模式在不对齐或未配对的图像上工作得更好。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419210602.png" alt=""></p>
<p>然而，Cycle-consistency模式有其局限性。在医学图像到图像的转换中，不仅需要图像域之间的风格转换，还需要特定图像对之间的转换。最佳解决方案应该是唯一的。例如，翻译后的图像应尽可能保持原图像的解剖特征。众所周知，Cycle-consistency模式可能会产生多个解，这意味着训练过程可能比较混乱，结果可能不准确。Pix2Pix模式也不理想。即使它有唯一的解决方案，也很难满足成对图像对齐的要求。对于错位的图像，误差通过Pix2Pix模式，可能导致最终的平移图像不合理的位移。</p>
<p>到目前为止，还没有一种图像到图像的转换模式可以在对齐数据上优于Pix2Pix模式，在未对齐或未配对数据上优于Cycle-consistency模式。受[6-10]的启发，我们将失调的目标图像视为有噪声的标签，这意味着我们将存在的问题视为带噪声标签的监督学习。</p>
<h2 id="Methodology-1"><a href="#Methodology-1" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Theoretical-Motivation"><a href="#Theoretical-Motivation" class="headerlink" title="Theoretical Motivation"></a>Theoretical Motivation</h3><p>如果我们将失调的目标图像视为有噪声的标签，那么图像到图像的翻译训练就变成了一个有噪声标签的监督学习过程。给定一个训练数据集 $\{ (x_{n},\widetilde{y}_{n}) \}_{n=1}^{N}$ ，有n个噪声标签，其中 $x_{n}$, $\widetilde{y}_{n}$ 是来自两种模式的图像，假设 $y_{n}$ 是 $x_{n}$ 的正确标签，但在现实场景中是未知的。我们的目标是使用数据集 $\{ (x_{n},\widetilde{y}_{n}) \}_{n=1}^{N}$ 带噪声的标签，其性能相当于在干净数据集 $\{ (x_{n},y_{n}) \}_{n=1}^{N}$ 尽可能多。基于方程4的直接优化通常是无效的，并且会导致不好的结果，因为发生器不能挤出噪声的影响。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419212746.png" alt=""></p>
<p>为了解决噪声问题，我们提出了一个基于“损耗校正”的解决方案，如方程5所示。我们的解决方案通过建模噪声转移 $\phi$ 来匹配噪声分布来校正生成器 $G(x_{n})$ 的输出。之前，Patrini et al从数学上证明了用噪声标签训练的模型可以等价于用干净标签训练的模型，只要噪声发生转移 $\phi$ 匹配噪声分布。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419213250.png" alt=""></p>
<p>为此，Goldberger等提出将正确的标签视为潜在的随机变量，并将标签噪声显式建模为网络结构的一部分，记为 $R$ 。方程5可以改写为对数似然的形式，将对数似然作为神经网络训练的损失函数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419213846.png" alt=""></p>
<h3 id="RegGAN"><a href="#RegGAN" class="headerlink" title="RegGAN"></a>RegGAN</h3><p>与现有的使用的求解方程6的方法例如最大化期望，全连通层、锚点估计和Drichlet分布比较。在我们的问题中，噪声分布的类型更清楚，它可以表示为位移误差: $\widetilde{y}=y\circ T$ 。这里T表示为一个随机变形场，它为每个像素产生随机位移。因此，我们采用生成器G后的配准网络R作为标签噪声模型对结果进行校正。修正损失如式7所示</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419214445.png" alt=""></p>
<p>式中 $R(G(x), \widetilde{y})$ 为变形场， $\circ$ 代表重采样操作。注册网络基于U-Net。在式8中定义了平滑损失来评价变形场的平滑性，使变形场的梯度最小。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419214930.png" alt=""></p>
<p>最后，将产生器与鉴别器之间的平均损耗相加(式1)，总损耗如式9所示</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220419215013.png" alt=""></p>
<h1 id="Characterizing-possible-failure-modes-in-physics-informed-neural-networks"><a href="#Characterizing-possible-failure-modes-in-physics-informed-neural-networks" class="headerlink" title="Characterizing possible failure modes in physics-informed neural networks"></a>Characterizing possible failure modes in physics-informed neural networks</h1><h2 id="Abstract-5"><a href="#Abstract-5" class="headerlink" title="Abstract"></a>Abstract</h2><p>我们证明，虽然现有的PINN方法可以学习相对次要问题的良好模型，但它们很容易无法学习相关的物理现象，即使是稍微复杂一点的问题。特别地，我们分析了几个不同的情况，广泛的物理兴趣，包括学习微分方程的对流，反应和扩散算子。我们提供证据，软正则化的PINN，其中涉及到基于偏微分算子，可以引入许多微妙的问题，包括使问题更病态。重要的是，我们表明，这些可能的失效模式不是由于缺乏神经网络结构的表现力，而是PINN的设置使损失景观非常难以优化。然后，我们描述了解决这些故障模式的两个有希望的解决方案。第一种方法是使用课程正则化，其中PINN的损失项从一个简单的PDE正则化开始，并随着NN的训练逐渐变得更加复杂。第二种方法是将问题作为一个顺序对顺序的学习任务，而不是学习一次性预测整个时空。大量的测试表明，与常规的PINN训练相比，我们可以实现高达1-2个数量级的误差。</p>
<h2 id="Introduction-9"><a href="#Introduction-9" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Problem-overview"><a href="#Problem-overview" class="headerlink" title="Problem overview"></a>Problem overview</h3><p>PINN 相关知识</p>
<h3 id="Main-contributions-1"><a href="#Main-contributions-1" class="headerlink" title="Main contributions"></a>Main contributions</h3><ul>
<li>我们分析了简单但物理相关的对流、反应和反应扩散问题的PINN模型。我们发现，普通/常规的PINN方法只适用于非常简单的参数体系。</li>
<li>我们分析了训练过的PINN模型的损失情况，发现增加基于pde的软约束正则化使其更加复杂和难以优化，特别是对于具有非平凡系数的情况。</li>
<li>我们证明了 NN 架构有能力/表现力来找到一个好的解，从而表明这些问题不是由于NN网格结构的容量有限引起的。相反，我们认为失败是由于相关的优化困难使用 PINN 的软 PDE 约束。</li>
<li>我们提出了解决这些失败模式的两种途径:(i)课程正规化(ii)将学习问题作为一个序列对序列的学习任务。</li>
</ul>
<h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><p>一些关于机器学习和PDE结合的工作</p>
<h2 id="Possible-failure-modes-for-physics-informed-neural-networks"><a href="#Possible-failure-modes-for-physics-informed-neural-networks" class="headerlink" title="Possible failure modes for physics-informed neural networks"></a>Possible failure modes for physics-informed neural networks</h2><h3 id="Experiment-setup"><a href="#Experiment-setup" class="headerlink" title="Experiment setup."></a>Experiment setup.</h3><p>4-layer fully-connected NN with 50 neurons per layer; tangent activation function; randomly sample collocation points on the domain; measure relative error and absolute error</p>
<h3 id="convection、reaction-diffusion"><a href="#convection、reaction-diffusion" class="headerlink" title="convection、reaction-diffusion"></a>convection、reaction-diffusion</h3><p> we can see that the PINN also fails to learn advection and reaction-diffusion.  </p>
<h2 id="Diagnosing-possible-failure-modes-for-physics-informed-NNs"><a href="#Diagnosing-possible-failure-modes-for-physics-informed-NNs" class="headerlink" title="Diagnosing possible failure modes for physics-informed NNs"></a>Diagnosing possible failure modes for physics-informed NNs</h2><h3 id="Soft-PDE-regularization-and-optimization-difficulties"><a href="#Soft-PDE-regularization-and-optimization-difficulties" class="headerlink" title="Soft PDE regularization and optimization difficulties"></a>Soft PDE regularization and optimization difficulties</h3><p>我们表明，添加软正则化实际上可以使问题更难优化，即正则化导致更不平滑的损失景观。</p>
<p>最后，我们研究了改变软正则化项的权重/乘子的影响，这可能与提高PINN性能有关。虽然我们发现调谐λ可以帮助改变误差，但它不能解决问题。</p>
<h2 id="Expressivity-versus-optimization-difficulty"><a href="#Expressivity-versus-optimization-difficulty" class="headerlink" title="Expressivity versus optimization difficulty"></a>Expressivity versus optimization difficulty</h2><h3 id="Curriculum-PINN-Regularization"><a href="#Curriculum-PINN-Regularization" class="headerlink" title="Curriculum PINN Regularization"></a>Curriculum PINN Regularization</h3><p>我们设计了一个“课程正则化”，方法通过为权值找到一个好的初始化值来热启动神经网络训练。对于$\beta/\rho$较高的情况，我们不是训练PINN立即学习解，而是先在较低的$\beta/\rho$上训练PINN(对PINN来说更容易学习)，然后逐渐分别在较高的$\beta/\rho$上训练PINN。</p>
<h3 id="Sequence-to-sequence-learning-vs-learning-the-entire-space-time-solution"><a href="#Sequence-to-sequence-learning-vs-learning-the-entire-space-time-solution" class="headerlink" title="Sequence-to-sequence learning vs learning the entire space-time solution"></a>Sequence-to-sequence learning vs learning the entire space-time solution</h3><p>在这里，我们证明，将问题作为一个序列对序列(seq2seq)学习任务可能更好，其中神经网络学习预测下一个时间步骤的解决方案，而不是一直预测。这样，我们就可以使用时间推进方案来预测不同的序列/时间点。注意，这里唯一可用的数据来自PDE本身，也就是说，只有初始条件。我们取在$t=\Delta t$处的预测，以此作为在$t=2\Delta t$处的预测的初始条件，依此类推。</p>
<h1 id="Uncertainty-Quantification-in-Scientific-Machine-Learning-Methods-Metrics-and-Comparisons"><a href="#Uncertainty-Quantification-in-Scientific-Machine-Learning-Methods-Metrics-and-Comparisons" class="headerlink" title="Uncertainty Quantification in Scientific Machine Learning:Methods, Metrics, and Comparisons"></a>Uncertainty Quantification in Scientific Machine Learning:Methods, Metrics, and Comparisons</h1><h2 id="Abstract-6"><a href="#Abstract-6" class="headerlink" title="Abstract"></a>Abstract</h2><p>神经网络在如何将数据和物理工程方面的数学定理融合方面正在改变新的计算范式。然而，在基于神经网络的推理中，对误差和不确定性的量化比传统方法更加复杂。这是因为除了与噪声数据相关的任意不确定性外，还存在数据有限的不确定性，还有神经网络超参数、过度参数化、优化和采样误差以及模型误规范等。在这项工作中，我们提出了一个全面的框架，包括不确定性建模、新的和现有的解决方法，以及评估指标和事后改进方法。为了证明我们的框架的适用性和可靠性，我们提出了一个广泛的比较研究，其中各种方法在原型问题上进行了测试，包括混合输入输出数据问题和高维随机问题。</p>
<h2 id="Introduction-10"><a href="#Introduction-10" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Novel-contributions-of-this-work"><a href="#Novel-contributions-of-this-work" class="headerlink" title="Novel contributions of this work"></a>Novel contributions of this work</h3><ol>
<li>我们测试并将各种用于后验推理、先验学习、数据噪声建模以及训练后校准的方法集成到物理信息神经网络、神经算子和SPDE求解器中。</li>
<li>我们演示了如何使用函数先验来解决具有异方差噪声的历史数据的函数逼近问题。</li>
<li>将高斯过程回归和生成式对抗网络相结合，提出了一种解决确定性正向偏微分方程问题的新方法，并与现有方法进行了比较。</li>
<li>我们求解源项、问题参数和解数据中含有异方差噪声的混合偏微分方程问题。</li>
<li>我们解决了带有噪声的随机实现的混合SPDE问题，并提出了一种新的神经网络结构，用于使用多项式混沌量化不确定性。</li>
<li>我们演示了如何处理有噪声和不完整的推断数据给出一个预先训练的神经算子对干净的数据。</li>
<li>我们提出了检测神经算子外分布数据的方法，这对风险相关的应用是至关重要的。</li>
<li>我们提出了一个统一的UQ框架，通过无缝地将物理与可能被各种类型的噪声污染的新数据和历史数据结合起来，解决科学机器学习中的各种问题。</li>
</ol>
<h2 id="Neural-PDEs-and-neural-operators"><a href="#Neural-PDEs-and-neural-operators" class="headerlink" title="Neural PDEs and neural operators"></a>Neural PDEs and neural operators</h2><h3 id="Solving-forward-and-mixed-PDE-problems-Overview-of-PINN-method"><a href="#Solving-forward-and-mixed-PDE-problems-Overview-of-PINN-method" class="headerlink" title="Solving forward and mixed PDE problems: Overview of PINN method"></a>Solving forward and mixed PDE problems: Overview of PINN method</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506153709.png" alt=""></p>
<h3 id="Learning-operator-mappings-Overview-of-DeepONet-method"><a href="#Learning-operator-mappings-Overview-of-DeepONet-method" class="headerlink" title="Learning operator mappings: Overview of DeepONet method"></a>Learning operator mappings: Overview of DeepONet method</h3><p>DeepONet方法通过构造一个以 $\theta$ 为参数的神经网络逼近器来处理算子学习问题，来对 $u(x;\xi)$ 。</p>
<h2 id="Modeling-total-uncertainty"><a href="#Modeling-total-uncertainty" class="headerlink" title="Modeling total uncertainty"></a>Modeling total uncertainty</h2><h3 id="Uncertainty-in-function-approximation"><a href="#Uncertainty-in-function-approximation" class="headerlink" title="Uncertainty in function approximation"></a>Uncertainty in function approximation</h3><p>为了定义 $p(u|x,\theta)$ ，我们构建一个模型 $u_{\theta}(x)$ 在一些 $x$ 点来捕捉 $u(x)$ 的确定性部分并且为噪声假定一个模型。例如，因式高斯似然函数，通过如下式子给出</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506161343.png" alt=""></p>
<p>下标 $d$ 表示 $u$ 的每个 $D_{u}$ 维，通常用于多维函数逼近问题。在公式(4)中，输出向量 $u_{\theta}(x)$ 是假设 $u$ 在位置 $x$ 处的高斯分布的均值， $diag(\Sigma^{2}_{u})$ 是一个对角协方差矩阵 $\Sigma_{u}^{2} = [\sigma_{u}^{2},\dots,\sigma_{u}^{2}]$ 可以是已知的，也可以是假设的，也可以是从数据推断出来的。</p>
<p>在给定数据 $\mathcal{D}$ 的情况下， $x$ 位置 $u$ 的值是一个随机变量，表示为 $(u|x,\mathcal{D})$。为了求 $(u|x;\mathcal{D})$ 积分出模型参数 $\theta$，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506163025.png" alt=""></p>
<p>利用贝叶斯规则，后验 $p(\theta|\mathcal{D})$ 可以通过下式获得</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506185405.png" alt=""></p>
<p>式(6)中， $p(\mathcal{D}|\theta)$ 是数据的似然，即 $p(\mathcal{D}|\theta) = \prod_{i=1}^{N}p(u_{i}|x_{i},\theta)$ 为独立同分布(i.i.d.)数据； $p(\theta)$为模型 $\mathcal{H}$ 定义的参数 $\theta$ 的先验概率；而 $p(\mathcal{D})$ 被称为边际可能性或证据，因为它代表了在所有由 $\mathcal{H}$ 建模的可能数据集中，我们观察到 $\mathcal{D}$ 发生的概率。证据 $p(\mathcal{D})$ 给出如下</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506190851.png" alt=""></p>
<p>即，给定从先验 $p(\theta)$ 中抽取的随机样本，然后与似然函数结合使用， $p(\mathcal{D})$ 表示数据集 $\mathcal{D}$ 产生的概率。</p>
<p>后验推断阶段之后，Eq.(5)的BMA可以用蒙特卡罗(MC)来近似。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506191803.png" alt=""></p>
<p>这个方程提供了 $(u|x,\mathcal{D})$ 以预测PDF $\overline{p}(\mu|x)$ 的形式。 $(\mu|x,\mathcal{D})$ 通过 $\hat{u}(x) = E[\mu|x]$ 建模并且用 $\overline{\mu}(x)$近似表示为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506193734.png" alt=""></p>
<p>其中 $\{\mu_{\hat{\theta}_{j}}(x)\}_{j=1}^{M}$ 是样本 $\{\hat{\theta}_{j} \}_{j=1}^{M}$ 对应的NN预测集。求 $(u|x,\mathcal{D})$ ，将式(4)的高斯似然值代入式(8)，得到高斯混合协方差矩阵的对角线部分由下式给出</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220506195407.png" alt=""></p>
<h3 id="Uncertainty-in-PINNs"><a href="#Uncertainty-in-PINNs" class="headerlink" title="Uncertainty in PINNs"></a>Uncertainty in PINNs</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922185741.png" alt=""></p>
<h3 id="Uncertainty-in-DeepONets"><a href="#Uncertainty-in-DeepONets" class="headerlink" title="Uncertainty in DeepONets"></a>Uncertainty in DeepONets</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922190052.png" alt=""></p>
<h2 id="Methods-for-uncertainty-quantification"><a href="#Methods-for-uncertainty-quantification" class="headerlink" title="Methods for uncertainty quantification"></a>Methods for uncertainty quantification</h2><ul>
<li>Bayesian methods</li>
<li>Ensembles</li>
<li>Functional priors (FPs)</li>
<li>Solving stochastic PDEs (SPDEs)</li>
<li>Towards a unified view of the presented methods</li>
</ul>
<h1 id="Multi-Objective-Loss-Balancing-for-Physics-Informed-Deep-Learning"><a href="#Multi-Objective-Loss-Balancing-for-Physics-Informed-Deep-Learning" class="headerlink" title="Multi-Objective Loss Balancing for Physics-Informed Deep Learning"></a>Multi-Objective Loss Balancing for Physics-Informed Deep Learning</h1><h2 id="Abstract-7"><a href="#Abstract-7" class="headerlink" title="Abstract"></a>Abstract</h2><p>在这项工作中，我们观察到对多个竞争损失函数组合进行正确加权对有效训练PINN的重要作用。为此，我们实现并评估了不同的方法，旨在平衡PINN损失函数的多个项及其梯度的贡献。我们提出了一种新的自适应损失平衡称为ReLoBRaLo(相对随机回看的损失平衡)。我们的模拟研究证明了这一点与使用其他平衡方法训练PINN相比，ReLoBRaLo训练速度更快，准确率更高，因此非常有效，并增加了PINN算法的可持续性。</p>
<h2 id="Introduction-11"><a href="#Introduction-11" class="headerlink" title="Introduction"></a>Introduction</h2><p>物理信息神经网络的出现引起了人们对经常面临低数据系统问题的领域的极大兴趣。通过利用已知的物理定律，并将其作为隐式先验并入深度学习管道，PINN被证明需要很少或不需要数据，以近似不同复杂度的偏微分方程(PDE)。</p>
<h2 id="Physics-Informed-Neural-Networks-PINNs"><a href="#Physics-Informed-Neural-Networks-PINNs" class="headerlink" title="Physics-Informed Neural Networks (PINNs)"></a>Physics-Informed Neural Networks (PINNs)</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922182417.png" alt=""></p>
<p>然而，PINN训练的效率、收敛性和准确性仍面临严峻挑战。目前的研究可分为四种主要方法:修改神经网络的结构、分治/区域分解、参数初始化和损失平衡。</p>
<p>根据文献综述，自适应PINN训练过程可以被视为PDE约束的优化问题。本文关注的是对竞争力和适应性的仔细考虑，并从跨机器学习的几个领域提出的损失平衡技术中寻求灵感。</p>
<h2 id="Methodology-2"><a href="#Methodology-2" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Multi-Objective-Optimisation"><a href="#Multi-Objective-Optimisation" class="headerlink" title="Multi-Objective Optimisation"></a>Multi-Objective Optimisation</h3><p>多目标优化可以通过线性扩展转化为单一目标：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183152.png" alt=""></p>
<h3 id="Adaptive-Loss-Balancing-Methods"><a href="#Adaptive-Loss-Balancing-Methods" class="headerlink" title="Adaptive Loss Balancing Methods"></a>Adaptive Loss Balancing Methods</h3><h4 id="Learning-Rate-Annealing"><a href="#Learning-Rate-Annealing" class="headerlink" title="Learning Rate Annealing"></a>Learning Rate Annealing</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183302.png" alt=""></p>
<h4 id="GradNorm"><a href="#GradNorm" class="headerlink" title="GradNorm"></a>GradNorm</h4><p>更新内部刻度的损失GradNorm的计算方法如下:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183445.png" alt=""></p>
<p>更新网络参数的最终损失只是使用之前更新的缩放值进行线性扩展：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183525.png" alt=""></p>
<h4 id="SoftAdapt"><a href="#SoftAdapt" class="headerlink" title="SoftAdapt"></a>SoftAdapt</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922183605.png" alt=""></p>
<h2 id="Relative-Loss-Balancing-with-Random-Lookback-ReLoBRaLo"><a href="#Relative-Loss-Balancing-with-Random-Lookback-ReLoBRaLo" class="headerlink" title="Relative Loss Balancing with Random Lookback (ReLoBRaLo)"></a>Relative Loss Balancing with Random Lookback (ReLoBRaLo)</h2><p>从现有平衡技术中汲取灵感，我们提出了一种新的方法和实现，用于平衡扩展MOO损失函数中的多个项，用于训练PINN：</p>
<ul>
<li>采用SoftAdapt的平衡方法，利用连续训练步骤之间的变化率，并通过softmax函数进行归一化。</li>
<li>与学习率退火类似，为了利用过去不止一个训练步骤的损失统计数据，使用指数衰减来更新标量。</li>
<li>此外，在指数衰减中引入了一个随机回看(称为saudade $\rho$)，它决定是使用穿透步骤的损失统计来计算缩放，还是一直回看直到训练$\mathcal{L}_{i}^{(0)}$开始。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922184617.png" alt=""></p>
<h2 id="Hyperparameter-Tuning-and-Meta-Learning"><a href="#Hyperparameter-Tuning-and-Meta-Learning" class="headerlink" title="Hyperparameter Tuning and Meta Learning"></a>Hyperparameter Tuning and Meta Learning</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20220922184701.png" alt=""></p>
<h1 id="A-Unified-Hard-Constraint-Framework-for-Solving-Geometrically-Complex-PDEs"><a href="#A-Unified-Hard-Constraint-Framework-for-Solving-Geometrically-Complex-PDEs" class="headerlink" title="A Unified Hard-Constraint Framework for Solving Geometrically Complex PDEs"></a>A Unified Hard-Constraint Framework for Solving Geometrically Complex PDEs</h1><h2 id="Abstract-8"><a href="#Abstract-8" class="headerlink" title="Abstract"></a>Abstract</h2><p>a unified hard-constraint framework  $\rightarrow$ geometrically complex PDEs</p>
<p>introduce the “extra fields” $\rightarrow$ reformulate the PDEs so as to equivalently transform the three types of BCs into linear forms.  </p>
<p>derive the general solutions of the BCs analytically</p>
<h2 id="Introduction-12"><a href="#Introduction-12" class="headerlink" title="Introduction"></a>Introduction</h2><p>Among all types of BCs, Dirichlet, Neumann, and Robin are the most commonly used</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018145545.png" alt=""></p>
<p>in practical problems, physical systems can be very geometrically complex, there exists an unbalanced competition between the<br>terms of PDEs and BCs, limiting the application of PINNs to geometrically complex problems. There are some imroved methods. Nevertheless, these methods are only applicable to specific BCs (e.g., Dirichlet BCs, homogeneous BCs, etc) or geometrically simple PDEs.</p>
<h3 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h3><ul>
<li>a unified hard-constraint framework for all the three most commonly used BCs</li>
<li>introduce the extra fields, substitutes the gradient of a physical quantity with new variables, allowing the BCs to be reformulated as linear equations. </li>
<li>summarize a paradigm for constructing the hard-constraint ansatz under time-dependent, multiboundary, and high-dimensional cases </li>
</ul>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Physics-Informed-Neural-Networks"><a href="#Physics-Informed-Neural-Networks" class="headerlink" title="Physics-Informed Neural Networks"></a>Physics-Informed Neural Networks</h3><p>basic introduction to PINNs</p>
<h3 id="Hard-Constraint-Methods"><a href="#Hard-Constraint-Methods" class="headerlink" title="Hard-Constraint Methods"></a>Hard-Constraint Methods</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018154155.png" alt=""></p>
<p>where $x$ is the coordinate, $\Omega$ is the domain of interest, $u^{\partial\Omega}(x)$ is the general solution at the boundary $\partial\Omega$, and $l^{\partial\Omega}(x)$ is an extended distance function which satisfies</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221018154550.png" alt=""></p>
<p>However, it is hard to directly extend this method to more general cases of Robin BCs (see Eq. (7)), since we cannot obtain the general solution $u^{\partial\Omega}(x)$ analytically. </p>
<h2 id="Methodology-3"><a href="#Methodology-3" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Problem-Setup"><a href="#Problem-Setup" class="headerlink" title="Problem Setup"></a>Problem Setup</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115190422.png" alt=""></p>
<p>其中：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115191221.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115191016.png" alt=""></p>
<p>边界条件为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221115191607.png" alt=""></p>
<h3 id="Reformulating-PDEs-via-Extra-Fields"><a href="#Reformulating-PDEs-via-Extra-Fields" class="headerlink" title="Reformulating PDEs via Extra Fields"></a>Reformulating PDEs via Extra Fields</h3><p>引入中间变量：$p_{j}(x)=(p_{j1}(x),\cdots,p_{jd}(x))=\nabla u_{j},j=1,\cdots,n$，方程变成如下形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116200121.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116200232.png" alt=""></p>
<p>边界条件变成了有关 $u_{j}$ 和 $p_{j}(x)$ 的线性方程，该方程的通解比上面的通解更容易求，求通解的第一步是要在零空间内找一组基 $B(x)$，经过作者证明，这组基是存在的，只是需要carefully chosen。于是该方程的通解可以写成：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116205653.png" alt=""></p>
<h3 id="A-Unified-Hard-Constraint-Framework"><a href="#A-Unified-Hard-Constraint-Framework" class="headerlink" title="A Unified Hard-Constraint Framework"></a>A Unified Hard-Constraint Framework</h3><p>最终解的形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116213608.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116213714.png" alt=""></p>
<p>最终的loss形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221118212130.png" alt=""></p>
<h1 id="DeepONet-Learning-nonlinear-operators-for-identifying-differential-equations-based-on-the-universal-approximation-theorem-of-operators"><a href="#DeepONet-Learning-nonlinear-operators-for-identifying-differential-equations-based-on-the-universal-approximation-theorem-of-operators" class="headerlink" title="DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators"></a>DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators</h1><h2 id="Abstract-9"><a href="#Abstract-9" class="headerlink" title="Abstract"></a>Abstract</h2><p>具有单个隐藏层的神经网络可以精确逼近任何非线性连续算子。这个万能逼近定理暗示了神经网络在从数据中学习非线性算子方面的潜在应用。然而，对于一个足够大的网络，该定理只保证了一个很小的近似误差，而没有考虑重要的优化和泛化误差。</p>
<h2 id="Introduction-13"><a href="#Introduction-13" class="headerlink" title="Introduction"></a>Introduction</h2><p>万能逼近定理指出，在不限制隐藏层的宽度和深度的情况下，神经网络可以将任何连续函数近似到任意精度。然而，另一个更令人惊讶的近似结果（到目前为止尚未得到重视）指出，具有单一隐藏层的神经网络可以精确近似任何非线性连续泛函（从一个函数空间到实数的映射）或（非线性）算子（从一个函数空间到另一个函数空间的映射）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122154217.png" alt=""></p>
<p>这个近似定理表明了神经网络在从数据中学习非线性运算符方面的潜在应用，也就是说，类似于深度学习社区目前正在做的事情，即从数据中学习函数。然而，这个定理并没有告诉我们如何有效地学习运算符。以经典的图像分类任务为例，函数神经网络的普遍逼近定理表明，全连接神经网络(FNNs)能够精确地近似地真分类函数，但在实践中，FNNs的性能与具有特定架构的网络相去甚远，如广泛使用的卷积神经网络(CNN)或较新的胶囊神经网络(CapsNet)。性能差距主要在于神经网络的准确性可以通过将整个的误差分为三种主要类型：近似、优化和泛化来表征。对于一个足够大的网络，万能逼近定理只保证了一个很小的逼近误差，但它们根本没有考虑优化误差和泛化误差，这两个误差在实践中对总误差同样重要，而且往往占主导地位。有用的网络应该易于训练，即具有较小的优化误差，并且能够很好地泛化到不可见的数据，即具有较小的泛化误差。</p>
<p>为了准确、高效地学习算子，我们提出了一种特定的网络结构——深度算子网络(DeepONet)，以实现更小的总误差。我们将证明，基于两个子网络的设计，DeepONet显著改善了泛化，分支网络用于输入函数，主干网络用于评估输出函数的位置。</p>
<h2 id="Methodology-4"><a href="#Methodology-4" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Deep-operator-networks-DeepONets"><a href="#Deep-operator-networks-DeepONets" class="headerlink" title="Deep operator networks (DeepONets)"></a>Deep operator networks (DeepONets)</h3><p>我们专注于在更一般的设置中学习算子，其中对训练数据集的唯一要求是传感器的一致性 $\{x_{1},x_{2},\cdots,x_{m}\}$ 用于输入函数。在这种一般设置中，网络输入由两个独立的部分组成： $[u(x_{1}),u (x_{2}),\cdots,u(x_{m})]^{T}$ 和 $y$，目标是通过设计网络架构来实现良好的性能。一个简单的解决方案是直接使用一个经典网络，如FNN, CNN或RNN，并将两个输入连接在一起作为网络输入，即 $[u(x_{1}),u (x_{2}),\cdots,u(x_{m}),y]^{T}$ 。然而，输入没有任何特定的结构，因此选择CNN或RNN这样的网络是没有意义的。这里我们使用FNN作为基线模型。</p>
<p>在高维问题中， $y$ 是一个有 $d$ 个分量的向量，所以 $y$ 的维数和 $u(x_{i})$的维数不匹配。我们提出的架构如图1C所示。首先是“中继”网络，以 $y$ 为输入，输出为 $[t_{1},t_{2},\cdots,t_{p}]\in \mathbb{R}^{p}$ ；除了主干网络，还有 $p$ 个“分支”网络，每个“分支”网络 $[u(x_{1}),u(x_{2}),\cdots,u(x_{m})]^{T}$ 作为输入和输出标量 $b_{k}\in \mathbb{R}$ 对于 $k=1,2,\cdots,p$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122160053.png" alt=""></p>
<p>在实践中， $p$ 至少是10的数量级，并且使用大量的分支网络在计算和内存方面都很昂贵。因此，我们将所有的分支网络合并为一个单独的分支网络（图1D），即单个分支网络输出一个向量 $[b_{1},b_{2},\cdots,b_{p}^{T}]\in \mathbb{R}^{p}$ 。</p>
<p>DeepONet是一种高级网络架构，没有定义内部主干和分支网络的架构。为了展示DeepONet单独的能力和良好的性能，我们选择了最简单的FNN作为子网络的体系结构。使用卷积层我们有可能进一步提高精度。</p>
<p>将一些先验知识融入到神经网络体系结构中通常能产生良好的泛化效果。这种归纳偏差已经反映在许多网络中，如CNN用于图像，RNN用于顺序数据。DeepONet即使使用FNN作为子网络也能取得成功，这也是由于其强烈的归纳偏差。输出 $G(u)(y)$ 有两个独立的输入 $u$ 和 $y$ ，因此显式地使用中继和分支网络与这个先验知识是一致的。更广泛地说， $G(u)(y)$ 可以被视为 $y$ 条件作用于 $u$ 的函数。寻找一种有效的方式来表示条件作用输入仍然是一个开放的问题，已经提出了不同的方法，如特征明智的转换。</p>
<h3 id="Data-generation"><a href="#Data-generation" class="headerlink" title="Data generation"></a>Data generation</h3><p>过程的输入信号 $u(x)$ 在系统辨识中起着重要作用。显然，为了收集其响应的信息，输入信号是影响过程的唯一可能，而识别信号的质量决定了精度的上限，在最好的情况下，任何模型都可以达到这个上限。在本研究中，我们主要考虑两个函数空间:高斯随机场(GRF)和正交(Chebyshev)多项式。</p>
<p>mean-zero GRF:  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122193732.png" alt=""></p>
<p>Chebyshev polynomials:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122193746.png" alt=""></p>
<p>从选定的函数空间中采样u后，采用龙格-库塔(4,5)法求解ODE系统，采用二阶有限差分法求解pde系统，得到参考解。我们注意到一个数据点是三元组 $(u,y,G(u)(y))  $ ，因此一个特定的输入 $u$ 可能出现在具有不同 $y$ 值的多个数据点中。例如，一个10000大小的数据集可能只由100个 $u$ 轨迹生成，每个轨迹对100个 $y$ 位置计算 $G(u)(y)$ 。</p>
<h2 id="Conclusion-1"><a href="#Conclusion-1" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>在本文中，我们在一个更一般的设置中提出了算子学习的问题，并提出了学习非线性算子的DeepONets。在DeepONets中，我们首先构建两个子网络分别编码输入函数和位置变量，然后将它们合并在一起计算输出。我们在四个常/偏微分方程问题上测试了DeepONets，并表明DeepONets可以通过使用这种归纳偏差实现小的泛化误差。在仿真中，我们系统地研究了不同因素对测试误差的影响，包括传感器数量、最大预测时间、输入函数空间复杂度、训练数据集大小和网络规模。我们观察到与训练数据集大小相关的不同阶多项式甚至指数误差收敛。据我们所知，这是第一次在深度学习中观察到指数收敛。此外，从理论上推导了近似误差对不同因素的依赖性，这与我们的计算结果一致。尽管取得了上述成就，但还需要进行更多的理论和计算工作。例如，算子近似的网络大小还没有任何理论结果，类似于函数近似的宽度和深度界限。我们还不明白为什么DeepONets会导致小的泛化误差。另一方面，在本文中，我们对两个子网络使用了完全连接的神经网络，但正如我们在2.1节中讨论的那样，我们也可以使用其他网络架构，如卷积神经网络或“注意”机制。这些修改可能会进一步提高DeepONets的准确性。</p>
<h1 id="FOURIER-NEURAL-OPERATOR-FOR-PARAMETRIC-PARTIAL-DIFFERENTIAL-EQUATIONS"><a href="#FOURIER-NEURAL-OPERATOR-FOR-PARAMETRIC-PARTIAL-DIFFERENTIAL-EQUATIONS" class="headerlink" title="FOURIER NEURAL OPERATOR FOR PARAMETRIC PARTIAL DIFFERENTIAL EQUATIONS"></a>FOURIER NEURAL OPERATOR FOR PARAMETRIC PARTIAL DIFFERENTIAL EQUATIONS</h1><p>傅里叶神经算子起作用的原因可能是做傅里叶变换时过滤了高频的噪声信号。</p>
<p>物理空间 (即以x为变量的空间)上的<strong>微分</strong>等效于傅立叶空间中的<strong>乘法</strong>，因此通过傅立叶变换，PDE上的一部分偏微分被消除，<strong>PDE也被转化成一个ODE</strong>。</p>
<p>FNO的一些优点：</p>
<ul>
<li>Fourier Filter是global的，而如果只使用CNN filter的话，感受是local的。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306281141887.png" alt=""></p>
<ul>
<li>FNO的一个设计目的就是要与分辨率无关，而传统的偏微分方程求解方法之一的谱方法也有可借鉴的思路。因为从傅立叶空间中学习参数，相当于将物理空间投影在以 $e^{2\pi i\langle x,k \rangle}$ 为基的空间下，而这个空间下是处处well-defined，与离散无关。</li>
<li>除此之外，使用FFT之后，计算复杂度变成了准线性的，为大规模计算提供了可能。</li>
</ul>
<h2 id="Abstract-10"><a href="#Abstract-10" class="headerlink" title="Abstract"></a>Abstract</h2><p>神经网络的经典发展主要集中在有限维欧几里得空间之间的学习映射。最近，这已被推广到学习函数空间之间映射的神经算子。对于偏微分方程(PDEs)，神经算子直接学习从任何泛函参数依赖到解的映射。因此，他们学习了一整套的偏微分方程，而不是求解一个方程实例的经典方法。在这项工作中，我们通过在傅里叶空间中直接参数化积分核来构造一种新的神经算子，从而实现了一种具有表达性和效率的体系结构。我们对Burgers方程、Darcy flow和N-S方程进行了实验。傅里叶神经算子是第一个基于机器学习的零射超分辨率湍流模型。与传统的PDE求解器相比，它的速度快了3个数量级。此外，与以前的基于学习的固定分辨率求解器相比，它具有更高的精度。</p>
<h2 id="Introduction-14"><a href="#Introduction-14" class="headerlink" title="Introduction"></a>Introduction</h2><p>科学和工程中的许多问题都涉及到求解复杂的偏微分方程(PDE)系统重复对某些参数的不同值。分子动力学、微观力学和湍流流动中都有例子。通常这样的系统需要精细的离散化，以便捕捉被建模的现象。因此，传统的数值求解很慢，有时效率很低。例如，在设计机翼等材料时，需要解决相关的逆向问题，其中需要对正向模型进行数千次评估。一个快速的方法可以使这些问题变得可行。</p>
<h3 id="Conventional-solvers-vs-Data-driven-methods"><a href="#Conventional-solvers-vs-Data-driven-methods" class="headerlink" title="Conventional solvers vs. Data-driven methods."></a>Conventional solvers vs. Data-driven methods.</h3><p>传统的求解方法如有限元法和有限差分法是通过对空间离散化来求解方程的。因此，它们对分辨率进行了权衡：粗糙的网格速度快，但准确性较低；精细的网格是准确的，但速度慢。如上所述，复杂的PDE系统通常需要非常精细的离散化，因此对于传统的求解器来说非常具有挑战性和耗时。另一方面，数据驱动方法可以直接从数据中学习方程组族的轨迹。因此，基于学习的方法可以比传统的求解器快几个数量级。通过提供近似或增强传统算法的快速求解器，机器学习方法可能是科学学科革命的关键。然而，经典的神经网络在有限维空间之间映射，因此只能学习与特定离散化相关的解。这往往是实际应用的一个限制，因此需要开发网格不变神经网络。我们首先概述了两种主流的基于神经网络的方法有限维算子和神经有限元。</p>
<h3 id="Finite-dimensional-operators"><a href="#Finite-dimensional-operators" class="headerlink" title="Finite-dimensional operators."></a>Finite-dimensional operators.</h3><p>这些方法将解算子参数化为有限维欧氏空间之间的深度卷积神经网络。根据定义，这样的方法是依赖于网格的，并且需要针对不同的分辨率和离散化进行修改和调优，以便实现一致的误差（如果可能的话）。此外，这些方法受限于训练数据的离散化大小和几何形状，因此不可能在域中的新点查询解。相反，对于我们的方法，我们展示了误差对网格分辨率的不变性，以及在网格之间传递解的能力。</p>
<h3 id="Neural-FEM"><a href="#Neural-FEM" class="headerlink" title="Neural-FEM."></a>Neural-FEM.</h3><p>第二种方法直接将解函数参数化为神经网络。这种方法设计用于建模PDE的一个特定实例，而不是解决方案操作符。它是网格无关的和准确的，但对于任何给定的功能参数/系数的新实例，它需要训练一个新的神经网络。该方法与有限元等经典方法非常相似，用神经网络的空间代替了局部基函数有限集的线性跨度。神经有限元方法与经典方法存在相同的计算问题：优化问题需要针对每个新实例进行求解。此外，该方法仅限于已知底层PDE的设置。</p>
<h3 id="Neural-Operators"><a href="#Neural-Operators" class="headerlink" title="Neural Operators."></a>Neural Operators.</h3><p>最近，一项新的工作提出了使用神经网络学习无网格、无限维算子。神经算符通过产生一组可用于不同离散化的网络参数，弥补了上面讨论的有限维算符方法的网格依赖特性。它具有在网格之间传输解的能力。此外，神经算子只需要训练一次。获得参数的新实例的解只需要网络的向前通过，减轻了神经有限元方法产生的主要计算问题。最后，神经算符不需要基础PDE的知识，只需要数据。到目前为止，由于计算积分算子的成本，神经算子还没有产生有效的数值算法，可以在有限维环境下与卷积或递归神经网络的成功并行。通过快速傅里叶变换，我们的工作缓解了这个问题。</p>
<h3 id="Fourier-Transform"><a href="#Fourier-Transform" class="headerlink" title="Fourier Transform."></a>Fourier Transform.</h3><p>傅立叶变换常用于求解微分方程的谱方法中，因为微分等价于傅立叶域中的乘法。傅里叶变换在深度学习的发展中也扮演了重要的角色。理论上，它们出现在万能逼近定理的证明中，而在经验上，它们已被用于加速卷积神经网络。涉及傅里叶变换或使用正弦激活函数的神经网络架构也被提出和研究。最近，一些PDE的谱方法已经扩展到神经网络。在这些工作的基础上，我们提出了一个直接定义在傅里叶空间中的神经算子体系结构，具有准线性时间复杂度和最先进的逼近能力。</p>
<h2 id="LEARNING-OPERATORS"><a href="#LEARNING-OPERATORS" class="headerlink" title="LEARNING OPERATORS"></a>LEARNING OPERATORS</h2><p>我们的方法从观察到的有限的输入输出对集合中学习两个无限维空间之间的映射。再者让 $G^{\dagger}:\mathcal{A}\rightarrow \mathcal{U}$ 是一个(典型的)非线性映射。我们研究了作为参数偏微分方程解算符出现的映射 $G^{\dagger}$ - 参见第5节的例子。我们的目标是通过构造一个参数映射来建立一个近似的 $G^{\dagger}$:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122213846.png" alt=""></p>
<p>对某有限维参数空间 $\Theta$ ，选择 $\theta^{\dagger}\in \Theta$ ，使 $G(\cdot,\theta^{\dagger})=G_{\theta^{\dagger}}\approx G^{\dagger}$ 。这是无限维学习的自然框架，就像我们可以定义成本函数一样 $C:\mathcal{U}\times\mathcal{U}\rightarrow\mathbb{R}$ ，寻找问题的最小值</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221122214437.png" alt=""></p>
<p>这直接与经典的有限维设定平行。在无限维环境中，如何证明最小化函数的存在性，仍然是一个具有挑战性的开放问题。我们将通过使用用于确定 $\theta$ 和测试近似准确性的成本的数据驱动的经验近似，在测试训练设置中处理这个问题。因为我们在无限维环境中概念化了我们的方法，所有有限维近似都有一组在无限维环境中一致的参数。</p>
<h3 id="Learning-the-Operator"><a href="#Learning-the-Operator" class="headerlink" title="Learning the Operator."></a>Learning the Operator.</h3><p>近似算符 $G^{\dagger}$ 是一项不同的任务，通常比为参数 $a\in \mathcal{A}$ 的单个实例寻找PDE的解 $u\in \mathcal{U}$ 更具挑战性。大多数现有的方法，从经典的有限元、有限差分和有限体积到现代机器学习方法，如物理信息神经网络(PINN)针对的是后者，因此计算成本可能很高。这使得它们对于对于许多不同的参数实例都需要PDE解决方案的应用程序来说是不切实际的。另一方面，我们的方法直接逼近运算符，因此更便宜和更快，与传统求解器相比，提供了巨大的计算节省。有关贝叶斯逆问题的示例应用程序，请参见第5.5节。</p>
<h3 id="Discretization"><a href="#Discretization" class="headerlink" title="Discretization."></a>Discretization.</h3><p>由于我们的数据 $a_{j}$ 和 $u_{j}$ 通常是函数，要在数值上使用它们，所以我们假设只能访问按点计算的值。设 $D_{j}=\{x_{1},x_{2},\cdots,x_{n}\} \subset D$ 是定义域 $D$ 的 $n$ - 点离散化，假设我们有 $a_{j}|_{D_{j}}\in \mathbb{R}^{n\times d_{a}},u_{j}|_{D_{j}}\in\mathbb{R}^{n\times d_{v}}$ ，对于 $j$ 索引的输入输出对的有限集合。要做到离散不变，神经算子可以对任何 $x\in D$产生答案 $u(x)$ ，可能 $x \notin D_{j}$。这样的特性是非常可取的，因为它允许在不同的网格几何形状和离散化之间传递解。</p>
<h2 id="NEURAL-OPERATOR"><a href="#NEURAL-OPERATOR" class="headerlink" title="NEURAL OPERATOR"></a>NEURAL OPERATOR</h2><p>神经算子被表述为迭代体系结构 $v_{0} \mapsto v_{1} \mapsto \cdots \mapsto v_{T}$ 其中 $v_{j}$ 对于 $j=0,1,\cdots,T−1$ 是一个函数序列，每个函数都有一个值 $\mathbb{R}^{d_{v}}$ 。如图2 (a)所示，输入 $a\in \mathcal{A}$ 首先通过局部变换 $P$ 提升到高维表示 $v_{0}(x) = P(a(x))$，局部变换 $P$ 通常由浅全连通神经网络参数化。然后我们然后我们应用几次更新迭代 $v_{t}\mapsto v_{t+1}$ (定义如下)。输出 $u(x) = Q(v_{T}(x))$ 是 $v_{T}$ 通过局部变换 $Q: \mathbb{R}^{d_{v}}\mapsto \mathbb{R}^{d_{u}}$ 。在每一次迭代中，更新 $v_{t}\mapsto v_{t+1}$ 被定义为一个非局部积分算子的复合 $\mathcal{K}$ 和一个局部非线性激活函数 $\sigma$ 。</p>
<p>$a(x)$ 作为输入，经过 $P$ 这个神经网络映射到高维（为了高斯平滑），然后经历T个Fourier Layer，经过 $Q$ 之后恢复回 $u(x)$ 。具体对于一个Fourier layer来说， $v(x)$ 进来以后，经过Fourier变换，将其转化到Fourier空间， $R$ 则是一个线性变换，目的是滤掉高频模态，然后用Fourier逆变换将其转化回源空间， $R$ 之所以不选用神经网络映射作者说是因为实验发现线性效果更好，下面那条支路就类似于ResNet的“短路”结构，相加求和之后，经过激活函数进行非线性映射。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123152103.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123170343.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123170408.png" alt=""></p>
<p>在这里， $k_{\phi}$ 起着核函数的作用。定义1和2构成了神经网络到无限维空间的泛化。注意，即使积分算符是线性的，神经算符可以通过将线性积分算符与非线性激活函数组合在一起来学习高度非线性的算符，类似于标准神经网络。如果我们去掉函数 $\kappa(x,y,a(x),a(y))$ 对 $a$ 的依赖并强加 $\kappa(x,y)=\kappa(x-y)$ ，那么(3)是一个卷积算子（$f_{1} \ast f_{2}=\int_{-\infty}^{\infty}f_{1}(\tau)f_{2}(t-\tau)d\tau$）。</p>
<h2 id="FOURIER-NEURAL-OPERATOR"><a href="#FOURIER-NEURAL-OPERATOR" class="headerlink" title="FOURIER NEURAL OPERATOR"></a>FOURIER NEURAL OPERATOR</h2><p>我们建议用傅里叶空间中定义的卷积算子替换(3)中的核积分算子。设 $\mathcal{F}$ 表示函数 $f:D\rightarrow \mathbb{R}^{d_{v}}$ 的傅里叶变换和 $\mathcal{F}^{-1}$ 是它的倒数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123183426.png" alt=""></p>
<p>取 $\kappa_{\phi}(x, y, a(x), a(y)) = \kappa_{\phi}(x-y)$ ，应用卷积定理，得到</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123184335.png" alt=""></p>
<p>因此，我们建议在傅里叶空间中直接参数化 $\kappa_{\phi}$ 。</p>
<p>两函数的傅里叶变换的乘积等于它们卷积后的傅里叶变换，简单证明：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202307272018331.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123184435.png" alt=""></p>
<p>对于频率模态 $k \in D$ ，我们有 $(\mathcal{F}v_{t})(k)\in\mathbb{C}^{d_{v}}$ 和 $R_{\phi}(k)\in \mathbb{C}^{d_{v}\times d_{v}}$ 。注意，因为我们假设 $\kappa$ 是周期性的，它允许傅里叶级数展开，所以我们可以用离散模 $k\in \mathbb{Z}^{d}$ 。我们通过在最大模数处截断傅立叶级数来选择有限维参数化 $k_{max}=|Z_{k_{max}}|=|\{k\in\mathbb{Z}^{d}:|k_{j}|\leq k_{max,j}, for \ j=1,\cdots,d\}|$ 。因此，我们将 $R_{\phi}$ 直接参数化为复值 $(k_{max} \times d_{v} \times d_{v})$ - 张量，由截断傅里叶模的集合组成，因此从我们的符号中去掉 $\phi$ 。因为 $\kappa$ 是实值的，我们施加共轭对称性。我们注意到集合 $Z_{k_{max}}$ 不是 $v_{t}$ 的低频模态的规范选择。事实上，低频模态通常是通过在的上限界来定义的 $k\in \mathbb{Z}^{d}$ 的 $l_{1}$ - 范数。我们像上面那样选择 $Z_{k_{max}}$ ，因为它允许高效的实现。</p>
<h3 id="The-discrete-case-and-the-FFT"><a href="#The-discrete-case-and-the-FFT" class="headerlink" title="The discrete case and the FFT."></a>The discrete case and the FFT.</h3><p>假设域 $D$ 被 $n\in \mathbb{N}$ 个点离散，我们得到 $v_{t} \in \mathbb{R}^{n \times d_{v}}$ 和 $\mathcal{F}(v_{t}) \in \mathbb{C}^{n \times d_{v}}$ 。由于我们将 $v_{t}$ 与一个只有 $k_{max}$ 傅里叶模态的函数进行卷积，我们可以简单地截断更高的模态，从而得到 $\mathcal{F}(v_{t}) \in \mathbb{C}^{k_{max} \times d_{v}}$ 。乘以权重张量 $R \in \mathbb{C}^{k_{max} \times d_{v} \times d_{v}}$ 是</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123203344.png" alt=""></p>
<p>当离散化均匀，分辨率为 $s_{1} \times \cdots \times s_{d} = n$ 时， $\mathcal{F}$ 可以用快速傅里叶变换代替。对于 $f \in \mathbb{R}^{n \times d_{v}}$ ， $k = (k_{1}, \cdots, k_{d}) \in \mathbb{Z}_{s_{1}} \times \cdots \times \mathbb{Z}_{s_{d}}$ ，且 $x=(x_{1}, \cdots, x_{d}) \in D$ ， 快速傅里叶变换 $\hat{\mathcal{F}}$ 及其逆 $\hat{\mathcal{F}}^{-1}$ 定义为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123203431.png" alt=""></p>
<p>在这种情况下，截断模的集合变成</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123204243.png" alt=""></p>
<h3 id="Parameterizations-of-R"><a href="#Parameterizations-of-R" class="headerlink" title="Parameterizations of R."></a>Parameterizations of R.</h3><p>一般情况下，R 可以定义为依赖于 $(\mathcal{F}a)$ 平行于(3)。确实，我们可以定义 $R_{\phi}:\mathbb{Z}^{d} \times \mathbb{R}^{d_{v}} \rightarrow \mathbb{R}^{d_{v} \times d_{v}}$ 作为将 $(k,(\mathcal{F}a)(k))$ 映射到相应的傅里叶模的值的参数函数。我们对 $R_{\phi}$ 进行了线性和神经网络参数化实验。我们发现线性参数化与前面描述的直接参数化具有相似的性能，而神经网络的性能更差。这可能是由于空间 $\mathbb{Z}^{d}$ 的离散结构。</p>
<h3 id="Invariance-to-discretization"><a href="#Invariance-to-discretization" class="headerlink" title="Invariance to discretization."></a>Invariance to discretization.</h3><p>傅里叶层是离散不变的，因为它们可以从以任意方式离散的函数中学习和求值。由于参数是在傅里叶空间中直接学习的，所以在物理空间中解析函数就相当于在 $\mathbb{R}^{d}$ 上处处定义良好的 $e^{2 \pi i \langle x,k \rangle}$ 的基础上投影。这允许我们实现如5.4节所示的零射超分辨率。此外，我们的体系结构在输入和输出的任何分辨率上都有一致的错误。另一方面，请注意，在图3中，我们比较的标准CNN方法有一个随着分辨率增加而增加的错误。</p>
<p>傅里叶神经算子与输入的分辨率无关的原因是因为它利用了傅里叶变换的性质。傅里叶变换是一种在时间和频率域之间转换信号或数据的方法。在傅里叶神经算子中，输入信号经过傅里叶变换后，被转换到频域，而频域的运算不受分辨率的影响。因此，即使输入信号的分辨率改变，傅里叶神经算子的输出结果也不会受到影响。</p>
<p>具体来说，傅里叶神经算子将输入信号的每个像素值视为一个复数，然后对其进行傅里叶变换，得到频域下的复数系数。这些系数代表了输入信号在不同频率下的贡献。由于傅里叶变换的性质，高频成分对应于图像的细节和边缘信息，而低频成分对应于图像的整体轮廓和形状。因此，傅里叶神经算子对图像进行特征提取时，主要关注的是图像的轮廓和形状信息，而忽略了一些细节和噪声。</p>
<p>由于傅里叶变换已经将输入信号从时域转换到了频域，所以傅里叶神经算子的运算都是在频域进行的。这种频域运算不受分辨率的影响，因此傅里叶神经算子的输出结果也不受输入分辨率的影响。</p>
<h3 id="Quasi-linear-complexity"><a href="#Quasi-linear-complexity" class="headerlink" title="Quasi-linear complexity."></a>Quasi-linear complexity.</h3><p>权重张量 $R$ 包含 $k_{max} &lt; n$ 个模态，因此内部乘法的复杂度为 $O(k_{max})$ 。因此，大部分的计算成本在于计算傅里叶变换 $\mathcal{F}(v_{t})$ 及其反变换。一般的傅里叶变换的复杂度是 $O(n^{2})$ ，然而，由于我们截断了级数，复杂度实际上是 $O(nk_{max})$ ，而快速傅里叶变换的复杂度是 $O(n \log n)$ 。通常，我们发现使用快速傅里叶变换非常高效。然而，统一的离散化是必需的。</p>
<h2 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h2><p>假设我们有一个二阶椭圆偏微分方程如下，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123210401.png" alt=""></p>
<p>其中 $u$ 是我们的目标求解对象， $f(x)$ 就是右端项，在很多物理方程中被视为强迫项，而这个 $a(x)$ 是参数， $a \in \mathcal{A}$ ，其中 $\mathcal{A}$ 是参数空间。如果我们把其写成算子的形式，则表达成如下形式</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123210533.png" alt=""></p>
<p>其中 $\mathcal{L} \cdot =−div⁡(a\triangledown \cdot)$ ，下标 $a$ 的意思是说在参数 $a$ 时的算子 $\mathcal{L}$ 。</p>
<p>有一种偏微分方程求解析解的方法，被称作格林函数法。大概意思就是说，可以构造一个格林函数 $G$ ，定义域满足 $D \times D \rightarrow R$ ，使得方程解 $u$ 的形式可以写为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123210855.png" alt=""></p>
<p>这个格林函数 $G$ 可以理解为是一个核函数，这个思想大体就是说，假设 $x$ 的定义域是 $[0,1]$ ，则 $x=0.5$ 处的解 $u(0.5)$ 是受 $x$ 在 $[0,1]$ 所有点影响的，而这个影响大小取决于 $G$ ，比如 $G(0.5,0)$ 就是 $x=0$ 这个点对 $x=0.5$ 的影响，而 $G(0.5,1)$ 则同理。因为定义域是连续的，所以累加就变成了积分，而 $y$ 只是个积分符号而已，就代表格林函数后面的那个点在 $D$ 上积分。</p>
<p>之所以可以这么表达，是因为格林函数 $G$ 满足 $\mathcal{L}_{a}G(x, \cdot)=\delta a$ 其中 $\delta x$ 被称为狄拉克测度（dirac delta measure），测度这个概念比较抽象，在实数域里不妨就当dirac函数理解即可。dirac函数有一个性质，就是和任意函数积分后为函数本身，这样就可以证明了。下式成功的从左边推到了右边，和方程原始形式一致。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123211556.png" alt=""></p>
<p>受格林函数法的指导下，设计出了这么一个神经网络架构。这时候熟悉格林函数的朋友可能会问了，格林函数法成立的前提不是叠加原理么？叠加原理的前提不是线性微分方程么？难道其不能解决非线性方程么？其实神经网络的非线性激活函数就把这个问题解决了。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221123211716.png" alt=""></p>
<h3 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h3><h4 id="傅里叶变换的定义"><a href="#傅里叶变换的定义" class="headerlink" title="傅里叶变换的定义"></a>傅里叶变换的定义</h4><p>傅里叶变换将信号$f(t)$从时域转换到频域，得到频域信号$F(\omega)$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192138011.png" alt=""></p>
<h4 id="逆傅里叶变换的定义"><a href="#逆傅里叶变换的定义" class="headerlink" title="逆傅里叶变换的定义"></a>逆傅里叶变换的定义</h4><p>逆傅里叶变换将频域信号$F(\omega)$转换回时域信号$f(t)$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192156898.png" alt=""></p>
<h4 id="含义解读"><a href="#含义解读" class="headerlink" title="含义解读"></a>含义解读</h4><p>$F(\omega)$表示信号$f(t)$在频率$\omega$上的成分。每个$\omega$对应一个频率分量，$F(\omega)$的值（包括振幅和相位）描述了该频率分量的贡献。</p>
<p>通过对所有可能的$\omega$值进行积分（逆傅里叶变换），我们可以将频域信号$F(\omega)$转换回时域信号$f(t)$。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192157408.png" alt=""></p>
<h3 id="在傅里叶变换中，频域中的卷积操作简化为逐元素乘法的原理"><a href="#在傅里叶变换中，频域中的卷积操作简化为逐元素乘法的原理" class="headerlink" title="在傅里叶变换中，频域中的卷积操作简化为逐元素乘法的原理"></a>在傅里叶变换中，频域中的卷积操作简化为逐元素乘法的原理</h3><p>时域中的卷积定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192157467.png" alt=""></p>
<p>傅里叶变换定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192158252.png" alt=""></p>
<p>对卷积$(f\ast g)(t)$进行傅里叶变换：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192158767.png" alt=""></p>
<p>交换积分顺序：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192159160.png" alt=""></p>
<p>令$u=t−\tau$，则$t=u+\tau$，$dt=du$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192159176.png" alt=""></p>
<p>将指数项拆分：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192159204.png" alt=""></p>
<p>根据傅里叶变换的定义：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192200403.png" alt=""></p>
<p>将$G(\omega)$提到积分外：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192200460.png" alt=""></p>
<p>根据傅里叶变换的定义：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503192201897.png" alt=""></p>
<h3 id="FFT"><a href="#FFT" class="headerlink" title="FFT"></a>FFT</h3><p>为什么截断corner，这与numpy、pytorch对FFT的实现有关，先是低频，然后慢慢增长到高频，然后变成负的高频，慢慢增长到负的低频，所以低频信息就存在边角corner处。</p>
<h3 id="代码流程"><a href="#代码流程" class="headerlink" title="代码流程"></a>代码流程</h3><ol>
<li>输入是 $5\ast128\ast128\ast10\ast2$，分别代表批大小，x轴分辨率，y轴分辨率，时间步长，物理量数目；</li>
<li>首先将最后两维合并，变成 $5\ast128\ast128\ast20$；</li>
<li>接着将x轴和y轴坐标合并进来（坐标进行傅里叶变换有利于学到结构和形状），变成 $5\ast128\ast128\ast22$；</li>
<li>通过fc层进行升维，变成 $5\ast128\ast128\ast20$；</li>
<li>转换维度，变成 $5\ast20\ast128\ast128$；</li>
<li>做padding，变成 $5\ast20\ast130\ast130$；</li>
<li>做FFT，得到x_ft，大小为 $5\ast20\ast130\ast66$</li>
<li>生成一个同样大小的out_ft，按照需要的modes截断填充</li>
<li>做IRFFT，得到输出，大小为 $5\ast20\ast130\ast130$</li>
<li>unpadding，大小为 $5\ast20\ast128\ast128$</li>
<li>permutate之后得到输出，大小为 $5\ast128\ast128\ast20$</li>
<li>通过fc变换维度，变成 $5\ast20\ast128\ast128\ast128$</li>
<li>通过fc层转换到输出的维度，变成 $50\ast20\ast128\ast128\ast2$</li>
<li>通过unsqueeze函数增加时间维度，变成 $50\ast20\ast128\ast128\ast1\ast2$</li>
</ol>
<h3 id="为什么与分辨率无关"><a href="#为什么与分辨率无关" class="headerlink" title="为什么与分辨率无关"></a>为什么与分辨率无关</h3><p>对于CNN来说，理论上可以输入任意尺寸的大小，只要每次卷积的图像和卷积核的大小匹配得上，而傅里叶神经算子不涉及ViT当中的分成小patch或者CNN当中的卷积操作，他只在通道维度进行升维降维，因此是与分辨率无关的。</p>
<h1 id="A-composite-neural-network-that-learns-from-multi-fidelity-data-Application-to-function-approximation-and-inverse-PDE-problems"><a href="#A-composite-neural-network-that-learns-from-multi-fidelity-data-Application-to-function-approximation-and-inverse-PDE-problems" class="headerlink" title="A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems"></a>A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems</h1><p>我们提出了一种新的复合神经网络(NN)，可以基于多保真度数据进行训练。它由三个神经网络组成，第一个神经网络使用低保真度数据训练，并与两个高保真度数据耦合为了分别发现和利用低保真度和高保真度数据之间的非线性和线性相关性，一个具有激活函数，另一个没有激活函数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205170739.png" alt=""></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>主要就是充分利用不同精度的数据来得到更加精确的结果</p>
<ol>
<li>给定低精度数据 $\{x_{i}, y_{i}\}_{i=1}^{N_{l}}$ ，我们可以训练出一个低精度神经网络 $    \mathcal{NN}_{lf}$</li>
<li>同样，给定高精度数据 $\{x_{i},y_{i}\}_{i=N_{l}+1}^{N_{l}+N_{h}}$ ，我们可以训练出一个高精度神经网络 $\mathcal{NN}_{hf}$</li>
<li>然后将高精度数据输入到低精度网络当中，得到 $z_{i}$ ，即为高精度数据的低精度网络预测值。</li>
<li>将 $\{(x_{i},z_{i}),y_{i}\}_{i=N_{l}+1}^{N_{l}+N_{h}}$ 作为训练数据训练一个神经网络 $\mathcal{NN}_{lf \rightarrow hf}$ ，这个神经网络可以实现将低精度数据变为高精度数据。</li>
<li>考虑到线性和非线性的影响，$\mathcal{NN}_{lf\rightarrow hf}$ 可以变成两个神经网络的和，一个使用激活函数（非线性），另一个不使用激活函数。</li>
</ol>
<h1 id="NSFnets-Navier-Stokes-flow-nets-Physics-informed-neural-networks-for-the-incompressible-Navier-Stokes-equations"><a href="#NSFnets-Navier-Stokes-flow-nets-Physics-informed-neural-networks-for-the-incompressible-Navier-Stokes-equations" class="headerlink" title="NSFnets (Navier-Stokes flow nets): Physics-informed neural networks for the incompressible Navier-Stokes equations"></a>NSFnets (Navier-Stokes flow nets): Physics-informed neural networks for the incompressible Navier-Stokes equations</h1><h2 id="Abstract-11"><a href="#Abstract-11" class="headerlink" title="Abstract"></a>Abstract</h2><p>在许多实际情况下，我们仍然不能将无缝(多保真)数据合并到现有的算法中，而且对于工业复杂性的应用程序，网格生成是耗时的，仍然是一门艺术。此外，解决不适定问题（例如，缺乏边界条件）或逆问题通常是非常昂贵的，需要不同的公式和新的计算机代码。我们开发了通过考虑Navier-Stokes方程的两种不同的数学公式：速度-压力(VP)公式和涡速(VV)公式来建立Navier-Stokes流网(NSFnets)。与传统的数值方法不同，NSFnets继承了神经网络(NNs)的特性，因此总误差由近似误差、优化误差和泛化误差组成。在这里，我们尝试通过改变抽样来量化这些残差点，迭代求解器，以及NN体系结构的大小。</p>
<h2 id="Introduction-15"><a href="#Introduction-15" class="headerlink" title="Introduction"></a>Introduction</h2><p>在超过50年的时间里发展出了许多不同的计算流体动力学(CFD)方法，如果能精确地知道控制方程或精确地求解所有的尺度，这些方法就能非常有效地工作。然而，在许多现实世界的应用中，要么物理是不完全知道的，例如在反应输运中，要么解决尺度的大时空谱可能是非常昂贵的，因此求助于亚网格尺度闭包。在过去的五年中，人们采用不同的方法将神经网络(NNs)集成到不可压缩Navier-Stokes方程的求解中。对于湍流流动，最常见的方法是推导数据驱动的湍流闭合模型。</p>
<p>我们通过利用神经网络的普遍近似性质走了一条不同的道路，它使用自动微分使我们能够开发不需要网格生成的Navier-Stokes“求解器”。它们很容易实现，对于多物理和逆流体力学问题尤其有效（多保真度）数据可以为缺失的物理起到闭合的作用。Raissi等人首次引入了物理信息神经网络(PINN)的概念，以解决涉及几种不同类型的偏微分方程的正向和逆向问题。这一方法还被用于模拟涡旋诱导振动，并用于解决不适定逆流体力学问题，即“隐藏流体力学”的框架。一个基本问题是PINN是否可以直接模拟湍流，类似于使用高阶离散化的直接数值模拟(DNS)。另一个重要的问题是，是否有另一种Navier-Stokes方程的公式，例如涡速(VV)形式，可以达到更高的精度或可能适合更有效的训练。</p>
<p>VP-NSFnet的输入是时空坐标，输出是瞬时速度场和压力场。对于VV-NSFnet，输入仍然是空间和时间坐标，输出是瞬时速度和涡量场。</p>
<h2 id="Methodology-5"><a href="#Methodology-5" class="headerlink" title="Methodology"></a>Methodology</h2><p>不可压缩Navier-Stokes方程的VP形式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205203028.png" alt=""></p>
<p>Navier-Stokes方程的解决方案采用深度神经网络逼近，以空间和时间坐标作为输入，预测相应的速度场和压力场，VP形式的网络结构示意图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205214837.png" alt=""></p>
<p>Navier-Stokes方程VV形成的旋转形式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205215023.png" alt=""></p>
<p>VV形式的网络结构示意图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221205214955.png" alt=""></p>
<h1 id="Spatio-Temporal-Super-Resolution-of-Dynamical-Systems-using-Physics-Informed-Deep-Learning"><a href="#Spatio-Temporal-Super-Resolution-of-Dynamical-Systems-using-Physics-Informed-Deep-Learning" class="headerlink" title="Spatio-Temporal Super-Resolution of Dynamical Systems using Physics-Informed Deep-Learning"></a>Spatio-Temporal Super-Resolution of Dynamical Systems using Physics-Informed Deep-Learning</h1><h2 id="Abstract-12"><a href="#Abstract-12" class="headerlink" title="Abstract"></a>Abstract</h2><p>这项工作提出了一种基于物理的深度学习超分辨率框架，以提高时间相关偏微分方程(PDE)解的时空分辨率。先前关于基于深度学习的超分辨率模型的工作已经显示出通过减少传统数值格式的计算费用来加速工程设计的前景。然而，这些模型严重依赖训练期间所需的高分辨率(HR)标记数据的可用性。</p>
<p>在这项工作中，我们提出了一个基于物理的深度学习框架，以增强粗尺度(空间和时间上)PDE解决方案的空间和时间分辨率，而不需要任何HR数据。该框架由两个可训练模块组成，首先在空间上，然后在时间方向上独立地对PDE解决方案进行超分辨。基于物理的损失以一种新颖的方式实现，以确保不同时间的时空细化输出之间的紧密耦合，并提高框架精度。我们通过研究其在弹性动力学问题上的表现来分析所开发的框架的能力。结果表明，该框架在满足物理约束条件的同时，能够成功地在空间和时间上对低分辨率偏微分方程解进行超解析，并获得较高的精度。此外，分析和得到的加速结果表明，所提出的框架非常适合与传统数值方法集成，以降低工程设计中的计算复杂度。</p>
<h2 id="Introduction-16"><a href="#Introduction-16" class="headerlink" title="Introduction"></a>Introduction</h2><p>非线性系统动态行为的精确建模对于从微型MEMS传感器到大型结构系统的许多工业应用都是至关重要的。因此，人们正在进行重要的研究，以理解和解决在极小的空间和时间尺度上发生在这些动力系统内的复杂物理现象。这种捕捉发生在广泛变化的时空尺度上的复杂物理现象的科学追求导致了物理系统控制偏微分方程(PDEs)的日益复杂。例如，基于PDE的模型在纳米尺度上捕捉材料中的缺陷演化已被证明优于传统理论，具有广泛的应用范围。然而，大量的数据存储和高保真度模拟这种多物理场耦合偏微分方程所需的计算费用使传统的数值求解方法达到了极限。因此，在多尺度上快速准确地执行这些多物理场模拟的技术是至关重要的。</p>
<p>另一方面，机器学习(ML)的最新进展导致了几个数据驱动和物理知情ML模型的发展，以解决流体中发生的偏微分方程和固体力学。然而，从其理论考虑(如收敛性、稳定性、准确性和可泛化性)到边界条件、神经网络架构设计或优化方面的问题仍需要完全解决。因此，将基于物理的ML与传统方法相结合的混合策略正在成为解决复杂的多物理场微分方程的计算挑战的一个有前途的选择。</p>
<p>为此，在本研究中，我们旨在研究一种集成ML和传统方法的两阶段混合方法，以获得(重建)时空偏微分方程的解。1）在第一阶段，通过在空间和时间上进行粗尺度的数值模拟(使用大网格尺寸和时间步长)获得低分辨率PDE解。与精细尺度的PDE求解相比，可以生成具有满意精度的低分辨率解，并大大减少了计算费用。2）在第二阶段，使用物理形成的基于深度学习的框架增强了该粗尺度解决方案的时空分辨率。这种“物理引导分辨率增强”方法的一个显著优势是减少了科学探索阶段的计算费用和数据存储需求，这将大大加快科学调查和工程设计的进程。这种分辨率的增强在本研究中也被称为上采样或超分辨率(SR)。</p>
<p>最近的工作涉及物理系统的时空超分辨率使用标记高分辨率(HR)真实数据进行模型训练。Fukami等人提出了一个纯数据驱动的SR框架，因此超分辨场可能无法准确地满足基于物理的约束。Ren等人和Soheil等人“几乎是数据驱动的”，因为预测/数据损失的比例系数被选择为总损失中物理损失系数的20倍，以获得最佳精度。事实上，如果不考虑人力资源标签数据(纯物理驱动)，误差是巨大的。此外，获得人力资源标记的数据的计算成本很高。因此，在训练期间使用它完全否定了ML模型旨在实现的加速科学计算的巨大好处。在这项研究中，我们提出了一个基于物理信息的端到端深度学习框架，以增强粗尺度(空间和时间)PDE解决方案的空间和时间分辨率，而不需要任何高分辨率标记的数据。</p>
<h2 id="Background-1"><a href="#Background-1" class="headerlink" title="Background"></a>Background</h2><h3 id="Governing-equations"><a href="#Governing-equations" class="headerlink" title="Governing equations"></a>Governing equations</h3><p>控制动力系统的典型的时空偏微分方程可以写成如下形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217220123.png" alt=""></p>
<p>初始条件和边界条件：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217220133.png" alt=""></p>
<p>式中， $z$ 表示由 $m$ 个状态变量组成的系统解， $\dot{z}$ 表示其时间导数。 $\mathcal{F}$ 是多项式的非线性泛函及其参数的导数项。 $\Omega$ 和 $\partial\Omega$ 分别表示物理域及其边界。系统中固有的或由于数值方法(如混合有限元方法)而需要的任何附加约束，都可以组合成 $\mathcal{C}(z)=0$ 。</p>
<p>给出方程在粗尺度上求解得到的解 $z_{c}$ (大网格尺寸和时间步长)，我们的目标是通过使用基于物理的深度学习方法来提高解决方案的空间和时间分辨率。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217220736.png" alt=""></p>
<h2 id="Methodology-6"><a href="#Methodology-6" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Objective-function"><a href="#Objective-function" class="headerlink" title="Objective function"></a>Objective function</h3><p>我们注意到，在这项工作中提出的框架是无监督的，因此复合损失函数只能从系统的控制方程-初始条件，边界条件和偏微分方程中获得。我们以“硬”方式（准确地）施加边界条件，从而消除了复合损失对边界条件损失的贡献。基于物理的目标函数如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217221314.png" alt=""></p>
<p>我们使用四阶有限差分格式来计算网格上解的空间导数。对于时间离散化，我们使用了Crank-Nicholson算法，该算法具有无条件稳定的优点，并且在空间和时间维度上都是二阶精确的。</p>
<h3 id="Input-and-output-for-the-framework"><a href="#Input-and-output-for-the-framework" class="headerlink" title="Input and output for the framework"></a>Input and output for the framework</h3><p>框架的输入由LR粗尺度偏微分方程在连续时间步长 $t$ 和 $t+\Delta t$ 的解所构成的元组 $\mathcal{I}_{c}^{t}=\{z_{c}^{t},z_{c}^{t+\Delta t}\}$ 组成。该框架的输出包括在相同时间步长的空间上放大的偏微分方程解 $\{\hat{z}^{t},\hat{z}^{t+\Delta t}\}$ 和 (k−1)中间时间步长的HR快照的合成 $\{\hat{z}^{t+\frac{\Delta}{k}},\hat{z}^{t+2\frac{\Delta}{k}},\cdots,\hat{z}^{t+(k-1)\frac{\Delta}{k}} \}$ 。因此，该框架在(k + 1)个时间步 $\mathcal{O}^{t}$ 产生空间上放大的PDE解决方案。我们将标量k称为时间上标因子，它表示为粗尺度时间步与细尺度时间步的比值，即 $k=\frac{\Delta t_{c}}{\Delta t_{f}}$ 。同样，空间方向s上的升尺度因子为粗网格分辨率与细网格分辨率之比，即 $s=\frac{\Delta x_{c}}{\Delta x_{f}}$ 。</p>
<h3 id="Framework-Architecture"><a href="#Framework-Architecture" class="headerlink" title="Framework Architecture"></a>Framework Architecture</h3><p>该框架由两个可训练模块组成:空间分辨率增强模块和时间分辨率增强模块。这两个模块分别独立执行空间和时间上的超分辨率。我们观察到，这种双模块方法首先在空间中执行超分辨率，随后增加时间分辨率，从而导致超分辨率场的更好收敛性和准确性，这也在Fukami等人的数据驱动方法中观察到。</p>
<p>任何动力系统的典型解 $z$ 由 $m$ 个状态变量组成。因此，框架中的每个模块由 $m$ 个深度学习模型(具有相同的架构)组成，分别重构每个状态变量。然而，这些模型在训练过程中通过目标函数(损失)进行耦合。第3.3.1节和3.3.2节分别更详细地讨论了这些空间和时间超分辨率模块。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217223920.png" alt=""></p>
<h4 id="Spatial-resolution-enhancement-module"><a href="#Spatial-resolution-enhancement-module" class="headerlink" title="Spatial resolution enhancement module"></a>Spatial resolution enhancement module</h4><p>对于状态向量 $z$ ，给定两个连续时间步长的LR快照元组 $\mathcal{I}_{c}^{t}=\{z_{c}^{t},z_{c}^{t+\Delta t}\}$ ，空间提升模块输出相应的HR帧 $\{\hat{z}^{t},\hat{z}^{t+\Delta t}\}$ 表示输入状态在原时间步长的增强空间分辨率。因此，输入（输出）由表示时间步长 $t$ 和 $t+\Delta t$ 时LR (HR)状态变量值的双通道图像组成。</p>
<p>在训练过程中，我们观察到，为了从两个输出通道中的初始条件成功地演化出解决方案，PDE损失必须在输出内部和跨输出实现。这种损耗耦合有助于减轻该模块的传输故障模式。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221217232831.png" alt=""></p>
<p>空间提升模块中的每个模型都建立在中提出的残差密集网络(Residual Dense Network, RDN)之上，与其他网络相比，RDN在图像SR方面具有独特的优势。我们使用4个残差块，每个块有8层，特征通道大小为32。卷积的核大小设置为3。</p>
<h4 id="Temporal-resolution-enhancement-module"><a href="#Temporal-resolution-enhancement-module" class="headerlink" title="Temporal resolution enhancement module"></a>Temporal resolution enhancement module</h4><p>时态模块增强了状态变量在时间上的分辨率。空间模块的输出作为时间模块的输入。因此，输入是表示时间步长 $t$ 和 $t+\Delta t$ 的HR状态变量值的双通道图像。该模块输出带有(k+1)个通道的图像，用来表示在时间步长 $\{t, t+\frac{\Delta t}{k},\cdots, t+\Delta t\}$ 的状态变量。我们在这里注意到，时间模块的输入仍然存在 $O(\Delta t^{2})$ 阶的时间离散化误差。因此，时间模块也会在初始时间 $t$ 和最终时间 $t+\Delta t$ 重建解，将此误差减小到 $O((\frac{\Delta t}{k})^{2})$ 。为了训练这个模块，我们对复合损失做了如下修改:</p>
<ul>
<li>类似于空间模块中PDE损耗的实现，空间模块的PDE损失也是实现在输出和跨输出。</li>
<li>由于我们在初始时间步长和最终时间步长( $t$ 和 $t+\Delta t$ )重构了输出，因此我们在这些输入和输出之间增加了约束损失，这有助于更快地收敛模块。</li>
</ul>
<h1 id="Error-Aware-B-PINNs-Improving-Uncertainty-Quantification-in-Bayesian-Physics-Informed-Neural-Networks"><a href="#Error-Aware-B-PINNs-Improving-Uncertainty-Quantification-in-Bayesian-Physics-Informed-Neural-Networks" class="headerlink" title="Error-Aware B-PINNs: Improving Uncertainty Quantification in Bayesian Physics-Informed Neural Networks"></a>Error-Aware B-PINNs: Improving Uncertainty Quantification in Bayesian Physics-Informed Neural Networks</h1><h2 id="Abstract-13"><a href="#Abstract-13" class="headerlink" title="Abstract"></a>Abstract</h2><p>基于物理的神经网络(PINN)作为求解微分方程的一种方法正越来越受欢迎。虽然在某些情况下比经典的数值技术更可行，PINN仍然缺乏可信度。在不确定性量化(UQ)中可以找到一种补救方法，它刚刚开始出现在PINN的背景下。评估训练好的PINN是否符合强加微分方程是解决不确定性问题的关键，但目前还缺乏全面的方法。我们提出了一个贝叶斯PINN (B-PINN)中UQ的框架，它包含了B-PINN解和未知真解之间的差异。我们利用线性动力系统上PINN的误差界的最新结果，证明了一类线性ODE的预测不确定性。</p>
<h2 id="Introduction-17"><a href="#Introduction-17" class="headerlink" title="Introduction"></a>Introduction</h2><p>物理神经网络(PINN)是深度神经网络(DNN)，能够将微分方程(PDEs)编码为神经网络本身的一个组成部分。Lagaris等的早期结果首次提出使用神经网络求解微分方程，随后近年来关于PINN的出版物迅速增长。与传统数值求解器相比，PINN具有许多优点，例如，它们提供封闭形式的解，是无网格的。例如，在培训后支持按需解决方案计算，可以通过利用迁移学习快速发现新的解决方案，等等。</p>
<p>然而，为了真正蓬勃发展并部署在安全关键应用中，像PINN这样的深度学习技术需要是可靠的，即赋予高质量的不确定性量化(UQ)方法。在PINN的背景下，UQ方法仍然很少被使用，也没有公认的黄金标准。最近，基于物理的高斯过程(PIGP)和贝叶斯PINNs (B-PINNs)已被提出作为经典贝叶斯概率机器学习技术的对应物。另一个研究方向考虑了生成对抗网络的使用，其中贝叶斯推理在潜在空间而不是参数空间中执行。</p>
<p>由于存在多种不确定性来源，从噪声数据到模型架构相关问题，B-PINN中的UQ可以被视为比传统数值求解器中的UQ更具挑战性。还有一个黑盒不确定性，与网络实际上如何被告知控制物理方程有关。它源于PINN的无监督性质，但由于考虑到有噪声的测量数据，它经常被掩盖。作为一项规则，所有前面提到的不确定性来源都是使用一个“一概而论”的术语来建模的。在这项工作中，我们的目标是解开这些不确定性，并展示如何用有用的误差估计在总不确定性中增加单独的项，从而提高UQ方法的预测质量。</p>
<h2 id="Background-2"><a href="#Background-2" class="headerlink" title="Background"></a>Background</h2><h3 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h3><p>PINN可以解最一般形式的微分方程，如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218200105.png" alt=""></p>
<h3 id="Physics-Informed-Neural-Networks-1"><a href="#Physics-Informed-Neural-Networks-1" class="headerlink" title="Physics-Informed Neural Networks"></a>Physics-Informed Neural Networks</h3><p>软约束：边界/初值条件作为损失项加入loss当中</p>
<p>硬约束： $\widetilde{u}_{\theta}(x)=u_{0}+(1 - e^{-(x-x_{0})})u_{\theta}(x)$</p>
<h3 id="Uncertainty-Quantification-in-Bayesian-Neural-Networks"><a href="#Uncertainty-Quantification-in-Bayesian-Neural-Networks" class="headerlink" title="Uncertainty Quantification in Bayesian Neural Networks"></a>Uncertainty Quantification in Bayesian Neural Networks</h3><p>假设我们有一个有限的观测集合 $O$ ，在一个有界的区域 $\Omega_{O} \subset \Omega$ 。假设观测值是独立同分布的，并且是从分布 $p(O|\theta)$ 中得出的。这种分布被称为似然函数并且通常是由一个可分解的高斯分布建模的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218202953.png" alt=""></p>
<p>均值 $y_{\theta}$ 是由相关神经网络给出的并且 $\Sigma_{O} = \sigma^{2}_{O}I$ 。因此，假设观测结果 $O$ 是由数据生成过程产生的，该过程包含由 $y_{\theta}$ 建模的确定性部分以及一些附加噪声。此噪声表示不可约或任意的不确定性，其协方差矩阵 $\Sigma_{O}$ 可能是已知的或假设的，也可能是从数据中推断出来的。</p>
<p>标准的神经网络训练以频率论的方式进行，不考虑不确定性。模型参数 $\theta$ 通过最大化似然来推断为点估计，假设似然是高斯的，则等于均方误差最小化。请注意，在无监督PINN的情况下，为了推导MSE损失，我们假设虚拟“观测值”总是等于零，而均值由剩余网络 $r_{\theta}$ 给出， $\sigma^{2}_{O}$ 可以是任意的。</p>
<p>与频率论推理相反，贝叶斯推理不仅在观测值 $O$ 上放置分布，而且在参数 $\theta$ 上也放置分布，从而形成贝叶斯神经网络(BNNs)。贝叶斯框架中参数的概率性导致了认知的不确定性。</p>
<p>参数 $θ$ 的后验分布，即基于观测值 $O$ 的“合理”参数值的分布，由贝叶斯定理给出，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218205354.png" alt=""></p>
<p>其中 $p(\theta)$ 是参数的先验分布， $p(O)$ 是证据。通过(5)精确地获得后验值通常在计算和分析上是难以解决的。</p>
<p>UQ的目标是估计预测分布 $p(y |x,O)$ 。其中,  $\hat{y}$ 表示在 $x$ 预测并且在给定的观测 $O$ 上具有条件分布。它可以通过对模型参数 $\theta$ 积分得到，或者，如果难以计算，可以用蒙特卡罗估计进行近似，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218210144.png" alt=""></p>
<p>其中 $θ^{∗}_{i} \thicksim p(\theta|O)$ 为后验样本。</p>
<p>预测分布的均值可近似计算为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218212706.png" alt=""></p>
<p>预测分布的方差也可以近似计算。利用总方差定律，并假设分布 $p(y|x,\theta)$ 具有与(4)相同的均值和方差，我们有</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221218212838.png" alt=""></p>
<p>(8)中的第一个和第二个总和分别表示总不确定性的任意部分和认识部分。</p>
<h4 id="Methods-for-Finding-the-Posterior-Distribution"><a href="#Methods-for-Finding-the-Posterior-Distribution" class="headerlink" title="Methods for Finding the Posterior Distribution"></a>Methods for Finding the Posterior Distribution</h4><p>最流行的后验逼近方法可分为两大类:抽样法和变分法。对于简化后的BNN，还有一种有效的封闭解，即丢弃隐层中的参数分布，只保留最后一层中的参数分布。我们将其称为神经线性模型(NLM)。</p>
<p>抽样方法。马尔可夫链蒙特卡罗方法利用 $p(\theta|O)$ 为平稳分布的马尔可夫链从后验中抽取参数样本。广泛使用的方法是哈密顿蒙特卡罗和朗之万动力学。这种方法的缺点是计算成本高。在本文中我们将不考虑它们。</p>
<p>变分方法。变分推理(VI)方法通过使用变分分布 $q_{w}(θ)$ 来近似 $p(\theta|O)$ ，该分布通过最大化证据下界来优化 $w$ 。流行的方法是反向传播贝叶斯(利用因式高斯变分分布)和蒙特卡洛Dropout (通过对每个样本随机降低固定百分比的参数来抽取样本)。</p>
<p>确切的方法。NLM 代表了可处理性和表达性之间的妥协。可以将NLM解释为学习到的特征基 $\Phi_{w} =[\phi_{w}(x_{1}),\cdots,\phi_{w}(x_{M})]^{T}$对其进行贝叶斯线性回归执行 $\Phi_{w}\theta$ 。我们将用 $r_{\theta}^{NLM}$ 表示用NLM训练的残差网络，以便与标准BNN区分开来。</p>
<h2 id="Uncertainty-Quantification-in-B-PINNs"><a href="#Uncertainty-Quantification-in-B-PINNs" class="headerlink" title="Uncertainty Quantification in B-PINNs"></a>Uncertainty Quantification in B-PINNs</h2><p>在前一节中，我们在一个集合术语 $O$ 下考虑了所有可观测信息。事实上，在PINN的背景下，这些观测包括各种来源：噪声和/或有限的数据，与控制物理方程的一致性，物理模型中的随机性，神经网络架构。我们将用 $\mathcal{D}$ 表示与数据相关的观测值，用 $\mathcal{P}$表示与方程相关的观测值，其余观测值统称为 $\mathcal{H}$ 。如前所述，我们的主要目标是研究具有固定DNN架构的无数据确定性情况，因此我们将专注于建模 $\mathcal{P}$ 对不确定性的影响。随后，可以将其纳入一般框架，从而得到预测分布 $p(u|x,\mathcal{D},\mathcal{P},\mathcal{H})$ 。这里， $u$ 表示DE解的概率预测。</p>
<p>据我们所知，与B-PINN相关的方程观测在文献中还没有被彻底研究过。其中一个原因可能是不可能完全理清不确定性的不同来源：</p>
<ul>
<li>$f$ 的观测值可以同时看作数据相关观测值 $\mathcal{D}$ 和方程相关观测值 $\mathcal{P}$ 。因此，由于不需要为 $\mathcal{P}$ 构造一个特殊的似然函数，这可能会模糊了在后面的推理阶段明确考虑 $\mathcal{P}$ 的重要性。</li>
<li>(8)中的总方差受任意不确定性影响不仅通过相应的项，而且通过认知项，预计会随着噪音的增加而增加。这就模糊了 $Var(\hat{u} |x,\mathcal{P})$ 中任意项 $\sigma_{\mathcal{P}}^{2}$ 正确建模的重要性。事实上，现有的B-PINN方法中没有这项，这可能导致不确定性估计不太可靠。</li>
</ul>
<h3 id="Existing-Approach"><a href="#Existing-Approach" class="headerlink" title="Existing Approach"></a>Existing Approach</h3><p>由于我们假设 $f$ 是完全已知的，并且没有噪声，我们可以考虑一个虚拟数据集 $\mathcal{D} = \{(x_{j},0)\}^{M}_{j=1}$，而相应的似然由</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219220719.png" alt=""></p>
<p>如果 $\sigma^{2}_{\mathcal{D}}$ 是未知的，可以估计，例如，通过分层建模。假设先验分布 $p(\theta)$ 为零均值和对角协方差矩阵的高斯分布。相应的方差，如果不知道，可以类似地推断 $\sigma^{2}_{\mathcal{D}}$ 。然后，在我们使用第2.3.1节的方法从后验中获得样本后，我们估计预测分布</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219221457.png" alt=""></p>
<p>由于我们处于无数据的情况下，(10)右边的分布的自然选择是</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219222626.png" alt=""></p>
<p>将(11)代入(8)产生如下式子，其中只有认知不确定性的项</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219222817.png" alt=""></p>
<p>虽然(12)中的预测方差通过 $\mathcal{D}$ 隐式地“告知”了底层DE，但它可能不足以覆盖训练区域之外的真实解，或者当B-PINN由于某种原因没有得到很好的训练时，如图1所示。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219225014.png" alt=""></p>
<p>当前方法的另一个缺点是它与 $r_{\theta}^{NLM}$ 不兼容。通过施加 $\mathcal{F}_{\lambda}[\Phi_{w}\theta]$ ，我们失去了推导封闭形式解的能力。</p>
<h3 id="Error-Aware-B-PINNs"><a href="#Error-Aware-B-PINNs" class="headerlink" title="Error-Aware B-PINNs"></a>Error-Aware B-PINNs</h3><p>在带BNN的经典函数逼近问题中，除非对函数类没有特定的假设，否则不能保证不确定性覆盖无数据区域的误差 $y−y_{\theta}$ 。与BNN不同，B-PINN在一定程度上意识到代理网络和真实解之间的差异。当然，这取决于对损失函数的选择，以及所选损失函数与代理网络所犯错误之间的联系。</p>
<p>在本节中，我们引入一个伪任意不确定性，量化 $u$ 和 $u_{\theta}$ 之间的差异。我们仍然称它为任意不确定性，因为它在经典贝叶斯框架中充当了任意不确定性的对应物。另一方面，它不是来自数据，而是来自PINN本身。</p>
<p>我们的目标是构造一个分布 $p(\hat{u}|x,\theta,\mathcal{P})$ ，其均值由 $u_{\theta}(x)$ 给出，伪任意方差由某个算子 $E$ 给出，该算子作用于预训练的PINN，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219230838.png" alt=""></p>
<p>其中 $r_{MSE}(x)$ 表示用MSE训练的PINN。显然，这不是一个简单的任务，它提出了如何构造 $E$ 以及如何找到PDE的适当功能形式的问题。在这一点上，我们能够在线性动力系统的特殊情况下用可证明的保证回答第一个问题(见第3.2.1节)。对于 $p(\hat{u}|x,\theta,\mathcal{P})$ 的泛函形式，我们考虑正态分布作为概念的证明。虽然它不代表真实解的概率，但它确保了在误差高的区域不确定性被夸大，并且真实解被不确定性覆盖。</p>
<p>误差感知情况下的预测方差为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219232152.png" alt=""></p>
<p>对于不属于第3.2.1节类别的DE，没有关于如何构造(13)的严格理论。可以考虑各种启发式方法，而最简单的方法是使用 $E[r_{MSE}(x)] = r_{MSE}(x)$ 或 $E[r_{MSE}(x_{n})] =\Sigma_{i=0}^{n} r_{MSE}(x_{i})$ 。我们在第3.2.2节中用一个非线性偏微分方程的例子来测试后者。</p>
<p>现在我们展示如何将我们的方法与rθNLM结合起来，这样封闭形式的解仍然存在。也就是说，我们的伪随机方差分布可以作为模拟数据 $\mathcal{D}_{\mathcal{P}}=\{(x_{j},u_{MSE}(x_{j}))\}^{M}_{j=1}$的似然函数，其中 $u_{MSE}$ 表示用MSE训练的代理网络，得到</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219235252.png" alt=""></p>
<p>如果与这种可能性结合使用， $r_{\theta}^{NLM}$ 提供了可处理的推断。注意 $\sigma^{2}_{\mathcal{P}}(x_{j})$ 现在是异方差的。只要具有异方差的贝叶斯线性回归模型不太常用，我们在这里给出了预测分布的显式形式，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221219235653.png" alt=""></p>
<p>其中后验协方差矩阵和平均值是由</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221220000003.png" alt=""></p>
<p>我们在算法2中总结了我们的错误感知B-PINN的方法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221220001036.png" alt=""></p>
<h2 id="My-Summary"><a href="#My-Summary" class="headerlink" title="My Summary"></a>My Summary</h2><p>这篇文章使用B-PINN的相关做法来表达认知不确定性，使用PINN训练的结果来表达偶然不确定性。</p>
<h1 id="A-Dimension-Augmented-Physics-Informed-Neural-Network-DaPINN-with-High-Level-Accuracy-and-Efficiency"><a href="#A-Dimension-Augmented-Physics-Informed-Neural-Network-DaPINN-with-High-Level-Accuracy-and-Efficiency" class="headerlink" title="A Dimension-Augmented Physics-Informed Neural Network(DaPINN) with High Level Accuracy and Efficiency"></a>A Dimension-Augmented Physics-Informed Neural Network(DaPINN) with High Level Accuracy and Efficiency</h1><h2 id="Abstract-14"><a href="#Abstract-14" class="headerlink" title="Abstract"></a>Abstract</h2><p>在DaPINN模型中，我们在神经网络中引入了归纳偏差，通过在损失函数中添加一个特殊的正则化项来增强网络的泛化性。此外，我们通过插入额外的样本特征来操纵网络输入维度，并将扩展的维度合并到损失函数中。</p>
<h2 id="Introduction-18"><a href="#Introduction-18" class="headerlink" title="Introduction"></a>Introduction</h2><p>PINN的输入维数通常取决于方程变量的数量，这比自然语言处理和计算机视觉等其他领域的神经网络中的变量数量要低得多。网络的输入维数客观上影响着网络的准确性。例如，在卷积神经网络(CNN)中，图像分辨率的降低降低了模型性能。因此，输入维度可以通过在输入向量中插入更多的特征来增强PINN。</p>
<p>在这项工作中，我们提出了一种维数增强的PINN (DaPINN)，通过系统地操纵网络输入维数来提高PINN的准确性和效率，扩展维数由考虑偏导数的损失函数约束。DaPINN模型采用幂级数增广、傅立叶级数增广和复制增广等方法提高了求解精度。</p>
<h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><h3 id="Physics-informed-neural-networks-PINN"><a href="#Physics-informed-neural-networks-PINN" class="headerlink" title="Physics-informed neural networks (PINN)"></a>Physics-informed neural networks (PINN)</h3><p>PINN相关知识</p>
<h3 id="Dimension-augmentated-PINN"><a href="#Dimension-augmentated-PINN" class="headerlink" title="Dimension-augmentated PINN"></a>Dimension-augmentated PINN</h3><p>引入映射函数：<img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230211153611.png" alt=""></p>
<p>新的神经网络的输入维数为n，而PINN的输入维数只与x的大小相关。</p>
<p>DaPINN模型的损失函数中PDE的残差项和边界/初始误差可以重新表示为如下形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230211155200.png" alt=""></p>
<p>例如，对于一维拉普拉斯方程： $\Delta u(x)=0$ ，通过使用映射 $t_{1}:x \rightarrow x,t_{2}:x \rightarrow x^{2}$ 时，双输入神经网络可构造为 $\mathcal{N}(\tau_{1},\tau_{2})$ 。将微分方程的残差项可以很简单地表示为（根据复合函数求导得来）</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212144228.png" alt=""></p>
<h3 id="Several-input-dimension-augmentation-methods"><a href="#Several-input-dimension-augmentation-methods" class="headerlink" title="Several input dimension augmentation methods"></a>Several input dimension augmentation methods</h3><ol>
<li>Power series augmentation（幂级数增广）：这个想法是从函数的泰勒展开得来的</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212153208.png" alt=""></p>
<ol>
<li>Fourier series augmentation（傅里叶级数增广）：引入这样的映射 $t_{1}: x \rightarrow x, t_{2} : x \rightarrow sin(\frac{2 \pi nx}{T}),<br>t3 : x \rightarrow cos(\frac{2 \pi nx}{T})$ 。由于任何周期函数都可以写成三角函数的和，通过傅里叶级数的增广公式，可以用三角级数近似表示该函数。傅立叶级数增广法可用于具有周期性边界条件的问题。</li>
<li>Replica augmentation（复制增广）：引入映射 $t{1} : x \rightarrow x; t_{2} : x \rightarrow x  $ 。这种扩展方法引入了镜像输入，为网络逼近提供了多条路径，从而提高了模型的精度。</li>
</ol>
<h1 id="L-HYDRA-MULTI-HEAD-PHYSICS-INFORMED-NEURAL-NETWORKS"><a href="#L-HYDRA-MULTI-HEAD-PHYSICS-INFORMED-NEURAL-NETWORKS" class="headerlink" title="L-HYDRA: MULTI-HEAD PHYSICS-INFORMED NEURAL NETWORKS"></a>L-HYDRA: MULTI-HEAD PHYSICS-INFORMED NEURAL NETWORKS</h1><h2 id="Abstract-15"><a href="#Abstract-15" class="headerlink" title="Abstract."></a>Abstract.</h2><p>我们将多头神经网络(MH-NNs)引入到基于物理的机器学习中，它是一种以所有非线性隐藏层为主体，以多个线性输出层为多头的神经网络。因此，我们构建了多头物理神经网络(MH-PINNs)，作为多任务学习(MTL)、生成建模和科学机器学习(SciML)中各种问题的少镜头学习的有效工具。MH-PINNs通过共享主体作为基本功能和头部的共享分布连接多个功能/任务。前者通过MH-PINNs解决多个任务，每个头独立对应于每个任务，而后者通过采用归一化流(NFs)进行密度估计和生成建模。</p>
<h2 id="Introduction-19"><a href="#Introduction-19" class="headerlink" title="Introduction."></a>Introduction.</h2><p>一些相关背景知识。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212155919.png" alt=""></p>
<h2 id="Methodology-7"><a href="#Methodology-7" class="headerlink" title="Methodology."></a>Methodology.</h2><p>在本文中，我们将 $\{ \mathcal{T_{k}} \}_{k=1}^{M}$ 作为一个整体，并将它们与MH-PINNs连接起来，在解决方案 $u_{k}$ 上强制执行基函数共享预测。除了信息表示/主体，我们进一步将 $\{ \mathcal{T_{k}} \}_{k=1}^{M}$ 联系起来，假设它们在MH-PINNs中对应的头部，记为 $\{ H_{k} \}_{k=1}^{M}$ ，分别是具有未知概率密度函数(PDF)的随机变量的样本，记为 $H$ 和 $P(H)$ 。通过将 $u$ 代入和自动微分，共享体和 $H$ 的生成模型立即形成解 $u$ 的生成模型，同时生成源项 $f$ 和边界/初始项 $b$ 的生成项，由此无缝地发展了随机过程近似的生成方法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212163209.png" alt=""></p>
<p>主体表示从MH-PINNs求解 $\{ \mathcal{T_{k}} \}_{k=1}^{M}$ 中学习到的基函数集，头部的密度使用NFs从其样本中估计出来，与主体一起作为正则化、先验分布或生成器，这取决于MH-PINNs在应用中的使用情况。</p>
<h3 id="Multi-head-physics-informed-neural-networks-MH-PINNs"><a href="#Multi-head-physics-informed-neural-networks-MH-PINNs" class="headerlink" title="Multi-head physics-informed neural networks (MH-PINNs)."></a>Multi-head physics-informed neural networks (MH-PINNs).</h3><p>我们用 $\Phi$ 表示主体，用 $H_{k}$ 表示 $\mathcal{T}_{k}$ 的头部。注意这里 $\Phi: \mathbb{R}^{D_{x}} \rightarrow \mathbb{R}^{L}$ 是一个参数为 $\theta$ 的神经网络参数化的函数， $H_{k} \in \mathbb{R}^{L+1}$ 是一个向量，其中 $L$ 是主体最后一层神经元的数量。让我们定义 $H_{k} = [h^{0}_{k},h^{1}_{k},\cdots,h^{L}_{k}]^{T}$ ， $\Phi(x) = [\phi^{1}(x),\cdots,\phi^{L}(x)]^{T}$ ，其中 $\phi : \mathbb{R}^{D_{x}} \rightarrow \mathbb{R}$ ，则 $\mathcal{T}_{k}$ 中解的代入式可改写为 $\hat{u}_{k}(x)=h_{k}^{0}+\sum_{l=1}^{L}h_{k}^{l}\phi^{l}(x),\forall x \in \Omega$ 。</p>
<h3 id="Generative-modeling-and-normalizing-flows-NFs"><a href="#Generative-modeling-and-normalizing-flows-NFs" class="headerlink" title="Generative modeling and normalizing flows (NFs)."></a>Generative modeling and normalizing flows (NFs).</h3><p>MH-PINNs通过两个假设连接 $\{ \mathcal{T}_{k} \}_{k=1}^{M}$ ：(1)解 $u_{k},k=1,\cdots,M$ 共享同一组基函数， $\Phi$ (2)对应系数为同一随机变量 $H$ 的样本。在这项工作中，我们通过利用来自头部的信息，以及通过估计PDF和来自其样本的 $H$ 的生成器 $\{ H_{k} \}_{k=1}^{M}$ ，使用归一化流来扩展它(NFs)。我们选择NFs而不是其他常用的生成模型，例如生成对抗网络(GANs)，变分自动编码器(VAE)，或扩散模型，因为NF既可以作为密度估计器，也可以作为生成器。前者能够在下游的少量物理信息学习任务中提供适当的正则化，而后者则导致了一种物理信息生成方法来逼近随机过程。我们的模型通过头部的样本进行学习，这是第一步从MTL中获得的。这种学习策略带来了两个巨大的优势：(1)处理非结构化数据的灵活性，例如跨任务的不一致测量；(2)通过将物理知识学习和生成建模分离，实现训练的简单性和可控性。</p>
<h3 id="Prior-knowledge-utilized-in-the-downstream-tasks"><a href="#Prior-knowledge-utilized-in-the-downstream-tasks" class="headerlink" title="Prior knowledge utilized in the downstream tasks."></a>Prior knowledge utilized in the downstream tasks.</h3><p>在这里，我们详细描述了如何利用MH-PINNs中存储的先验知识，用于下游的少量物理知识学习任务 $\tilde{\\ \mathcal{T} \\}$ ，它的定义与上游训练中的所有其他任务相同，但测量量要少得多。训练MH-PINNs和NFs得到一个主体 $\Phi$ ，头部样本 $\{ H_{k} \}_{k=1}^{M}$ ，以及对头部的估计 $\hat{p}(H)=p(H)$ 。在用 $\tilde{\mathcal{D}}$ 求解 $\tilde{\\ \mathcal{T} \\}$ 时，我们固定了主体 $\Phi$ ，找到了头部 $\tilde{H}$ 最好地解释了数据 $\tilde{\mathcal{D}}$ 和物理知识。</p>
<p>本文考虑了无噪声数据和有噪声数据：对于无噪声数据，针对新任务对头部进行常规NN训练，以提供确定性预测，其中学习到的头部PDF $\hat{p}(H)$ 作为损失函数中的正则化项；对于有噪声的数据，贝叶斯推理也在头部进行，其中 $\hat{p}(H)$ 表示先验分布。</p>
<h4 id="Regularization-in-optimization"><a href="#Regularization-in-optimization" class="headerlink" title="Regularization in optimization."></a>Regularization in optimization.</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212201155.png" alt=""></p>
<h4 id="Prior-distribution-in-Bayesian-inference"><a href="#Prior-distribution-in-Bayesian-inference" class="headerlink" title="Prior distribution in Bayesian inference."></a>Prior distribution in Bayesian inference.</h4><p>与通过求解优化问题(2.4)得到的点估计不同，头部在 $\tilde{\\ \mathcal{T} \\}$ 的后验分布是通过贝叶斯推理得到的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230212202332.png" alt=""></p>
<h2 id="My-Summary-1"><a href="#My-Summary-1" class="headerlink" title="My Summary"></a>My Summary</h2><p>文章整体思路有点类似神经算子的思路。用了类似DeepONet中的方式，提取出基函数，对于训练数据 $x \in \mathbb{R}^{D}$ ，训练神经网络得到维度为 $L$ 的body向量 $\Phi(x)$ ；同时对于每一个任务，我们采样维度为 $L+1$ 的head向量 $H_{k}$ ，通过这些向量我们可以推测出head向量的密度分布。对于每个任务，我们想要的解就是 $\hat{u}_{k}(x)=h_{k}^{0}+\sum_{l=1}^{L}h_{k}^{l}\phi^{l}(x)$ ，然后使用这个解正常进行PINN的损失函数构建训练即可。对于新的任务来说，我们前面已经训练好了body向量 $\Phi(x)$ 并且得到了head向量的密度分布，如果此时的训练数据是无噪声的，我们就可以训练一个NN来获得最优的 $H^{\star}$ ；如果训练数据是带噪声的，则通过贝叶斯推断来获取 $H^{\star}$ 。既然我们得到了新任务的body向量和head向量，则新任务的 $u(x)$ 也可以得到。</p>
<h1 id="LSA-PINN-Linear-Boundary-Connectivity-Loss-for-Solving-PDEs-on-Complex-Geometry"><a href="#LSA-PINN-Linear-Boundary-Connectivity-Loss-for-Solving-PDEs-on-Complex-Geometry" class="headerlink" title="LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex Geometry"></a>LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex Geometry</h1><h2 id="Abstract-16"><a href="#Abstract-16" class="headerlink" title="Abstract"></a>Abstract</h2><p>现有版本的PINN被认为在许多问题上学习能力很差，特别是对于复杂的几何图形。如果样本过于稀疏，现有PINN容易过拟合近边界区域，导致不正确的解。为了防止这样的问题，我们提出了一个新的边界连接(BCXN)损失函数，它提供了线性局部结构近似(LSA)对PINN边界梯度行为的影响。</p>
<h2 id="Introduction-20"><a href="#Introduction-20" class="headerlink" title="Introduction"></a>Introduction</h2><p>现有PINN通过自动微分(AD)或数值微分(ND)类型的方法来评估训练损失中的PDE约束。最近的研究表明，ND型方法，特别是耦合自动数值微分(CAN)-loss可以在训练样本更少的情况下更健壮有效地生成准确的解，而传统的AD-loss在训练过程中容易失败。这是因为ND型方法使用来自邻近样本的PINN输出来近似高阶导数，因此，它们可以通过这些局部近似有效地将稀疏样本连接到分段区域，从而促进在整个范围内使用更稀疏样本的快速物理知识学习。</p>
<p>在处理不规则几何图形时，现有PINN很难将域内部的训练样本完美地连接到边界。如果不这样做，可能会导致意想不到的训练失败，因为PINN开始在近边界区域过拟合。由于许多具有实际意义的偏微分方程是边值问题，因此最好有PINN为正确的边界行为建模。</p>
<p>这种新的边界连通性(BCXN)损失函数是一种新型LSA-PINN方法的关键，它可以更有效地学习具有稀疏训练样本的偏微分方程的解，而不考虑域几何结构。此外，该方法可以与其他PINN在优化方面的进展联合实现，如损失平衡、区域分解和自适应采样。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230213101414.png" alt=""></p>
<h2 id="Related-Work-1"><a href="#Related-Work-1" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Efficient-sampling-in-PINNs"><a href="#Efficient-sampling-in-PINNs" class="headerlink" title="Efficient sampling in PINNs."></a>Efficient sampling in PINNs.</h3><p>一些研究集中在有效的抽样策略，如重要抽样，自适应抽样和顺序抽样，以减少PINN训练所需的训练样本数量。域分解和并行化策略也被用于加速PINN的训练。我们的LSA-PINN与这些工作的不同之处在于，我们通过新提出的BCXN-loss使基于物理的学习在稀疏样本体系中更加健壮。</p>
<h3 id="CNN-architecture-and-numerical-differentiation-ND-type-loss-for-PINNs"><a href="#CNN-architecture-and-numerical-differentiation-ND-type-loss-for-PINNs" class="headerlink" title="CNN architecture and numerical differentiation (ND)-type loss for PINNs."></a>CNN architecture and numerical differentiation (ND)-type loss for PINNs.</h3><p>为了更好地处理不规则域，以CNN为基础的形式可能需要执行繁琐的坐标转换。我们的方法进一步提高了ND型损失在不规则几何上的算法的效率和适用性。</p>
<h3 id="Enforcing-BC-constraint-in-PINN-loss"><a href="#Enforcing-BC-constraint-in-PINN-loss" class="headerlink" title="Enforcing BC constraint in PINN loss."></a>Enforcing BC constraint in PINN loss.</h3><p>通常采用惩罚法将BCs作为软约束施加到PINN损失中。在此背景下，研究了各种策略来动态校准PDE和BC约束之间的相对重要性PINN训练。（动态加权方式）</p>
<p>还有其他方法可以绕过损失平衡问题。例如，可以设计一个ansatz函数，使BC完全满足构造，或隐式地将BC约束表述为PDE损失，只留下单个损失项PDE残差有待优化。（硬约束方式）</p>
<p>另一个例子是使用增广拉格朗日方法将BC约束施加到PINN损耗中。</p>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>一些相关的背景知识</p>
<h2 id="Method-2"><a href="#Method-2" class="headerlink" title="Method"></a>Method</h2><h3 id="Enforcing-linear-constraint-at-near-boundary-samples"><a href="#Enforcing-linear-constraint-at-near-boundary-samples" class="headerlink" title="Enforcing linear constraint at near-boundary samples"></a>Enforcing linear constraint at near-boundary samples</h3><p>这里我们将近边界样本的外部(域外)模板表示为ES点。在域内边界点P和选定的镜像点Q处定义边界条件 $\vec{u}_{BC}$ 和场值 $\vec{u}_{MI}$ ，在ES点A处的场值 $\vec{u}_{ES}$ 为待定值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302131715182.png" alt=""></p>
<p>通过对点A和点Q沿 $\overline{AQ}$ 相对于局部坐标n(曲面法线方向)对点P进行泰勒级数展开，可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230213161638.png" alt=""></p>
<p>其中 $\overline{AP}$ 和 $\overline{PQ}$ 是A和P之间以及P和Q之间的距离， $\overline{AQ}=\overline{AP}+\overline{PQ}$。则A点的场值 $\vec{u}_{ES}$ 可导出为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230213161939.png" alt=""></p>
<p>由上式可知 $\vec{u}_{ES}$ 受 $\vec{u}_{BC}$ 和 $\vec{u}_{MI}$ 的线性约束。镜点Q可以方便地选择在模具中心，即近边界的样本位置，但我们选择沿边界P法线方向的镜点Q，因为它更通用，在我们的实验中表现更好。因此， $\overline{AP}=\overline{PQ}$ ，式(4)为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302131656136.png" alt=""></p>
<p>类似的过程可以应用于推导Neumann-型和Robin-型边界条件的相应线性约束。</p>
<h3 id="Boundary-connectivity-BCXN-loss-with-direct-forcing"><a href="#Boundary-connectivity-BCXN-loss-with-direct-forcing" class="headerlink" title="Boundary connectivity (BCXN)-loss with direct forcing"></a>Boundary connectivity (BCXN)-loss with direct forcing</h3><p>我们可以直接应用式(5)计算在ND型格式下近边界样本PDE约束评估时，任意外部模板点的场值 $\vec{u}_{ES}$ 。这种直接强迫方法与数值计算中的直接强迫浸没边界方法有关。</p>
<p>然后我们可以使用以下BCXN-loss：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302131924672.png" alt=""></p>
<p>作为我们的LSA-PINN的PDE损失项，其中近边界样本上的PDE约束由局部线性约束调制。在这种实现中，BC被隐式地注入到训练损失中，避免了BC损失项。</p>
<h3 id="Procedure-to-evaluate-the-field-value-vec-u-MI-at-mirror-point"><a href="#Procedure-to-evaluate-the-field-value-vec-u-MI-at-mirror-point" class="headerlink" title="Procedure to evaluate the field value $\vec{u}_{MI}$ at mirror point"></a>Procedure to evaluate the field value $\vec{u}_{MI}$ at mirror point</h3><p>我们首先描述计算镜像点位置(法线方向)的步骤：</p>
<ol>
<li><p>如何确定模板是否为外部模板？</p>
<p>在本研究中，我们首先构造了目标几何结构的水平集函数 $\phi$ ，其中可以找到模板点A到边界点P之间的最短距离 $\overline{AP}$ 。从水平集函数的符号，我们可以判断一个模具是否是外部的。</p>
</li>
<li><p>如何计算外部模板的镜像点位置？</p>
<p>一旦 $\overline{AP}$ 确定，我们计算镜像点Q在流体域内的位置，其中满足 $\overline{AP}=\overline{PQ}$。</p>
</li>
</ol>
<p>在实践中，给定一组固定的训练样本，可以预先计算出所有外部模板点及其镜像位置。另一方面，镜像点上的字段值 $\vec{u}_{MI}$ 取决于LSA-PINN的输出，并在训练迭代中评估：</p>
<ol>
<li><p>针对MLP模型</p>
<p>通过在镜像点处求 $\vec{u}_{MI}(\vec{x},w)$ ，可以直接得到 $\vec{u}_{MI}$ 值。</p>
</li>
<li><p>针对CNN模型</p>
<p>当镜像点位置与CNN网格不重合时，可以利用以下反距离加权插值函数得到镜像点处 $\vec{u}_{MI}$ 值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302132056756.png" alt=""></p>
</li>
</ol>
<h1 id="DMIS-Dynamic-Mesh-based-Importance-Sampling-for-Training-Physics-Informed-Neural-Networks"><a href="#DMIS-Dynamic-Mesh-based-Importance-Sampling-for-Training-Physics-Informed-Neural-Networks" class="headerlink" title="DMIS: Dynamic Mesh-based Importance Sampling for Training Physics-Informed Neural Networks"></a>DMIS: Dynamic Mesh-based Importance Sampling for Training Physics-Informed Neural Networks</h1><h2 id="Abstract-17"><a href="#Abstract-17" class="headerlink" title="Abstract"></a>Abstract</h2><p>DMIS是一种基于重要性抽样的新型抽样方案，它构造一个动态三角网格来有效估计样本权重。</p>
<h2 id="Introduction-21"><a href="#Introduction-21" class="headerlink" title="Introduction"></a>Introduction</h2><p>虽然经典数值算法极大地促进了相关领域的发展，但这些算法计算成本高，在多物理场和多尺度系统中面临严峻的挑战。随着数据采集能力的提高，如何利用数据进行模拟结果的修改成为一个重要问题。一般来说，数据同化是经典数值算法与观测数据结合的主要方法，但数据同化会引入额外的不确定性，严重影响收敛。</p>
<p>实践表明，PINN可用于求解不同类型的偏微分方程，包括整数阶偏微分方程、分数阶偏微分方程和随机偏微分方程。</p>
<p>PINN的三个主流改进方向：损失项权重、并行计算和采样。</p>
<p>在本文中，我们提出了一种新的抽样方案，称为基于动态网格的重要性抽样(DMIS)，在不显著增加计算成本的情况下加快收敛速度。为了从理论上保证抽样方法的正确性，在DMIS中引入了重要抽样的概念。但是，重要性抽样需要计算每个点的抽样概率，计算成本很高。为了降低计算成本，我们提出了一种新的采样权值估计方法，称为基于动态网格的权值估计(DMWE)，该方法构造一个动态三角网格，有效地估计每个数据点的权重。DMWE构造的网格在训练过程中根据整个域的损耗分布进行动态更新。</p>
<h2 id="Related-Work-2"><a href="#Related-Work-2" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Physics-Informed-Neural-Networks-2"><a href="#Physics-Informed-Neural-Networks-2" class="headerlink" title="Physics-Informed Neural Networks"></a>Physics-Informed Neural Networks</h3><p>PINN相关介绍</p>
<h3 id="Importance-Sampling"><a href="#Importance-Sampling" class="headerlink" title="Importance Sampling"></a>Importance Sampling</h3><p>重要抽样是加速蒙特卡罗积分的一种有效方法，已被应用于训练神经网络。从理论上证明，如果小批按照唯一的分布进行抽样，即每个点的抽样概率与损失梯度的2范数与参数成正比，则SGD具有最快的收敛速度。</p>
<h2 id="Optimization-Problem-of-PINNs"><a href="#Optimization-Problem-of-PINNs" class="headerlink" title="Optimization Problem of PINNs"></a>Optimization Problem of PINNs</h2><p>把PINN看成是优化问题，从而对PINN进行重述</p>
<h2 id="Method-3"><a href="#Method-3" class="headerlink" title="Method"></a>Method</h2><h3 id="Importance-Sampling-for-PINNs"><a href="#Importance-Sampling-for-PINNs" class="headerlink" title="Importance Sampling for PINNs"></a>Importance Sampling for PINNs</h3><p>基于重要性抽样的理论完备性和小批量抽样的不可忽略性，我们设计了一种基于重要性抽样的小批量抽样方法，以提高PINN的收敛速度和模型精度。根据蒙特卡罗近似，我们可以引入一种更有效的采样方法。由于边界条件和初始条件都是惩罚项，所以我们只在对 $N_{f}$ 的抽样中引入了重要性抽样。PDE残差 $L_{f}$ 结合重要性抽样的损失为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302212130293.png" alt=""></p>
<p>其中 $\alpha_{i}$、 $p_{i}$ 和 $q_{i}$ 分别为数据点 $x_{i}$ 的样本权值、抽样概率和备选抽样概率。考虑到小批量一般是通过均匀采样获得的，所以 $p_{i}$ 等于 $\frac{1}{N_{f}}$</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221930860.png" alt=""></p>
<h3 id="Simplified-Calculation-amp-Reweighting"><a href="#Simplified-Calculation-amp-Reweighting" class="headerlink" title="Simplified Calculation &amp; Reweighting"></a>Simplified Calculation &amp; Reweighting</h3><p>配点的最佳采样概率由 $q^{\star} \propto ||\triangledown_{\theta}l(x,\theta)||_{2}$ 决定。然而，这种理论最优采样方法的计算成本是不可接受的，有必要寻找替代方法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221935195.png" alt=""></p>
<p>因此，式(8)是一个合理的近似。但是，我们发现由式(8)计算的样本权值在初始阶段会导致训练不稳定。这一问题是由于数据点损耗大，导致局部梯度急剧。为了解决这个问题，我们引入了一个超参数 $\beta$ 来调整 $\alpha$ 。对于 $\beta &gt; 1$ ，对损失大的数据点施加更大的惩罚，结果记为 $\alpha^{‘}$ ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221938520.png" alt=""></p>
<h3 id="DMWE"><a href="#DMWE" class="headerlink" title="DMWE"></a>DMWE</h3><p>由于式(8)降低了每个数据点的计算成本，采样概率仍然需要逐点计算，这对于求解复杂的偏微分方程是一个巨大的负担。为了进一步降低计算成本，我们提出了基于动态网格的权重估计(DMWE)，通过插值来计算样本权重。</p>
<p>在DMWE中，采用了基于Delaunay三角剖分的插值方法。具体来说，我们从 $N_{f}$ 动态生成一个子集S来构造一个三角形网格。DMWE只精确地计算了S中点的样本权值，其他点的权值通过插值得到。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221943064.png" alt=""></p>
<p>基于Delaunay的插值算法耗时较长，且无需在每个迭代步骤中更新三角网格。因此，我们引入基于余弦相似度的评估方法来决定是否重新选择S并重建三角形网格。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202302221945395.png" alt=""></p>
<h1 id="Transfer-Learning-Enhanced-DeepONet-for-Long-Time-Prediction-of-Evolution-Equations"><a href="#Transfer-Learning-Enhanced-DeepONet-for-Long-Time-Prediction-of-Evolution-Equations" class="headerlink" title="Transfer Learning Enhanced DeepONet for Long-Time Prediction of Evolution Equations"></a>Transfer Learning Enhanced DeepONet for Long-Time Prediction of Evolution Equations</h1><h2 id="Abstract-18"><a href="#Abstract-18" class="headerlink" title="Abstract"></a>Abstract</h2><p>深度算子网络(DeepONet)在各种学习任务中取得了巨大的成功，包括学习偏微分方程的解算子。特别地，它提供了一种在有限时间范围内预测演化方程的有效方法。然而，普通的DeepONet在长期预测中存在稳定性退化的问题。本文提出了一种迁移学习辅助方法增强DeepONet的稳定性。我们的想法是使用迁移学习来按顺序更新DeepONet，作为在不同时间框架中学习的传播体的替代品。进化中的DeepONet可以更好地跟踪进化方程的不同复杂性，而只需要通过对一小部分操作网络进行有效训练来进行更新。通过系统实验，我们证明了该方法不仅提高了DeepONet的长期精度，同时保持了相似的计算成本，而且大幅减少了训练集的样本量。</p>
<h2 id="Introduction-22"><a href="#Introduction-22" class="headerlink" title="Introduction"></a>Introduction</h2><p>利用深度学习方法求解偏微分方程近年来受到广泛关注。由于神经网络的万能逼近定理，用神经网络来近似偏微分方程的解是很自然的。最近提出了许多流行的基于神经网络的方法，如Deep Ritz Method，Deep Galerkin Method，Physics Informed Neural Networks(PINNs) 和弱对抗网络(Zang et al. 2020)。尽管这些方法在求解各种偏微分方程方面取得了巨大成功，但如果要为同一偏微分方程寻找对应于不同初始条件(IC)、边界条件(BC)或参数的解，则需要重新训练神经网络。相反，最近提出的参数算子学习方法，如DeepONet和FNO可以在不重新训练网络的情况下学习不同BC或IC对应的PDE。然而，在前面提到的算子神经网络中有一个重要的限制。也就是说，它们本质上是监督学习，通常需要求解大量的偏微分方程来形成训练数据，这可能是非常广泛的，特别是当感兴趣的偏微分方程位于高维空间时。为了克服这个问题，Wang等人提出了物理信息的DeepONet，它只使用物理信息(例如PDE的支配律)来构建损失函数，从而使DeepONet自监督。然而，在实践中，物理信息DeepONet与普通版本相比更难训练，因为精确的微分算子作用于网络，并使收敛行为高度依赖于潜在的物理问题。</p>
<p>最近DeepONet也被应用于进化方程的传播子的学习。基本思想是使用DeepONets在短时间间隔内学习PDE的解算符，这取决于(随机)初始条件的集合。PDE在以后的时间的解可以计算为训练有素的网络算子的递归动作在先前的步骤中获得的解决方案。然而，从长远来看，至少有两个原因会导致解的近似精度下降。首先，由于近似误差的存在，经过训练的DeepONet作为代理传播器，即使精确传播器是非可膨胀的，也可能是可膨胀的，这导致了近似误差在时间上的累积，从而难以长期预测解。其次，在偏微分方程的时间演化过程中，传播器输入和输出的函数可以随时间变化，即使在固定时隙内传播器的形式可能保持不变(例如，当动态是自主的)。以扩散方程为例，我们观察到传播子或半群的范围空间中的函数比定义域中的函数平滑得多，因此，后一时刻的解比前一时刻的解越来越正则。此外，一些演化方程可能在较长的时间范围内发展出各种复杂性，如湍流和尺度分离。对于这些方程，迭代通常只在单一(短)时间框架内使用有限初始函数集合训练的DeepONet代理可能无法在长时间内捕获正确的正则性或解的复杂性。</p>
<p>迁移学习是一类重要的机器学习技术，它将一个用于某一任务的神经网络用于另一个用于不同相关任务的新神经网络。其思想是，通过训练前一种神经网络获得的某个问题的知识或重要特征可以转移到其他问题上。迁移学习已广泛应用于图像识别，以及最近的。据我们所知，目前的工作是第一个将迁移学习应用于进化偏微分方程的学习解算子的工作。</p>
<h3 id="Related-works-1"><a href="#Related-works-1" class="headerlink" title="Related works"></a>Related works</h3><p>迁移学习之前已经与物理神经网络相结合，用于解决来自不同领域的偏微分方程问题，包括裂缝的相场建模，湍流的超分辨率，多保真数据上的CNN训练(例如细网格和粗网格上偏微分方程解的多分辨率图像)等。迁移学习也被应用于复杂几何上定义的pde的学习解的领域适应方法。最近的论文提出了一种一次性迁移学习策略，该策略冻结了预训练PINN的隐藏层，并将用于求解新微分方程的训练神经网络减少到仅优化最后一层(线性)。这种方法消除了重新训练整个网络参数的需要，同时仍然通过在最后一层调整一小部分参数来产生高质量的解决方案。本文将这种迁移学习思想与DeepONet相结合，学习进化方程的传播子，以预测长时间进化。</p>
<p>虽然我们正在完成当前的论文，但我们注意到最近的预印本，其中迁移学习与DeepONet一起用于在条件移位下学习PDE。其目的是用一个源域的足够标记数据训练一个源PDE模型，并将学习到的参数转移到一个标记数据有限的目标域。这里开发的技术主要用于将在PDE系统上受过训练的解决方案算子的知识从一个领域转移到另一个领域。与其不同的是，我们利用迁移学习来连续调优通过物理感知的DeepONet学习的传播体代理模型，以便调优的算子网络可以自适应地跟踪携带进化输入和输出的进化传播体。实验证明，该方法对于学习偏微分方程的长期演化具有更高的准确性和鲁棒性。</p>
<h2 id="Numerical-method"><a href="#Numerical-method" class="headerlink" title="Numerical method"></a>Numerical method</h2><p>考虑一般进化方程的初边值问题：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032014921.png" alt=""></p>
<p>在整个论文中，我们假设方程在 $\int_{\Omega_{x}}f\mathcal{L}fdx\leq 0$ 的意义上是耗散的。给定时间步长 $\Delta t$ ，我们考虑解 $f(n\Delta t,x)$ 的半离散近似 $f^{n}(x)$ 由向后定义欧拉离散化：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032028309.png" alt=""></p>
<p>我们的目标是近似传播子</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032029896.png" alt=""></p>
<p>通过算子神经网络 $\mathcal{P}_{NN}$ ，使神经网络只有一次向前传递才能实现从一个步骤到下一个步骤的时间推进解决方案，并且可以在很长的时间范围内捕获进化动态。需要指出的是，向后欧拉格式并不是时间行进的唯一选择。人们可以将其扩展到高阶时间离散化方案，如RungeKutta方法，只要选择 $\Delta t$ ，使得 $\mathcal{P}^{\Delta t}$ 是非展开算子。</p>
<h3 id="Physics-informed-DeepONet"><a href="#Physics-informed-DeepONet" class="headerlink" title="Physics-informed DeepONet"></a>Physics-informed DeepONet</h3><p>DeepONet中输出的形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032100151.png" alt=""></p>
<p>整个网络的loss：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032100790.png" alt=""></p>
<p>训练数据是一对对样本，获取代价太大，于是使用physics-informed DeepONet：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303032101711.png" alt=""></p>
<h3 id="DeepONet-with-transfer-learning"><a href="#DeepONet-with-transfer-learning" class="headerlink" title="DeepONet with transfer learning"></a>DeepONet with transfer learning</h3><p>迁移学习的主要思想是在大数据集上训练神经网络，然后部分冻结并将其应用于相关但不可见的任务。我们使用迁移学习技术在预测步骤中依次纠正训练好的DeepONet：我们冻结大部分训练良好的DeepONet，仅通过拟合底层定义的相同物理信息损失(4)来重新训练分支网络最后一个隐藏层的权重PDE。</p>
<h2 id="Theoretical-result"><a href="#Theoretical-result" class="headerlink" title="Theoretical result"></a>Theoretical result</h2><p>理论方面的证明</p>
<h2 id="Numerical-experiments"><a href="#Numerical-experiments" class="headerlink" title="Numerical experiments"></a>Numerical experiments</h2><p>Reaction diffusion equation、Allen-Cahn and Cahn-Hilliard equations、Allen-Cahn and Cahn-Hilliard equations和Multiscale linear radiative transfer equation做了实验</p>
<h1 id="Theory-guided-physics-informed-neural-networks-for-boundary-layer-problems-with-singular-perturbation"><a href="#Theory-guided-physics-informed-neural-networks-for-boundary-layer-problems-with-singular-perturbation" class="headerlink" title="Theory-guided physics-informed neural networks for boundary layer problems with singular perturbation"></a>Theory-guided physics-informed neural networks for boundary layer problems with singular perturbation</h1><h2 id="Abstract-19"><a href="#Abstract-19" class="headerlink" title="Abstract"></a>Abstract</h2><p>PINNs尽管发展很快，但是大梯度和高度非线性特征仍然具有很大的挑战。薄边界层问题是大梯度的突出例子，通常出现在传输问题。通过将薄边界层问题看成是奇异摄动问题，本文提出了BL-PINNs。定义了不同的并行PINN网络来表示内部和外部区域边界层问题的不同近似阶数。在不同的基准问题（正问题和逆问题）中，BL-PINN表现出优于传统PINN方法的性能，能够得到准确的结果，而经典PINN方法无法提供有意义的解决方案。与其他扩展PINN(XPINN)方法相比，BL-PINN也显示出明显更好的结果。BL-PINN中扰动参数的自然结合提供了评估参数解的机会，而不需要重新训练。BL-PINN演示了如何使用经典数学理论来指导深度神经网络的设计，以解决具有挑战性的问题。</p>
<h2 id="Introduction-23"><a href="#Introduction-23" class="headerlink" title="Introduction"></a>Introduction</h2><p>大梯度薄边界层是高雷诺数流动和高Peclet数传热/传质的共同特征。湍流边界层的减阻气动问题、冷却边界层的对流换热问题和浓度边界层的生物输运问题是几个重要的例子。普朗特在20世纪初提出的边界层理论引发了过去这一领域的持续研究120年了。由于薄边界层固有的大梯度，对它的建模在计算上具有挑战性。在动量输运分析中，薄边界层在实践中通常是湍流的，因此在数值上建模昂贵。在热和质量传输中，由于扩散系数的降低，薄边界层也可以出现在层流区。例如，由于生物化学物质在血液中的扩散系数非常小，心血管质量运输问题的浓度边界层非常薄，这使得数值模拟非常具有挑战性。</p>
<p>近年来，数据驱动建模和科学机器学习方法在流体流动和输运建模方面引起了相当大的兴趣。也许最早的关于边界层的工作是由Thwaites在1949年的论文中，通过使用一系列可用的实验和分析结果来拟合动量积分方程中的一项，从而找到了边界层动量积分方程的解，并实现了封闭形式的解析解。Thwaites的相关方法是流体力学和边界层中数据驱动和基于物理的混合建模的早期例子。</p>
<p>基于物理的神经网络(PINN)是科学机器学习中的一个热门话题，它可以在深度学习设置中实现基于物理和数据驱动的混合建模。PINN已应用于各种流体力学和热传导问题。然而，PINN在某些问题中的鲁棒性仍然是一个问题。PINN在复杂和高度非线性的流型中精度有限，如湍流、涡结构和边界层。开发健壮可靠的模型已被确定为科学机器学习研究的优先事项。边界层是挑战PINN鲁棒性的课题之一。在现有的PINN模型中，当边界层厚度足够减小后（如扩散系数减小），PINN会出现收敛问题。这种难度也给DeepONet等算子学习方法带来了挑战，它们可能无法学习所有参数解中的参数变化，因此鲁棒性将难以实现。</p>
<p>在过去的几年中，人们提出了原始PINN方法的各种变体，试图克服某些PINN限制。在PINN中使用傅立叶特征网络，以克服深度神经网络中的频谱偏差，这限制了高频函数的学习效果。保守PINN (cPINN)，扩展PINN (XPINN)和其他类似的域分解技术已经被提出，以利用高梯度或复杂模式区域的局部神经网络来实现复杂函数的有效学习。另外，其他方法使用了对高梯度区域附近的搭配点或训练点进行增强的局部采样来提高收敛性。然而，这些技术都没有研究薄边界层。我们证明，不经过特殊处理的域分解不能解决学习薄边界层的问题，因为薄边界层具有高度局域化的突变行为。此外，我们还表明，增加边界层内搭配点的分辨率并不能解决PINN训练问题。PINN已应用于各种平流-扩散输运问题，包括边界层。这些研究研究了损失项的最佳加权，主要集中在低Peclet数上，以解决这些具有挑战性的问题。然而，薄边界层（粘度/扩散系数消失的极限）仍然是PINN难以捉摸的目标。</p>
<p>在本文中，我们提出了一种理论指导和模型驱动的机器学习方法来学习薄边界层行为。我们的框架受到求解微分方程的奇异摄动和渐近展开方法的启发。奇异摄动理论是应用数学中公认的方法，它的许多发展都受到流体动力学社区的启发。在奇异摄动问题中，一个小的摄动参数（例如，动量传输中的粘度或热/质量传输中的扩散率）乘以最高阶导数。问题的奇异性质使得系统在微扰消失极限下的行为与微扰参数的零值非常不同。在这样的问题中会产生一个非常薄的边界层，由此导致的解中的突变甚至很难用传统的和已建立的数值技术来解决，如有限元方法。奇异摄动解是为这种情况量身定做的，因为随着边界层变薄和梯度增加，它们实际上变得越来越准确。例如，Galerkin投影中使用了这种渐近基函数作为基函数，以便准确地捕捉和表示这种解中固有的奇异行为。受摄动理论及其在投影方法中作为渐近基函数的启发，我们提出了边界层物理信息神经网络(BL-PINN)来克服目前深度学习在解决薄边界层方面的局限性。也就是说，通过渐近展开的透镜，我们的BL-PINN方法可以被视为PINN驱动的降阶模型(ROM)，其中与传统ROM模型（例如，适当的正交分解或动态模式分解）不同，我们的ROM方法不是数据驱动的，而是物理驱动的。这篇文章的主要贡献：</p>
<ol>
<li>本文提出了一种新的基于物理信息的薄边界层神经网络建模方法。我们在基准问题中证明了我们的方法克服了PINN在解决正反薄边界层问题时的局限性。</li>
<li>我们演示了经典数学理论（摄动方法）如何在理论指导/模型驱动的方法中与PINN结合。</li>
<li>我们的方法在PINN中提供了一个简化物理模型(RPM)。这种方法完全由控制的数学方程驱动，与目前的数据驱动ROM方法不同，后者依赖数据来形成基函数。BL-PINN可以被理解为RPM和PINN的组合。</li>
<li>我们在BL-PINN中的渐近基函数方法结合了规范函数（包含摄动参数）和空间坐标依赖性，因此可以用于在小参数(此处为扩散系数)变化时重新评估解。与传统的数据驱动方法相比，这种参数依赖性的自然结合是一种改进。BL-PINN能够在不需要重新训练的情况下进行参数PINN评估，因此提供了类似于DeepONet等算子学习方法的有吸引力的优势。事实上，随着雷诺数/Peclet数的增加，BL-PINN变得更加精确，这与传统PINN随着边界层变薄和相应梯度的增加而失效相反。</li>
</ol>
<h2 id="Methods-1"><a href="#Methods-1" class="headerlink" title="Methods"></a>Methods</h2><h3 id="Problem-statement-singularly-perturbed-differential-equations"><a href="#Problem-statement-singularly-perturbed-differential-equations" class="headerlink" title="Problem statement: singularly perturbed differential equations"></a>Problem statement: singularly perturbed differential equations</h3><p>考虑一个这样的微分方程：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132019570.png" alt=""></p>
<p>在适当的边界条件下，其中是$\epsilon$出现在算子$L_{\epsilon}$中的小参数（例如，给定的小扩散系数）。我们假设这是一个奇摄动问题，这意味着微分方程在$\epsilon=0$时得到的解与在极限$\epsilon\rightarrow0$时得到的解有很大不同。一个常见的情况是当它乘以最高阶导数项。这将导致一个“边界层”，在这个“边界层”中，解在一个小区域内迅速变化。该区域的厚度在极限$\epsilon\rightarrow0$时趋近于零。在摄动理论中，这类问题的解用渐近展开式表示，解分为内外区域，如图1所示。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132057323.png" alt=""></p>
<p>外层区域（远离边界层）近似为规则扩展：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132101706.png" alt=""></p>
<p>其中$\delta(\epsilon)$是规范函数，表示解中项的渐近序列（例如，$\epsilon^{n}$），而$\phi(x)$是嵌入$\epsilon$每一阶解的空间函数。由于这是一个正则展开，前导阶解对应于$\epsilon=0$。另一方面，引入拉伸变量来近似边界层区域$\xi=\frac{x-x_{0}}{\delta(\epsilon)}$，使我们可以放大到薄边界层区域，并局部表示为解：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132119440.png" alt=""></p>
<p>其中$\bar{\psi}_{n}(\xi)$是$\psi_{n}(x,\xi)$以拉伸变量的形式表示的空间函数。最后利用匹配渐近展开式在重叠区域内匹配外解和内解，得到最终解。简而言之，当$\xi\rightarrow\infty$时的内解被强制与$x\rightarrow0$时的外解匹配。</p>
<h3 id="Boundary-layer-physics-informed-neural-networks-BL-PINN"><a href="#Boundary-layer-physics-informed-neural-networks-BL-PINN" class="headerlink" title="Boundary layer physics-informed neural networks (BL-PINN)"></a>Boundary layer physics-informed neural networks (BL-PINN)</h3><p>我们建议使用PINN来解决上述扰动框架下的边界层问题，因此利用PINN提供的混合数据驱动和模型驱动的深度学习框架。在提出的BL-PINN方法中，我们使用独立的神经网络来近似外部和内部展开中的每个解级别，并使用匹配条件来获得一致的解。该框架的概述如图1所示。多个并行PINN用于表示内部和外部表示的不同近似阶数。每个PINN网络都有自己的物理损失函数，该函数基于为指定的近似顺序和区域（内部或外部）推导的偏微分方程。内部和外部区域的最终解是通过形成由已知规范函数$\delta_{n}(\epsilon)$加权的每个PINN输出的线性组合来推导的。最后的解仅在提供测量数据并定义了数据丢失的情况下才用于训练过程。最后，对每个网络施加适当的边界条件，并使用匹配条件确保内外解在重叠区域内一致。每个神经网络表示外层解$\phi_{n}(x)$和内层解$\psi_{n}(x)$是使用以下损失函数进行优化的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304132153659.png" alt=""></p>
<p>其中$n=1,2,\cdots$表示不同阶的渐近展开解，每个解都具有适当的物理$\mathcal{L}_{phys}^{n}$和边界条件$\mathcal{L}_{BC}^{n}$损失函数，这些损失函数是根据它们的定义域（内与外）和对$\epsilon$近似阶(n)定义的。利用匹配损失函数$\mathcal{L}_{match}^{n}$作为内外神经网络的匹配条件。总损失$\mathcal{L}_{tot}$是通过将内外损失函数在其近似阶上与匹配条件相加来定义的。最后，如果数据可用，则定义数据损失函数$\mathcal{L}_{data}$，并根据所有解的线性组合产生的最终输出进行反传播，如图1所示。$\lambda$超参数被设置为加权每个损失项的贡献。使用标准的随机梯度下降算法(Adam)为每一层i和每个内外网络n找到最佳权重$W_{i}$和偏差$b_{i}$。</p>
<p>匹配条件将要求内部PINN的$\xi\rightarrow\infty$输出与对应的外部PINN的$x\rightarrow0$输出匹配。然而，无限限制是不可能的，因为神经网络输入应该是理想的标准化。为了解决这个问题，一个新的变量$0 &lt; z &lt; 1$被定义为$z = \frac{\xi}{A}$，并使用该变量重新缩放内部方程。常数A被设置为一个足够大的值，$\xi\rightarrow\infty$近似为$z = 1$。这种方法受到边界层理论中的经典相似解的启发，其中根据方程估计一个适当的大值，近似于无穷大。下面我们讨论常数A的选择。</p>
<p>总而言之，BL-PINN利用了摄动理论不过是一系列微分方程的观察，这些微分方程在适当的边界/匹配条件下求解，并将解相加形成最终解。因此，人们可以使用不同的PINN网络来求解这些微分方程中的每一个，然后将这些预测线性相加，形成最终的解。</p>
<h1 id="Is-L2-Physics-Informed-Loss-Always-Suitable-for-Training-Physics-Informed-Neural-Network"><a href="#Is-L2-Physics-Informed-Loss-Always-Suitable-for-Training-Physics-Informed-Neural-Network" class="headerlink" title="Is L2 Physics-Informed Loss Always Suitable for Training Physics-Informed Neural Network?"></a>Is L2 Physics-Informed Loss Always Suitable for Training Physics-Informed Neural Network?</h1><h2 id="Abstract-20"><a href="#Abstract-20" class="headerlink" title="Abstract"></a>Abstract</h2><p>某些情况下， $L^{2}$ 损失函数可能不适合， $L^{p}$ 才适合。</p>
<h2 id="Introduction-24"><a href="#Introduction-24" class="headerlink" title="Introduction"></a>Introduction</h2><p>我们知道一个简单的事实当L2损失为零时，学习解等于精确解。然而，具有小但非零损失的学习解的质量仍然是未知的，没有任何近似保证，这是实践中更现实的场景。我们的目标是回答一个基本问题：我们能保证具有小物理信息损失的学习解总是对应于精确解的良好近似值吗？</p>
<h2 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h2><p>一些PINN收敛性的工作。</p>
<h2 id="Preliminary-1"><a href="#Preliminary-1" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>PINN和随机最优控制的相关背景知识。</p>
<h2 id="Failure-Mode-of-PINN-on-High-Dimensional-Stochastic-Optimal-Control"><a href="#Failure-Mode-of-PINN-on-High-Dimensional-Stochastic-Optimal-Control" class="headerlink" title="Failure Mode of PINN on High-Dimensional Stochastic Optimal Control"></a>Failure Mode of PINN on High-Dimensional Stochastic Optimal Control</h2><p>在这种情况下，一个自然的问题出现了：一个具有小损失的学习 $u(x)$ 是否对应于精确解 $u ^{\ast} (x)$ 的良好近似值？作者针对HJB方程的稳定性给出了证明。</p>
<h2 id="Solving-HJB-Equations-with-Adversarial-Training"><a href="#Solving-HJB-Equations-with-Adversarial-Training" class="headerlink" title="Solving HJB Equations with Adversarial Training"></a>Solving HJB Equations with Adversarial Training</h2><p>当p很大的时候，p范数和无穷范数的效果是差不多的，所以我们使用无穷范数来代替p范数。因此，训练目标就变成了如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305241731730.png" alt=""></p>
<p>上式其实可以看作是一个min-max优化问题。内部循环是一个最大化问题，以找到 $\Omega$ 和 $\partial \Omega$ 上u违反PDE最多的数据点，外部循环是一个最小化问题，以找到 $u$ ，使这些点的损失最小化。</p>
<p>我们首先固定模型 $u$ 和随机采样数据点 $x^{(1)},\cdots,x^{(N_{1})}\in \Omega$ 和 $\widetilde{x}^{(1)},\cdots,\widetilde{x}^{(N_{2})}\in \partial \Omega$ ，作为内循环优化的随机初始化。然后，我们执行基于梯度的方法来获得具有较大PDE损失的数据点，坐标更新方式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305241749960.png" alt=""></p>
<p>当内环优化完成后，我们将生成的数据点固定，并计算梯度g到模型参数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305241755648.png" alt=""></p>
<h1 id="Extended-physics-informed-neural-networks-XPINNs-A-generalized-space-time-domain-decomposition-based-deep-learning-framework-for-nonlinear-partial"><a href="#Extended-physics-informed-neural-networks-XPINNs-A-generalized-space-time-domain-decomposition-based-deep-learning-framework-for-nonlinear-partial" class="headerlink" title="Extended physics-informed neural networks (XPINNs) : A generalized space-time domain decomposition based deep learning framework for nonlinear partial"></a>Extended physics-informed neural networks (XPINNs) : A generalized space-time domain decomposition based deep learning framework for nonlinear partial</h1><p>differential equations</p>
<h2 id="Abstract-21"><a href="#Abstract-21" class="headerlink" title="Abstract"></a>Abstract</h2><p>提出了一种基于物理信息的神经网络的广义时空域分解框架来求解非线性偏微分方程在任意复杂几何区域上。与PINN方法相比，XPINN方法由于在较小的子域中部署多个神经网络的固有特性，具有<strong>更大的表示和并行化能力</strong>。深度神经网络可以应用于具有复杂解的子域，而浅神经网络可以应用于具有相对简单和光滑解的子域。</p>
<h2 id="Introduction-25"><a href="#Introduction-25" class="headerlink" title="Introduction"></a>Introduction</h2><p>DNN的发展；PINN的发展；PINN的不足之处以及XPINN的优点。</p>
<ol>
<li>广义空时域分解：XPINN的形式提供了高度不规则的，凸/非凸时空域分解。</li>
<li>对任意微分方程的扩展：与cPINN方法不同，基于XPINN的域分解方法可以扩展到任何类型的PDE，而不考虑其物理性质。</li>
<li>简单界面条件：在XPINN中，对于任意形状的接口，接口条件非常简单，不需要法线方向，因此，所提出的方法可以很容易地扩展到任何复杂的几何形状，甚至在更高的维度上。</li>
</ol>
<h2 id="Problem-Formulation-1"><a href="#Problem-Formulation-1" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h2><p>简单介绍偏微分方程</p>
<h2 id="Methodology-8"><a href="#Methodology-8" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Mathematical-setup-for-fully-connected-neural-networks"><a href="#Mathematical-setup-for-fully-connected-neural-networks" class="headerlink" title="Mathematical setup for fully connected neural networks"></a>Mathematical setup for fully connected neural networks</h3><p>本文采用的是局部自适应激活函数。数学上，可以通过比较自适应激活函数方法和固定激活方法的梯度动力学来证明这一点。自适应激活的梯度动态通过将条件矩阵乘以梯度并添加近似二阶项来修改标准动态（固定激活）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291451457.png" alt=""></p>
<h3 id="Extended-Physics-Informed-Neural-Networks"><a href="#Extended-Physics-Informed-Neural-Networks" class="headerlink" title="Extended Physics-Informed Neural Networks"></a>Extended Physics-Informed Neural Networks</h3><ul>
<li>Subdomains：不相交；所有subdomain的并集是全集；交集就是它们的连接部分</li>
<li>Interface：两个或多个subdomain的边界</li>
<li>Sub-Net：指在每个子域中使用自己的一组优化超参数的单个PINN</li>
<li>Interface Conditions：利用这些条件将分解的子域拼接在一起，从而得到控制偏微分方程在整个域上的解</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291457474.png" alt=""></p>
<p>则最终解的形式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291556942.png" alt=""></p>
<p>其中距离函数的定义如下，如果点不在subdomain中，系数为0；如果点在subdomain中，系数为1；如果点在连接处，系数为$\frac{1}{S}$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291556510.png" alt=""></p>
<h4 id="Subdomain-loss-function"><a href="#Subdomain-loss-function" class="headerlink" title="Subdomain loss function"></a>Subdomain loss function</h4><p>XPINN的损失函数是按子域定义的，它在每个子域中具有与PINN损失函数相似的结构，但被赋予了将子域拼接在一起的接口条件。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291616203.png" alt=""></p>
<p>上式中各项的具体形式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305291619802.png" alt=""></p>
<p>其中 $MSE_{\mathcal{R}}$ 表达的是残差连续性条件， $MSE_{u_{avg}}$ 表达的是值的连续性条件，$\{ \{ u_{\widetilde{\Theta}_{q}} \}\}=\frac{u_{\widetilde{\Theta}_{q}}+u_{\widetilde{\Theta}_{q^{+}}}}{2}$ ， $q^{+}$ 表示的邻居，这里以两个邻居为例。</p>
<h1 id="Conservative-physics-informed-neural-networks-on-discrete-domains-for-conservation-laws-Applications-to-forward-and-inverse-problems"><a href="#Conservative-physics-informed-neural-networks-on-discrete-domains-for-conservation-laws-Applications-to-forward-and-inverse-problems" class="headerlink" title="Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems"></a>Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems</h1><h2 id="Abstract-22"><a href="#Abstract-22" class="headerlink" title="Abstract"></a>Abstract</h2><p>介绍了本文的工作；cPINN的优点；简要讨论了各种误差及其来源；cPINN当中使用的局部自适应激活函数。</p>
<h2 id="Introduction-26"><a href="#Introduction-26" class="headerlink" title="Introduction"></a>Introduction</h2><p>DNN的发展；SciML的发展；PINN的发展以及不足之处。</p>
<h2 id="Problem-setup"><a href="#Problem-setup" class="headerlink" title="Problem setup"></a>Problem setup</h2><p>引出待解决的问题</p>
<h2 id="Methodology-9"><a href="#Methodology-9" class="headerlink" title="Methodology"></a>Methodology</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292133138.png" alt=""></p>
<h3 id="Sub-domain-loss-function-and-optimization-algorithm"><a href="#Sub-domain-loss-function-and-optimization-algorithm" class="headerlink" title="Sub-domain loss function and optimization algorithm"></a>Sub-domain loss function and optimization algorithm</h3><p>损失函数的形式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292200111.png" alt=""></p>
<p>每个损失项的具体表达形式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292201794.png" alt=""></p>
<p>$f_{p}\cdot \mathbf{n}$ 和 $f_{p^{+}}\cdot \mathbf{n}$ 是垂直于公共面的界面通量由两个不同的神经网络分别在子域 $p$ 和 $p^{+}$ 上给出的接口；</p>
<h3 id="Error-analysis-for-cPINN"><a href="#Error-analysis-for-cPINN" class="headerlink" title="Error analysis for cPINN"></a>Error analysis for cPINN</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292208610.png" alt=""></p>
<p>cPINN中的总误差定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305292208510.png" alt=""></p>
<h1 id="ADAPTIVE-FOURIER-NEURAL-OPERATORS-EFFICIENT-TOKEN-MIXERS-FOR-TRANSFORMERS"><a href="#ADAPTIVE-FOURIER-NEURAL-OPERATORS-EFFICIENT-TOKEN-MIXERS-FOR-TRANSFORMERS" class="headerlink" title="ADAPTIVE FOURIER NEURAL OPERATORS: EFFICIENT TOKEN MIXERS FOR TRANSFORMERS"></a>ADAPTIVE FOURIER NEURAL OPERATORS: EFFICIENT TOKEN MIXERS FOR TRANSFORMERS</h1><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>ViT在表示学习方向取得了巨大的成功，主要是由于借助自注意力的token mixing。但是随着像素点的增加会有一个平方倍地缩减，这就使得其对于高精度输入不可行。为了解决的这个问题，文章提出了AFNO(Adaptive Fourier Neural Operator)，核心思想是在傅里叶空间做token mixing。AFNO的理论基础是算子学习，将token mixing看作是一个与输入分辨率无关的连续全局卷积。为了应对视觉表征学习中的挑战，如图像不连续和高分辨率输入，我们提出了FNO的原则性架构修改，从而提高了内存和计算效率。主要包括在不同通道之间的mixing weights使用了一个块对角结构，token之间动态地共享权重，通过软阈值和收缩对频率模式进行稀疏化。</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>ViT在为识别和生成任务生成丰富的上下文表示方面做出了很大的贡献。然而，一个主要的挑战是来自高分辨率图像和视频的长序列。在这里，远程和多向依赖关系对于理解场景中对象之间的组合性和关系至关重要。Transformer有效性的一个关键组成部分归因于token的适当混合。然而，找到一个好的mixer是具有挑战性的，因为它需要随序列大小缩放，并系统地推广到下游任务。</p>
<p>原始的自注意力施加图结构，并使用标记之间的相似性来捕获长期依赖关系；它具有参数高效和自适应的特点，但在序列大小上具有二次复杂度。为了实现与线性复杂性的有效混合，引入了几个自注意力的近似。这些近似通常会为了效率而牺牲精度。例如，long-short Transformer聚集了具有动态投影的远程注意力来模拟远距离相关性，并聚集了短期注意力来捕捉局部相关性。长距离依赖关系是在低维中建模的，这可能会限制表达性。</p>
<p>最近，引入了自注意力的替代方案，放宽了图假设以实现有效混合。相反，他们利用傅里叶变换来利用几何结构。例如，Global Filter Networks (GFN)提出了用于token mixing的深度全局卷积，该卷积在傅里叶域中得到了有效的实现。GFN主要包括三个步骤：(i)通过快速傅里叶变换(FFT)进行空间标记混合；(ii)频率门控；(iii)用于令牌分离的逆FFT。然而，GFN在高分辨率下缺乏自适应性和表达性，因为参数数量随着序列大小而增长，并且在(ii)中不涉及channel mixing。</p>
<p>为了解决这些缺点，我们将token mixing作为学习无限维空间中连续函数之间映射的算子学习。我们将token视为函数空间中的连续元素，并将token mixing建模为连续的全局卷积，以捕获几何空间中的全局关系。一种有效解决全局卷积的方法是通过FFT。更一般地，我们将这样的全局卷积运算与非线性（如ReLU）组合在一起，以学习任何一般的非线性算子。这构成了设计傅里叶神经算子(FNOs)的基础，FNOs在解决PDEs方面显示出希望。因此，我们采用FNO作为设计高效token mixing的起点。</p>
<p>从PDE中调整FNO到视觉需要几个设计修改。图像具有由于边缘和其他结构而不连续性的高分辨率内容。标准FNO中的channel mixing导致channel大小的二次复杂度。为了控制这种复杂性，我们对token mixing权重施加块对角结构。为了增强泛化能力，受稀疏回归的启发，通过软阈值化对频率进行稀疏化。此外，为了参数效率，我们的MLP层在token之间共享权重。我们将由此产生的模型称为自适应FNO (AFNO)。</p>
<h2 id="RELATED-WORKS"><a href="#RELATED-WORKS" class="headerlink" title="RELATED WORKS"></a>RELATED WORKS</h2><p>提升自注意力的方法：</p>
<ul>
<li>基于图的Mixer：核心是找到合适的代理来近似自注意力。稀疏attention；低秩attention；核方法；聚类方法。</li>
<li>基于MLP的Mixer：利用MLP投影放宽自注意力和空间混合标记的图相似性约束。</li>
<li>基于傅里叶的Mixer：将傅里叶变换作用于空间混合标记。</li>
</ul>
<p>算子学习处理函数到函数的映射问题，并且经常用于PDEs。算子学习也可以被应用于计算机视觉当中，因为图像是二维平面上的RGB值函数。</p>
<h2 id="PRELIMINARIES-AND-PROBLEM-STATEMENT"><a href="#PRELIMINARIES-AND-PROBLEM-STATEMENT" class="headerlink" title="PRELIMINARIES AND PROBLEM STATEMENT"></a>PRELIMINARIES AND PROBLEM STATEMENT</h2><p>将一个二维图像分成 $h \times w$ 的patch，每个patch都是d维的，所以每一个token tensor就被表示为 $X \in \mathbb{R}^{h \times w \times d}$ 。</p>
<p>一些背景知识。</p>
<h3 id="Discrete-FNO"><a href="#Discrete-FNO" class="headerlink" title="Discrete FNO"></a>Discrete FNO</h3><p>受FNO的启发，对于离散网格上有限维的图像，我们的想法是使用离散傅里叶变换(DFT)混合标记。对于输入变量$X \in \mathbb{R}^{h \times w \times d}$，定义复值权重张量 $W:=DFT(k) \in \mathbb{C}^{h \times w \times d \times d}$ 来参数化核。然后，FNO混合需要对每个token进行以下操作：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151113163.png" alt=""></p>
<h3 id="Local-Features"><a href="#Local-Features" class="headerlink" title="Local Features"></a>Local Features</h3><p>DFT假设在周期性图像上应用了一个全局卷积，这对于真实世界的图像来说通常是不成立的。为了补偿局部特征和非周期边界，我们可以在FNO中的token分解步骤3中添加残差项 $x_{m,n}$ （也可以参数化为简单的局部卷积）。</p>
<h3 id="Resolution-Invariance"><a href="#Resolution-Invariance" class="headerlink" title="Resolution Invariance"></a>Resolution Invariance</h3><p>FNO模型对离散的 $h,w$ 是不变的，它是通过对潜在分辨率不变的傅里叶基来参数化token函数的。因此，在一个分辨率上训练后，可以直接在另一个分辨率上进行评估（zero-shot 超分辨率）。</p>
<h2 id="ADAPTIVE-FOURIER-NEURAL-OPERATORS-FOR-TRANSFORMERS"><a href="#ADAPTIVE-FOURIER-NEURAL-OPERATORS-FOR-TRANSFORMERS" class="headerlink" title="ADAPTIVE FOURIER NEURAL OPERATORS FOR TRANSFORMERS"></a>ADAPTIVE FOURIER NEURAL OPERATORS FOR TRANSFORMERS</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151156212.png" alt=""></p>
<h3 id="Block-Diagonal-Structure-on-W"><a href="#Block-Diagonal-Structure-on-W" class="headerlink" title="Block-Diagonal Structure on W"></a>Block-Diagonal Structure on W</h3><p>FNO对每个token都涉及一个 $k \times k$ 的权重矩阵，这就导致了 $O(Nd^{2})$ 的参数量。为了减少参数量，我们采用了块对角结构，权重矩阵被分成 $k$ 个大小维 $d/k \times d/k$ 的权重块。其实可以看成是多头自注意力，它投射到数据的一个子空间。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151134329.png" alt=""></p>
<h3 id="Weight-Sharing"><a href="#Weight-Sharing" class="headerlink" title="Weight Sharing"></a>Weight Sharing</h3><p>FNO的另一个不足之处在于权重是静态的，一旦学习，它们将不会自适应地改变新的样本。受自注意力的启发，我们希望tokens具有适应性。此外，静态权重在tokens之间是独立的，但我们希望tokens相互作用并决定传递某些低频和高频模式。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151152897.png" alt=""></p>
<h3 id="Soft-Thresholding-and-Shrinkage"><a href="#Soft-Thresholding-and-Shrinkage" class="headerlink" title="Soft-Thresholding and Shrinkage"></a>Soft-Thresholding and Shrinkage</h3><p>图像在傅里叶空间是天然稀疏的，大部分都集中在低频模式中。因此，我们可以动态地根据它们对终端任务的重要性对tokens进行掩码。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151155277.png" alt=""></p>
<h1 id="FOURCASTNET-A-GLOBAL-DATA-DRIVEN-HIGH-RESOLUTION-WEATHER-MODEL-USING-ADAPTIVE-FOURIER-NEURAL-OPERATORS"><a href="#FOURCASTNET-A-GLOBAL-DATA-DRIVEN-HIGH-RESOLUTION-WEATHER-MODEL-USING-ADAPTIVE-FOURIER-NEURAL-OPERATORS" class="headerlink" title="FOURCASTNET: A GLOBAL DATA-DRIVEN HIGH-RESOLUTION WEATHER MODEL USING ADAPTIVE FOURIER NEURAL OPERATORS"></a>FOURCASTNET: A GLOBAL DATA-DRIVEN HIGH-RESOLUTION WEATHER MODEL USING ADAPTIVE FOURIER NEURAL OPERATORS</h1><h2 id="Abstract-23"><a href="#Abstract-23" class="headerlink" title="Abstract"></a>Abstract</h2><p>FourCastNet以0.25°分辨率（遥感图像能分辨的最小地物单元为0.25经/纬度）提供准确的短期到中期全球预测。FourCastNet可以准确预测高分辨率、快速的时间尺度变量，如地面风速、降水和大气水蒸气。它对规划风能资源、预测热带气旋、热带外气旋和大气河流等极端天气事件具有重要意义。FourCastNet在短时间内的大尺度变量的预测精度与ECMWF的Integrated Forecasting System (IFS)的精度相当，然而在小尺度变量上的精度高于IFS。FourCastNet在不到2秒的时间内生成一个为期一周的预测，比IFS快了几个数量级。FourCastNet的速度使创建快速和廉价的大型集合预测与数以千计的集合成员，以提高概率预测。我们讨论了数据驱动的深度学习模型(如FourCastNet)如何成为气象工具包的一个有价值的补充，以帮助和增强NWP模型。</p>
<h2 id="Introduction-27"><a href="#Introduction-27" class="headerlink" title="Introduction"></a>Introduction</h2><p>数值天气预报的重要性以及其发展历程。</p>
<p>现在数据驱动的深度学习也开始发展起来。</p>
<p>数据驱动模型克服了NWP模型中存在的模型偏差，能够以较低的计算成本为概率预报和数据同化生成大集合，在改善天气预报方面具有很大的潜力。</p>
<p>大多数数据驱动的天气模型使用低分辨率数据进行训练。然而，粗化过程会导致关键的、精细的物理信息的丢失。数据驱动的模型要想真正发挥作用，就必须以与当前最先进的数值天气模型相同或更高的分辨率生成预报。</p>
<p>我们开发了基于傅里叶的神经网络预测模型FourCastNet，以0.25°分辨率生成关键大气变量的全球数据驱动预测，这对应于赤道附近大约30 km × 30km的空间分辨率和720 × 1440像素的全球网格大小。</p>
<p>我们选择了ViT作为主干网络，因为它能够很好地建模远程依赖关系。将ViT与基于傅立叶的令牌混合相结合，可以产生最先进的高分辨率模型，该模型可以解析细粒度特征，并可以很好地扩展数据集的分辨率和大小。这种方法能够以真正前所未有的分辨率训练高保真的数据驱动模型。</p>
<h2 id="Training-Methods"><a href="#Training-Methods" class="headerlink" title="Training Methods"></a>Training Methods</h2><p>在这项工作中，我们重点预测了两个重要且具有挑战性的大气变量，即(1)距离地球表面10米的风速和(2)6小时总降水量。由于计算和模型架构的限制，以前基于DL的天气预报工作无法在全ERA5分辨率下对这些变量进行全球预报。近地面风速预报在陆上和海上风电场的储能规划、电网传输和其他操作考虑中发挥着关键作用，因此具有巨大的实用性。正如我们在3.1节中所展示的，近地风预报（以及大气边界层以上的风预报）可以帮助跟踪极端风事件，如飓风，并可用于备灾。我们的第二个重点是预测总降水量，其中DL模型可能显示出很大的潜力。NWP模型，如可操作的IFS，有几种参数化方案来可跟踪地预测降水，由于神经网络在从高分辨率观测数据推断参数化方面具有令人印象深刻的能力，因此它们非常适合这项任务。</p>
<h3 id="FourCastNet-Model-Description"><a href="#FourCastNet-Model-Description" class="headerlink" title="FourCastNet: Model Description"></a>FourCastNet: Model Description</h3><p>为了产生高分辨率的预测，我们选择了自适应傅立叶神经算子(AFNO)模型。这种特殊的神经网络架构很有吸引力，因为它是专门为高分辨率输入设计的，并将深度学习的几个关键最新进展综合到一个模型中。也就是说，它结合了傅里叶神经的算子学习方法与ViT主干，前者已被证明在建模复杂PDE系统非常有优势。</p>
<p>ViT架构及其变体在过去几年中已经成为计算机视觉领域的最新技术，在许多任务上表现出卓越的性能，并且随着模型和数据集大小的增加而良好地扩展。这种性能主要归功于这些网络中的多头自注意力机制，该机制允许网络在每一层全局建模特征（在ViT表示术语中称为token）之间的相互作用。然而，通过自注意力进行的空间混合在token数量上是二次的，因此对于高分辨率输入很快变得不可行。</p>
<p>ViT的一些变体通过找到一些可替代的空间token混合的机制来降低计算复杂度。然而，AFNO模型的独特之处在于，它将混合操作表征为连续的全局卷积，通过FFT在傅里叶域中有效地实现，这允许灵活地、可扩展地跨空间和通道维度建模依赖关系。</p>
<p>鉴于卷积网络架构的普遍流行，特别是它们在先前预测ERA5变量的工作中的使用，值得将我们的AFNO模型与这些更传统的架构进行比较。首先，AFNO能够很好地随分辨率进行扩展，从而产生直接的实际好处——在我们的720x1440分辨率下，FourCastNet模型的内存占用约为10GB，批处理大小为1。为了对比这一点，我们可以从WeatherBench的先前结果中看到19层的ResNet架构，它以非常粗糙的分辨率（32×64像素）进行训练。将此架构转移到我们的数据集并以720×1440分辨率进行训练，对于批大小为1的数据集将需要83GB。</p>
<p>除了实际考虑之外，我们初步的非详尽实验表明，在自回归推理中，卷积架构在捕获小尺度上的许多时间步长表现不佳。这些观察结果以及我们对图像去噪、超分辨率和去模糊的高分辨率图像处理当前状态的了解是我们选择ViT架构而不是卷积架构的强烈动机。</p>
<h3 id="Model-structure"><a href="#Model-structure" class="headerlink" title="Model structure"></a>Model structure</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202307271409187.png" alt=""></p>
<h3 id="Training-methods"><a href="#Training-methods" class="headerlink" title="Training methods"></a>Training methods</h3><p>模型的训练分为两个阶段：预训练阶段，从x(k)生成x(k+1)，使用x(k+1)和x(k+1)的真实值做损失；微调阶段，从x(k)生成x(k+1)，再用生成的x(k+1)生成x(k+2)，然后使用x(k+1)和x(k+2)的真实值分别做损失。</p>
<h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p>模型的预测是一个迭代式的方式：先用x(k)生成x(k+1)，再从x(k+1)生成x(k+2)，依此类推，直到我们想要的步长。</p>
<h1 id="Prediction-of-transonic-flow-over-supercritical-airfoils-using-geometric-encoding-and-deep-learning-strategies"><a href="#Prediction-of-transonic-flow-over-supercritical-airfoils-using-geometric-encoding-and-deep-learning-strategies" class="headerlink" title="Prediction of transonic flow over supercritical airfoils using geometric-encoding and deep-learning strategies"></a>Prediction of transonic flow over supercritical airfoils using geometric-encoding and deep-learning strategies</h1><h2 id="Methods-2"><a href="#Methods-2" class="headerlink" title="Methods"></a>Methods</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101600250.png" alt=""></p>
<p>输入是翼型和自由流条件的几何信息。首先做一个网格变换来利用结构化网络；接着采用多种方法对几何信息进行编码，选择神经网络的有效特征输入；AI模型方面采用了基于小波变换和梯度分布的各种损失函数，尤其是在激波附近。</p>
<h3 id="Encoding-of-geometric-information"><a href="#Encoding-of-geometric-information" class="headerlink" title="Encoding of geometric information"></a>Encoding of geometric information</h3><p>机翼周围的边界层附近网格是细化处理的，因为需要保留流动细节。基于CNN和Transformer的模型需要均匀和结构化的输入，通过一元变换将几何信息和流信息从笛卡尔坐标转换为曲线坐标。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101633201.png" alt=""></p>
<p>文章共采用了四种Encoding的方法：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101641619.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101644169.png" alt=""></p>
<h3 id="Neural-network-architecture"><a href="#Neural-network-architecture" class="headerlink" title="Neural network architecture"></a>Neural network architecture</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101707037.png" alt=""></p>
<h3 id="Loss-functions"><a href="#Loss-functions" class="headerlink" title="Loss functions"></a>Loss functions</h3><p>平均绝对误差(MAE)通常用于训练神经网络来预测翼型上的流场。本研究将剧烈变化视为流场的高频信号，并在 $l_{1}$ 损失函数中加入两个损失函数，即多层小波变换的损失函数($l_{wt}$)和梯度分布的损失函数($l_{grad}$)。</p>
<h4 id="Multilevel-wavelet-transformation"><a href="#Multilevel-wavelet-transformation" class="headerlink" title="Multilevel wavelet transformation"></a>Multilevel wavelet transformation</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101725583.png" alt=""></p>
<p>其中，$\psi^{H}$为运行k−1次DWT后的高频分量，$\psi^{L}_{k-1}$为运行k−1次DWT后的低频分量。DWT实现后，结合$l_{wt}$得到总损失函数的最终形式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101735864.png" alt=""></p>
<p>这些系数是可训练的，可以通过多任务损失优化来学习：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101735384.png" alt=""></p>
<h4 id="Gradient-distribution"><a href="#Gradient-distribution" class="headerlink" title="Gradient distribution"></a>Gradient distribution</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308111724017.png" alt=""></p>
<p>通过中心差分法可以得到 $\xi$ 和 $\eta$ 方向上的梯度。总损失函数表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308111728085.png" alt=""></p>
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>RLlib使用总结</title>
    <url>/2024/09/30/RLlib%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下开源分布式计算框架<code>Ray</code>以及基于其的强化学习算法库<code>RLlib</code>的使用。</p>
<a id="more"></a>
<p><code>Ray</code>是一个开源的分布式计算框架，旨在解决大规模计算任务的高性能和分布式处理需求。它提供了丰富的功能，包括任务调度、并行计算、分布式存储等。通过<code>Ray</code>，我们可以将计算任务并行化并分布到多个计算节点上，以充分利用计算资源，从而加速计算过程。在强化学习中，<code>Ray</code>可以帮助我们实现多进程训练，提高模型的收敛速度。</p>
<p><code>RLlib</code>是<code>Ray</code>框架下的一个专门用于强化学习任务的库。它提供了多种强化学习算法的实现，如<code>A2C</code>、<code>PPO</code>、<code>DQN</code>等，并支持在多种环境下进行训练和测试。<code>RLlib</code>不仅提供了丰富的算法和环境支持，还提供了高效的并行化能力。通过利用<code>Ray</code>的分布式计算特性，<code>RLlib</code>可以在多个<code>CPU</code>或<code>GPU</code>上并行执行训练任务，从而加速强化学习模型的训练过程。</p>
<h1 id="具体用法"><a href="#具体用法" class="headerlink" title="具体用法"></a>具体用法</h1><h2 id="初步使用"><a href="#初步使用" class="headerlink" title="初步使用"></a>初步使用</h2><p>使用<code>PPO</code>算法在<code>CartPole-v1</code>环境上进行训练，对其进行<code>10</code>个<code>epoch</code>的训练，并且每<code>5</code>个<code>epoch</code>保存一下生成的策略。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> ray.rllib.algorithms.ppo <span class="keyword">import</span> PPOConfig</span><br><span class="line"><span class="keyword">from</span> ray.tune.logger <span class="keyword">import</span> pretty_print</span><br><span class="line"></span><br><span class="line">algo = (</span><br><span class="line">    PPOConfig()</span><br><span class="line">    .rollouts(num_rollout_workers=<span class="number">1</span>)</span><br><span class="line">    .resources(num_gpus=<span class="number">0</span>)</span><br><span class="line">    .environment(env=<span class="string">&quot;CartPole-v1&quot;</span>)</span><br><span class="line">    .build()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    result = algo.train()</span><br><span class="line">    print(pretty_print(result))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        checkpoint_dir = algo.save().checkpoint.path</span><br><span class="line">        print(<span class="string">f&quot;Checkpoint saved in directory <span class="subst">&#123;checkpoint_dir&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="自定义环境"><a href="#自定义环境" class="headerlink" title="自定义环境"></a>自定义环境</h2><h3 id="单智能体环境"><a href="#单智能体环境" class="headerlink" title="单智能体环境"></a>单智能体环境</h3><p>在使用自定义单智能体环境时，首先要构建一个自己的环境类，该类继承自<code>gymnasium.Env</code>。在<code>__init__</code>函数中声明动作空间和状态空间；在<code>reset</code>函数中完成环境重置的逻辑；在<code>step</code>函数中完成环境推进的逻辑。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> gymnasium <span class="keyword">as</span> gym</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> exception <span class="keyword">import</span> CustomResetException, CustomStepException</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Env</span>(<span class="params">gym.Env</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, env_config</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        self.action_space = gym.spaces.Discrete(<span class="number">3</span>)</span><br><span class="line">        self.observation_space = gym.spaces.Dict(&#123;</span><br><span class="line">            <span class="string">&quot;observations&quot;</span>: gym.spaces.Box(low=-<span class="number">10</span>, high=<span class="number">10</span>, shape=(<span class="number">9</span>,), dtype=np.float32),</span><br><span class="line">            <span class="string">&quot;action_mask&quot;</span>: gym.spaces.Box(low=<span class="number">0</span>, high=<span class="number">1</span>, shape=(<span class="number">3</span>,), dtype=np.int8)</span><br><span class="line">        &#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self, seed=<span class="literal">None</span>, options=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;observations&quot;</span>: obs, <span class="string">&quot;action_mask&quot;</span>: action_masked&#125;, &#123;&#125;</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self, action</span>):</span></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;observations&quot;</span>: obs_next, <span class="string">&quot;action_mask&quot;</span>: action_masked&#125;, reward, done, <span class="literal">False</span>, info</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>具体使用过程中，将<code>environment</code>的<code>env</code>声明为自定义环境即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">algo = (</span><br><span class="line">    PPOConfig()</span><br><span class="line">    .environment(</span><br><span class="line">        env=Env</span><br><span class="line">    )</span><br><span class="line">    .build()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="多智能体环境"><a href="#多智能体环境" class="headerlink" title="多智能体环境"></a>多智能体环境</h3><p>多智能体环境的声明及使用与单智能体类似，不同之处在于多智能体环境类继承自<code>ray.rllib.env.multi_agent_env</code>中的<code>MultiAgentEnv</code>；同时要声明每个智能体<code>observation</code>、<code>reward</code>、<code>done</code>、<code>truncated</code>和<code>info</code>；<code>done</code>和<code>truncated</code>选项中也必须存在<code>__all__</code>参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedEnv</span>(<span class="params">MultiAgentEnv</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, env_config</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        self.action_space = gym.spaces.Discrete(<span class="number">4</span>)</span><br><span class="line">        self.observation_space = gym.spaces.Dict(&#123;</span><br><span class="line">            <span class="string">&quot;observations&quot;</span>: gym.spaces.Box(low=-<span class="number">1</span>, high=<span class="number">1</span>, shape=(<span class="number">12</span>,), dtype=np.float32),</span><br><span class="line">            <span class="string">&quot;action_mask&quot;</span>: gym.spaces.Box(low=<span class="number">0</span>, high=<span class="number">1</span>, shape=(<span class="number">4</span>,), dtype=np.int8)</span><br><span class="line">        &#125;)</span><br><span class="line">        self.num_agent = <span class="number">4</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self, seed=<span class="literal">None</span>, options=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> data, &#123;&#125;</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self, action</span>):</span></span><br><span class="line">        <span class="keyword">return</span> obs_next, reward, done, truncated, info</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>一个具体的数据示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dict_obs_next = &#123;&#125;</span><br><span class="line">dict_reward = &#123;&#125;</span><br><span class="line">dict_done = &#123;&#125;</span><br><span class="line">dict_truncated = &#123;&#125;</span><br><span class="line">dict_info = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    dict_obs_next[i] = &#123;</span><br><span class="line">        <span class="string">&quot;observations&quot;</span>: obs[i],</span><br><span class="line">        <span class="string">&quot;action_mask&quot;</span>: action_legal[i]</span><br><span class="line">    &#125;</span><br><span class="line">    dict_reward[i] = reward[i]</span><br><span class="line">    dict_done[i] = done</span><br><span class="line">    dict_truncated[i] = <span class="literal">False</span></span><br><span class="line">    dict_info[i] = &#123;</span><br><span class="line">        <span class="string">&quot;win&quot;</span>: flag_win</span><br><span class="line">    &#125;</span><br><span class="line">dict_done[<span class="string">&quot;__all__&quot;</span>] = done</span><br><span class="line">dict_truncated[<span class="string">&quot;__all__&quot;</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h2 id="自定义回调"><a href="#自定义回调" class="headerlink" title="自定义回调"></a>自定义回调</h2><p>在使用自定义回调时，首先需要声明一个回调类，该类继承自<code>ray.rllib.algorithms.callbacks</code>中的<code>DefaultCallbacks</code>，在该类中我们可以重写一些回调函数。例如，我们想要每训练<code>10</code>个<code>epoch</code>测试一下当前模型的胜率，就可以通过重写回调函数<code>on_train_result</code>来实现该功能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EvaluationCallback</span>(<span class="params">DefaultCallbacks</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_train_result</span>(<span class="params">self, *, algorithm, result: <span class="built_in">dict</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">if</span> result[<span class="string">&quot;training_iteration&quot;</span>] % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            eval_result = self.evaluate(algorithm)</span><br><span class="line">            win_rate = eval_result[<span class="string">&quot;win_rate&quot;</span>]</span><br><span class="line">            append_to_csv(os.path.join(os.path.dirname(os.path.abspath(__file__)), <span class="string">&quot;win_rate.csv&quot;</span>), win_rate)</span><br><span class="line">            print(win_rate)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">self, algorithm</span>):</span></span><br><span class="line">        config_env = &#123;&#125;</span><br><span class="line">        env = RedEnv(config_env)</span><br><span class="line">        num_episodes = <span class="number">10</span></span><br><span class="line">        win_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_episodes):</span><br><span class="line">            obs, _ = env.reset()</span><br><span class="line">            done = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">                dict_action = &#123;&#125;</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):            </span><br><span class="line">                    action = algorithm.compute_single_action(obs[i], explore=<span class="literal">False</span>)</span><br><span class="line">                    dict_action[i] = action</span><br><span class="line">                obs, reward, dones, truncated, infos = env.step(dict_action)</span><br><span class="line">                done = dones[<span class="string">&quot;__all__&quot;</span>]</span><br><span class="line">                <span class="keyword">if</span> done:</span><br><span class="line">                    <span class="comment"># 统计胜负结果</span></span><br><span class="line">                    <span class="keyword">if</span> infos[<span class="number">0</span>][<span class="string">&quot;win&quot;</span>] == <span class="number">0</span>:</span><br><span class="line">                        win_count += <span class="number">1</span></span><br><span class="line">        win_rate = win_count / num_episodes</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;win_rate&quot;</span>: win_rate&#125;</span><br></pre></td></tr></table></figure>
<p>具体使用过程中，在<code>callbacks</code>中传入自定义回调类即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">algo = (</span><br><span class="line">    PPOConfig()</span><br><span class="line">    .callbacks(EvaluationCallback)</span><br><span class="line">    .build()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="动作掩码"><a href="#动作掩码" class="headerlink" title="动作掩码"></a>动作掩码</h2><p>无论是单智能体环境还是多智能体环境，使用动作掩码时要在返回当前的<code>observations</code>时，同时返回智能体在当前观测下能够采取的合法动作，这个键是可以随意定义的，例如<code>action_mask</code>或<code>legal_action</code>，上文中的自定义单智能体和多智能体环境示例采用的便是<code>action_mask</code>。</p>
<p>除此之外，我们想要更新的神经网络模型必须也支持动作掩码。例如，<code>ray.rllib.examples.models.action_mask_model</code>中支持的<code>TorchActionMaskModel</code>。</p>
<p>具体使用时，我们需要在<code>training</code>当中声明采用的神经网络模型，同时需要在<code>environment</code>当中声明<code>action_mask_key</code>，这里的<code>action_mask_key</code>需要与环境定义是声明的键保持一致。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">algo = (</span><br><span class="line">    PPOConfig()</span><br><span class="line">    .training(</span><br><span class="line">        model=&#123;</span><br><span class="line">            <span class="string">&quot;custom_model&quot;</span>: TorchActionMaskModel</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">    .environment(</span><br><span class="line">        env=Env, </span><br><span class="line">        action_mask_key=<span class="string">&quot;action_mask&quot;</span></span><br><span class="line">    )</span><br><span class="line">    .build()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="自定义存储路径"><a href="#自定义存储路径" class="headerlink" title="自定义存储路径"></a>自定义存储路径</h2><p><code>Ray</code>的训练结果的默认存储路径是<code>~/ray_results</code>。如果我们想要让结果存储在指定的存储路径下，便需要修改默认的<code>logger_creator</code>，该参数是一个<code>Callable</code>对象，因此我们可以实现一个函数来自定义存储路径，然后将该函数作为参数传入即可。例如，下面的代码定义了一个名为 <code>custom_log_creator</code> 的函数，它接受一个参数 <code>logger_dir</code>。该函数返回另一个函数 <code>logger_creator</code>，该函数接收一个配置参数 <code>config</code>，并返回一个 <code>UnifiedLogger</code> 实例。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">custom_log_creator</span>(<span class="params">logger_dir</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">logger_creator</span>(<span class="params">config</span>):</span></span><br><span class="line">        <span class="keyword">return</span> UnifiedLogger(config, logger_dir, loggers=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">return</span> logger_creator</span><br></pre></td></tr></table></figure>
<p>具体使用时，我们可以根据当前时间生成一个文件存储路径，然后在<code>build</code>中传入自定的<code>logger_creator</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">time_now = datetime.now().strftime(<span class="string">&quot;%Y_%m_%d_%H_%M_%S&quot;</span>)</span><br><span class="line">logger_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), <span class="string">&quot;ray_results&quot;</span>, time_now)</span><br><span class="line">algo = (</span><br><span class="line">    PPOConfig()</span><br><span class="line">    .build(</span><br><span class="line">        logger_creator=custom_log_creator(logger_dir)</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>RLlib</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>RLlib</tag>
      </tags>
  </entry>
  <entry>
    <title>Python知识点</title>
    <url>/2021/11/07/Python%E6%8B%BE%E9%81%97/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下一些Python的知识点</p>
<a id="more"></a>
<h1 id="垃圾回收机制"><a href="#垃圾回收机制" class="headerlink" title="垃圾回收机制"></a>垃圾回收机制</h1><p>参考链接：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/83251959">Python垃圾回收机制！非常实用</a></li>
<li><a href="https://www.cnblogs.com/fat-girl-spring/p/15094805.html">Python垃圾回收机制</a></li>
</ol>
<p>Python采用的是引用计数机制为主，标记-清除和分代收集两种机制为辅的策略</p>
<h2 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h2><p>在Python中每一个对象的核心就是一个结构体PyObject，它的内部有一个引用计数器（ob_refcnt）。程序在运行的过程中会实时的更新ob_refcnt的值，来反映引用当前对象的名称数量。当某对象的引用计数值为0,那么它的内存就会被立即释放掉。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> struct_object &#123;</span><br><span class="line"> <span class="keyword">int</span> ob_refcnt;</span><br><span class="line"> struct_typeobject *ob_type;</span><br><span class="line">&#125; PyObject;</span><br></pre></td></tr></table></figure>
<p>以下情况是导致引用计数加一的情况:</p>
<ul>
<li>对象被创建，例如a=2</li>
<li>对象被引用，b=a</li>
<li>对象被作为参数，传入到一个函数中</li>
<li>对象作为一个元素，存储在容器中</li>
</ul>
<p>下面的情况则会导致引用计数减一:</p>
<ul>
<li>对象别名被显式销毁 del</li>
<li>对象别名被赋予新的对象</li>
<li>一个对象离开他的作用域</li>
<li>对象所在的容器被销毁或者是从容器中删除对象</li>
</ul>
<p>引用计数机制的优点：</p>
<ol>
<li>简单</li>
<li>实时性：一旦没有引用，内存就直接释放了。不用像其他机制等到特定时机。实时性还带来一个好处：处理回收内存的时间分摊到了平时。</li>
</ol>
<p>引用计数机制的缺点：</p>
<ol>
<li>维护引用计数消耗资源</li>
<li>循环引用</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list1 = []</span><br><span class="line">list2 = []</span><br><span class="line">list1.append(list2)</span><br><span class="line">list2.append(list1)</span><br></pre></td></tr></table></figure>
<p>list1与list2相互引用，如果不存在其他对象对它们的引用，list1与list2的引用计数也仍然为1，所占用的内存永远无法被回收，这将是致命的。</p>
<h2 id="标记-清除"><a href="#标记-清除" class="headerlink" title="标记-清除"></a>标记-清除</h2><p>Python采用了<strong>“标记-清除”(Mark and Sweep)</strong>算法，解决容器对象可能产生的循环引用问题。（注意，只有容器对象才会产生循环引用的情况，比如列表、字典、用户自定义类的对象、元组等。而像数字，字符串这类简单类型不会出现循环引用。作为一种优化策略，对于只包含简单类型的元组也不在标记清除算法的考虑之列）</p>
<p>该算法在进行垃圾回收时分成了两步，分别是：</p>
<ul>
<li>A）标记阶段，遍历所有的对象，如果是可达的（reachable），也就是还有对象引用它，那么就标记该对象为可达；</li>
<li>B）清除阶段，再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。</li>
</ul>
<p>在标记清除算法中，为了追踪容器对象，需要每个容器对象维护两个额外的指针，用来将容器对象组成一个双端链表，指针分别指向前后两个容器对象，方便插入和删除操作。python解释器(Cpython)维护了两个这样的双端链表，一个链表存放着需要被扫描的容器对象，另一个链表存放着临时不可达对象。每一个节点除了有一个记录当前引用计数的变量ref_count还有一个gc_ref变量，这个gc_ref是ref_count的一个副本，所以初始值为ref_count的大小。</p>
<p>过程：</p>
<ol>
<li>gc启动的时候，会逐个遍历”Object to Scan”链表中的容器对象，并且将当前对象所引用的所有对象的gc_ref减一。</li>
<li>接着，gc会再次扫描所有的容器对象，如果对象的gc_ref值为0，那么这个对象就被标记为GC_TENTATIVELY_UNREACHABLE，并且被移至”Unreachable”链表中。</li>
<li>如果对象的gc_ref不为0，那么这个对象就会被标记为GC_REACHABLE。同时当gc发现有一个节点是可达的，那么他会递归式的将从该节点出发可以到达的所有节点标记为GC_REACHABLE。</li>
<li>除了将所有可达节点标记为GC_REACHABLE之外，如果该节点当前在”Unreachable”链表中的话，还需要将其移回到”Object to Scan”链表中。</li>
<li>第二次遍历的所有对象都遍历完成之后，存在于”Unreachable”链表中的对象就是真正需要被释放的对象。</li>
</ol>
<h2 id="分代回收"><a href="#分代回收" class="headerlink" title="分代回收"></a>分代回收</h2><p>在循环引用对象的回收中，整个应用程序会被暂停，为了减少应用程序暂停的时间，Python 通过<strong>“分代回收”(Generational Collection)</strong>以空间换时间的方法提高垃圾回收效率。</p>
<p>分代回收是基于这样的一个统计事实，<strong>对于程序，存在一定比例的内存块的生存周期比较短；而剩下的内存块，生存周期会比较长，甚至会从程序开始一直持续到程序结束。生存期较短对象的比例通常在 80%～90% 之间，这种思想简单点说就是：对象存在时间越长，越可能不是垃圾，应该越少去收集。这样在执行标记-清除算法时可以有效减小遍历的对象数，从而提高垃圾回收的速度。</strong></p>
<p>python gc给对象定义了三种世代(0,1,2),每一个新生对象在generation zero中，如果它在一轮gc扫描中活了下来，那么它将被移至generation one,在那里他将较少的被扫描，如果它又活过了一轮gc,它又将被移至generation two，在那里它被扫描的次数将会更少。</p>
<p>gc的扫描在什么时候会被触发呢?答案是当某一世代中被分配的对象与被释放的对象之差达到某一阈值的时候，就会触发gc对某一世代的扫描。值得注意的是当某一世代的扫描被触发的时候，比该世代年轻的世代也会被扫描。也就是说如果世代2的gc扫描被触发了，那么世代0,世代1也将被扫描，如果世代1的gc扫描被触发，世代0也会被扫描。</p>
<p>该阈值可以通过下面两个函数查看和调整:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gc.get_threshold() <span class="comment"># (threshold0, threshold1, threshold2).</span></span><br><span class="line">gc.set_threshold(threshold0[, threshold1[, threshold2]])</span><br></pre></td></tr></table></figure>
<p>下面对set_threshold()中的三个参数threshold0, threshold1, threshold2进行介绍。gc会记录自从上次收集以来新分配的对象数量与释放的对象数量，当两者之差超过threshold0的值时，gc的扫描就会启动，初始的时候只有世代0被检查。如果自从世代1最近一次被检查以来，世代0被检查超过threshold1次，那么对世代1的检查将被触发。相同的，如果自从世代2最近一次被检查以来，世代1被检查超过threshold2次，那么对世代2的检查将被触发。get_threshold()是获取三者的值，默认值为(700,10,10).</p>
<h1 id="整数缓存问题"><a href="#整数缓存问题" class="headerlink" title="整数缓存问题"></a>整数缓存问题</h1><p>Python仅仅对比较小的整数对象进行缓存（范围为[-5,256]），而并非所有的整数对象。需要注意的是，这仅仅是在<strong>命令行</strong>中执行，而在Pycharm或保存为文件执行，结果是不一样的，因为解释器做了一部分优化（范围变成了[-5, 任意正整数]）（注：自己在Pycharm中实践发现小于-5的好像也可）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="number">1000</span></span><br><span class="line">b = <span class="number">1000</span></span><br><span class="line">a <span class="keyword">is</span> b <span class="comment"># False</span></span><br><span class="line"></span><br><span class="line">a = <span class="number">100</span></span><br><span class="line">b = <span class="number">100</span></span><br><span class="line">a <span class="keyword">is</span> b <span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<h1 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h1><ol>
<li>字符串拼接尽量使用<code>join()</code>而不是<code>+=</code>，因为<code>+=</code>每次会创建新对象</li>
<li><strong>字符串驻留</strong>：仅保存一份相同且不可变的字符串的方法，不同的值被存放在字符串驻留池中。Python支持字符串驻留机制，对于符合标识规则的字符串（仅包含下划线<code>_</code>，字母和数字）会启用字符串驻留机制。（似乎Pycharm中不需要满足命名规则）</li>
</ol>
<h1 id="字典核心底层原理"><a href="#字典核心底层原理" class="headerlink" title="字典核心底层原理"></a>字典核心底层原理</h1><p>字典对象核心是散列表。散列表是一个稀疏数组（总有空白元素的数组），数组的每个单元叫做bucket。每个bucket有两个部分：一是键对象的引用，一个是值对象的引用。可以通过偏移量来读取指定的bucket。</p>
<p>键值对放进字典的底层过程：</p>
<ol>
<li>计算见的散列值，python中通过<code>hash()</code>来计算。</li>
<li>查看偏移量对应的bucket是否为空，如果为空，则放入。如果不为空，则取新的偏移量，查看新偏移量对应的bucket是否为空，直到找到空的bucket存放。</li>
<li>如果数组2/3已经满了，自动扩容，已存放的自动复制</li>
</ol>
<p>根据键查找键值对的底层过程：</p>
<ol>
<li>算散列值</li>
<li>根据散列值找bucket，bucket为空，返回None；bucket不为空则取出键，并计算新散列值，比较第一步的散列值和当前散列值是否相同。相同返回，不同则继续取新的散列值。</li>
</ol>
<h1 id="判断"><a href="#判断" class="headerlink" title="判断"></a>判断</h1><p><code>if not A</code> 和 <code>if A is None</code> 看起来都是在判断<code>A</code>是否为<strong>空</strong>，实际上这两者是不同的：</p>
<ul>
<li><code>if not A</code> 判断的是<code>A</code>是否为<strong>空</strong>，也就是说里面有东西没？</li>
<li><code>if A is None</code>则判断的是<code>A</code>是否<strong>声明并定义</strong>了？</li>
</ul>
<h1 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a>默认参数</h1><p>在Python里，函数的默认值是在函数的定义时实例化的，而不是调用时。当且仅当默认参数所在的“def”语句执行的时候，默认值才会进行计算。“def”是Python的可执行语句，默认参数在“def”的语句环境里被计算。如果执行多次“def”语句，每次都会创建一个新的参数对象。</p>
<p>为什么调用函数的时候，这个默认值却被赋予了不同的值呢？因为在每次给函数指定一个默认值的时候，Python都会存储这个值。如果在调用函数的时候重写了默认值，那么这个存储的值就不会被使用。当不重写默认值的时候，那么Python就会让默认值引用存储的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">x, lst=[]</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> lst:</span><br><span class="line">        lst.append(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> lst</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    list1 = add(<span class="number">1</span>)</span><br><span class="line">    print(list1)</span><br><span class="line"></span><br><span class="line">    list2 = add(<span class="number">2</span>)</span><br><span class="line">    print(list2)</span><br><span class="line"></span><br><span class="line">    list3 = add(<span class="number">3</span>, [<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>])</span><br><span class="line">    print(list3)</span><br><span class="line"></span><br><span class="line">    list4 = add(<span class="number">4</span>)</span><br><span class="line">    print(list4)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<p>我们以为的输出结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">1</span>]</span><br><span class="line">[<span class="number">2</span>]</span><br><span class="line">[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">3</span>]</span><br><span class="line">[<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>实际的输出结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">3</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>为了更好地理解调用情况，可以在add函数中输出lst的id，如以下代码：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">x, lst=[]</span>):</span></span><br><span class="line">    print(<span class="built_in">id</span>(lst))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> lst:</span><br><span class="line">        lst.append(x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> lst</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    list1 = add(<span class="number">1</span>)</span><br><span class="line">    print(list1)</span><br><span class="line"></span><br><span class="line">    list2 = add(<span class="number">2</span>)</span><br><span class="line">    print(list2)</span><br><span class="line"></span><br><span class="line">    list3 = add(<span class="number">3</span>, [<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>])</span><br><span class="line">    print(list3)</span><br><span class="line"></span><br><span class="line">    list4 = add(<span class="number">4</span>)</span><br><span class="line">    print(list4)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">4469603648</span></span><br><span class="line">[<span class="number">1</span>]</span><br><span class="line"><span class="number">4469603648</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line"><span class="number">4469670472</span></span><br><span class="line">[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">3</span>]</span><br><span class="line"><span class="number">4469603648</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>如何避免踩坑呢？建议的正确代码的形式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">x, lst=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> lst <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        lst = []</span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> lst:</span><br><span class="line">        lst.append(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> lst</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    list1 = add(<span class="number">1</span>)</span><br><span class="line">    print(list1)</span><br><span class="line"></span><br><span class="line">    list2 = add(<span class="number">2</span>)</span><br><span class="line">    print(list2)</span><br><span class="line"></span><br><span class="line">    list3 = add(<span class="number">3</span>, [<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>])</span><br><span class="line">    print(list3)</span><br><span class="line"></span><br><span class="line">    list4 = add(<span class="number">4</span>)</span><br><span class="line">    print(list4)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h1 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h1><p>代码优化：</p>
<ol>
<li>尽量减少循环内部不必要的计算</li>
<li>嵌套循环中，尽量减少内层循环的计算，尽可能向外提</li>
<li>局部变量查询较快，尽量使用局部变量</li>
</ol>
<h2 id="for…else循环"><a href="#for…else循环" class="headerlink" title="for…else循环"></a>for…else循环</h2><p>当迭代的对象迭代完并为空时，位于else的子句将执行，而如果在for循环中含有break时则直接终止循环，并不会执行else子句。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2022/2/24 18:51</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">5</span>:</span><br><span class="line">        print(<span class="string">f&quot;Find <span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">&quot;Not find&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>预期的结果是找到5时打印出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Find <span class="number">5</span></span><br></pre></td></tr></table></figure>
<h1 id="浅拷贝和深拷贝"><a href="#浅拷贝和深拷贝" class="headerlink" title="浅拷贝和深拷贝"></a>浅拷贝和深拷贝</h1><p>浅拷贝：不拷贝子对象的内容，只是拷贝子对象的引用</p>
<p>深拷贝：会连子对象的内存也全部拷贝一份，对子对象的修改不会影响源对象</p>
<p><strong>浅拷贝</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">a = [<span class="number">10</span>, <span class="number">20</span>, [<span class="number">30</span>, <span class="number">40</span>]]</span><br><span class="line">b_shallow = copy.copy(a)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;a:&quot;</span>, a)</span><br><span class="line">print(<span class="string">&quot;b_shallow:&quot;</span>, b_shallow)</span><br><span class="line"></span><br><span class="line">b_shallow.append(<span class="number">60</span>)</span><br><span class="line">b_shallow[<span class="number">2</span>].append(<span class="number">70</span>)</span><br><span class="line">print(<span class="string">&quot;######浅拷贝后######&quot;</span>)</span><br><span class="line">print(<span class="string">&quot;a:&quot;</span>, a)</span><br><span class="line">print(<span class="string">&quot;b_shallow:&quot;</span>, b_shallow)</span><br><span class="line"></span><br><span class="line"><span class="comment"># a: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># b_shallow: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># ######浅拷贝后######</span></span><br><span class="line"><span class="comment"># a: [10, 20, [30, 40, 70]]</span></span><br><span class="line"><span class="comment"># b_shallow: [10, 20, [30, 40, 70], 60]</span></span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/shallow.png" alt="浅拷贝"><strong>深拷贝</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">a = [<span class="number">10</span>, <span class="number">20</span>, [<span class="number">30</span>, <span class="number">40</span>]]</span><br><span class="line">b_deep = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;a:&quot;</span>, a)</span><br><span class="line">print(<span class="string">&quot;b_deep:&quot;</span>, b_deep)</span><br><span class="line"></span><br><span class="line">b_deep.append(<span class="number">60</span>)</span><br><span class="line">b_deep[<span class="number">2</span>].append(<span class="number">70</span>)</span><br><span class="line">print(<span class="string">&quot;######深拷贝######&quot;</span>)</span><br><span class="line">print(<span class="string">&quot;a:&quot;</span>, a)</span><br><span class="line">print(<span class="string">&quot;b_deep:&quot;</span>, b_deep)</span><br><span class="line"></span><br><span class="line"><span class="comment"># a: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># b_deep: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># ######深拷贝######</span></span><br><span class="line"><span class="comment"># a: [10, 20, [30, 40]]</span></span><br><span class="line"><span class="comment"># b_deep: [10, 20, [30, 40, 70], 60]</span></span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/deep.png" alt="深拷贝"></p>
<h1 id="LEGB规则"><a href="#LEGB规则" class="headerlink" title="LEGB规则"></a>LEGB规则</h1><p>Python在查找名称时，是按照LEGB规则查找的：Local $\longrightarrow$ Enclosed $\longrightarrow$ Global $\longrightarrow$ Built in</p>
<ul>
<li>Local：指的是函数或者类的方法的内部</li>
<li>Enclosed：指的是嵌套函数（一个函数内包裹另一个函数，闭包）</li>
<li>Global：指的是模块中的全局变量</li>
<li>Built in：指的是Python为自己保留的特殊名称</li>
</ul>
<h1 id="MRO"><a href="#MRO" class="headerlink" title="MRO"></a>MRO</h1><p>Python支持多继承，如果父类中有相同名字的方法，在子类没有指定父类名时，解释器将“从左到右”顺序搜索。</p>
<p>MRO（Method Resolution Order）：方法解析顺序。我们可以通过<code>mro()</code>方法获取类的层次结构，方法也是按照这个类的层次结构寻找的。</p>
<p>子类和父类同时实现某个方法，根据<code>MRO</code>原则，调用子类的方法。下述例子输出<code>B load</code>，其层次结构为<code>[&lt;class &#39;__main__.B&#39;&gt;, &lt;class &#39;__main__.A&#39;&gt;, &lt;class &#39;object&#39;&gt;]</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;A load&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>(<span class="params">A</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;B load&quot;</span>)</span><br><span class="line"></span><br><span class="line">c = B()</span><br><span class="line">c.load()</span><br><span class="line">print(B.mro())</span><br></pre></td></tr></table></figure>
<p>子类继承多个父类，子类没有实现某个方法但多个父类都实现了该方法，根据<code>MRO</code>原则，从左到右搜索，即先继承的类先调用。下述例子输出<code>A load</code>，其层次结构为<code>[&lt;class &#39;__main__.C&#39;&gt;, &lt;class &#39;__main__.A&#39;&gt;, &lt;class &#39;__main__.B&#39;&gt;, &lt;class &#39;object&#39;&gt;]</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;A load&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;B load&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span>(<span class="params">A, B</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">c = C()</span><br><span class="line">c.load()</span><br><span class="line">print(C.mro())</span><br></pre></td></tr></table></figure>
<h1 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h1><p>Serialization系列化，将内存中对象存储下来，变成一个个字节。</p>
<p>deSerialization反序列化，将文件的一个个字节到内存中。</p>
<p>序列化保存到文件就是持久化。</p>
<p>可将数据序列化后持久化，或者网络传输，也可以将文件中或者网络接受到的字节序列反序列化。</p>
<h1 id="sys-path和模块路径搜索"><a href="#sys-path和模块路径搜索" class="headerlink" title="sys.path和模块路径搜索"></a>sys.path和模块路径搜索</h1><p>当我们导入某个模块文件时，<code>Python</code>解释器一般按照以下路径寻找模块文件（按照顺序寻找，找到即停不继续往下寻找）：</p>
<ol>
<li>内置模块</li>
<li>当前目录</li>
<li>程序的主目录</li>
<li><code>pythonpath</code>目录（如果已经设置了<code>pythonpath</code>环境变量）</li>
<li>标准链接库目录</li>
<li>第三方库目录（<code>site-packages</code>目录）</li>
<li><code>.pth</code>文件的内容（如果存在的话）</li>
<li><code>sys.path.append()</code>临时添加的目录</li>
</ol>
<h1 id="进程和线程区别"><a href="#进程和线程区别" class="headerlink" title="进程和线程区别"></a>进程和线程区别</h1><div class="table-container">
<table>
<thead>
<tr>
<th>区别</th>
<th>进程</th>
<th>线程</th>
</tr>
</thead>
<tbody>
<tr>
<td>根本区别</td>
<td>作为资源分配的单位</td>
<td>调度和执行的单位</td>
</tr>
<tr>
<td>开销</td>
<td>每个进程都有独立的代码和数据空间，进程间的切换会有较大的开销</td>
<td>线程可以看成是轻量级的进程，多个线程共享内存，线程切换的开销小</td>
</tr>
<tr>
<td>所处环境</td>
<td>在操作系统中，同时运行的多个任务</td>
<td>在程序中多个顺序流同时执行</td>
</tr>
<tr>
<td>分配内存</td>
<td>系统在运行的时候为每一个进程分配不同的内存区域</td>
<td>线程使用的资源是他所属进程的资源</td>
</tr>
<tr>
<td>包含关系</td>
<td>一个进程可以拥有多个线程</td>
<td>线程是进程的一部分，所有线程有时候称为是轻量级的进程</td>
</tr>
</tbody>
</table>
</div>
<h1 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h1><p>协程，又称微线程，纤程。英文名Coroutine，是一种用户态的轻量级线程。</p>
<p>子程序，或者称为函数，在所有的语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。所以子程序调用时通过栈实现的，一个线程就是执行一个子程序。子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。</p>
<p>线程是<strong>系统</strong>级别的，他们由操作系统调度，而协程则是<strong>程序</strong>级别的，由程序根据需要自己调度。在一个线程中会有很多函数，我们把这些函数称为子程序，在子程序的执行过程中可以中断去执行别的子程序，而别的子程序也可以中断回来继续执行之前的子程序，这个过程就称为协程。也就是说同一线程内一段代码在执行过程中会中断然后跳转执行别的代码，接着在之前中断的地方继续开始执行。</p>
<p>协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此：协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。</p>
<p><strong>优点</strong></p>
<ul>
<li>无需线程上下文切换的开销，协程避免了无意义的调度，由此可以提高性能（但也因此，程序员必须自己承担调度的责任，同时，协程也失去了标准线程使用多CPU的能力）</li>
<li>无需原子操作锁定及同步的开销</li>
<li>方便切换控制流，简化编程模型</li>
<li>高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>无法利用多核资源：协程的本质是个单线程，它不能同时将单个CPU的多个核用上，协程需要和进程配合才能运行在多CPU上。当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。</li>
<li>进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序。</li>
</ul>
<h2 id="yield的使用"><a href="#yield的使用" class="headerlink" title="yield的使用"></a>yield的使用</h2><p>在函数中使用了yield，则该函数就成为了一个生成器。<br>yield的理解：</p>
<ol>
<li>当成return，程序返回</li>
<li>当成生成器</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/19 15:24</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    print(<span class="string">&quot;starting&quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        res = <span class="keyword">yield</span> <span class="number">4</span></span><br><span class="line">        print(<span class="string">&quot;res:&quot;</span>, res)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在函数中使用了yield，则该函数就成为了一个生成器</span></span><br><span class="line"><span class="string">yield的理解：</span></span><br><span class="line"><span class="string">（1）当成return，程序返回</span></span><br><span class="line"><span class="string">（2）当成生成器</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">g = foo()</span><br><span class="line">print(<span class="built_in">next</span>(g))</span><br><span class="line">print(<span class="string">&quot;*&quot;</span> * <span class="number">20</span>)</span><br><span class="line">print(<span class="built_in">next</span>(g))</span><br></pre></td></tr></table></figure>
<h2 id="send的使用"><a href="#send的使用" class="headerlink" title="send的使用"></a>send的使用</h2><ol>
<li>除了可以使用next()函数唤醒生成器继续执行外，还可以使用send()函数唤醒执行。</li>
<li>使用send()函数的优点之一是可以在唤醒的同时将附加数据传输到断点。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/19 16:00</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    print(<span class="string">&quot;starting&quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        res = <span class="keyword">yield</span> <span class="number">4</span></span><br><span class="line">        print(<span class="string">f&quot;res:<span class="subst">&#123;res&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">g = foo()</span><br><span class="line">print(<span class="built_in">next</span>(g))</span><br><span class="line">print(g.send(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<h2 id="同步和异步"><a href="#同步和异步" class="headerlink" title="同步和异步"></a>同步和异步</h2><p>同步：先执行第一个事务，如果遇到阻塞，会一直等待，直到第一个事务执行完毕，才会执行第二个事务。</p>
<p>异步：与同步是相对的，指执行第一个事务的时候，如果遇到阻塞，会直接执行第二个事务，不会等待。通过状态、通知、回调来执行。</p>
<h2 id="task的使用"><a href="#task的使用" class="headerlink" title="task的使用"></a>task的使用</h2><p>协程对象不能直接运行，在注册事件循环的时候，其实是run_until_complete方法将协程包装成为了一个任务(task)对象。所谓task对象是future类的子类。保存了协程运行后的状态，用于未来获取协程的结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/19 16:38</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">do_work</span>(<span class="params">x</span>):</span></span><br><span class="line">    print(<span class="string">f&quot;waiting:<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">coroutine = do_work(<span class="number">3</span>)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line"><span class="comment"># loop.run_until_complete(coroutine)</span></span><br><span class="line"><span class="comment"># 创建任务的方式1</span></span><br><span class="line"><span class="comment"># task = asyncio.ensure_future(coroutine)</span></span><br><span class="line"><span class="comment"># loop.run_until_complete(task)</span></span><br><span class="line"><span class="comment"># 创建任务的方式2</span></span><br><span class="line">task = loop.create_task(coroutine)</span><br><span class="line">loop.run_until_complete(task)</span><br></pre></td></tr></table></figure>
<h2 id="绑定回调"><a href="#绑定回调" class="headerlink" title="绑定回调"></a>绑定回调</h2><p>在task执行完毕的时候可以获取执行的结果，回调的最后一个参数是future对象，通过该对象可以获取协程返回值。如果需要回调多个函数，可以通过偏函数导入。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/19 17:07</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time, asyncio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">do_work</span>(<span class="params">x</span>):</span></span><br><span class="line">    print(<span class="string">f&quot;waiting:<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;Done after <span class="subst">&#123;x&#125;</span> s&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义回调函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">callback</span>(<span class="params">future</span>):</span></span><br><span class="line">    print(<span class="string">f&quot;Callback:<span class="subst">&#123;future.result()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取协程对象</span></span><br><span class="line">coroutine = do_work(<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 创建事件循环</span></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">task = loop.create_task(coroutine)</span><br><span class="line"><span class="comment"># 给任务添加绑定函数</span></span><br><span class="line">task.add_done_callback(callback)</span><br><span class="line">loop.run_until_complete(task)</span><br></pre></td></tr></table></figure>
<h2 id="协程阻塞"><a href="#协程阻塞" class="headerlink" title="协程阻塞"></a>协程阻塞</h2><p>使用async可以定义协程对象，使用await可以针对耗时的操作进行挂起，就像生成器里的yield一样，函数让出控制权。协程遇到await，事件循环将会挂起该协程，执行别的协程，直到其他的协程也挂起或者执行完毕，再进行下一个协程的执行。耗时的操作一般是一些IO操作，例如网络请求，文件读取等。我们使用asyncio.sleep函数来模拟IO操作。协程的目的也是让这些IO操作异步化。</p>
<h2 id="协程并发"><a href="#协程并发" class="headerlink" title="协程并发"></a>协程并发</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/19 17:24</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> asyncio,time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">do_work</span>(<span class="params">x</span>):</span></span><br><span class="line">    print(<span class="string">f&quot;waiting:<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(x)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;Done after <span class="subst">&#123;x&#125;</span> s&quot;</span></span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line">coroutine1 = do_work(<span class="number">1</span>)</span><br><span class="line">coroutine2 = do_work(<span class="number">2</span>)</span><br><span class="line">coroutine3 = do_work(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">tasks = [asyncio.ensure_future(coroutine1),</span><br><span class="line">         asyncio.ensure_future(coroutine2),</span><br><span class="line">         asyncio.ensure_future(coroutine3)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建事件循环</span></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> task <span class="keyword">in</span> tasks:</span><br><span class="line">    print(<span class="string">f&quot;task result:<span class="subst">&#123;task.result()&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;running time:<span class="subst">&#123;time.time()-start&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="协程嵌套"><a href="#协程嵌套" class="headerlink" title="协程嵌套"></a>协程嵌套</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/19 17:31</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> asyncio, time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">do_work</span>(<span class="params">x</span>):</span></span><br><span class="line">    print(<span class="string">f&quot;waiting <span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(x)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;done after <span class="subst">&#123;x&#125;</span> s&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># 创建多个协程对象</span></span><br><span class="line">    <span class="comment"># 封装任务列表</span></span><br><span class="line">    coroutine1 = do_work(<span class="number">1</span>)</span><br><span class="line">    coroutine2 = do_work(<span class="number">2</span>)</span><br><span class="line">    coroutine3 = do_work(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    tasks = [asyncio.ensure_future(coroutine1),</span><br><span class="line">             asyncio.ensure_future(coroutine2),</span><br><span class="line">             asyncio.ensure_future(coroutine3)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取协程返回结果的方式1</span></span><br><span class="line">    <span class="comment"># dones, pending = await asyncio.wait(tasks)</span></span><br><span class="line">    <span class="comment"># for task in dones:</span></span><br><span class="line">    <span class="comment">#     print(f&quot;result: &#123;task.result()&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取协程返回结果的方式2</span></span><br><span class="line">    <span class="comment"># results = await asyncio.gather(*tasks)</span></span><br><span class="line">    <span class="comment"># for result in results:</span></span><br><span class="line">    <span class="comment">#     print(f&quot;result: &#123;result&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取协程返回结果3</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> asyncio.gather(*tasks)</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"><span class="comment"># 将main协程加入到事件循环当中</span></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">results = loop.run_until_complete(main())</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    print(<span class="string">f&quot;result: <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;running time: <span class="subst">&#123;time.time()-start&#125;</span> s&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="协程停止"><a href="#协程停止" class="headerlink" title="协程停止"></a>协程停止</h2><p>创建future的时候，task为pending，事件循环调用执行的时候就是running，调用完毕自然是done，如果需要停止时间循环，就需要先把task取消。可以使用asyncio.Task获取事件循环的task。</p>
<h1 id="网络通信"><a href="#网络通信" class="headerlink" title="网络通信"></a>网络通信</h1><h2 id="OSI模型"><a href="#OSI模型" class="headerlink" title="OSI模型"></a>OSI模型</h2><p>OSI模型七层标准模型：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层，上层可以调用下层完成通信。</p>
<h2 id="TCP-IP协议"><a href="#TCP-IP协议" class="headerlink" title="TCP/IP协议"></a>TCP/IP协议</h2><p>TCP/IP是一个协议族，也是按照层次进行划分，共四层：应用层（应用层+会话层+表示层）、传输层、互连网络层、网络接口层（物理层+数据链路层）。</p>
<h2 id="TCP-UDP"><a href="#TCP-UDP" class="headerlink" title="TCP/UDP"></a>TCP/UDP</h2><p>TCP协议和UDP协议是<strong>传输层</strong>的两种协议。Socket是传输层供给应用层的编程接口，所以Socket编程就分为TCP编程和UDP编程两类。</p>
<p>TCP方式就类似于打电话，使用该种方式进行网络通讯时，需要建立专门的虚拟连接，然后进行可靠的数据传输，如果数据发送失败，则客户端会自动重发该数据。而UDP方式就类似于发送短信，使用这种方式进行网络通讯时，不需要建立专门的虚拟连接，传输也不是很可靠，如果发送失败则客户端无法获得。</p>
<p>重要数据一般使用TCP方式进行数据传输，而大量非核心数据则可以通过UDP方式传输，在一些程序中甚至结合使用这两种方式进行数据传递。</p>
<p>由于TCP需要建立专用的虚拟连接以及确认传输是否正确，所以使用TCP方式的速度稍微慢一些，而传输时产生的数据量要比UDP稍微大一些。</p>
<h3 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a>TCP三次握手</h3><ul>
<li>第一步，客户端发送一个包含SYN即同步（Synchronize）标志的TCP报文，SYN同步报文会指明客户端使用的端口以及TCP连接的初始序号。</li>
<li>第二步，服务器在收到客户端的SYN报文后，将返回一个SYN+ACK的报文，表示客户端的请求被接受，同时TCP序号被加一，ACK即确认（Acknowledgement）。</li>
<li>第三步，客户端也返回一个确认报文ACK给服务器端，同样TCP序号被加一，到此一个TCP连接完成。然后才开始通信的第二步：数据处理。</li>
</ul>
<h2 id="TFTP协议"><a href="#TFTP协议" class="headerlink" title="TFTP协议"></a>TFTP协议</h2><p>TFTP协议全称为简单文件传输协议，它是以UDP为基础的<strong>应用层</strong>协议。</p>
<ul>
<li>数据传输起始于一个读取或者写入文件的请求，只有客户端才可以发送这种请求。</li>
<li>默认情况下，数据以定长512字节传输，如果服务器支持扩展选项，可以使用blksize选项协商数据长度。每个数据包中仅包含一个数据块。只有收到对方的应答数据包，才会发送下一包数据。</li>
<li>如果一个数据包数据大小小于512字节或小于通过blksize选项协商定的数据长度，表示数据传输结束。</li>
<li>两台机器进行数据传输时，一台为发送方一台为接收方。发送方发送数据并接收应答，接收方发送应答接收数据。</li>
<li>大部分的错误会导致连接中断，错误由一个错误的数据包引起，这个包不会被确认，也不会被重新发送。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305131448838.png" alt=""></p>
<h1 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h1><p>既然变量可以指向函数，函数的参数能接收变量，那么一个函数就能接收另外一个函数作为参数，这种函数就称为高阶函数。函数式编程就是指这种高度抽象的编程范式。</p>
<h2 id="高阶函数map"><a href="#高阶函数map" class="headerlink" title="高阶函数map"></a>高阶函数map</h2><p>map函数接收两个参数，一个是函数，一个是序列，<code>map</code>将传入的函数依次作用到序列的每个元素，并把结果作为新的list返回。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterator</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nums = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">nums_iter = <span class="built_in">map</span>(f, nums)</span><br><span class="line">print(<span class="string">f&quot;是否是可迭代的对象：<span class="subst">&#123;<span class="built_in">isinstance</span>(nums_iter, Iterator)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="高阶函数reduce"><a href="#高阶函数reduce" class="headerlink" title="高阶函数reduce"></a>高阶函数reduce</h2><p>reduce把一个函数作用在一个序列上，这个函数必须接收两个参数，reduce把结果和继续和序列的下一个元素做累积计算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 14:47</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x + y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]</span><br><span class="line">total = reduce(f, a)</span><br><span class="line">print(total)</span><br></pre></td></tr></table></figure>
<h2 id="高阶函数filter"><a href="#高阶函数filter" class="headerlink" title="高阶函数filter"></a>高阶函数filter</h2><p>Python内置的filter函数用于过滤序列。和map类似，filter也接收一个函数和一个序列，和map不同的是，filter把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 14:56</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_odd</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x % <span class="number">2</span> == <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nums = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">print(<span class="built_in">list</span>(<span class="built_in">filter</span>(is_odd, nums)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="高阶函数sorted"><a href="#高阶函数sorted" class="headerlink" title="高阶函数sorted"></a>高阶函数sorted</h2><p>Python内置的sorted函数可以对list进行排序。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 15:08</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">nums = [-<span class="number">100</span>, <span class="number">100</span>, <span class="number">99</span>, <span class="number">2</span>, <span class="number">0</span>, -<span class="number">20</span>]</span><br><span class="line">sorted_nums = <span class="built_in">sorted</span>(nums)</span><br><span class="line">print(<span class="string">f&quot;默认升序：<span class="subst">&#123;sorted_nums&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">nums = [-<span class="number">100</span>, <span class="number">100</span>, <span class="number">99</span>, <span class="number">2</span>, <span class="number">0</span>, -<span class="number">20</span>]</span><br><span class="line">sorted_nums = <span class="built_in">sorted</span>(nums, reverse=<span class="literal">True</span>)</span><br><span class="line">print(<span class="string">f&quot;使用reverse降序：<span class="subst">&#123;sorted_nums&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">nums = [-<span class="number">100</span>, <span class="number">100</span>, <span class="number">99</span>, <span class="number">2</span>, <span class="number">0</span>, -<span class="number">20</span>]</span><br><span class="line">sorted_nums = <span class="built_in">sorted</span>(nums, key=<span class="built_in">abs</span>)</span><br><span class="line">print(<span class="string">f&quot;按绝对值排序：<span class="subst">&#123;sorted_nums&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="高阶函数zip"><a href="#高阶函数zip" class="headerlink" title="高阶函数zip"></a>高阶函数zip</h2><p>zip函数用于将可迭代对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的对象。如果各个可迭代对象的元素个数不一致，则返回的对象长度与最短的可迭代对象相同。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">b = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">c = [<span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]</span><br><span class="line">print(<span class="built_in">list</span>(<span class="built_in">zip</span>(a, b, c)))</span><br><span class="line"><span class="comment"># [(1, 4, 9), (2, 5, 10), (3, 6, 11)]</span></span><br></pre></td></tr></table></figure>
<p>利用 * 号操作符，与zip相反，进行解压。如下图例子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">b = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">print(<span class="built_in">list</span>(<span class="built_in">zip</span>(a, b)))</span><br><span class="line"><span class="comment"># [(1, 4), (2, 5), (3, 6)]</span></span><br><span class="line">print(*<span class="built_in">zip</span>(a, b))</span><br><span class="line"><span class="comment"># (1, 4) (2, 5) (3, 6)</span></span><br><span class="line">print(<span class="built_in">list</span>(<span class="built_in">zip</span>(*<span class="built_in">zip</span>(a, b))))</span><br><span class="line"><span class="comment"># [(1, 2, 3), (4, 5, 6)]</span></span><br></pre></td></tr></table></figure>
<h2 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h2><p>在传入函数时，有时不需要显式地定义函数，直接传入匿名函数更方便。在Python中，对匿名函数提供了支持，使用lambda可以声明一个匿名函数。匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 15:26</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">f = <span class="keyword">lambda</span> x, y, z: x + y + z</span><br><span class="line">print(f(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">nums = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>]</span><br><span class="line">print(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x * x, nums)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, age</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">students = [Student(<span class="string">&#x27;a&#x27;</span>, <span class="number">7</span>), Student(<span class="string">&#x27;b&#x27;</span>, <span class="number">5</span>), Student(<span class="string">&#x27;c&#x27;</span>, <span class="number">3</span>)]</span><br><span class="line">sorted_students = <span class="built_in">sorted</span>(students, key=<span class="keyword">lambda</span> x: x.age)</span><br><span class="line"><span class="keyword">for</span> student <span class="keyword">in</span> sorted_students:</span><br><span class="line">    print(<span class="string">f&quot;name:<span class="subst">&#123;student.name&#125;</span>, age:<span class="subst">&#123;student.age&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h2><p>闭包实际上就是一个函数，创建方式如下：</p>
<ol>
<li>要有函数的嵌套（内部函数，外部函数）</li>
<li>内部函数中要使用外部函数的变量</li>
<li>外部函数必须有返回值，返回内部函数名</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 15:41</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun_out</span>(<span class="params">num1</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun_in</span>(<span class="params">num2</span>):</span></span><br><span class="line">        <span class="keyword">return</span> num1 + num2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fun_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f = fun_out(<span class="number">100</span>)</span><br><span class="line">res = f(<span class="number">200</span>)</span><br><span class="line">print(<span class="string">f&quot;两个数的和为<span class="subst">&#123;res&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dist_out</span>(<span class="params">x1, y1</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_dist_in</span>(<span class="params">x2, y2</span>):</span></span><br><span class="line">        <span class="keyword">return</span> math.sqrt((x1 - x2) ** <span class="number">2</span> + (y1 - y2) ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> get_dist_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f = get_dist_out(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">res = f(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">print(<span class="string">f&quot;距离为<span class="subst">&#123;res&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>闭包的特殊用途：在不修改源代码的前提下，添加新的功能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 16:30</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_log</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        file = <span class="built_in">open</span>(<span class="string">&quot;log.txt&quot;</span>, <span class="string">&#x27;a&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">        file.write(<span class="string">&quot;访问：&quot;</span>)</span><br><span class="line">        file.write(func.__name__)</span><br><span class="line">        file.write(<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">        file.write(<span class="string">&quot;时间：&quot;</span>)</span><br><span class="line">        file.write(time.asctime())</span><br><span class="line">        file.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(e.args)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        file.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func1</span>():</span></span><br><span class="line">    print(<span class="string">&quot;功能1&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func2</span>():</span></span><br><span class="line">    print(<span class="string">&quot;功能2&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun_out</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun_in</span>():</span></span><br><span class="line">        write_log(func)</span><br><span class="line">        func()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fun_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f1 = fun_out(func2)</span><br><span class="line">f1()</span><br></pre></td></tr></table></figure>
<h2 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h2><p>在Python中，装饰器就是一种闭包，它可以使闭包的访问方式更加简单。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 16:49</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_log</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        file = <span class="built_in">open</span>(<span class="string">&quot;decorator.txt&quot;</span>, <span class="string">&#x27;a&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">        file.write(<span class="string">&quot;访问：&quot;</span>)</span><br><span class="line">        file.write(func.__name__)</span><br><span class="line">        file.write(<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">        file.write(<span class="string">&quot;时间：&quot;</span>)</span><br><span class="line">        file.write(time.asctime())</span><br><span class="line">        file.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(e.args)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        file.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun_out</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun_in</span>():</span></span><br><span class="line">        write_log(func)</span><br><span class="line">        func()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fun_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 相当于fun_out(fun1)</span></span><br><span class="line"><span class="meta">@fun_out</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun1</span>():</span></span><br><span class="line">    print(<span class="string">&quot;功能1&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@fun_out</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun2</span>():</span></span><br><span class="line">    print(<span class="string">&quot;功能2&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fun1()</span><br></pre></td></tr></table></figure>
<p>多个装饰器同时装饰一个函数的场景下，其装饰顺序与执行顺序为：靠近原函数的先进行装饰后执行，离原函数远的后装饰先执行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 17:17</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun_out1</span>(<span class="params">fun</span>):</span></span><br><span class="line">    print(<span class="string">&quot;装饰器1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun_in1</span>():</span></span><br><span class="line">        print(<span class="string">&quot;hello 1&quot;</span>)</span><br><span class="line">        fun()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fun_in1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun_out2</span>(<span class="params">fun</span>):</span></span><br><span class="line">    print(<span class="string">&quot;装饰器2&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun_in2</span>():</span></span><br><span class="line">        print(<span class="string">&quot;hello 2&quot;</span>)</span><br><span class="line">        fun()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fun_in2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@fun_out2</span></span><br><span class="line"><span class="meta">@fun_out1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun1</span>():</span></span><br><span class="line">    print(<span class="string">&quot;功能1&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fun1()</span><br></pre></td></tr></table></figure>
<p>带参数的装饰器实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 18:40</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_log</span>(<span class="params">func</span>):</span></span><br><span class="line">    print(<span class="string">f&quot;访问了方法：<span class="subst">&#123;func.__name__&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun_out</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun_in</span>(<span class="params">x, y</span>):</span></span><br><span class="line">        write_log(func)</span><br><span class="line">        <span class="keyword">return</span> func(x, y)</span><br><span class="line">    <span class="keyword">return</span> fun_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@fun_out</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">f&quot;两数之和为<span class="subst">&#123;add(<span class="number">10</span>, <span class="number">20</span>)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>对于一个函数而言，它的参数可能是一个、两个或者多个，因此需要使用一个通用的装饰器来装饰函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 18:57</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_log</span>(<span class="params">func</span>):</span></span><br><span class="line">    print(<span class="string">f&quot;于<span class="subst">&#123;time.asctime()&#125;</span>调用了函数<span class="subst">&#123;func.__name__&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun_out</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun_in</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">        write_log(func)</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fun_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@fun_out</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@fun_out</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minus</span>(<span class="params">a, b, c</span>):</span></span><br><span class="line">    <span class="keyword">return</span> a - b - c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">f&quot;两数之和为<span class="subst">&#123;add(<span class="number">10</span>, <span class="number">20</span>)&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;三数之差为<span class="subst">&#123;minus(<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="偏函数"><a href="#偏函数" class="headerlink" title="偏函数"></a>偏函数</h2><p>Python的functools模块提供了很多有用的功能，其中一个就是偏函数（Partial function）。偏函数是用于对函数固定属性的函数，作用就是把一个函数某些参数固定住（也就是设置默认值），返回一个新的函数，调用这个新的函数会更简单。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/16 19:11</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line">new_int = partial(<span class="built_in">int</span>, base=<span class="number">2</span>)</span><br><span class="line">print(new_int(<span class="string">&quot;10&quot;</span>))</span><br><span class="line">print(new_int(<span class="string">&quot;1010&quot;</span>))</span><br><span class="line">print(new_int(<span class="string">&quot;101010&quot;</span>))</span><br></pre></td></tr></table></figure>
<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p>正则表达式是对字符串操作的一种逻辑表达式，就是用事先定义好的一些特定字符及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑（可以用来做检索、截取或者替换操作）。</p>
<p>正则表述式用于搜索、替换和解析字符串。正则表达式遵循一定的语法规则，使用非常灵活，功能强大。使用正则表达式编写一些逻辑验证非常方便，例如电子邮件地址格式的验证。</p>
<p>正则表达式是对字符串（包括普通字符（例如，a到z之间的字母）和特殊字符)操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑，正则表达式是一种文本模式，模式描述在搜索文本时要匹配一个或多个字符串。</p>
<p><strong>正则表达式的作用</strong></p>
<ol>
<li>给定的字符串是否符合正则表达式的过滤逻辑（简称“匹配”）。</li>
<li>可以通过正则表达式，从字符串中获取我们想要的特定部分。</li>
<li>还可以对目标字符串进行替换操作。</li>
</ol>
<h3 id="常用字符"><a href="#常用字符" class="headerlink" title="常用字符"></a>常用字符</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">.</td>
<td style="text-align:center">匹配任意一个字符（’\n’除外）</td>
</tr>
<tr>
<td style="text-align:center">[]</td>
<td style="text-align:center">匹配列表中的字符</td>
</tr>
<tr>
<td style="text-align:center">\w</td>
<td style="text-align:center">匹配字母、数字、下划线，即a-z，A-Z，0-9，_</td>
</tr>
<tr>
<td style="text-align:center">\W</td>
<td style="text-align:center">匹配不是字母、数字、下划线</td>
</tr>
<tr>
<td style="text-align:center">\s</td>
<td style="text-align:center">匹配空白字符，即空格（\n，\t）</td>
</tr>
<tr>
<td style="text-align:center">\S</td>
<td style="text-align:center">匹配不是空白的字符</td>
</tr>
<tr>
<td style="text-align:center">\d</td>
<td style="text-align:center">匹配数字，即0-9</td>
</tr>
<tr>
<td style="text-align:center">\D</td>
<td style="text-align:center">匹配非数字的字符</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">&quot;=================.的使用==================&quot;</span>)</span><br><span class="line">s = <span class="string">&#x27;a&#x27;</span></span><br><span class="line">pattern = <span class="string">&#x27;.&#x27;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================\d的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">pattern = <span class="string">&quot;\d&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================\D的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&#x27;-&#x27;</span></span><br><span class="line">pattern = <span class="string">&quot;\D&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================\s的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">pattern = <span class="string">&quot;\s&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================\S的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&#x27;9&#x27;</span></span><br><span class="line">pattern = <span class="string">&quot;\S&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================\w的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&#x27;l&#x27;</span></span><br><span class="line">pattern = <span class="string">&quot;\w&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================\W的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&#x27;+&#x27;</span></span><br><span class="line">pattern = <span class="string">&quot;\W&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================[]的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&#x27;2&#x27;</span></span><br><span class="line">pattern = <span class="string">&quot;[2468]&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br></pre></td></tr></table></figure>
<h3 id="重复限定符"><a href="#重复限定符" class="headerlink" title="重复限定符"></a>重复限定符</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">*</td>
<td style="text-align:center">匹配零次或多次</td>
</tr>
<tr>
<td style="text-align:center">+</td>
<td style="text-align:center">匹配一次或多次</td>
</tr>
<tr>
<td style="text-align:center">?</td>
<td style="text-align:center">匹配一次或零次</td>
</tr>
<tr>
<td style="text-align:center">{m}</td>
<td style="text-align:center">重复m次</td>
</tr>
<tr>
<td style="text-align:center">{m,n}</td>
<td style="text-align:center">重复m到n次，其中n可以省略，表示m到任意次</td>
</tr>
<tr>
<td style="text-align:center">{m,}</td>
<td style="text-align:center">至少m次</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/17 16:47</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;=================*的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;123qwe&quot;</span></span><br><span class="line">pattern = <span class="string">&quot;\d*&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================+的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;a123qwe&quot;</span></span><br><span class="line">pattern = <span class="string">&quot;\d+&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================?的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;a123qwe&quot;</span></span><br><span class="line">pattern = <span class="string">&quot;\d?&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================&#123;m&#125;的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;123qwe&quot;</span></span><br><span class="line">pattern = <span class="string">&quot;\d&#123;2&#125;&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================&#123;m,n&#125;的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;123456qwe&quot;</span></span><br><span class="line">pattern = <span class="string">&quot;\d&#123;2,5&#125;&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(<span class="string">&quot;=================&#123;m,&#125;的使用=================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;123456qwe&quot;</span></span><br><span class="line">pattern = <span class="string">&quot;\d&#123;2,&#125;&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br></pre></td></tr></table></figure>
<h3 id="边界字符"><a href="#边界字符" class="headerlink" title="边界字符"></a>边界字符</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">字符</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">^</td>
<td style="text-align:center">匹配字符串开头</td>
</tr>
<tr>
<td style="text-align:center">$</td>
<td style="text-align:center">匹配字符串结尾</td>
</tr>
<tr>
<td style="text-align:center">\b</td>
<td style="text-align:center">匹配一个单词的边界</td>
</tr>
<tr>
<td style="text-align:center">\B</td>
<td style="text-align:center">匹配非单词的边界</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/18 10:51</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">print(<span class="string">&quot;===============$的使用=================&quot;</span>)</span><br><span class="line"><span class="comment"># 匹配5-10位的QQ邮箱，开头数字不能是0</span></span><br><span class="line">pattern = <span class="string">r&quot;[1-9]\d&#123;4,9&#125;@qq.com$&quot;</span></span><br><span class="line"><span class="comment"># 可以匹配</span></span><br><span class="line"><span class="comment"># qq = r&quot;12345@qq.com&quot;</span></span><br><span class="line"><span class="comment"># 不可以匹配</span></span><br><span class="line">qq = <span class="string">r&quot;12345@qq.com.126.com&quot;</span></span><br><span class="line">o = re.match(pattern, qq)</span><br><span class="line">print(o)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;===============^的使用=================&quot;</span>)</span><br><span class="line">pattern = <span class="string">r&quot;^hello&quot;</span></span><br><span class="line">s = <span class="string">r&quot;hello python&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line"></span><br><span class="line">print(<span class="string">r&quot;===============\b左边界的使用=================&quot;</span>)</span><br><span class="line">pattern = <span class="string">r&quot;.*\bhello&quot;</span></span><br><span class="line">s = <span class="string">r&quot;python hello python&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line"></span><br><span class="line">print(<span class="string">r&quot;===============\b右边界的使用=================&quot;</span>)</span><br><span class="line">pattern = <span class="string">r&quot;.*python\b&quot;</span></span><br><span class="line">s = <span class="string">r&quot;python hello python&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line"></span><br><span class="line">print(<span class="string">r&quot;===============\B非单词边界的使用=================&quot;</span>)</span><br><span class="line">pattern = <span class="string">r&quot;.*python\B&quot;</span></span><br><span class="line">s = <span class="string">r&quot;hello pythonhello&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br></pre></td></tr></table></figure>
<h3 id="择一匹配字符"><a href="#择一匹配字符" class="headerlink" title="择一匹配字符"></a>择一匹配字符</h3><p>search方法搜索一个字符串，要想搜索多个字符串，如搜索aa、bb和cc，最简单的方法是在文本模式字符串中使用择一匹配符号（|）。择一匹配符号和逻辑或类似，只要满足任何一个就算匹配成功。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pattern = <span class="string">&quot;aa|bb|cc&quot;</span></span><br><span class="line">s = <span class="string">&quot;aa&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 匹配0-100的所有数字</span></span><br><span class="line">pattern = <span class="string">r&quot;[1-9][0-9]$|100$&quot;</span></span><br><span class="line">s = <span class="string">&quot;123&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br></pre></td></tr></table></figure>
<h3 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h3><p>如果一个模式字符串中有用一堆圆括号括起来的部分，那么这部分就会作为一组，可以通过group方法的参数获取指定的组匹配的字符串。当然，如果模式字符串中没有任何用圆括号括起来的部分，那么就不会对待匹配的字符串进行分组。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">字符</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">(ab)</td>
<td style="text-align:center">将括号中的字符作为一个分组</td>
</tr>
<tr>
<td style="text-align:center">\num</td>
<td style="text-align:center">引用分组num匹配到的字符串</td>
</tr>
<tr>
<td style="text-align:center">(?P<name>)</td>
<td style="text-align:center">分组起别名</td>
</tr>
<tr>
<td style="text-align:center">(?P=name)</td>
<td style="text-align:center">引用别名为name分组匹配到的字符串</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/5/18 11:39</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">print(<span class="string">&quot;================分组的使用===============&quot;</span>)</span><br><span class="line"><span class="comment"># 匹配座机号码，区号&#123;3,4&#125;-电话号码&#123;5,8&#125;</span></span><br><span class="line">pattern = <span class="string">r&quot;(\d&#123;3,4&#125;)-([1-9]\d&#123;4,7&#125;$)&quot;</span></span><br><span class="line">s = <span class="string">&quot;010-1234567&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(o.groups())</span><br><span class="line">print(o.group(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 匹配网页的标签数据</span></span><br><span class="line"><span class="comment"># pattern = r&#x27;&lt;.+&gt;&lt;.+&gt;.+&lt;/.+&gt;&lt;/.+&gt;&#x27;</span></span><br><span class="line">pattern = <span class="string">r&#x27;&lt;(.+)&gt;&lt;(.+)&gt;.+&lt;/\2&gt;&lt;/\1&gt;&#x27;</span></span><br><span class="line">s1 = <span class="string">&quot;&lt;html&gt;&lt;head&gt;这是head部分&lt;/head&gt;&lt;/html&gt;&quot;</span></span><br><span class="line">o1 = re.match(pattern, s1)</span><br><span class="line">print(o1)</span><br><span class="line">s2 = <span class="string">&quot;&lt;html&gt;&lt;head&gt;这是head部分&lt;/head&gt;&lt;/body&gt;&quot;</span></span><br><span class="line">o2 = re.match(pattern, s2)</span><br><span class="line">print(o2)</span><br><span class="line"><span class="comment"># 分组起别名</span></span><br><span class="line">pattern = <span class="string">r&#x27;&lt;(?P&lt;k_html&gt;.+)&gt;&lt;(?P&lt;k_head&gt;.+)&gt;.+&lt;/(?P=k_head)&gt;&lt;/(?P=k_html)&gt;&#x27;</span></span><br><span class="line">s1 = <span class="string">&quot;&lt;html&gt;&lt;head&gt;这是head部分&lt;/head&gt;&lt;/html&gt;&quot;</span></span><br><span class="line">o1 = re.match(pattern, s1)</span><br><span class="line">print(o1)</span><br><span class="line">s2 = <span class="string">&quot;&lt;html&gt;&lt;head&gt;这是head部分&lt;/head&gt;&lt;/body&gt;&quot;</span></span><br><span class="line">o2 = re.match(pattern, s2)</span><br><span class="line">print(o2)</span><br></pre></td></tr></table></figure>
<h3 id="match方法"><a href="#match方法" class="headerlink" title="match方法"></a>match方法</h3><p>可选标志位，即flags参数</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">修饰符</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">re.I</td>
<td style="text-align:center">使匹配对大小写不敏感</td>
</tr>
<tr>
<td style="text-align:center">re.L</td>
<td style="text-align:center">做本地化识别（local-aware）匹配</td>
</tr>
<tr>
<td style="text-align:center">re.M</td>
<td style="text-align:center">多行匹配，影响’^’和’$’</td>
</tr>
<tr>
<td style="text-align:center">re.S</td>
<td style="text-align:center">使’.’匹配包括换行在内的所有字符</td>
</tr>
<tr>
<td style="text-align:center">re.U</td>
<td style="text-align:center">根据Unicode字符集解析字符，这个标志影响’\w’，’\W’，’\b’，’\B’</td>
</tr>
<tr>
<td style="text-align:center">re.X</td>
<td style="text-align:center">该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># match方法</span></span><br><span class="line">print(<span class="string">&quot;==============================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;hello python hello&quot;</span></span><br><span class="line">pattern = <span class="string">&quot;hello&quot;</span></span><br><span class="line">o = re.match(pattern, s)</span><br><span class="line">print(o)</span><br><span class="line">print(o.group())</span><br><span class="line">print(o.span())</span><br><span class="line">print(o.start())</span><br><span class="line">print(<span class="string">&quot;============flags=============&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;hello python hello&quot;</span></span><br><span class="line">pattern = <span class="string">&quot;Hello&quot;</span></span><br><span class="line">o = re.match(pattern, s, re.I)</span><br><span class="line">print(o)</span><br><span class="line">print(o.group())</span><br><span class="line">print(o.span())</span><br><span class="line">print(o.start())</span><br></pre></td></tr></table></figure>
<h3 id="search方法"><a href="#search方法" class="headerlink" title="search方法"></a>search方法</h3><p>search在一个字符串中搜索满足文本模式的字符串。与match方法的不同之处在于match从头开始匹配，search是在整个字符串中寻找。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">s = <span class="string">&quot;I love python&quot;</span></span><br><span class="line">pattern = <span class="string">&quot;love&quot;</span></span><br><span class="line">o1 = re.search(pattern, s)</span><br><span class="line">print(o1)</span><br><span class="line">o2 = re.match(pattern, s)</span><br><span class="line">print(o2)</span><br></pre></td></tr></table></figure>
<h3 id="sub和subn函数"><a href="#sub和subn函数" class="headerlink" title="sub和subn函数"></a>sub和subn函数</h3><p>sub和subn函数用于实现搜索和替换功能。这两个函数的功能几乎完全相同，都是将某个字符串中所有匹配正则表达式的部分替换成其他字符串。用来替换的部分可能是一个字符串，也可以是一个函数，该函数返回一个用来替换的字符串。sub函数返回替换后的结果，subn函数返回一个元组，元组的第一个元素是替换后的结果，第二个元素是替换的总数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;=====================sub和subn========================&quot;</span>)</span><br><span class="line"><span class="comment"># 将phone中的注释去掉</span></span><br><span class="line">phone = <span class="string">&quot;010-234567-78979 # 这是一个电话号码&quot;</span></span><br><span class="line">pattern = <span class="string">r&quot;#.*$&quot;</span></span><br><span class="line">res = re.sub(pattern, <span class="string">&#x27;&#x27;</span>, phone)</span><br><span class="line">print(res)</span><br><span class="line">res = re.subn(pattern, <span class="string">&#x27;&#x27;</span>, phone)</span><br><span class="line">print(res)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="compile函数"><a href="#compile函数" class="headerlink" title="compile函数"></a>compile函数</h3><p>compile函数用于编译正则表达式，生成一个正则表达式对象，供match和search这两个函数使用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">print(<span class="string">&quot;=====================compile========================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;first123 line&quot;</span></span><br><span class="line">pattern = <span class="string">r&quot;\w+&quot;</span></span><br><span class="line">regex = re.<span class="built_in">compile</span>(pattern)</span><br><span class="line">res = regex.match(s)</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure>
<h3 id="findall函数"><a href="#findall函数" class="headerlink" title="findall函数"></a>findall函数</h3><p>在字符串中找到正则表达式所匹配的所有子串，并返回一个列表，如果没有找到匹配的，则返回空列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">print(<span class="string">&quot;=====================findall========================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;first 1 second 2 third 3&quot;</span></span><br><span class="line">pattern = <span class="string">r&quot;\w+&quot;</span></span><br><span class="line">res = re.findall(pattern, s)</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure>
<h3 id="finditer函数"><a href="#finditer函数" class="headerlink" title="finditer函数"></a>finditer函数</h3><p>和findall类似，在字符串中找到正则表达式所匹配的所有子串，并把它们作为一个迭代器返回。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">print(<span class="string">&quot;=====================finditer========================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;first 1 second 2 third 3&quot;</span></span><br><span class="line">pattern = <span class="string">r&quot;\w+&quot;</span></span><br><span class="line">res = re.finditer(pattern, s)</span><br><span class="line"><span class="keyword">for</span> o <span class="keyword">in</span> res:</span><br><span class="line">    print(o)</span><br></pre></td></tr></table></figure>
<h3 id="split函数"><a href="#split函数" class="headerlink" title="split函数"></a>split函数</h3><p>split函数用于根据正则表达式分隔字符，也就是说，将字符串与模式匹配的子字符串都作为分隔符来分隔这个字符串。split函数返回一个列表形式的分隔结果，每一个列表元素都是分隔的子字符串。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">print(<span class="string">&quot;=====================split========================&quot;</span>)</span><br><span class="line">s = <span class="string">&quot;first 11 second 22 third 33&quot;</span></span><br><span class="line">pattern = <span class="string">r&quot;\d+&quot;</span></span><br><span class="line">res = re.split(pattern, s)</span><br><span class="line">print(res)</span><br><span class="line">res = re.split(pattern, s, <span class="number">1</span>)</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure>
<h3 id="贪婪模式和非贪婪模式"><a href="#贪婪模式和非贪婪模式" class="headerlink" title="贪婪模式和非贪婪模式"></a>贪婪模式和非贪婪模式</h3><p>贪婪模式指python里数量词默认是贪婪的，总是尝试匹配尽可能多的字符。非贪婪模式与贪婪模式相反，总是尝试匹配尽可能少的字符，可以使用’*’，’?’，’+’，’{m,n}’后面加上?，使得贪婪变成非贪婪。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">print(<span class="string">&quot;==============================贪婪模式===============================&quot;</span>)</span><br><span class="line">v = re.match(<span class="string">r&#x27;(.+)(\d+-\d+-\d+)&#x27;</span>, <span class="string">&quot;this is my tel:133-1234-1234&quot;</span>)</span><br><span class="line">print(v.group(<span class="number">1</span>))</span><br><span class="line">print(v.group(<span class="number">2</span>))</span><br><span class="line">print(<span class="string">&quot;==============================非贪婪模式===============================&quot;</span>)</span><br><span class="line">v = re.match(<span class="string">r&#x27;(.+?)(\d+-\d+-\d+)&#x27;</span>, <span class="string">&quot;this is my tel:133-1234-1234&quot;</span>)</span><br><span class="line">print(v.group(<span class="number">1</span>))</span><br><span class="line">print(v.group(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<h3 id="type类型"><a href="#type类型" class="headerlink" title="type类型"></a>type类型</h3><p>在<code>python</code>中，<code>type</code>是一个类型而不是内置函数，该类重载了初始化方法<code>__init__</code>，因此其主要有两种用法。第一种是常见的判断对象属于什么类型，传入一个参数，基本用法为<code>type(object)</code>；第二种是返回新的类型对象，传入三个参数，基本用法为<code>type(name, bases, dict)</code>，<code>name</code>为类的名称，<code>bases</code>为基类的元组，<code>dict</code>为类内定义的命名空间变量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">type</span>:</span></span><br><span class="line">    <span class="comment"># object.__base__ is None. Otherwise, it would be a type.</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__base__</span>(<span class="params">self</span>) -&gt; type | <span class="keyword">None</span>:</span> ...</span><br><span class="line">    __bases__: <span class="built_in">tuple</span>[<span class="built_in">type</span>, ...]</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__basicsize__</span>(<span class="params">self</span>) -&gt; int:</span> ...</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__dict__</span>(<span class="params">self</span>) -&gt; types.MappingProxyType[str, Any]:</span> ...  <span class="comment"># type: ignore[override]</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__dictoffset__</span>(<span class="params">self</span>) -&gt; int:</span> ...</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__flags__</span>(<span class="params">self</span>) -&gt; int:</span> ...</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__itemsize__</span>(<span class="params">self</span>) -&gt; int:</span> ...</span><br><span class="line">    __module__: <span class="built_in">str</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__mro__</span>(<span class="params">self</span>) -&gt; tuple[type, ...]:</span> ...</span><br><span class="line">    __name__: <span class="built_in">str</span></span><br><span class="line">    __qualname__: <span class="built_in">str</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__text_signature__</span>(<span class="params">self</span>) -&gt; str | <span class="keyword">None</span>:</span> ...</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__weakrefoffset__</span>(<span class="params">self</span>) -&gt; int:</span> ...</span><br><span class="line"><span class="meta">    @overload</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, o: <span class="built_in">object</span>, /</span>) -&gt; <span class="keyword">None</span>:</span> ...</span><br><span class="line"><span class="meta">    @overload</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name: <span class="built_in">str</span>, bases: <span class="built_in">tuple</span>[<span class="built_in">type</span>, ...], <span class="built_in">dict</span>: <span class="built_in">dict</span>[<span class="built_in">str</span>, Any], /, **kwds: Any</span>) -&gt; <span class="keyword">None</span>:</span> ...</span><br><span class="line"><span class="meta">    @overload</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>(<span class="params">cls, o: <span class="built_in">object</span>, /</span>) -&gt; type:</span> ...</span><br><span class="line"><span class="meta">    @overload</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">        cls: <span class="built_in">type</span>[_typeshed.Self], name: <span class="built_in">str</span>, bases: <span class="built_in">tuple</span>[<span class="built_in">type</span>, ...], namespace: <span class="built_in">dict</span>[<span class="built_in">str</span>, Any], /, **kwds: Any</span></span></span><br><span class="line"><span class="function"><span class="params">    </span>) -&gt; _typeshed.Self:</span> ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args: Any, **kwds: Any</span>) -&gt; Any:</span> ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__subclasses__</span>(<span class="params">self: _typeshed.Self</span>) -&gt; list[_typeshed.Self]:</span> ...</span><br><span class="line">    <span class="comment"># Note: the documentation doesn&#x27;t specify what the return type is, the standard</span></span><br><span class="line">    <span class="comment"># implementation seems to be returning a list.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mro</span>(<span class="params">self</span>) -&gt; list[type]:</span> ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__instancecheck__</span>(<span class="params">self, instance: Any, /</span>) -&gt; bool:</span> ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__subclasscheck__</span>(<span class="params">self, subclass: <span class="built_in">type</span>, /</span>) -&gt; bool:</span> ...</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__prepare__</span>(<span class="params">metacls, name: <span class="built_in">str</span>, bases: <span class="built_in">tuple</span>[<span class="built_in">type</span>, ...], /, **kwds: Any</span>) -&gt; MutableMapping[str, object]:</span> ...</span><br><span class="line">    <span class="keyword">if</span> sys.version_info &gt;= (<span class="number">3</span>, <span class="number">10</span>):</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__or__</span>(<span class="params">self, value: Any, /</span>) -&gt; types.UnionType:</span> ...</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__ror__</span>(<span class="params">self, value: Any, /</span>) -&gt; types.UnionType:</span> ...</span><br><span class="line">    <span class="keyword">if</span> sys.version_info &gt;= (<span class="number">3</span>, <span class="number">12</span>):</span><br><span class="line">        __type_params__: <span class="built_in">tuple</span>[TypeVar | ParamSpec | TypeVarTuple, ...]</span><br></pre></td></tr></table></figure>
<h2 id="一些库的使用"><a href="#一些库的使用" class="headerlink" title="一些库的使用"></a>一些库的使用</h2><h3 id="bisect库"><a href="#bisect库" class="headerlink" title="bisect库"></a>bisect库</h3><p>bisect()和bisect_right()等同，那下面就介绍bisect_left()和bisec_right()的区别！</p>
<p><strong>列表中没有元素x</strong>，bisect_left(ls, x)和bisec_right(ls, x)返回相同的值，该值是x在ls中“<strong>合适的插入点索引，使得数组有序</strong>”。</p>
<p><strong>列表中只有一个元素等于x</strong>，那么bisect_left(ls, x)的值是x在ls中的<strong>索引</strong>，ls[index2] = x。而bisec_right(ls, x)的值是x在ls中的<strong>索引加1</strong>。</p>
<p><strong>列表中存在多个元素等于x</strong>，那么bisect_left(ls, x)返回<strong>最左边的那个索引</strong>，此时ls[index2] = x。bisect_right(ls, x)返回<strong>最右边的那个索引加1</strong>。</p>
<h3 id="heapq库"><a href="#heapq库" class="headerlink" title="heapq库"></a>heapq库</h3><p> heapq库中的堆默认是<strong>最小堆</strong>，即树种各个父节点的值总是小于或等于任何一个子节点的值。</p>
<p><strong>heappush()</strong></p>
<p>将item压入到堆数组heap中。如果不进行此步操作，后面的heappop()失效，会直接返回原列表第一个值，而且必须从头开始heappush，不然也会返回原列表第一个值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">12</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">63</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">heapq.heappush(a, <span class="number">123</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># [12, 2, 4, 5, 63, 3, 2, 123]</span></span><br><span class="line">b = heapq.heappop(a)</span><br><span class="line">print(b)</span><br><span class="line"><span class="comment"># 12</span></span><br></pre></td></tr></table></figure>
<p><strong>heappop()</strong></p>
<p>删除并返回最小值，因为堆的特征是heap[0]永远是最小的元素，所以一般都是删除第一个元素。注意，如果不是压入堆中，而是通过append追加一个数值，堆的函数并不能操作这个增加的数值，或者说它堆对来讲是不存在的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = []</span><br><span class="line">heapq.heappush(a, <span class="number">11</span>)</span><br><span class="line">heapq.heappush(a, <span class="number">2</span>)</span><br><span class="line">heapq.heappush(a, <span class="number">3</span>)</span><br><span class="line">heapq.heappush(a, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">a.append(<span class="number">1</span>)</span><br><span class="line">b = heapq.heappop(a)</span><br><span class="line">print(b)</span><br><span class="line"><span class="comment"># 2</span></span><br></pre></td></tr></table></figure>
<p><strong>heapify()</strong></p>
<p>参数必须是list，此函数将list变成堆，实时操作。从而能够在任何情况下使用堆的函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">12</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">63</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">heapq.heapify(a)</span><br><span class="line">b = heapq.heappop(a)</span><br><span class="line">print(b)</span><br><span class="line"><span class="comment"># 2</span></span><br></pre></td></tr></table></figure>
<p><strong>heapq.heappushpop()</strong></p>
<p>是上述heappush和heappop的合体，同时完成两者的功能，注意：相当于先操作了heappush()，然后操作heappop()</p>
<p><strong>heapq.heapreplace()</strong></p>
<p>是上述heappop和heappush的联合操作。注意：与heappushpop()的区别在于，顺序不同，这里是先进行删除，后压入堆。</p>
<p><strong>heapq.merge()</strong></p>
<p>将多个堆合并。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>]</span><br><span class="line">b = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>]</span><br><span class="line">c = heapq.merge(a, b)</span><br><span class="line"><span class="keyword">for</span> cc <span class="keyword">in</span> c:</span><br><span class="line">    print(cc, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="comment"># 1 2 3 4 5 6 </span></span><br></pre></td></tr></table></figure>
<p><strong>heapq.nlargest()</strong></p>
<p>查询堆中的最大n个元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = [<span class="number">1</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">23</span>, <span class="number">7</span>, -<span class="number">4</span>, <span class="number">18</span>, <span class="number">23</span>, <span class="number">42</span>, <span class="number">37</span>, <span class="number">2</span>]</span><br><span class="line">print(heapq.nlargest(<span class="number">3</span>, nums))</span><br><span class="line"><span class="comment"># [42, 37, 23]</span></span><br></pre></td></tr></table></figure>
<p><strong>heapq.nsmallest()</strong></p>
<p>查询堆中的最小n个元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = [<span class="number">1</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">23</span>, <span class="number">7</span>, -<span class="number">4</span>, <span class="number">18</span>, <span class="number">23</span>, <span class="number">42</span>, <span class="number">37</span>, <span class="number">2</span>]</span><br><span class="line">print(heapq.nsmallest(<span class="number">3</span>, nums))</span><br><span class="line"><span class="comment"># [-4, 1, 2]</span></span><br></pre></td></tr></table></figure>
<h3 id="functools库"><a href="#functools库" class="headerlink" title="functools库"></a>functools库</h3><p><strong>cmp_to_key</strong></p>
<p>可以将一个cmp函数变成一个key函数，从而支持自定义排序。具体用法是，定义一个函数，接受两个变量x和y，然后返回值如果大于1说明在排序的数组中x在y后面。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = [<span class="number">3</span>, <span class="number">30</span>, <span class="number">34</span>, <span class="number">5</span>, <span class="number">9</span>]</span><br><span class="line">new_nums = <span class="built_in">sorted</span>(nums, key=cmp_to_key(<span class="keyword">lambda</span> x, y: y - x))</span><br><span class="line">new_nums2 = <span class="built_in">sorted</span>(nums, key=cmp_to_key(<span class="keyword">lambda</span> x, y: x - y))</span><br><span class="line">print(new_nums)</span><br><span class="line">print(new_nums2)</span><br><span class="line"><span class="comment"># [34, 30, 9, 5, 3]</span></span><br><span class="line"><span class="comment"># [3, 5, 9, 30, 34]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nums = [<span class="number">3</span>, <span class="number">30</span>, <span class="number">34</span>, <span class="number">5</span>, <span class="number">9</span>]</span><br><span class="line">nums2 = <span class="built_in">map</span>(<span class="built_in">str</span>, nums)</span><br><span class="line">new_nums2 = <span class="built_in">sorted</span>(nums2, key=cmp_to_key(<span class="keyword">lambda</span> x, y: <span class="built_in">int</span>(x + y) - <span class="built_in">int</span>(y + x)))</span><br><span class="line">print(new_nums2)</span><br><span class="line"><span class="comment"># [&#x27;30&#x27;, &#x27;3&#x27;, &#x27;34&#x27;, &#x27;5&#x27;, &#x27;9&#x27;]</span></span><br></pre></td></tr></table></figure>
<h3 id="argparse库"><a href="#argparse库" class="headerlink" title="argparse库"></a>argparse库</h3><p>argparse模块是Python内置的用于命令项选项与参数解析的模块，argparse模块可以让人轻松编写用户友好的命令行接口，能够帮助程序员为模型定义参数。</p>
<h4 id="argparse定义四个步骤"><a href="#argparse定义四个步骤" class="headerlink" title="argparse定义四个步骤"></a>argparse定义四个步骤</h4><ol>
<li>导入argparse包 ——import argparse</li>
<li>创建一个命令行解析器对象 ——创建 ArgumentParser() 对象</li>
<li>给解析器添加命令行参数 ——调用add_argument() 方法添加参数</li>
<li>解析命令行的参数 ——使用 parse_args() 解析添加的参数</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个命令行解析对象</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;demo&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加命令行参数</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--epochs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--batch&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 从命令行中结构化解析参数</span></span><br><span class="line">args = parser.parse_args()</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<h3 id="os库"><a href="#os库" class="headerlink" title="os库"></a>os库</h3><h4 id="os-path-realpath和os-path-abspath"><a href="#os-path-realpath和os-path-abspath" class="headerlink" title="os.path.realpath和os.path.abspath"></a>os.path.realpath和os.path.abspath</h4><p><code>os.path.realpath</code>返回的是使用软链接的真实地址，<code>os.path.abspath</code>返回目标地址。如下所示，首先创建文件<code>a.txt</code>；随后创建软链接<code>b.txt</code>；最后分别测试<code>abspath</code>和<code>realpath</code>的返回值。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">touch a.txt</span><br><span class="line"></span><br><span class="line">ln -s  a.txt  b.txt</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import os</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; os.path.abspath(<span class="string">&quot;a.txt&quot;</span>)</span></span><br><span class="line">&#x27;/home/ubuntu/xxx/workspace/demo/a.txt&#x27;</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; os.path.abspath(<span class="string">&quot;b.txt&quot;</span>)</span></span><br><span class="line">&#x27;/home/ubuntu/xxx/workspace/demo/b.txt&#x27;</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; os.path.realpath(<span class="string">&quot;a.txt&quot;</span>)</span></span><br><span class="line">&#x27;/home/ubuntu/xxx/workspace/demo/a.txt&#x27;</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; os.path.realpath(<span class="string">&quot;b.txt&quot;</span>)</span></span><br><span class="line">&#x27;/home/ubuntu/xxx/workspace/demo/a.txt&#x27;</span><br></pre></td></tr></table></figure>
<h1 id="函数与方法辨析"><a href="#函数与方法辨析" class="headerlink" title="函数与方法辨析"></a>函数与方法辨析</h1><p>在标准库<code>inspect</code>中，它提供了两个自省的函数，即<code>ismethod()</code>和<code>isfunction()</code>，可以用来判断什么是方法，什么是函数。</p>
<ul>
<li><p><code>isfunction()</code>判断出的是用户定义的函数（<code>user-defined function</code>）， 它拥有<code>__doc__</code>、<code>__name__</code>等属性，其主要作用是判断一个对象（<code>object</code>）是否是<code>types.FunctionType</code>的实例。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isfunction</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return true if the object is a user-defined function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Function objects provide these attributes:</span></span><br><span class="line"><span class="string">        __doc__         documentation string</span></span><br><span class="line"><span class="string">        __name__        name with which this function was defined</span></span><br><span class="line"><span class="string">        __code__        code object containing compiled function bytecode</span></span><br><span class="line"><span class="string">        __defaults__    tuple of any default values for arguments</span></span><br><span class="line"><span class="string">        __globals__     global namespace in which this function was defined</span></span><br><span class="line"><span class="string">        __annotations__ dict of parameter annotations</span></span><br><span class="line"><span class="string">        __kwdefaults__  dict of keyword only parameters with defaults&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">isinstance</span>(<span class="built_in">object</span>, types.FunctionType)</span><br></pre></td></tr></table></figure></li>
<li><p><code>ismethod()</code>判断出的是实例方法（<code>instance method</code>）， 它拥有函数的一些属性，最特别的是还有一个<code>__self__</code>属性，其主要作用是判断一个对象（<code>object</code>）是否是<code>types.MethodType</code>的实例。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ismethod</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return true if the object is an instance method.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Instance method objects provide these attributes:</span></span><br><span class="line"><span class="string">        __doc__         documentation string</span></span><br><span class="line"><span class="string">        __name__        name with which this method was defined</span></span><br><span class="line"><span class="string">        __func__        function object containing implementation of method</span></span><br><span class="line"><span class="string">        __self__        instance to which this method is bound&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">isinstance</span>(<span class="built_in">object</span>, types.MethodType)</span><br></pre></td></tr></table></figure>
<h2 id="推论"><a href="#推论" class="headerlink" title="推论"></a>推论</h2></li>
</ul>
<ol>
<li><p>非用户定义的函数，即内置函数，在<code>isfunction()/ismethod()</code>眼里并不是“函数/方法”（<code>FunctionType/MethodType</code>）！事实上，它们有专属的类别（<code>BuiltinFunctionType</code>、<code>BuiltinMethodType</code>），<code>BuiltinFunctionType</code>和<code>BuiltinMethodType</code>的类型是相同的，都指向类型<code>builtin_function_or_method</code>。例如，<code>len()</code>和<code>[].append</code>的类型都为<code>builtin_function_or_method</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">&quot;------------------------&quot;</span>)</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.isfunction(<span class="built_in">len</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.isfunction(<span class="built_in">str</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.isfunction(<span class="built_in">list</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.isfunction(<span class="built_in">dir</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.isfunction(<span class="built_in">range</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.ismethod(<span class="built_in">len</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.ismethod(<span class="built_in">str</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.ismethod(<span class="built_in">list</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.ismethod(<span class="built_in">dir</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.ismethod(<span class="built_in">range</span>))</span><br><span class="line">print(<span class="string">&quot;------------------------&quot;</span>)</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(types.BuiltinFunctionType <span class="keyword">is</span> types.BuiltinMethodType)</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(<span class="built_in">type</span>(<span class="built_in">len</span>)==types.BuiltinMethodType)</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(<span class="built_in">type</span>(<span class="built_in">len</span>)==types.BuiltinFunctionType)</span><br><span class="line"><span class="comment"># &lt;class &#x27;builtin_function_or_method&#x27;&gt;</span></span><br><span class="line">print(<span class="built_in">type</span>(<span class="built_in">len</span>))</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(<span class="built_in">type</span>([].append)==types.BuiltinMethodType)</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(<span class="built_in">type</span>([].append)==types.BuiltinFunctionType)</span><br><span class="line"><span class="comment"># &lt;class &#x27;builtin_function_or_method&#x27;&gt;</span></span><br><span class="line">print(<span class="built_in">type</span>([].append))</span><br><span class="line">print(<span class="string">&quot;-------------------------&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>一个类的静态方法，在<code>ismethod()</code>眼里并不是方法（<code>MethodType</code>）！对于<code>class_method</code>，无论是类调用和实例调用，都存在隐式传参，为方法。对于<code>instance_method</code>，虽然属于实例方法，但不用调用方式得到不同结果，当实例调用时，存在隐式传参，为方法；当类调用时，不存在隐式传参，为函数。对于<code>static_method</code>，调用时不存在隐式传参，为函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">class_method</span>(<span class="params">cls</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">instance_method</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">static_method</span>():</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;------------------------&quot;</span>)</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.isfunction(A.class_method))</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(inspect.isfunction(A.instance_method))</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(inspect.isfunction(A.static_method))</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(inspect.ismethod(A.class_method))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.ismethod(A.instance_method))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.ismethod(A.static_method))</span><br><span class="line">print(<span class="string">&quot;------------------------&quot;</span>)</span><br><span class="line">a = A()</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.isfunction(a.class_method))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.isfunction(a.instance_method))</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(inspect.isfunction(a.static_method))</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(inspect.ismethod(a.class_method))</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">print(inspect.ismethod(a.instance_method))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">print(inspect.ismethod(a.static_method))</span><br><span class="line">print(<span class="string">&quot;------------------------&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="多线程-多进程"><a href="#多线程-多进程" class="headerlink" title="多线程/多进程"></a>多线程/多进程</h1><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><h3 id="锁（Lock）"><a href="#锁（Lock）" class="headerlink" title="锁（Lock）"></a>锁（Lock）</h3><p>锁是一种同步机制，用于控制对共享资源的访问。当一个进程或线程获取锁后，它就拥有了对该资源的独占访问权。在此期间，其他尝试获取锁的进程或线程会被阻塞，直到锁被释放。</p>
<h3 id="临界区（Critical-Section）"><a href="#临界区（Critical-Section）" class="headerlink" title="临界区（Critical Section）"></a>临界区（Critical Section）</h3><p>临界区是指访问共享资源的一段代码。为了避免竞态条件（race condition），在同一时间只能有一个进程或线程执行这段代码。锁用于确保同一时间只有一个进程或线程进入临界区。</p>
<h3 id="条件变量（Condition）"><a href="#条件变量（Condition）" class="headerlink" title="条件变量（Condition）"></a>条件变量（Condition）</h3><p>条件变量通常用于进程间通信和同步。它们是基于锁（Lock或RLock）实现的，提供了一种在特定条件下等待和通知其他进程的机制。条件变量有以下几个主要方法：</p>
<ul>
<li><code>acquire()</code>: 获取锁。</li>
<li><code>release()</code>: 释放锁。</li>
<li><code>wait()</code>: 释放锁并进入等待状态，直到被 <code>notify()</code> 或 <code>notify_all()</code> 唤醒。</li>
<li><code>notify()</code>: 唤醒一个等待的进程。</li>
<li><code>notify_all()</code>: 唤醒所有等待的进程。</li>
</ul>
<h2 id="实例分析"><a href="#实例分析" class="headerlink" title="实例分析"></a>实例分析</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> receiving_condition:</span><br><span class="line">    <span class="keyword">while</span> num_receptions.value &lt; training_freq:</span><br><span class="line">        receiving_condition.wait()</span><br><span class="line">    data = mem_pool.sample(size=batch_size)</span><br><span class="line">    num_receptions.value -= training_freq</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol>
<li><code>with receiving_condition:</code>这行代码会调用<code>receiving_condition.acquire()</code>，获取<code>receiving_condition</code>的锁。</li>
<li><code>while num_receptions.value &lt; training_freq:</code>这行代码进入<code>while</code>循环，检查<code>num_receptions.value</code>是否小于<code>training_freq</code>。</li>
<li><code>receiving_condition.wait()</code>这行代码首先释放当前持有的锁，这允许其他等待该锁的进程可以获取锁并执行它们的代码；其次让当前进程进入等待状态，直到被<code>receiving_condition.notify()</code>或<code>receiving_condition.notify_all()</code>唤醒。</li>
<li>当另一个进程调用<code>receiving_condition.notify()</code>或<code>receiving_condition.notify_all()</code>时，当前等待的进程会被唤醒，并尝试重新获取锁。一旦锁被重新获取，<code>wait()</code>方法返回，进程继续执行后续代码。</li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>ROS</title>
    <url>/2024/11/29/ROS/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>公司后续可能会做无人机相关业务，提前了解一下<code>ROS</code>相关内容。</p>
<a id="more"></a>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="Docker安装"><a href="#Docker安装" class="headerlink" title="Docker安装"></a><code>Docker</code>安装</h2><p>基础设置，先跳过。</p>
<h2 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h2><ul>
<li><p>手动修改<code>Docker</code>的配置文件来添加镜像源：</p>
<ul>
<li><p>使用编辑器打开配置文件<code>/etc/docker/daemon.json</code>（如果没有该文件，则新建一个）。</p>
</li>
<li><p>粘贴以下内容。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line"><span class="string">&quot;https://docker.hpcloud.cloud&quot;</span>,</span><br><span class="line"><span class="string">&quot;https://docker.m.daocloud.io&quot;</span>,</span><br><span class="line"><span class="string">&quot;https://docker.unsee.tech&quot;</span>,</span><br><span class="line"><span class="string">&quot;https://docker.1panel.live&quot;</span>,</span><br><span class="line"><span class="string">&quot;http://mirrors.ustc.edu.cn&quot;</span>,</span><br><span class="line"><span class="string">&quot;https://docker.chenby.cn&quot;</span>,</span><br><span class="line"><span class="string">&quot;http://mirror.azure.cn&quot;</span>,</span><br><span class="line"><span class="string">&quot;https://dockerpull.org&quot;</span>,</span><br><span class="line"><span class="string">&quot;https://dockerhub.icu&quot;</span>,</span><br><span class="line"><span class="string">&quot;https://hub.rat.dev&quot;</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>保存文件后，通过以下命令重启<code>Docker</code>服务。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure></li>
<li><p>通过以下命令验证配置是否生效。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker info | grep &quot;Registry Mirrors&quot;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>通过以下命令拉取镜像。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo docker pull osrf/ros:melodic-desktop-full</span><br></pre></td></tr></table></figure>
<h1 id="运行示例"><a href="#运行示例" class="headerlink" title="运行示例"></a>运行示例</h1></li>
<li><p>使用以下命令修改<code>X server</code>的访问控制策略，允许本地机器上的用户或进程连接到<code>X server</code>，从而允许它们显示图形界面，来实现<code>Docker</code>容器与宿主机之间的图形界面共享。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo xhost +local:</span><br></pre></td></tr></table></figure></li>
<li><p>使用以下命令启动一个容器，<code>--volume=/tmp/.X11-unix:/tmp/.X11-unix</code>的作用是挂载卷，将宿主机的<code>/tmp/.X11-unix</code>目录挂载到容器的相同路径，这个目录包含了<code>X11</code>服务器的<code>UNIX</code>域套接字，用于图形界面的通信；<code>--device=/dev/snd</code>的作用是授予容器访问宿主机的<code>/dev/snd</code>设备的权限，这是声卡设备文件，用于音频输入输出；<code>--env=&quot;DISPLAY=$DISPLAY&quot;</code>的作用是设置环境变量<code>DISPLAY</code>，用于图形界面的显示，这里使用宿主机的<code>DISPLAY</code>环境变量值，使得容器内的图形界面程序可以在宿主机上显示。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -it -d --volume=/tmp/.X11-unix:/tmp/.X11-unix --device=/dev/snd --env=&quot;DISPLAY=$DISPLAY&quot; --name=&lt;CONTAINER_NAME&gt; &lt;IMAGE_NAME&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>使用以下命令进入刚刚启动的容器：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it &lt;CONTAINER_ID&gt; /bin/bash</span><br></pre></td></tr></table></figure></li>
<li><p>在容器内部执行以下命令配置<code>ROS</code>的环境变量。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source ./ros_entrypoint.sh</span><br></pre></td></tr></table></figure></li>
<li><p>在容器中运行以下命令启动<code>ROS</code>的主节点。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">roscore</span><br></pre></td></tr></table></figure></li>
<li><p>新建终端，按照前述步骤进入容器并配置<code>ROS</code>的环境变量。</p>
</li>
<li><p>在容器中运行以下命令启动<code>ROS</code>节点，其中<code>turtlesim</code>是包名，<code>turtlesim_node</code>是节点名。命令执行成功后乌龟能够正常的显示在桌面上。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rosrun turtlesim turtlesim_node</span><br></pre></td></tr></table></figure></li>
<li><p>新建终端，同样按照前述步骤进入容器并配置<code>ROS</code>的环境变量。</p>
</li>
<li><p>在容器中运行以下命令启动<code>ROS</code>节点。命令成功执行后可以通过键盘控制乌龟。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rosrun turtlesim turtle_teleop_key</span><br></pre></td></tr></table></figure>
<h1 id="开发基础"><a href="#开发基础" class="headerlink" title="开发基础"></a>开发基础</h1></li>
</ul>
<h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><ul>
<li><code>workspace</code>：开发目录，包含各种模块自己源码安装的、新写的模块，二次开发主要是在这个目录中进行。</li>
<li><code>package</code>：一个独立的模块，完整功能的单元，比如一个实现从摄像头取流、转换成<code>mp4</code>文件保存到本地功能的模块。</li>
<li><code>node</code>：<code>package</code>中的一个执行程序，完成消息的接收、处理、发送等功能，传递给下一个<code>node</code>。</li>
</ul>
<p>三者的关系是：一个<code>workspace</code>会包含多个<code>package</code>，多个<code>package</code>之间可以是依赖关系，也可以不存在依赖关系，一个<code>package</code>可以包含多个<code>node</code>，每个<code>node</code>提供一个具体功能。运行起来之后，最常打交道的是<code>node</code>。</p>
<h2 id="创建工作空间"><a href="#创建工作空间" class="headerlink" title="创建工作空间"></a>创建工作空间</h2><p>首先在系统中创建工作空间文件夹，<code>mkdir</code>用于创建文件夹路径，<code>-p</code>表明当没有这个目录的父目录时则创建一个新的目录。 这里创建一个名为<code>catkin_ws</code>的工作空间文件夹，文件夹名称可以任意指定。<code>src</code>是存放源码所在的空间，必须命名为<code>src</code>。<code>catkin_init_workspace</code>用于初始化代码空间，声明<code>ROS</code>源码区域，此时我们打开<code>src</code>文件夹下会发现多出来一个文件名为<code>CMakeLists.txt</code>。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p ~/catkin_ws/src</span><br><span class="line">cd ~/catkin_ws/src/</span><br><span class="line">catkin_init_workspace</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411291824666.png" alt=""></p>
<h2 id="编译工作空间"><a href="#编译工作空间" class="headerlink" title="编译工作空间"></a>编译工作空间</h2><p>回到<code>catkin_ws</code>工程路径下并使用<code>catkin_make</code>编译整个工作空间，在后续操作过程中，凡是编译均需要回到此路径。使用<code>catkin_make</code>命令后，<code>catkin_ws</code>文件夹下会多出<code>build</code>文件夹和<code>devel</code>文件夹。其中<code>build</code>文件夹存放编译过程中产生的中间文件，<code>devel</code>文件夹保存编译链接后生成的可执行文件，可执行文件路径为<code>devel/lib</code>。</p>
<p><code>source devel/setup.bash</code>用于更新环境变量，使得系统能够找到整个工作空间中的相对路径。可以使用<code>echo $ROS_PACKAGE_PATH</code>查看功能包的路径以测试当前环境变量是否更新，如果不使用这句话则系统环境找不到相应的功能包。</p>
<p><code>echo &quot;source ~/catkin_ws/devel/setup.bash&quot;&gt;&gt;~/.bashrc</code>将引号中的字符串直接写入<code>&quot;~/&quot;</code>路径下的<code>.bashrc</code>隐藏文件中，如果不写这句话则每次开启一个新终端时都需要输入<code>source ~/catkin_ws/devel/setup.bash</code>。注意如果文件路径错了那么每次打开一个新终端时终端最上方都会出现找不到路径报错。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ~/catkin_ws/</span><br><span class="line">catkin_make</span><br><span class="line">source devel/setup.bash</span><br><span class="line">echo &quot;source ~/catkin_ws/devel/setup.bash&quot;&gt;&gt;~/.bashrc</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411291825892.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411291825590.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411291825359.png" alt=""></p>
<h2 id="创建功能包"><a href="#创建功能包" class="headerlink" title="创建功能包"></a>创建功能包</h2><p>使用命令<code>cd ~/catkin_ws/src/</code>进入代码空间，并在代码空间中创建功能包。使用<code>catkin_create_pkg</code>创建名为<code>my_turtle_package</code>的功能包，功能包的支撑库为<code>roscpp</code>、<code>rospy</code>和<code>std_msgs</code>，创建功能包的命令格式为<code>catkin_create_pkg &lt;package_name&gt; [depends1] [depends2] [depends3]</code>。此时<code>~/catkin_ws/src</code>路径下会出现两个文件，一个是<code>CMakeLists.txt</code>，另外一个是功能包<code>my_turtle_package</code>，<code>my_turtle_package</code>路径下会出现<code>4</code>个文件，分别是<code>include</code>文件夹（用于存放类似于<code>.h</code>的头文件），<code>src</code>文件夹（用于存放<code>cpp</code>文件），<code>CMakeLists.txt</code>（指定编译的规则），<code>package.xml</code>（支持包的相关信息，如果后续文件需要扩展就在此文件中增加相关的库），到此功能包已经创建完毕。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~&#x2F;catkin_ws&#x2F;src&#x2F;</span><br><span class="line">catkin_create_pkg my_turtle_package rospy roscpp std_msgs</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412021649295.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412021649776.png" alt=""></p>
<h2 id="创建源码"><a href="#创建源码" class="headerlink" title="创建源码"></a>创建源码</h2><p>进入<code>~/catkin_ws/src/my_turtle_package/src</code>文件夹，使用<code>touch</code>命令创建一个<code>draw_circle.cpp</code>文件，在<code>cpp</code>文件中输入以下内容。代码创建一个名为<code>vel_ctrl</code>的节点，该节点通过<code>/turtle1/cmd_level</code>话题发布消息。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;ros/ros.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;geometry_msgs/Twist.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span>&#123;</span><br><span class="line">    ros::init(argc, argv, <span class="string">&quot;vel_ctrl&quot;</span>);</span><br><span class="line">    ros::NodeHandle n;</span><br><span class="line">    ros::Publisher vel_pub = n.advertise&lt;geometry_msgs::Twist&gt;(<span class="string">&quot;/turtle1/cmd_vel&quot;</span>, <span class="number">10</span>);</span><br><span class="line">    ROS_INFO(<span class="string">&quot;draw_circle start...&quot;</span>);</span><br><span class="line">    <span class="keyword">while</span>(ros::ok())&#123;</span><br><span class="line">        geometry_msgs::Twist vel_cmd;</span><br><span class="line"></span><br><span class="line">        vel_cmd.linear.x = <span class="number">2.0</span>;</span><br><span class="line">        vel_cmd.linear.y = <span class="number">0.0</span>;</span><br><span class="line">        vel_cmd.linear.z = <span class="number">0.0</span>;</span><br><span class="line"> </span><br><span class="line">        vel_cmd.angular.x = <span class="number">0</span>;</span><br><span class="line">        vel_cmd.angular.y = <span class="number">0</span>;</span><br><span class="line">        vel_cmd.angular.z = <span class="number">1.8</span>;</span><br><span class="line">        vel_pub.publish(vel_cmd);</span><br><span class="line"> </span><br><span class="line">        ros::spinOnce();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="编译源码"><a href="#编译源码" class="headerlink" title="编译源码"></a>编译源码</h2><p>编辑<code>my_turtle_package</code>下的<code>CMakeList.txt</code>，定位到<code>## Declare a C++ executable</code>附近，向其中添加如下内容。随后在<code>devel/lib</code>文件夹下生成名为<code>draw_circle_node</code>的可执行文件，这两条编译码的一般格式为：<code>add_executable([可执行文件名] src/[cpp文件名])</code> 和<code>target_link_libraries([可执行文件名] $&#123;catkin_LIBRARIES&#125;)</code>。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">add_executable(draw_circle_node src/draw_circle.cpp)</span><br><span class="line">target_link_libraries(draw_circle_node $&#123;catkin_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure>
<p>随后回到工作空间下并使用<code>catkin_make</code>编译整个工作空间。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ~/catkin_ws</span><br><span class="line">catkin_make</span><br></pre></td></tr></table></figure>
<h2 id="执行代码"><a href="#执行代码" class="headerlink" title="执行代码"></a>执行代码</h2><p>进入容器，第一个终端输入<code>roscore</code>，第二个终端打开小乌龟节点<code>rosrun turtlesim turtlesim_node</code>，第三个终端启动画圆程序<code>rosrun my_turtle_package draw_circle_node</code>。可以通过<code>rosnode list</code>和<code>rostopic list</code>命令查看目前的节点列表和话题列表，可以看到目前的<code>node</code>和<code>topic</code>与<code>draw_circle.cpp</code>文件中声明的<code>node</code>和<code>topic</code>保持一致。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rosnode list</span><br><span class="line">rostopic list</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412021651898.png" alt=""></p>
<h1 id="自定义消息"><a href="#自定义消息" class="headerlink" title="自定义消息"></a>自定义消息</h1><p>在<code>ROS</code>通信协议中，数据载体是一个较为重要组成部分，<code>ROS</code>中通过<code>std_msgs</code>封装了一些原生的数据类型，比如：<code>String</code>、<code>Int32</code>、<code>Int64</code>、<code>Char</code>、<code>Bool</code>、<code>Empty</code>。但是，这些数据一般只包含一个<code>data</code>字段，结构的单一意味着功能上的局限性，当传输一些复杂的数据，比如: 激光雷达的信息<code>std_msgs</code>由于描述性较差而显得力不从心，这种场景下可以使用自定义的消息类型。</p>
<h2 id="定义msg文件"><a href="#定义msg文件" class="headerlink" title="定义msg文件"></a>定义<code>msg</code>文件</h2><p>功能包下新建<code>msg</code>目录，添加文件<code>pose.msg</code>，因为数据属于浮点型，选择<code>float32</code>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412031809640.png" alt=""></p>
<h2 id="编辑配置文件"><a href="#编辑配置文件" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h2><p>向<code>package.xml</code>中添加编译依赖时依赖与执行时依赖。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412031810928.png" alt=""></p>
<p>在<code>CMakeLists.txt</code>编辑<code>msg</code>相关配置。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412031810311.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412031811121.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412031811523.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412031811298.png" alt=""></p>
<h3 id="CMakeLists-txt与package-xml"><a href="#CMakeLists-txt与package-xml" class="headerlink" title="CMakeLists.txt与package.xml"></a><code>CMakeLists.txt</code>与<code>package.xml</code></h3><p>在<code>ROS</code>中，节点的编写语言通常只有<code>C++</code>和<code>Python</code>，<code>C++</code>需要编译后才能运行，<code>Python</code>则无需编译。我们知道<code>Linux</code>平台编译<code>C++</code>文件，需要编译器和链接器，其中编译器是将源代码编译成目标代码，链接器是将目标代码链接到可执行文件。若编译单个文件，用<code>g++</code>即可；若编译一个<code>C++</code>工程，则需要批处理编译工具，如<code>make</code>，通过设定规则文件<code>makefile</code>调用<code>g++</code>等编译工具进行批量编译。但<code>makefile</code>的编写十分复杂，便诞生了<code>CMake</code>，通过编写简单的<code>CMakeLists.txt</code>规则文件，就能自动生成<code>makefile</code>文件，并且<code>CMake</code>是跨平台的，十分强大。</p>
<p><code>ROS</code>的编译器便是<code>CMake</code>，为了更加人性化，<code>ROS</code>在<code>CMake</code>基础上封装了<code>catkin</code>命令，用<code>cmake</code>命令创建功能包时，会自动生成<code>CMakeLists.txt</code>文件，已配置了多数编译选项，且包含详细的注释，只需稍作修改便可编译自己的文件。而<code>package.xml</code>文件是描述功能包清单的文件，包括功能包的名称、版本号、作者信息、许可信息、编译依赖和运行依赖等。</p>
<h4 id="CMakeLists-txt文件"><a href="#CMakeLists-txt文件" class="headerlink" title="CMakeLists.txt文件"></a><code>CMakeLists.txt</code>文件</h4><h5 id="include-directories"><a href="#include-directories" class="headerlink" title="include_directories"></a><code>include_directories</code></h5><ul>
<li>用于设置头文件的相对路径</li>
<li>全局路径默认为功能包所在目录，功能包的头文件一般放在功能包根目录下的<code>include</code>文件夹，所以需要此处添加此文件夹</li>
<li>还包含<code>catkin</code>编译器默认的其他头文件路径，如：<code>ROS</code>默认安装路径、<code>Linux</code>系统路径等</li>
</ul>
<h5 id="add-exectuable"><a href="#add-exectuable" class="headerlink" title="add_exectuable"></a><code>add_exectuable</code></h5><ul>
<li>用于设置需要编译的代码和可执行文件</li>
<li>第一个参数为期望生成的可执行文件（节点）名称</li>
<li>后面的参数为参与编译的源文件<code>.cpp</code>，若需要多个代码文件，可依次列出，空格分隔</li>
</ul>
<h5 id="target-link-libraries"><a href="#target-link-libraries" class="headerlink" title="target_link_libraries"></a><code>target_link_libraries</code></h5><ul>
<li>用于设置链接库</li>
<li>有些功能需要使用系统或第三方库函数，通过该选项可以配置执行文件链接的库文件</li>
<li>第一个参数与<code>add_exectuable</code>相同，为可执行文件（节点）名称</li>
<li>后面的参数为需要链接的库，依次列出，空格分隔</li>
</ul>
<h5 id="add-dependencies"><a href="#add-dependencies" class="headerlink" title="add_dependencies"></a><code>add_dependencies</code></h5><ul>
<li>用于设置依赖</li>
<li>有时候需要自定义消息类型，消息类型会在编译过程中产生相应语言的代码。若编译的可执行文件依赖这些动态生成的代码，则需要添加<code>$&#123;PROJECT_NAME&#125;_generate_messages_cpp</code>配置</li>
</ul>
<h5 id="自定义数据类型"><a href="#自定义数据类型" class="headerlink" title="自定义数据类型"></a>自定义数据类型</h5><ul>
<li><code>find_package(catkin REQUIRE COMPONENTS message_generation)</code></li>
<li><code>catkin_package(CATKIN_DEPENDS message_runtime)</code></li>
<li><code>add_message_files(FILES xxx.msg)</code></li>
<li><code>add_service_files(FILES xxx.srv)</code></li>
<li><code>add_action_files(FILES xxx.action)</code></li>
<li><code>generate_messages(DEPENDENCIES std_msgs)</code></li>
</ul>
<h5 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h5><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required(VERSION <span class="number">2.8</span><span class="number">.3</span>)</span><br><span class="line">project(test)</span><br><span class="line"></span><br><span class="line">## Compile as C++<span class="number">11</span>, supported in ROS Kinetic <span class="keyword">and</span> newer</span><br><span class="line"># add_compile_options(-<span class="built_in">std</span>=c++<span class="number">11</span>)</span><br><span class="line"></span><br><span class="line">## Find catkin macros <span class="keyword">and</span> libraries</span><br><span class="line">#<span class="meta"># <span class="meta-keyword">if</span> COMPONENTS list like find_package(catkin REQUIRED COMPONENTS xyz)</span></span><br><span class="line">#<span class="meta"># is used, also find other catkin packages</span></span><br><span class="line">find_package(catkin REQUIRED COMPONENTS</span><br><span class="line">  roscpp</span><br><span class="line">  rospy</span><br><span class="line">  std_msgs</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">## System dependencies are found with CMake<span class="number">&#x27;</span>s conventions</span><br><span class="line"># find_package(Boost REQUIRED COMPONENTS system)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## Uncomment <span class="keyword">this</span> <span class="keyword">if</span> the package has a setup.py. This macro ensures</span><br><span class="line">#<span class="meta"># modules and global scripts declared therein get installed</span></span><br><span class="line">## See http:<span class="comment">//ros.org/doc/api/catkin/html/user_guide/setup_dot_py.html</span></span><br><span class="line"># catkin_python_setup()</span><br><span class="line"></span><br><span class="line">################################################</span><br><span class="line">## Declare ROS messages, services <span class="keyword">and</span> actions ##</span><br><span class="line">################################################</span><br><span class="line"></span><br><span class="line">## To declare <span class="keyword">and</span> build messages, services <span class="keyword">or</span> actions from within <span class="keyword">this</span></span><br><span class="line">#<span class="meta"># package, follow these steps:</span></span><br><span class="line">## * Let MSG_DEP_SET be the <span class="built_in">set</span> of packages whose message types you use in</span><br><span class="line">#<span class="meta">#   your messages/services/actions (e.g. std_msgs, actionlib_msgs, ...).</span></span><br><span class="line">## * In the file package.xml:</span><br><span class="line">##   * add a build_depend tag <span class="keyword">for</span> <span class="string">&quot;message_generation&quot;</span></span><br><span class="line">##   * add a build_depend <span class="keyword">and</span> a exec_depend tag <span class="keyword">for</span> each package in MSG_DEP_SET</span><br><span class="line">##   * If MSG_DEP_SET isn<span class="number">&#x27;</span>t empty the following dependency has been pulled in</span><br><span class="line">#<span class="meta">#     but can be declared for certainty nonetheless:</span></span><br><span class="line">##     * add a exec_depend tag <span class="keyword">for</span> <span class="string">&quot;message_runtime&quot;</span></span><br><span class="line">## * <span class="function">In <span class="keyword">this</span> <span class="title">file</span> <span class="params">(CMakeLists.txt)</span>:</span></span><br><span class="line">##   * add &quot;message_generation&quot; and every package in MSG_DEP_SET to</span><br><span class="line">##     find_package(catkin REQUIRED COMPONENTS ...)</span><br><span class="line">##   * add <span class="string">&quot;message_runtime&quot;</span> <span class="keyword">and</span> every package in MSG_DEP_SET to</span><br><span class="line">##     catkin_package(CATKIN_DEPENDS ...)</span><br><span class="line">##   * uncomment the add_*_files sections below as needed</span><br><span class="line">#<span class="meta">#     and list every .msg/.srv/.action file to be processed</span></span><br><span class="line">##   * uncomment the generate_messages entry below</span><br><span class="line">##   * <span class="function">add every package in MSG_DEP_SET to <span class="title">generate_messages</span><span class="params">(DEPENDENCIES ...)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line">## Generate messages in the &#x27;msg&#x27; folder</span><br><span class="line"># add_message_files(</span><br><span class="line">#   FILES</span><br><span class="line">#   Message1.msg</span><br><span class="line">#   Message2.msg</span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">## Generate services in the &#x27;srv&#x27; folder</span><br><span class="line"># add_service_files(</span><br><span class="line">#   FILES</span><br><span class="line">#   Service1.srv</span><br><span class="line">#   Service2.srv</span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">## Generate actions in the &#x27;action&#x27; folder</span><br><span class="line"># add_action_files(</span><br><span class="line">#   FILES</span><br><span class="line">#   Action1.action</span><br><span class="line">#   Action2.action</span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">## Generate added messages <span class="keyword">and</span> services with any dependencies listed here</span><br><span class="line"># generate_messages(</span><br><span class="line">#   DEPENDENCIES</span><br><span class="line">#   std_msgs</span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">################################################</span><br><span class="line">## Declare ROS dynamic reconfigure parameters ##</span><br><span class="line">################################################</span><br><span class="line"></span><br><span class="line">## To declare <span class="keyword">and</span> build dynamic reconfigure parameters within <span class="keyword">this</span></span><br><span class="line">#<span class="meta"># package, follow these steps:</span></span><br><span class="line">## * In the file package.xml:</span><br><span class="line">##   * add a build_depend <span class="keyword">and</span> a exec_depend tag <span class="keyword">for</span> <span class="string">&quot;dynamic_reconfigure&quot;</span></span><br><span class="line">## * <span class="function">In <span class="keyword">this</span> <span class="title">file</span> <span class="params">(CMakeLists.txt)</span>:</span></span><br><span class="line">##   * add &quot;dynamic_reconfigure&quot; to</span><br><span class="line">##     find_package(catkin REQUIRED COMPONENTS ...)</span><br><span class="line">##   * uncomment the <span class="string">&quot;generate_dynamic_reconfigure_options&quot;</span> section below</span><br><span class="line">#<span class="meta">#     and list every .cfg file to be processed</span></span><br><span class="line"></span><br><span class="line">## Generate dynamic reconfigure parameters in the &#x27;cfg&#x27; folder</span><br><span class="line"># generate_dynamic_reconfigure_options(</span><br><span class="line"><span class="meta">#   cfg/DynReconf1.cfg</span></span><br><span class="line"><span class="meta">#   cfg/DynReconf2.cfg</span></span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">###################################</span><br><span class="line">#<span class="meta"># catkin specific configuration ##</span></span><br><span class="line">###################################</span><br><span class="line">## The catkin_package macro generates cmake config files <span class="keyword">for</span> your package</span><br><span class="line">## Declare things to be passed to dependent projects</span><br><span class="line">## INCLUDE_DIRS: uncomment <span class="keyword">this</span> <span class="keyword">if</span> your package contains header files</span><br><span class="line">## LIBRARIES: libraries you create in <span class="keyword">this</span> project that dependent projects also need</span><br><span class="line">## CATKIN_DEPENDS: catkin_packages dependent projects also need</span><br><span class="line">## DEPENDS: system dependencies of <span class="keyword">this</span> project that dependent projects also need</span><br><span class="line">catkin_package(</span><br><span class="line">#  INCLUDE_DIRS include</span><br><span class="line">#  LIBRARIES test</span><br><span class="line">#  CATKIN_DEPENDS roscpp rospy std_msgs</span><br><span class="line">#  DEPENDS system_lib</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">###########</span><br><span class="line">## Build ##</span><br><span class="line">###########</span><br><span class="line"></span><br><span class="line">## Specify additional locations of header files</span><br><span class="line">## Your package locations should be listed before other locations</span><br><span class="line">include_directories(include $&#123;catkin_INCLUDE_DIRS&#125;)</span><br><span class="line"></span><br><span class="line">## Declare a C++ library</span><br><span class="line"># add_library($&#123;PROJECT_NAME&#125;</span><br><span class="line"><span class="meta">#   src/$&#123;PROJECT_NAME&#125;/test.cpp</span></span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">## Add cmake target dependencies of the library</span><br><span class="line">#<span class="meta"># as an example, code may need to be generated before libraries</span></span><br><span class="line">#<span class="meta"># either from message generation or dynamic reconfigure</span></span><br><span class="line">add_dependencies($&#123;PROJECT_NAME&#125; $&#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; $&#123;catkin_EXPORTED_TARGETS&#125;)</span><br><span class="line"></span><br><span class="line">## Declare a C++ executable</span><br><span class="line">## With catkin_make all packages are built within a single CMake context</span><br><span class="line">## The recommended prefix ensures that target names across packages don<span class="number">&#x27;</span>t collide</span><br><span class="line">add_executable($&#123;PROJECT_NAME&#125;_node src/test_node.cpp)</span><br><span class="line"></span><br><span class="line">## Rename C++ executable without prefix</span><br><span class="line">## The above recommended prefix causes <span class="keyword">long</span> target names, the following renames the</span><br><span class="line">#<span class="meta"># target back to the shorter version for ease of user use</span></span><br><span class="line">#<span class="meta"># e.g. <span class="meta-string">&quot;rosrun someones_pkg node&quot;</span> instead of <span class="meta-string">&quot;rosrun someones_pkg someones_pkg_node&quot;</span></span></span><br><span class="line"># set_target_properties($&#123;PROJECT_NAME&#125;_node PROPERTIES OUTPUT_NAME node PREFIX <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">## Add cmake target dependencies of the executable</span><br><span class="line">#<span class="meta"># same as for the library above</span></span><br><span class="line">add_dependencies($&#123;PROJECT_NAME&#125;_node $&#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; $&#123;catkin_EXPORTED_TARGETS&#125;)</span><br><span class="line"></span><br><span class="line">## Specify libraries to link a library <span class="keyword">or</span> executable target against</span><br><span class="line">target_link_libraries($&#123;PROJECT_NAME&#125;_node $&#123;catkin_LIBRARIES&#125;)</span><br><span class="line"></span><br><span class="line">#############</span><br><span class="line">## Install ##</span><br><span class="line">#############</span><br><span class="line"></span><br><span class="line"><span class="meta"># all install targets should use catkin DESTINATION variables</span></span><br><span class="line"># See http:<span class="comment">//ros.org/doc/api/catkin/html/adv_user_guide/variables.html</span></span><br><span class="line"></span><br><span class="line">## <span class="function">Mark executable <span class="title">scripts</span> <span class="params">(Python etc.)</span> <span class="keyword">for</span> installation</span></span><br><span class="line">## in contrast to setup.py, you can choose the destination</span><br><span class="line"><span class="meta"># install(PROGRAMS</span></span><br><span class="line"><span class="meta">#   scripts/my_python_script</span></span><br><span class="line">#   DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;</span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">## Mark executables <span class="keyword">for</span> installation</span><br><span class="line">## See http:<span class="comment">//docs.ros.org/melodic/api/catkin/html/howto/format1/building_executables.html</span></span><br><span class="line"><span class="meta"># install(TARGETS $&#123;PROJECT_NAME&#125;_node</span></span><br><span class="line">#   RUNTIME DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;</span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">## Mark libraries <span class="keyword">for</span> installation</span><br><span class="line">## See http:<span class="comment">//docs.ros.org/melodic/api/catkin/html/howto/format1/building_libraries.html</span></span><br><span class="line"><span class="meta"># install(TARGETS $&#123;PROJECT_NAME&#125;</span></span><br><span class="line">#   ARCHIVE DESTINATION $&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125;</span><br><span class="line">#   LIBRARY DESTINATION $&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125;</span><br><span class="line">#   RUNTIME DESTINATION $&#123;CATKIN_GLOBAL_BIN_DESTINATION&#125;</span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">## Mark cpp header files <span class="keyword">for</span> installation</span><br><span class="line"><span class="meta"># install(DIRECTORY <span class="meta-keyword">include</span>/$&#123;PROJECT_NAME&#125;/</span></span><br><span class="line">#   DESTINATION $&#123;CATKIN_PACKAGE_INCLUDE_DESTINATION&#125;</span><br><span class="line">#   FILES_MATCHING PATTERN <span class="string">&quot;*.h&quot;</span></span><br><span class="line">#   PATTERN <span class="string">&quot;.svn&quot;</span> EXCLUDE</span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">## <span class="function">Mark other files <span class="keyword">for</span> <span class="title">installation</span> <span class="params">(e.g. launch <span class="keyword">and</span> bag files, etc.)</span></span></span><br><span class="line"><span class="function"><span class="meta"># install(FILES</span></span></span><br><span class="line">#   # myfile1</span><br><span class="line">#   # myfile2</span><br><span class="line">#   DESTINATION $&#123;CATKIN_PACKAGE_SHARE_DESTINATION&#125;</span><br><span class="line"># )</span><br><span class="line"></span><br><span class="line">#############</span><br><span class="line">## Testing ##</span><br><span class="line">#############</span><br><span class="line"></span><br><span class="line">## Add gtest based cpp test target <span class="keyword">and</span> link libraries</span><br><span class="line"># catkin_add_gtest($&#123;PROJECT_NAME&#125;-test test/test_test.cpp)</span><br><span class="line"><span class="meta"># <span class="meta-keyword">if</span>(TARGET $&#123;PROJECT_NAME&#125;-test)</span></span><br><span class="line">#   target_link_libraries($&#123;PROJECT_NAME&#125;-test $&#123;PROJECT_NAME&#125;)</span><br><span class="line"><span class="meta"># <span class="meta-keyword">endif</span>()</span></span><br><span class="line"></span><br><span class="line">## Add folders to be run by python nosetests</span><br><span class="line"># catkin_add_nosetests(test)</span><br></pre></td></tr></table></figure>
<h4 id="package-xml文件"><a href="#package-xml文件" class="headerlink" title="package.xml文件"></a><code>package.xml</code>文件</h4><h5 id="lt-build-depend-gt-lt-build-depend-gt"><a href="#lt-build-depend-gt-lt-build-depend-gt" class="headerlink" title="&lt;build_depend&gt;&lt;/build_depend&gt;"></a><code>&lt;build_depend&gt;&lt;/build_depend&gt;</code></h5><p>定义了功能包中代码编译时所依赖的其他功能包</p>
<h5 id="lt-exec-depend-gt-lt-exec-depend-gt"><a href="#lt-exec-depend-gt-lt-exec-depend-gt" class="headerlink" title="&lt;exec_depend&gt;&lt;/exec_depend&gt;"></a><code>&lt;exec_depend&gt;&lt;/exec_depend&gt;</code></h5><p>定义了功能包中可执行程序运行时所依赖的其他功能包</p>
<h5 id="自定义数据类型-1"><a href="#自定义数据类型-1" class="headerlink" title="自定义数据类型"></a>自定义数据类型</h5><p>自定义话题消息<code>msg</code>、服务数据<code>srv</code>，需添加如下内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build_depend</span>&gt;</span>message_generation<span class="tag">&lt;/<span class="name">build_depend</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">exec_depend</span>&gt;</span>message_runtime<span class="tag">&lt;/<span class="name">exec_depend</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="模板-1"><a href="#模板-1" class="headerlink" title="模板"></a>模板</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">package</span> <span class="attr">format</span>=<span class="string">&quot;2&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>test<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The test package<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- One maintainer tag required, multiple allowed, one person per tag --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Example:  --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- &lt;maintainer email=&quot;jane.doe@example.com&quot;&gt;Jane Doe&lt;/maintainer&gt; --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">maintainer</span> <span class="attr">email</span>=<span class="string">&quot;lab212@todo.todo&quot;</span>&gt;</span>lab212<span class="tag">&lt;/<span class="name">maintainer</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- One license tag required, multiple allowed, one license per tag --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Commonly used license strings: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   BSD, MIT, Boost Software License, GPLv2, GPLv3, LGPLv2.1, LGPLv3 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">license</span>&gt;</span>TODO<span class="tag">&lt;/<span class="name">license</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- Url tags are optional, but multiple are allowed, one per tag --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Optional attribute type can be: website, bugtracker, or repository --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Example: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- &lt;url type=&quot;website&quot;&gt;http://wiki.ros.org/test&lt;/url&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- Author tags are optional, multiple are allowed, one per tag --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Authors do not have to be maintainers, but could be --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Example: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- &lt;author email=&quot;jane.doe@example.com&quot;&gt;Jane Doe&lt;/author&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- The *depend tags are used to specify dependencies --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Dependencies can be catkin packages or system dependencies --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Examples: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Use depend as a shortcut for packages that are both build and exec dependencies --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   &lt;depend&gt;roscpp&lt;/depend&gt; --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   Note that this is equivalent to the following: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   &lt;build_depend&gt;roscpp&lt;/build_depend&gt; --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   &lt;exec_depend&gt;roscpp&lt;/exec_depend&gt; --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Use build_depend for packages you need at compile time: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   &lt;build_depend&gt;message_generation&lt;/build_depend&gt; --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Use build_export_depend for packages you need in order to build against this package: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   &lt;build_export_depend&gt;message_generation&lt;/build_export_depend&gt; --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Use buildtool_depend for build tool packages: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   &lt;buildtool_depend&gt;catkin&lt;/buildtool_depend&gt; --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Use exec_depend for packages you need at runtime: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   &lt;exec_depend&gt;message_runtime&lt;/exec_depend&gt; --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Use test_depend for packages you need only for testing: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   &lt;test_depend&gt;gtest&lt;/test_depend&gt; --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Use doc_depend for packages you need only for building documentation: --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--   &lt;doc_depend&gt;doxygen&lt;/doc_depend&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">buildtool_depend</span>&gt;</span>catkin<span class="tag">&lt;/<span class="name">buildtool_depend</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">build_depend</span>&gt;</span>roscpp<span class="tag">&lt;/<span class="name">build_depend</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">build_depend</span>&gt;</span>rospy<span class="tag">&lt;/<span class="name">build_depend</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">build_depend</span>&gt;</span>std_msgs<span class="tag">&lt;/<span class="name">build_depend</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">build_export_depend</span>&gt;</span>roscpp<span class="tag">&lt;/<span class="name">build_export_depend</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">build_export_depend</span>&gt;</span>rospy<span class="tag">&lt;/<span class="name">build_export_depend</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">build_export_depend</span>&gt;</span>std_msgs<span class="tag">&lt;/<span class="name">build_export_depend</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">exec_depend</span>&gt;</span>roscpp<span class="tag">&lt;/<span class="name">exec_depend</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">exec_depend</span>&gt;</span>rospy<span class="tag">&lt;/<span class="name">exec_depend</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">exec_depend</span>&gt;</span>std_msgs<span class="tag">&lt;/<span class="name">exec_depend</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- The export tag contains other, unspecified, tags --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">export</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Other tools can request additional information be placed here --&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">export</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">package</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="编译工程"><a href="#编译工程" class="headerlink" title="编译工程"></a>编译工程</h2><p>进入工作空间目录并<code>catkin_make</code>编译。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412031812257.png" alt=""></p>
<p><code>C++</code>需要调用的中间文件<code>~/&lt;workspace&gt;/devel/include/&lt;package_name&gt;/xxx.h)</code>，后续调用相关<code>msg</code>时，是从这些中间文件调用的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412031813194.png" alt=""></p>
<h2 id="自定义msg调用"><a href="#自定义msg调用" class="headerlink" title="自定义msg调用"></a>自定义<code>msg</code>调用</h2><h3 id="发布方实现"><a href="#发布方实现" class="headerlink" title="发布方实现"></a>发布方实现</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;ros/ros.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;std_msgs/String.h&quot;</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;geometry_msgs/Point.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_turtle_package/pose.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>  *argv[])</span></span>&#123;   </span><br><span class="line">    setlocale(LC_ALL,<span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line">    ros::init(argc,  argv, <span class="string">&quot;poseTalker&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    ros::NodeHandle nh;</span><br><span class="line"></span><br><span class="line">    ros::Publisher pub = nh.advertise&lt;my_turtle_package::pose&gt;(<span class="string">&quot;pose&quot;</span>, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">    my_turtle_package::pose pose;</span><br><span class="line">    </span><br><span class="line">    pose.axis_x  = <span class="number">1</span>;</span><br><span class="line">    pose.axis_y = <span class="number">2</span>;</span><br><span class="line">    pose.axis_z = <span class="number">3</span>;</span><br><span class="line">    pose.roll = <span class="number">4</span>;</span><br><span class="line">    pose.pitch = <span class="number">5</span>;</span><br><span class="line">    pose.yaw = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">ros::Rate <span class="title">r</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (ros::ok())</span><br><span class="line">    &#123;</span><br><span class="line">        pub.publish(pose);</span><br><span class="line">        r.sleep();</span><br><span class="line">        ros::spinOnce();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="订阅方实现"><a href="#订阅方实现" class="headerlink" title="订阅方实现"></a>订阅方实现</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;ros/ros.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;std_msgs/String.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;geometry_msgs/Point.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_turtle_package/pose.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dealPose</span><span class="params">(<span class="keyword">const</span> my_turtle_package::pose::ConstPtr &amp;msg_pose)</span></span>&#123;</span><br><span class="line">    ROS_INFO(<span class="string">&quot;axis_x: %f, axis_y: %f, axis_z: %f, roll: %f, pitch: %f, yaw: %f&quot;</span>, msg_pose-&gt;axis_x, msg_pose-&gt;axis_y, msg_pose-&gt;axis_z, msg_pose-&gt;roll, msg_pose-&gt;pitch, msg_pose-&gt;yaw);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>  *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    setlocale(LC_ALL,<span class="string">&quot;&quot;</span>);</span><br><span class="line">    ros::init(argc,argv,<span class="string">&quot;listener&quot;</span>);</span><br><span class="line">    ros::NodeHandle nh;</span><br><span class="line">    ros::Subscriber sub = nh.subscribe&lt;my_turtle_package::pose&gt;(<span class="string">&quot;pose&quot;</span>, <span class="number">10</span>, dealPose);</span><br><span class="line">    ros::spin();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="配置CMakeLists-txt"><a href="#配置CMakeLists-txt" class="headerlink" title="配置CMakeLists.txt"></a>配置<code>CMakeLists.txt</code></h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412031813865.png" alt=""></p>
<h3 id="编译工程-1"><a href="#编译工程-1" class="headerlink" title="编译工程"></a>编译工程</h3><p>参考前述编译工程的方式进行编译。</p>
<h3 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h3><p>分别启动<code>roscore</code>、发布节点和订阅节点。启动节点前首先需要进入<code>~/catkin_ws/devel/</code>目录，执行<code>source setup.bash</code>更新环境变量。</p>
<h1 id="PX4环境安装"><a href="#PX4环境安装" class="headerlink" title="PX4环境安装"></a><code>PX4</code>环境安装</h1><h2 id="拉取镜像-1"><a href="#拉取镜像-1" class="headerlink" title="拉取镜像"></a>拉取镜像</h2><p>拉取合适的镜像，本人系统安装的<code>Ubuntu</code>版本是<code>18.04</code>，拉取的是<code>px4io/px4-dev-ros-melodic</code>这个镜像，更多选择可参考<code>PX4</code>的[官方仓库][<a href="https://github.com/PX4/PX4-containers/tree/master?tab=readme-ov-file#container-hierarchy]。">https://github.com/PX4/PX4-containers/tree/master?tab=readme-ov-file#container-hierarchy]。</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull px4io/px4-dev-ros-melodic</span><br></pre></td></tr></table></figure>
<h2 id="下载代码"><a href="#下载代码" class="headerlink" title="下载代码"></a>下载代码</h2><p>使用<code>root</code>下载<code>PX4</code>官方仓库的代码，否则后续启动容器编译的时候会出现权限的问题。同时由于涉及到子模块，可以选择直接克隆的时候加上<code>--recursive</code>选项递归下载子模块，也可以选择先下载<code>PX4</code>的代码，然后再递归更新子模块。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1</span></span><br><span class="line">mkdir px4</span><br><span class="line">cd px4</span><br><span class="line">git clone https://github.com/PX4/PX4-Autopilot.git --recursive</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2</span></span><br><span class="line">mkdir px4</span><br><span class="line">cd px4</span><br><span class="line">git clone https://github.com/PX4/PX4-Autopilot.git</span><br><span class="line">cd PX4-Autopilot</span><br><span class="line">git submodule update --init --recursive --progress</span><br></pre></td></tr></table></figure>
<h2 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h2><p>首先执行下面的命令控制<code>X server</code>的访问权限。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xhost +</span><br></pre></td></tr></table></figure>
<p>启动容器时需要将本地的<code>PX4</code>源码路径映射到容器当中的指定路径，同时共享本地<code>unix</code>端口和设置<code>X Server</code>显示图形界面的显示器地址。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -it --privileged -v /home/&lt;user_name&gt;/px4/:/home/px4 -v /tmp/.X11-unix:/tmp/.X11-unix:ro -e DISPLAY=:0 --name=px4 --net=host px4io/px4-dev-ros-melodic:latest</span><br></pre></td></tr></table></figure>
<h2 id="编译PX4"><a href="#编译PX4" class="headerlink" title="编译PX4"></a>编译<code>PX4</code></h2><p>进入容器后切换到<code>PX4</code>源码文件夹，执行如下命令编译<code>gazebo-classic</code>模拟器的仿真环境。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /home/px4/PX4-Autopilot</span><br><span class="line">make px4_sitl gazebo-classic</span><br></pre></td></tr></table></figure>
<p>编译成功后系统会自动打开<code>gazebo</code>模拟器，如果出现闪退或者命令行报警告<code>VMware: vmw_ioctl_command error Invalid argument</code>，执行如下命令后再次编译即可，具体原因是运行在虚拟机上导致某些变量不合法。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export SVGA_VGPU10=0</span><br><span class="line">make px4_sitl gazebo-classic</span><br></pre></td></tr></table></figure>
<h2 id="简单测试"><a href="#简单测试" class="headerlink" title="简单测试"></a>简单测试</h2><h3 id="无人机起飞和降落"><a href="#无人机起飞和降落" class="headerlink" title="无人机起飞和降落"></a>无人机起飞和降落</h3><p>输入<code>commander takeoff</code>和<code>commander land</code>命令，可以控制无人机的起飞和降落。</p>
<h3 id="查看rostopic"><a href="#查看rostopic" class="headerlink" title="查看rostopic"></a>查看<code>rostopic</code></h3><p>从新建终端进入容器，首先更新环境变量，然后启动<code>roscore</code>，再新建终端通过<code>rostopic</code>查看所有的<code>topic</code>。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source /opt/ros/melodic/setup.sh</span><br><span class="line">roscore</span><br><span class="line">rostopic list</span><br></pre></td></tr></table></figure>
<h2 id="在gazebo中启动PX4"><a href="#在gazebo中启动PX4" class="headerlink" title="在gazebo中启动PX4"></a>在<code>gazebo</code>中启动<code>PX4</code></h2><p>编译完成之后不需要每次重新编译，直接通过运行<code>.launch</code>文件启动<code>gazebo</code>。需要在<code>PX4</code>源码路径下，按照以下命令更新环境变量，然后再启动，否则会报错<code>RLException: [posix_sitl.sh] is neither a launch file in package [px4] nor is [px4] a launch file name</code>。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source Tools/simulation/gazebo-classic/setup_gazebo.bash $(pwd) $(pwd)/build/px4_sitl_default</span><br><span class="line">export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:$(pwd)</span><br><span class="line">export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:$(pwd)/Tools/simulation/gazebo-classic/sitl_gazebo-classic</span><br><span class="line">roslaunch px4 posix_sitl.launch</span><br></pre></td></tr></table></figure>
<h2 id="启动Mavros节点"><a href="#启动Mavros节点" class="headerlink" title="启动Mavros节点"></a>启动<code>Mavros</code>节点</h2><p>直接运行以下命令启动<code>Mavros</code>节点。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">roslaunch mavros px4.launch fcu_url:=&quot;udp://:14540@127.0.0.1:14557&quot; </span><br></pre></td></tr></table></figure>
<h2 id="借助Mavros控制无人机画矩形"><a href="#借助Mavros控制无人机画矩形" class="headerlink" title="借助Mavros控制无人机画矩形"></a>借助<code>Mavros</code>控制无人机画矩形</h2><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>创建名为<code>uav_demo_ws</code>的工作空间。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p ~/uav_demo_ws/src</span><br></pre></td></tr></table></figure>
<p>创建名为<code>offboard_run</code>的功能包。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ~/uav_demo_ws/src/</span><br><span class="line">catkin_create_pkg offboard_run roscpp std_msgs geometry_msgs mavros_msgs</span><br></pre></td></tr></table></figure>
<p>创建脚本作为可执行文件。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd offboard_run/src/</span><br><span class="line">touch offboard_run_node.cpp</span><br></pre></td></tr></table></figure>
<p>把代码复制到文件里。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//一系列头文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//ros库</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ros/ros.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//发布的位置消息体对应的头文件，该消息体的类型为geometry_msgs::PoseStamped</span></span><br><span class="line"><span class="comment">//用来进行发送目标位置</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">ros官网上这样定义</span></span><br><span class="line"><span class="comment"># A Pose with reference coordinate frame and timestamp</span></span><br><span class="line"><span class="comment">Header header</span></span><br><span class="line"><span class="comment">Pose pose</span></span><br><span class="line"><span class="comment">实际上就是一个带有头消息和位姿的消息</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;geometry_msgs/PoseStamped.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//CommandBool服务的头文件，该服务的类型为mavros_msgs::CommandBool</span></span><br><span class="line"><span class="comment">//用来进行无人机解锁</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">其结构如下（来源于ros wiki）</span></span><br><span class="line"><span class="comment"># Common type for switch commands</span></span><br><span class="line"><span class="comment">bool value</span></span><br><span class="line"><span class="comment">---</span></span><br><span class="line"><span class="comment">bool success</span></span><br><span class="line"><span class="comment">uint8 result</span></span><br><span class="line"><span class="comment">可以看到，发送的请求是一个bool类型的数据，为True则解锁，为False则上锁</span></span><br><span class="line"><span class="comment">返回的响应中success是一个bool类型的参数，表示上电/断电操作是否成功执行。</span></span><br><span class="line"><span class="comment">如果操作成功执行，success值为True，否则为False。</span></span><br><span class="line"><span class="comment">result是一个int32类型的参数，表示执行上电/断电操作的结果。</span></span><br><span class="line"><span class="comment">如果解锁/上锁操作成功执行，result值为0，</span></span><br><span class="line"><span class="comment">否则为其他值，表示执行解锁/上锁操作时发生了某种错误或异常。可以根据这个数值查看是哪种问题导致</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mavros_msgs/CommandBool.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//SetMode服务的头文件，该服务的类型为mavros_msgs::SetMode</span></span><br><span class="line"><span class="comment">//用来设置无人机的飞行模式，切换offboard</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">wiki上的消息定义如下</span></span><br><span class="line"><span class="comment"># set FCU mode</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Known custom modes listed here:</span></span><br><span class="line"><span class="comment"># http://wiki.ros.org/mavros/CustomModes</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># basic modes from MAV_MODE</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_PREFLIGHT = 0</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_STABILIZE_DISARMED = 80</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_STABILIZE_ARMED = 208</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_MANUAL_DISARMED = 64</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_MANUAL_ARMED = 192</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_GUIDED_DISARMED = 88</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_GUIDED_ARMED = 216</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_AUTO_DISARMED = 92</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_AUTO_ARMED = 220</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_TEST_DISARMED = 66</span></span><br><span class="line"><span class="comment">uint8 MAV_MODE_TEST_ARMED = 194</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">uint8 base_mode # filled by MAV_MODE enum value or 0 if custom_mode != &#x27;&#x27;</span></span><br><span class="line"><span class="comment">string custom_mode # string mode representation or integer</span></span><br><span class="line"><span class="comment">---</span></span><br><span class="line"><span class="comment">bool success</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">String类型的变量custom_mode就是我们想切换的模式，有如下选择：</span></span><br><span class="line"><span class="comment">MANUAL，ACRO，ALTCTL，POSCTL，OFFBOARD，STABILIZED，RATTITUDE，AUTO.MISSION</span></span><br><span class="line"><span class="comment">AUTO.LOITER，AUTO.RTL，AUTO.LAND，AUTO.RTGS，AUTO.READY，AUTO.TAKEOFF</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mavros_msgs/SetMode.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//订阅的消息体的头文件，该消息体的类型为mavros_msgs::State</span></span><br><span class="line"><span class="comment">//查看无人机的状态</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">wiki上是这样的</span></span><br><span class="line"><span class="comment">std_msgs/Header header</span></span><br><span class="line"><span class="comment">bool connected</span></span><br><span class="line"><span class="comment">bool armed</span></span><br><span class="line"><span class="comment">bool guided</span></span><br><span class="line"><span class="comment">bool manual_input</span></span><br><span class="line"><span class="comment">string mode</span></span><br><span class="line"><span class="comment">uint8 system_status</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">解析如下：</span></span><br><span class="line"><span class="comment">header：消息头，包含时间戳和框架信息；</span></span><br><span class="line"><span class="comment">connected：表示是否连接到了 mavros 节点；</span></span><br><span class="line"><span class="comment">armed：表示无人机当前是否上锁；</span></span><br><span class="line"><span class="comment">guided：表示无人机当前是否处于 GUIDED 模式；</span></span><br><span class="line"><span class="comment">mode：表示当前无人机所处的模式，包括以下几种：</span></span><br><span class="line"><span class="comment">MANUAL，ACRO，ALTCTL，POSCTL，OFFBOARD，STABILIZED，RATTITUDE，AUTO.MISSION</span></span><br><span class="line"><span class="comment">AUTO.LOITER，AUTO.RTL，AUTO.LAND，AUTO.RTGS，AUTO.READY，AUTO.TAKEOFF</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mavros_msgs/State.h&gt;  </span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//建立一个订阅消息体类型的变量，用于存储订阅的信息</span></span><br><span class="line">mavros_msgs::State current_state;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//订阅时的回调函数，接受到该消息体的内容时执行里面的内容，内容是储存飞控当前的状态</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">state_cb</span><span class="params">(<span class="keyword">const</span> mavros_msgs::State::ConstPtr&amp; msg)</span></span>&#123;</span><br><span class="line">    current_state = *msg;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">geometry_msgs::PoseStamped local_pos;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">local_pos_cb</span><span class="params">(<span class="keyword">const</span> geometry_msgs::PoseStamped::ConstPtr&amp; msg)</span></span>&#123;</span><br><span class="line">    local_pos = *msg;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//ros系统的初始化，argc和argv在后期节点传值会使用，最后一个参数offb_node为节点名称</span></span><br><span class="line">    ros::init(argc, argv, <span class="string">&quot;offb_node&quot;</span>); </span><br><span class="line"></span><br><span class="line">    <span class="comment">//实例化ROS句柄，这个ros::NodeHandle类封装了ROS中的一些常用功能</span></span><br><span class="line">    ros::NodeHandle nh;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这是一个订阅者对象，可以订阅无人机的状态信息（状态信息来源为MAVROS发布），用来储存无人机的状态，在回调函数中会不断更新这个状态变量</span></span><br><span class="line">    <span class="comment">//&lt;&gt;里面为模板参数，传入的是订阅的消息体类型，（）里面传入三个参数，分别是该消息体的位置、缓存大小（通常为1000）、回调函数</span></span><br><span class="line">    ros::Subscriber state_sub = nh.subscribe&lt;mavros_msgs::State&gt;(<span class="string">&quot;mavros/state&quot;</span>, <span class="number">10</span>, state_cb);</span><br><span class="line"></span><br><span class="line">    ros::Subscriber local_pos_sub = nh.subscribe&lt;geometry_msgs::PoseStamped&gt;(<span class="string">&quot;mavros/local_position/pose&quot;</span>, <span class="number">10</span>, local_pos_cb);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这是一个发布者对象，用来在本地坐标系下发布目标点，后面会以20Hz频率发布目标点</span></span><br><span class="line">    <span class="comment">//&lt;&gt;里面为模板参数，传入的是发布的消息体类型，（）里面传入两个参数，分别是该消息体的位置、缓存大小（通常为1000）</span></span><br><span class="line">    ros::Publisher local_pos_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(<span class="string">&quot;mavros/setpoint_position/local&quot;</span>, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//一个客户端，用来解锁无人机，这是因为无人机如果降落后一段时间没有收到信号输入，会自动上锁来保障安全</span></span><br><span class="line">    <span class="comment">//启动服务的函数为nh下的serviceClient&lt;&gt;()函数，&lt;&gt;里面是该服务的类型，（）里面是该服务的路径</span></span><br><span class="line">    ros::ServiceClient arming_client = nh.serviceClient&lt;mavros_msgs::CommandBool&gt;(<span class="string">&quot;mavros/cmd/arming&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//一个客户端，用来切换飞行模式</span></span><br><span class="line">    <span class="comment">//启动服务的函数为nh下的serviceClient&lt;&gt;()函数，&lt;&gt;里面是该服务的类型，（）里面是该服务的路径</span></span><br><span class="line">    ros::ServiceClient set_mode_client = nh.serviceClient&lt;mavros_msgs::SetMode&gt;(<span class="string">&quot;mavros/set_mode&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//官方要求local_pos_pub发布速率必须快于2Hz，这里设置为20Hz</span></span><br><span class="line">    <span class="comment">//PX4在两个Offboard命令之间有一个500ms的延时，如果超过此延时，系统会将回到无人机进入Offboard模式之前的最后一个模式。</span></span><br><span class="line">    <span class="function">ros::Rate <span class="title">rate</span><span class="params">(<span class="number">20.0</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待飞控和MAVROS建立连接，current_state是我订阅的MAVROS的状态，在收到心跳包之后连接成功跳出循环</span></span><br><span class="line">    <span class="keyword">while</span>(ros::ok() &amp;&amp; !current_state.connected)&#123;</span><br><span class="line">        ros::spinOnce();</span><br><span class="line">        rate.sleep();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//实例化一个geometry_msgs::PoseStamped类型的对象，并对其赋值，最后将其发布出去</span></span><br><span class="line">    <span class="comment">//尽管PX4在航空航天常用的NED坐标系下操控飞机，但MAVROS将自动将该坐标系切换至常规的ENU坐标系下</span></span><br><span class="line">    geometry_msgs::PoseStamped pose;</span><br><span class="line">    pose.pose.position.x = <span class="number">0</span>;</span><br><span class="line">    pose.pose.position.y = <span class="number">0</span>;</span><br><span class="line">    pose.pose.position.z = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在进入Offboard模式之前，必须已经启动了local_pos_pub数据流，否则模式切换将被拒绝。</span></span><br><span class="line">    <span class="comment">//这里的100可以被设置为任意数</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">100</span>; ros::ok() &amp;&amp; i &gt; <span class="number">0</span>; --i)&#123;</span><br><span class="line">        local_pos_pub.publish(pose);</span><br><span class="line">        ros::spinOnce();</span><br><span class="line">        rate.sleep();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//建立一个类型为SetMode的服务端offb_set_mode，并将其中的模式mode设为&quot;OFFBOARD&quot;，作用便是用于后面的客户端与服务端之间的通信（服务）</span></span><br><span class="line">    mavros_msgs::SetMode offb_set_mode;</span><br><span class="line">    offb_set_mode.request.custom_mode = <span class="string">&quot;OFFBOARD&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//建立一个类型为CommandBool的服务端arm_cmd，并将其中的是否解锁设为&quot;true&quot;，作用便是用于后面的客户端与服务端之间的通信（服务）</span></span><br><span class="line">    mavros_msgs::CommandBool arm_cmd;</span><br><span class="line">    arm_cmd.request.value = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//更新时间</span></span><br><span class="line">    ros::Time last_request = ros::Time::now();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> step = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> sametimes = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//大循环，只要节点还在ros::ok()的值就为正</span></span><br><span class="line">    <span class="keyword">while</span>(ros::ok())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//首先判断当前模式是否为offboard模式，如果不是，则进入if语句内部</span></span><br><span class="line">        <span class="comment">//这里是5秒钟进行一次判断，避免飞控被大量的请求阻塞</span></span><br><span class="line">        <span class="keyword">if</span>( current_state.mode != <span class="string">&quot;OFFBOARD&quot;</span> &amp;&amp; (ros::Time::now() - last_request &gt; ros::Duration(<span class="number">5.0</span>)))</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//客户端set_mode_client向服务端offb_set_mode发起请求call，然后服务端回应response将模式返回，这就打开了offboard模式</span></span><br><span class="line">            <span class="keyword">if</span>( set_mode_client.call(offb_set_mode) &amp;&amp; offb_set_mode.response.mode_sent)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">//打开Offboard模式后在终端打印信息</span></span><br><span class="line">                ROS_INFO(<span class="string">&quot;Offboard enabled&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//更新时间</span></span><br><span class="line">            last_request = ros::Time::now();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//else指已经为offboard模式，则进入if语句内部</span></span><br><span class="line">        <span class="keyword">else</span> </span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//判断当前状态是否解锁，如果没有解锁，则进入if语句内部</span></span><br><span class="line">            <span class="comment">//这里是5秒钟进行一次判断，避免飞控被大量的请求阻塞</span></span><br><span class="line">            <span class="keyword">if</span>( !current_state.armed &amp;&amp; (ros::Time::now() - last_request &gt; ros::Duration(<span class="number">5.0</span>)))</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">//客户端arming_client向服务端arm_cmd发起请求call，然后服务端回应response成功解锁，则解锁成功</span></span><br><span class="line">                <span class="keyword">if</span>( arming_client.call(arm_cmd) &amp;&amp; arm_cmd.response.success)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="comment">//解锁后在终端打印信息</span></span><br><span class="line">                    ROS_INFO(<span class="string">&quot;Vehicle armed&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//更新时间</span></span><br><span class="line">                last_request = ros::Time::now();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">switch</span>(step)&#123;</span><br><span class="line">                    <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                        pose.pose.position.x = <span class="number">0</span>;</span><br><span class="line">                        pose.pose.position.y = <span class="number">0</span>;</span><br><span class="line">                        pose.pose.position.z = <span class="number">2</span>;</span><br><span class="line">                        <span class="comment">//</span></span><br><span class="line">                        <span class="keyword">if</span> (local_pos.pose.position.z &gt; <span class="number">1.9</span> &amp;&amp; local_pos.pose.position.z &lt; <span class="number">2.1</span>)&#123;</span><br><span class="line">                            <span class="keyword">if</span> (sametimes &gt; <span class="number">20</span>)</span><br><span class="line">                            &#123;</span><br><span class="line">                                sametimes = <span class="number">0</span>;</span><br><span class="line">                                step = <span class="number">1</span>;</span><br><span class="line">                                pose.pose.position.x = <span class="number">40</span>;</span><br><span class="line">                                pose.pose.position.y = <span class="number">0</span>;</span><br><span class="line">                                pose.pose.position.z = <span class="number">2</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                sametimes++;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span></span><br><span class="line">                        &#123;</span><br><span class="line">                            sametimes = <span class="number">0</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        local_pos_pub.publish(pose);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> (local_pos.pose.position.x &gt; <span class="number">39.9</span> &amp;&amp; local_pos.pose.position.x &lt; <span class="number">40.1</span>)</span><br><span class="line">                        &#123;</span><br><span class="line">                            <span class="keyword">if</span> (sametimes &gt; <span class="number">20</span>)</span><br><span class="line">                            &#123;</span><br><span class="line">                                step = <span class="number">2</span>;</span><br><span class="line">                                pose.pose.position.x = <span class="number">40</span>;</span><br><span class="line">                                pose.pose.position.y = <span class="number">20</span>;</span><br><span class="line">                                pose.pose.position.z = <span class="number">2</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                sametimes++;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span></span><br><span class="line">                        &#123;</span><br><span class="line">                            sametimes = <span class="number">0</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> (local_pos.pose.position.y &gt; <span class="number">19.9</span> &amp;&amp; local_pos.pose.position.y &lt; <span class="number">20.1</span>)</span><br><span class="line">                        &#123;</span><br><span class="line">                            <span class="keyword">if</span> (sametimes &gt; <span class="number">20</span>)</span><br><span class="line">                            &#123;               </span><br><span class="line">                                step = <span class="number">3</span>;</span><br><span class="line">                                pose.pose.position.x = <span class="number">0</span>;</span><br><span class="line">                                pose.pose.position.y = <span class="number">20</span>;</span><br><span class="line">                                pose.pose.position.z = <span class="number">2</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                sametimes++;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span></span><br><span class="line">                        &#123;</span><br><span class="line">                            sametimes = <span class="number">0</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> (local_pos.pose.position.x &gt; <span class="number">-0.1</span> &amp;&amp; local_pos.pose.position.x &lt; <span class="number">0.1</span>)</span><br><span class="line">                        &#123;</span><br><span class="line">                            <span class="keyword">if</span> (sametimes &gt; <span class="number">20</span>)</span><br><span class="line">                            &#123;</span><br><span class="line"></span><br><span class="line">                                step = <span class="number">4</span>;</span><br><span class="line">                                pose.pose.position.x = <span class="number">0</span>;</span><br><span class="line">                                pose.pose.position.y = <span class="number">0</span>;</span><br><span class="line">                                pose.pose.position.z = <span class="number">2</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                sametimes++;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span></span><br><span class="line">                        &#123;</span><br><span class="line">                            sametimes = <span class="number">0</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="number">4</span>:</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> (local_pos.pose.position.y &gt; <span class="number">-0.1</span> &amp;&amp; local_pos.pose.position.y &lt; <span class="number">0.1</span>)</span><br><span class="line">                        &#123;</span><br><span class="line">                            <span class="keyword">if</span> (sametimes &gt; <span class="number">20</span>)</span><br><span class="line">                            &#123;</span><br><span class="line">                                step = <span class="number">5</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                sametimes++;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span></span><br><span class="line">                        &#123;</span><br><span class="line">                            sametimes = <span class="number">0</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="number">5</span>:   <span class="comment">// 准备降落</span></span><br><span class="line">                        offb_set_mode.request.custom_mode = <span class="string">&quot;AUTO.LAND&quot;</span>;</span><br><span class="line">                        <span class="keyword">if</span> (current_state.mode != <span class="string">&quot;AUTO.LAND&quot;</span> &amp;&amp; (ros::Time::now() - last_request &gt; ros::Duration(<span class="number">5.0</span>)))</span><br><span class="line">                        &#123;</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">if</span> (set_mode_client.call(offb_set_mode) &amp;&amp; offb_set_mode.response.mode_sent)</span><br><span class="line">                            &#123;</span><br><span class="line">                                ROS_INFO(<span class="string">&quot;AUTO.LAND enabled&quot;</span>);</span><br><span class="line">                            &#125;</span><br><span class="line">                            last_request = ros::Time::now();</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">default</span>:</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//发布位置信息，所以综上飞机只有先打开offboard模式然后解锁才能飞起来</span></span><br><span class="line">        local_pos_pub.publish(pose); </span><br><span class="line">        </span><br><span class="line">        <span class="comment">//当spinOnce函数被调用时，会调用回调函数队列中第一个回调函数，这里回调函数是state_cb函数</span></span><br><span class="line">        ros::spinOnce();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//根据前面ros::Rate rate(20.0);制定的发送频率自动休眠 休眠时间 = 1/频率</span></span><br><span class="line">        rate.sleep();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>打开创建的<code>offboard_run</code>功能包里面的<code>CMakeLists.txt</code>文件，添加如下内容。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">add_executable($</span><span class="bash">&#123;PROJECT_NAME&#125;_node src/offboard_run_node.cpp)</span></span><br><span class="line"><span class="meta">target_link_libraries($</span><span class="bash">&#123;PROJECT_NAME&#125;_node</span></span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;catkin_LIBRARIES&#125;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>编译工作空间：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ~/uav_demo_ws</span><br><span class="line">catkin_make</span><br></pre></td></tr></table></figure>
<h3 id="运行程序"><a href="#运行程序" class="headerlink" title="运行程序"></a>运行程序</h3><p>进入容器终端，在<code>PX4</code>源码处启动无人机<code>gazebo</code>仿真。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">make px4_sitl gazebo</span><br></pre></td></tr></table></figure>
<p>新建容器终端，运行<code>Mavros</code>。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">roslaunch mavros px4.launch fcu_url:=&quot;udp://:14540@127.0.0.1:14557&quot;</span><br></pre></td></tr></table></figure>
<p>再新打开另一个终端，运行自定义<code>ROS</code>节点，这里注意需要先使用<code>source</code>命令配置好运行环境。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ~/uav_demo_ws</span><br><span class="line">source ./devel/setup.bash</span><br><span class="line">rosrun offboard_run offboard_run_node</span><br></pre></td></tr></table></figure>
<p>最终实现效果，可以在<code>QGC</code>地面站中查看飞行轨迹。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202412061925001.png" alt=""></p>
]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>ROS</tag>
      </tags>
  </entry>
  <entry>
    <title>多智能体强化学习</title>
    <url>/2024/11/17/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>学习一下多智能体强化学习相关算法。</p>
<a id="more"></a>
<h1 id="VDN"><a href="#VDN" class="headerlink" title="VDN"></a><code>VDN</code></h1><p><code>VDN</code>中提出一种通过反向传播将团队的奖励信号分解到各个智能体上的这样一种方式。其网络结构如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411171915509.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411172038329.png" alt=""></p>
<p>先看上图中的图<code>1</code>，画的是两个独立的智能体，因为对每个智能体来说，观测都是部分可观测的，所以<code>Q</code>函数是被定义成基于观测历史数据所得到的$Q(h_{t},a_{t})$，实际操作的时候直接用<code>RNN</code>来做就可以。图<code>2</code>说的就是联合动作值函数由各个智能体的值函数累加得到的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411171918940.png" alt=""></p>
<p>其中$d$表示$d$个智能体，$\tilde{Q}_{i}$由每个智能体的局部观测信息得到，$\tilde{Q}_{i}$是通过联合奖励信号反向传播到各个智能体的$\tilde{Q}_{i}$上进行更新的。这样各个智能体通过贪婪策略选取动作的话，也就会使得联合动作值函数最大。</p>
<p>总结来说：值分解网络旨在学习一个联合动作值函数$Q_{tot}(\tau,\mathbf{u})$，其中$\tau \in \mathbf{T} \equiv \mathcal{T}^{n}$是一个联合动作-观测的历史轨迹，$\mathbf{u}$是一个联合动作。它是由每个智能体$a$独立计算其值函数$Q_{a}\left(\tau^{a},u^{a};\theta^{a}\right)$，之后累加求和得到的。其关系如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411171923497.png" alt=""></p>
<h1 id="QMIX"><a href="#QMIX" class="headerlink" title="QMIX"></a><code>QMIX</code></h1><p>在之前的值分解网络中，拿到了联合动作的$Q$值之后，我们就可以直接取能够获取最大的$Q_{tot}(\tau, \mathbf{u})$所对应的联合动作。这种方式就能够实现集中式学习，但是得到分布式策略。并且对全局值函数做<code>argmax</code>与对单个智能体地值函数做<code>argmax</code>能够得到相同的结果：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411172041620.png" alt=""></p>
<p>这样的话，每个智能体$a$都可以基于$Q_{a}$以贪婪策略选择动作。由于每个子智能体都采用贪婪策略，因此这个算法必定会是<code>off-policy</code>的算法，这一点是很容易实现的，并且样本的利用率会比较高。在<code>VDN</code>中采用的是线性加权，因此上述等式会成立，而如果是采用一个神经网络来学习融合各个智能体的$Q$函数的话，上述等式就未必会成立了。</p>
<p>在<code>QMIX</code>中也是需要一个联合动作值函数的，但是与值分解网络的不同之处在于，这个联合动作值函数并不是简单地由各个智能体的值函数线性相加得到的。为了保证值函数的单调性来使得上式能够成立，作者对联合动作值函数$Q_{tot}$和单个智能体动作值函数$Q_{a}$之间做了一个约束：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411172046802.png" alt=""></p>
<p>设计思想如上所示，具体的网络结构如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411172048239.png" alt=""></p>
<p>上述这个复杂的网络结构可以拆分为如下三部分：</p>
<ul>
<li><code>agent networks</code>：对于每个智能体都要学一个独立的值函数$Q_{a}\left(\tau^{a}, u^{a}\right)$，单个智能体的网络结构采用<code>DRQN</code>的网络结构，在每个时间步，接收当前的独立观测$O_{t}^{a}$和上一个动作$\mu_{t-1}^{a}$，如上图<code>(c)</code>所示。</li>
<li><code>mixing network</code>：是一个全连接网络，接收每个智能体的输出$Q_{n}\left(\tau^{n}, u_{t}^{n}\right)$作为输入，输出联合动作值函数$Q_{t o t}(\boldsymbol{\tau}, \boldsymbol{u})$，对每个子智能体的动作值函数做非线性映射，并且要保证单调性约束。想要保证公式<code>(2)</code>的单调性约束的话，我们只需要保证<code>mixing network</code>的权重非负即可。</li>
<li><code>hypernetworks</code>：<code>hypernetworks</code>网络去产生<code>mixing network</code>的权重，超参数网络输入状态$s$，输出<code>Mixing</code>网络的每一层的超参数向量，激活函数来使得输出非负，对于<code>Mixing</code>网络参数的偏置并没有非负的要求。<code>Hypernetworks</code>表示用于产生较大规模网络参数的小规模网络，在这一过程中，主网络的作用与其他任意神经网络一样，将输入样本映射到对应的目标值，而超网络的作用则是接收一系列包含主网络参数结构信息的值作为输入然后产生主网络某一层的参数。超网络的思想源于进化计算（evolutionary computing）：在一个包含成千上万参数的空间中搜索参数是十分困难的，一种更加高效的方式是用较小的网络产生较大网络的参数，这样搜索空间就会被限制在一个小得多的空间中，超网络的参数和主网络通过端到端的方式进行训练。</li>
</ul>
<p><code>QMIX</code>的训练方式是端到端的训练：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411172102666.png" alt=""></p>
<h1 id="QTRAN"><a href="#QTRAN" class="headerlink" title="QTRAN"></a><code>QTRAN</code></h1><p>前面介绍的<code>VDN</code>，<code>QMIX</code>算法，都是基于值方法并且用于协作式<code>MARL</code>任务中。这些算法本质上都在找分布式最优策略，并且满足下式中描述的关系：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411182259010.png" alt=""></p>
<p>其中，$Q_{jt}$表示整体的联合$Q$函数；$Q_{i}$表示智能体$i$的值函数。在本文，作者将<code>(1)</code>式中描述的关系定义为<code>IGM(Individual-Global-Max)</code>条件。</p>
<p><code>VDN</code>为了满足<code>IGM</code>条件，直接将值函数分解成“加和形式<code>(Additivity)</code>”：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411182302432.png" alt=""></p>
<p>从<code>(2)</code>式可以得出$\frac{\partial Q_{jt}(\tau,u)}{\partial Q_{i}(\tau_{i},u_{i})}\equiv1,\forall i\in\mathcal{N}$，可见只要满足<code>(2)</code>式就能满足<code>IGM</code>条件。</p>
<p>但是<code>QMIX</code>觉得<code>VDN</code>这样做不至于，并且会导致很多复杂的函数无法很好地拟合出来，因此<code>QMIX</code>提出了更一般的<strong>“单调性条件<code>(Monotonicity)</code>”</strong>：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411182308208.png" alt=""></p>
<p><code>QMIX</code>认为只要满足<code>(3)</code>式，就能满足<code>IGM</code>条件。<code>(2)</code>式是<code>(3)</code>式的充分条件，但是同时，<code>(3)</code>式也是<code>(1)</code>式的充分条件。换句话说，<strong>它们对<code>IGM</code>条件来说，都不是必要的！</strong>因此，针对一些具有非单调收益的合作问题，<code>VDN</code>和<code>QMIX</code>的函数拟合能力就会受到限制。</p>
<p>因此，基于这样的问题，作者提出<code>QTRAN</code>算法，并且声称该算法能够分解任何可分解的任务，而不需要受<code>(2)</code>式和<code>(3)</code>式的约束。</p>
<h2 id="QTRAN直观理解"><a href="#QTRAN直观理解" class="headerlink" title="QTRAN直观理解"></a><code>QTRAN</code>直观理解</h2><p>在<code>VDN</code>和<code>QMIX</code>中是将$Q_{\mathrm{jt}}$通过累加求和和保证单调性的方式来分解的，作者这里提出一种更加鲁棒的分解方式，将原始的$Q_{\mathrm{jt}}$映射成$Q_{\mathrm{jt}}^{\prime}$，通过$Q_{\mathrm{jt}}^{\prime}$去分解值函数到各个子智能体上，来保证学到的$Q_{\mathrm{jt}}^{\prime}$与真实的动作值函数$Q^{*}$非常接近。这样在学习真实的动作值函数的时候，没有像<code>VDN</code>和<code>QMIX</code>那样对其加上一些累加求和和保证单调性的限制，所以它能学地更好。</p>
<p>但是由于部分可观测地限制，这个$Q_{\mathrm{jt}}^{\prime}$是没有办法用来进行具体地决策的，所以我们需要去找到$Q_{\mathrm{jt}}$、$Q_{\mathrm{jt}}^{\prime}$和$\left[Q_{i}\right]$三者之间的关系。</p>
<h2 id="可分解值函数的充分条件"><a href="#可分解值函数的充分条件" class="headerlink" title="可分解值函数的充分条件"></a>可分解值函数的充分条件</h2><p>由于不提供累加求和和单调性来保证可分解，<code>QTRAN</code>提出了一个满足<code>IGM</code>定义的充分条件：当动作值函数$Q_{\mathrm{jt}}(\boldsymbol{\tau}, \boldsymbol{u})$和$\left[Q_{i}\left(\tau_{i}, u_{i}\right)\right]$满足下面这个关系式时，我们认为它是可分解的，其中$V_{\mathrm{jt}}(\tau)=\max _{\boldsymbol{u}} Q_{\mathrm{jt}}(\boldsymbol{\tau}, \boldsymbol{u})-\sum_{i=1}^{N} Q_{i}\left(\tau_{i}, \bar{u}_{i}\right)$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411182329900.png" alt=""></p>
<p>想要通过上述条件证明出满足<code>IGM</code>条件，也就是$\arg \max _{\boldsymbol{u}} Q_{\mathrm{jt}}(\boldsymbol{\tau}, \boldsymbol{u})=\overline{\boldsymbol{u}}$时（其中$\bar{u}_{i}=\arg \max _{u_{i}} Q_{i}\left(\tau_{i}, u_{i}\right)$）才能取到全局最大的动作值函数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411182341968.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411182351374.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202503141754204.png" alt=""></p>
<h2 id="可分解值函数的必要条件"><a href="#可分解值函数的必要条件" class="headerlink" title="可分解值函数的必要条件"></a>可分解值函数的必要条件</h2><p>必要条件说的是，当满足<code>IGM</code>条件时，能够把充分条件给推出来。作者在论文中说到，存在一个仿射函数$\phi(\boldsymbol{Q})=A \cdot \boldsymbol{Q}+B$对$Q$进行一个映射，其中$\left[a_{i i}\right] \in \mathbb{R}_{+}^{N \times N}$为一个对角矩阵，并且$a_{i i}&gt;0$。相较<code>QMIX</code>还多一个$B$，$B=\left[b_{i}\right] \in \mathbb{R}^{N}$。作者将$Q_{i}$进行了一个缩放，$a_{i i} Q_{i}+b_{i}$。然后定义：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411190001341.png" alt=""></p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411190007735.png" alt=""></p>
<p>网络结构中主要有三部分：</p>
<ul>
<li>独立的动作值网络：$f_{\mathrm{q}}:\left(\tau_{i}, u_{i}\right) \mapsto Q_{i}$。对于每个动作值网络，输入是他自己的动作观测历史$\tau_{i}$，输出动作值函数$Q_{i}\left(\tau_{i}, \cdot\right)$。$Q_{\mathrm{jt}}^{\prime}$由各个子智能体的动作值函数累加得到。</li>
<li>联合动作值网络：$f_{\mathrm{r}}:(\tau, \boldsymbol{u}) \mapsto Q_{\mathrm{jt}}$。如上图所示，网络的前面几层参数是共享的，用所有的独立智能体的动作值函数向量来采样样本，更新联合动作值函数。</li>
<li>状态值网络：$f_{\mathrm{v}}: \tau \mapsto V_{\mathrm{jt}}$。状态值函数类似<code>dueling</code>网络，并且这里可以引入全局的状态信息，它是独立于动作轨迹的，但是可以用来辅助动作值函数的训练。</li>
</ul>
<p>此时损失函数可以表达成如下形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411190011682.png" alt=""></p>
<p>第一个$\mathcal{L}_{\mathrm{td}}$使用标准的<code>TD-error</code>来更新最优的联合动作值函数，$\mathcal{L}_{\mathrm{opt}}$和$\mathcal{L}_{\mathrm{nopt}}$是用来去满足可分解值函数地充分必要条件的，$\mathcal{L}_{\mathrm{opt}}$对应条件<code>(a)</code>，$\mathcal{L}_{\mathrm{nopt}}$对应条件<code>(b)</code>，$\hat{Q}_{\mathrm{total}}$表示将$Q_{\mathrm{total}}$固定，也就是说$\mathcal{L}_{\mathrm{opt}}$和$\mathcal{L}_{\mathrm{nopt}}$不更新$Q_{\mathrm{total}}$，$Q^{\prime}_{\mathrm{jt}}$是真实的，$Q_{\mathrm{jt}}$是网络学习到的，用$V$去弥补两者之间的差异。</p>
<h1 id="COMA"><a href="#COMA" class="headerlink" title="COMA"></a><code>COMA</code></h1><p><code>COMA</code>是一种<code>policy-based</code>的多智能体算法，其核心思想是在于“独立回报分配”。当多个智能体在执行任务时，获得的奖励分数是由所有智能体的行为共同决定的，那么怎么把一个奖励分数合理的分配给每一个智能体呢？这就是<code>COMA</code>算法要解决的关键问题。在网络结构上，<code>COMA</code>沿用了<code>Actor-Critic</code>架构，其中<code>Actor</code>使用基于<code>policy-based</code>的<code>RNN</code>网络。</p>
<h2 id="算法背景和思想"><a href="#算法背景和思想" class="headerlink" title="算法背景和思想"></a>算法背景和思想</h2><p>在多智能体强化学习场景中，每个智能体在某一时刻只掌握局部的信息，无法全局观测环境状态。为了促进合作，各个智能体的动作对全局奖励有不同的贡献，因此需要一种有效的方法来分配奖励。<code>COMA</code>引入了“反事实基线”<code>(Counterfactual Baseline)</code>的概念，专门用于降低多智能体策略梯度方法中的方差。</p>
<p><code>COMA</code>的核心思想是通过引入一个基线，该基线模拟在固定其他智能体动作的前提下，某个智能体选择不同动作时对全局奖励的影响，从而更精确地衡量当前动作的贡献，减少策略梯度更新中的方差。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411192146348.png" alt=""></p>
<h2 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h2><h3 id="全局策略梯度"><a href="#全局策略梯度" class="headerlink" title="全局策略梯度"></a>全局策略梯度</h3><p>对于多智能体问题，每个智能体$(i)$的策略梯度可以表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411192159569.png" alt=""></p>
<p>其中，$(\pi_{\theta_{i}}(a_{i} \vert s))$是智能体$(i)$在状态$(s)$下选择动作$(a_{i})$的概率，$(Q_{i}(s,a))$是该智能体在执行动作$(a_{i})$时的动作价值函数。</p>
<h3 id="反事实基线"><a href="#反事实基线" class="headerlink" title="反事实基线"></a>反事实基线</h3><p>为了减小方差，<code>COMA</code>提出了反事实基线$(b(s,a_{-i}))$，该基线衡量在保持其他智能体动作$(a_{-i})$不变的情况下，智能体$(i)$选择其他动作时的期望收益。具体公式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411192206736.png" alt=""></p>
<p>这里$(a_{-i})$的表示除智能体$(i)$之外，其他智能体的动作组合。</p>
<h3 id="策略更新"><a href="#策略更新" class="headerlink" title="策略更新"></a>策略更新</h3><p>有了反事实基线之后，<code>COMA</code>中智能体$(i)$的策略更新公式变为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411192208564.png" alt=""></p>
<p>其中，$(Q_{i}(s,a))$是在当前状态下，所有智能体执行一组动作$(a)$时的全局奖励，而$(b(s,a_{-i}))$是该动作的反事实基线。</p>
<h3 id="全局值函数"><a href="#全局值函数" class="headerlink" title="全局值函数"></a>全局值函数</h3><p><code>COMA</code>中的值函数$(Q(s,a))$和基线$(b(s,a_{-i}))$都是通过集中化的学习进行优化的，虽然决策是去中心化的，但值函数和基线都依赖于全局的状态和动作信息。</p>
<h2 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h2><ol>
<li>初始化智能体策略和集中式的全局值函数。</li>
<li>智能体与环境交互，收集经验数据。</li>
<li>使用经验数据更新全局值函数$(Q(s,a))$。</li>
<li>计算反事实基线$(b(s,a_{-i}))$。</li>
<li>计算每个智能体的策略梯度，并更新策略参数。</li>
<li>重复上述过程，直至智能体策略收敛。</li>
</ol>
<h1 id="MADDPG"><a href="#MADDPG" class="headerlink" title="MADDPG"></a><code>MADDPG</code></h1><h2 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h2><p> 在多智能体系统中，多个智能体同时作用于同一个环境，相互之间可能是竞争的、协作的，或者二者兼有。这类环境下，单智能体算法如<code>DDPG</code>往往无法取得较好的效果，因为每个智能体的行为都会影响其他智能体的状态和奖励。为了解决这一问题，<code>MADDPG</code>采用了一种集中式训练，分布式执行的架构。</p>
<ul>
<li>集中式训练：训练期间，每个智能体可以观察所有其他智能体的动作和状态，从而学到更有效的策略。</li>
<li>分布式执行：在执行阶段，智能体只依赖其自身的观测来做出决策，保持分布式控制的特性。</li>
</ul>
<h2 id="算法细节"><a href="#算法细节" class="headerlink" title="算法细节"></a>算法细节</h2><ul>
<li><code>Actor-Critic</code>架构：每个智能体都有一个<code>Actor</code>网络用于输出动作，以及一个<code>Critic</code>网络用于评估当前策略的好坏。<code>Actor</code>直接学习确定性策略，而<code>Critic</code>负责估算状态-动作对的$Q$值。</li>
<li>集中式训练，分布式执行：在训练阶段，Critic网络可以访问所有智能体的信息，包括状态和动作，这允许它准确评估每个动作的期望回报。然而，在执行阶段，每个智能体的<code>Actor</code>网络只能基于自己的局部观察来做出决策。</li>
<li>经验回放：为了提高训练的稳定性和效率，<code>MADDPG</code>使用了经验回放机制。智能体的每次交互会被存储在一个回放缓冲区中，训练时会从这个缓冲区中随机抽取一批经验来更新网络。</li>
<li>目标网络：为了进一步稳定训练过程，<code>MADDPG</code>为每个<code>Actor</code>和<code>Critic</code>网络维护了一个目标网络。这些目标网络的参数会缓慢跟踪对应网络的参数，用于计算期望回报的稳定目标。</li>
<li>奖励和惩罚：<code>MADDPG</code>允许设计复杂的奖励机制，包括对合作行为的奖励和对对立行为的惩罚，来引导智能体学习如何在多种交互场景中作出最优决策。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411202322720.png" alt=""></p>
<h3 id="中心化训练"><a href="#中心化训练" class="headerlink" title="中心化训练"></a>中心化训练</h3><p>与<code>DDPG</code>不同之处在于，<code>MADDPG</code>中的每个智能体在计算自身的<code>Critic</code>的前向传播时，把包括自身在内的所有智能体的观测拼接成观测向量$s=\{s_{1},s_{2},\cdots,s_{n}\}$，把所有智能体动作拼接成动作向量$\{a_{1},a_{2},\cdots,a_{n}\}$，$(s,a)$作为<code>Online Critic Net</code>的输入，输出一维的$Q$值，即$Q_{\phi_{i}}(s,a)$，换句话说就是利用环境中智能体的全局信息（全局观测和动作）来“中心化”训练自身的<code>Critic Net</code>。现在，有了$Q_{\phi_{i}}(s,a)$，同时有了回放样本可以计算出$Q_{\phi_{i}}(s^{\prime},a^{\prime})$，接下来要做的和<code>DDPG</code>相同，以时序差分误差构建二者的<code>MSE</code>损失函数，然后利用梯度下降更新参数$\phi_{i}$。具体的损失函数及梯度如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411202312830.png" alt=""></p>
<p>其中，$\boldsymbol{a}^{\prime}=\{\mu_{\tilde{\theta}_{1}}(s_{1}^{\prime}),\mu_{\tilde{\theta}_{1}}(s_{2}^{\prime}),\ldots,\mu_{\tilde{\theta}_{1}}(s_{N}^{\prime})\}$这里用<code>Target Policy Net</code>计算下一状态智能体所采取的动作。需要注意，每个智能体的<code>Target Policy Net</code>输入是自身局部观测$s_{i}$。</p>
<h3 id="分布式执行"><a href="#分布式执行" class="headerlink" title="分布式执行"></a>分布式执行</h3><p>在计算自身的<code>Actor</code>的前向传播时，每个智能体只将自身的局部观测向量$s=\{s_{1},s_{2},\ldots,s_{n}\}$作为<code>Online Actor Net</code>的输入，输出一个确定性动作$a_{i}$，即$\mu_{\theta_{i}}(s_{i})$。接下来和<code>DDPG</code>一样，计算时序差分误差的<code>MSE</code>损失函数并计算关于参数$\theta_{i}$的梯度，然后利用梯度下降更新参数。损失函数及梯度如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411202320613.png" alt=""></p>
<h1 id="MAPPO"><a href="#MAPPO" class="headerlink" title="MAPPO"></a><code>MAPPO</code></h1><h2 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h2><p>和单智能体<code>PPO</code>算法一样，<code>MAPPO</code>算法中每个智能体都有各自的<code>Actor</code>网络和<code>Critic</code>网络（如果所有智能体的状态空间和动作空间也相同，即同构，也可以所有智能体共享一套<code>Actor</code>和<code>Critic</code>网络）。与单智能体<code>PPO</code>不同的是，<code>MAPPO</code>的<code>Critic</code>网络可以接收有关全局状态的信息，这个全局状态可以是由所有智能体的观察拼接而成，也可以是环境直接提供。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411171817653.png" alt=""></p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>和单智能体<code>PPO</code>算法一样，损失函数由<code>Actor Loss</code>和<code>Critic Loss</code>组成：</p>
<ul>
<li><code>Actor Loss</code>为最小化负的智能体在当前策略下的预期累积奖励$-E[\frac{\pi(a|S_t;\theta)}{\pi(a|S_t;\theta_k)} A_t]$</li>
<li><code>Critic Loss</code>为回报和状态价值函数的均方差$[(G_t-V(s,w))]^{2}$</li>
</ul>
<h2 id="采样和更新方式"><a href="#采样和更新方式" class="headerlink" title="采样和更新方式"></a>采样和更新方式</h2><h3 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h3><p>如智能体间不共享参数，即每个智能体有各自的<code>Actor</code>和<code>Critic</code>网络，则给每个智能体建立一个<code>replay buffer</code>，将该智能体交互中获得的$s_{t}, a_{t}, r，s_{t+1}$存入对应的<code>replay buffer</code>中。另在<code>replay buffer</code>中增加<code>mask</code>，记录每一时刻智能体是否存活，以便后续死亡的智能体后续数据不用于更新网络。一般情况下，不同智能体间不共享奖励。</p>
<h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p>如果智能体间不共享参数，则针对每一个智能体分别从<code>replay buffer</code>中抽样，训练其网络，其更新函数与<code>PPO</code>更新函数整体一致，并且增加了<code>GAE</code>、<code>value normlization</code>等技巧。</p>
]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>gRPC使用总结</title>
    <url>/2024/05/20/gRPC%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下<code>gRPC</code>的使用方法。</p>
<a id="more"></a>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p><code>gRPC</code>基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 <code>gRPC</code>服务器来处理客户端调用。在客户端拥有一个存根（<code>Stub</code>），提供与服务端相同的方法。<br>在<code>gRPC</code>里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得我们能够更容易地创建分布式应用和服务。</p>
<p><code>gRPC</code>默认使用<code>protocol buffers</code>，这是<code>Google</code>开源的一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或<code>RPC</code>数据交换格式。</p>
<h1 id="Protobuf的使用"><a href="#Protobuf的使用" class="headerlink" title="Protobuf的使用"></a>Protobuf的使用</h1><h2 id="定义消息类型"><a href="#定义消息类型" class="headerlink" title="定义消息类型"></a>定义消息类型</h2><p>假设你想定义一个“搜索请求”的消息格式，每一个请求含有一个查询字符串、你感兴趣的查询结果所在的页数，以及每一页多少条查询结果。可以采用如下的方式来定义消息类型的<code>.proto</code>文件：</p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line">syntax = <span class="string">&quot;proto3&quot;</span>;  <span class="comment">// 声明使用proto3语法</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">SearchRequest</span> </span>&#123;</span><br><span class="line">  <span class="built_in">string</span> query = <span class="number">1</span>;  <span class="comment">// 每个字段都要指定数据类型</span></span><br><span class="line">  <span class="built_in">int32</span> page_number = <span class="number">2</span>; <span class="comment">// 这里的数字2是标识符，最小的标识号可以从1开始，最大到2^29-1，不可以使用其中的[19000－19999]</span></span><br><span class="line">  <span class="built_in">int32</span> result_per_page = <span class="number">3</span>; <span class="comment">// 这里是注释，使用//</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>第一行指定正在使用<code>proto3</code>语法：如果不指定，编译器会使用<code>proto2</code>。这个指定语法必须是文件的非空非注释的第一行。</li>
<li><code>SearchRequest</code>消息格式有三个字段，在消息中承载的数据分别对应于每一个字段。其中每个字段都有一个名字和一种类型。向<code>.proto</code>文件添加注释，可以使用<code>C/C++/JAVA</code>风格的双斜杠语法格式。</li>
<li>在消息体中，每个字段都有唯一的一个数字标识符。这些标识符用来在消息的二进制格式中识别各个字段，一旦开始使用就不能再改变。<ul>
<li><code>[1,15]</code>之内的标识号在编码的时候会占用一个字节。<code>[16,2047]</code>之内的标识号则占用<code>2</code>个字节。所以应该为那些频繁出现的消息元素保留<code>[1,15]</code>之内的标识号。切记：要为将来有可能添加的、频繁出现的标识号预留一些标识号。</li>
</ul>
</li>
</ul>
<h2 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h2><p>一个标量消息字段可以含有一个如下的类型，该表格展示了定义于<code>.proto</code>文件中的类型，以及与之对应的、在自动生成的访问类中定义的类型：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">.proto Type</th>
<th style="text-align:center">Notes</th>
<th style="text-align:center">C++ Type</th>
<th style="text-align:center">Java Type</th>
<th style="text-align:center">Python Type[2]</th>
<th style="text-align:center">Go Type</th>
<th style="text-align:center">Ruby Type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">double</td>
<td style="text-align:center"></td>
<td style="text-align:center">double</td>
<td style="text-align:center">double</td>
<td style="text-align:center">float</td>
<td style="text-align:center">float64</td>
<td style="text-align:center">Float</td>
</tr>
<tr>
<td style="text-align:center">int32</td>
<td style="text-align:center">使用变长编码，对于负值的效率很低，如果你的域有可能有负值，请使用sint64替代</td>
<td style="text-align:center">int32</td>
<td style="text-align:center">int</td>
<td style="text-align:center">int</td>
<td style="text-align:center">int32</td>
<td style="text-align:center">Fixnum或者Bignum（根据需要）</td>
</tr>
<tr>
<td style="text-align:center">uint32</td>
<td style="text-align:center">使用变长编码</td>
<td style="text-align:center">uint32</td>
<td style="text-align:center">int</td>
<td style="text-align:center">int/long</td>
<td style="text-align:center">uint32</td>
<td style="text-align:center">Fixnum或者Bignum（根据需要）</td>
</tr>
<tr>
<td style="text-align:center">uint64</td>
<td style="text-align:center">使用变长编码</td>
<td style="text-align:center">uint64</td>
<td style="text-align:center">long</td>
<td style="text-align:center">int/long</td>
<td style="text-align:center">uint64</td>
<td style="text-align:center">Bignum</td>
</tr>
<tr>
<td style="text-align:center">sint32</td>
<td style="text-align:center">使用变长编码，这些编码在负值时比int32高效的多</td>
<td style="text-align:center">int32</td>
<td style="text-align:center">int</td>
<td style="text-align:center">int</td>
<td style="text-align:center">int32</td>
<td style="text-align:center">Fixnum或者Bignum（根据需要）</td>
</tr>
<tr>
<td style="text-align:center">sint64</td>
<td style="text-align:center">使用变长编码，有符号的整型值，编码时比通常的int64高效</td>
<td style="text-align:center">int64</td>
<td style="text-align:center">long</td>
<td style="text-align:center">int/long</td>
<td style="text-align:center">int64</td>
<td style="text-align:center">Bignum</td>
</tr>
<tr>
<td style="text-align:center">fixed32</td>
<td style="text-align:center">总是4个字节，如果数值总是大于228，这个类型会比uint32高效</td>
<td style="text-align:center">uint32</td>
<td style="text-align:center">int</td>
<td style="text-align:center">int</td>
<td style="text-align:center">uint32</td>
<td style="text-align:center">Fixnum或者Bignum（根据需要）</td>
</tr>
<tr>
<td style="text-align:center">fixed64</td>
<td style="text-align:center">总是8个字节，如果数值总是大于256，这个类型会比uint64高效</td>
<td style="text-align:center">uint64</td>
<td style="text-align:center">long</td>
<td style="text-align:center">int/long</td>
<td style="text-align:center">uint64</td>
<td style="text-align:center">Bignum</td>
</tr>
<tr>
<td style="text-align:center">sfixed32</td>
<td style="text-align:center">总是4个字节</td>
<td style="text-align:center">int32</td>
<td style="text-align:center">int</td>
<td style="text-align:center">int</td>
<td style="text-align:center">int32</td>
<td style="text-align:center">Fixnum或者Bignum（根据需要）</td>
</tr>
<tr>
<td style="text-align:center">sfixed64</td>
<td style="text-align:center">总是8个字节</td>
<td style="text-align:center">int64</td>
<td style="text-align:center">long</td>
<td style="text-align:center">int/long</td>
<td style="text-align:center">int64</td>
<td style="text-align:center">Bignum</td>
</tr>
<tr>
<td style="text-align:center">bool</td>
<td style="text-align:center"></td>
<td style="text-align:center">bool</td>
<td style="text-align:center">boolean</td>
<td style="text-align:center">bool</td>
<td style="text-align:center">bool</td>
<td style="text-align:center">TrueClass/FalseClass</td>
</tr>
<tr>
<td style="text-align:center">string</td>
<td style="text-align:center">一个字符串必须是UTF-8编码或者7-bit ASCII编码的文本</td>
<td style="text-align:center">string</td>
<td style="text-align:center">String</td>
<td style="text-align:center">str/unicode</td>
<td style="text-align:center">string</td>
<td style="text-align:center">String(UTF-8)</td>
</tr>
<tr>
<td style="text-align:center">bytes</td>
<td style="text-align:center">可能包含任意顺序的字节数据</td>
<td style="text-align:center">string</td>
<td style="text-align:center">ByteString</td>
<td style="text-align:center">str</td>
<td style="text-align:center">[]byte</td>
<td style="text-align:center">String(ASCII-8BIT)</td>
</tr>
</tbody>
</table>
</div>
<h2 id="默认值"><a href="#默认值" class="headerlink" title="默认值"></a>默认值</h2><p>当一个消息被解析的时候，如果被编码的信息不包含一个特定的<code>singular</code>元素，被解析的对象锁对应的域被设置位一个默认值，对于不同类型指定如下：</p>
<ul>
<li>对于<code>strings</code>，默认是一个空<code>string</code></li>
<li>对于<code>bytes</code>，默认是一个空的<code>bytes</code></li>
<li>对于<code>bools</code>，默认是<code>false</code></li>
<li>对于数值类型，默认是<code>0</code></li>
<li>对于枚举，默认是第一个定义的枚举值，必须为<code>0</code></li>
<li>对于消息类型（<code>message</code>），域没有被设置，确切的消息是根据语言确定的</li>
<li>对于可重复域的默认值是空（通常情况下是对应语言中空列表）</li>
</ul>
<h2 id="嵌套类型"><a href="#嵌套类型" class="headerlink" title="嵌套类型"></a>嵌套类型</h2><p>你可以在其他消息类型中定义、使用消息类型，在下面的例子中，<code>Result</code>消息就定义在<code>SearchResponse</code>消息内，如：</p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">SearchResponse</span> </span>&#123;</span><br><span class="line">  <span class="class"><span class="keyword">message</span> <span class="title">Result</span> </span>&#123;</span><br><span class="line">    <span class="built_in">string</span> url = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">string</span> title = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">repeated</span> <span class="built_in">string</span> snippets = <span class="number">3</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">repeated</span> Result results = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>message SearchResponse</code>中，定义了嵌套消息<code>Result</code>，并用来定义<code>SearchResponse</code>消息中的<code>results</code>域。</p>
<h2 id="Protobuf文件编译"><a href="#Protobuf文件编译" class="headerlink" title="Protobuf文件编译"></a>Protobuf文件编译</h2><p>当用<code>protocol buffer</code>编译器来运行<code>.proto</code>文件时，编译器将生成所选择语言的代码，这些代码可以操作在<code>.proto</code>文件中定义的消息类型，包括获取、设置字段值，将消息序列化到一个输出流中，以及从一个输入流中解析消息。</p>
<ul>
<li>对<code>C++</code>来说，编译器会为每个<code>.proto</code>文件生成一个<code>.h</code>文件和一个<code>.cc</code>文件，<code>.proto</code>文件中的每一个消息有一个对应的类。</li>
<li>对<code>Java</code>来说，编译器为每一个消息类型生成一个<code>.java</code>文件，以及一个特殊的<code>Builder</code>类（该类是用来创建消息类接口的）。</li>
<li>对<code>Python</code>来说，有点不太一样——<code>Python</code>编译器为<code>.proto</code>文件中的每个消息类型生成一个含有静态描述符的模块，该模块与一个元类（<code>metaclass</code>）在运行时（<code>runtime</code>）被用来创建所需的Python数据访问类。</li>
<li>对<code>go</code>来说，编译器会为每个消息类型生成一个<code>.pd.go</code>文件。</li>
<li>对<code>Ruby</code>来说，编译器会为每个消息类型生成一个<code>.rb</code>文件。</li>
<li>对<code>javaNano</code>来说，编译器输出类似于<code>.java</code>的文件但是没有<code>Builder</code>类。</li>
<li>对<code>Objective-C</code>来说，编译器会为每个消息类型生成一个<code>pbobjc.h</code>文件和<code>pbobjc.m</code>文件，<code>.proto</code>文件中的每一个消息有一个对应的类。</li>
<li>对<code>C#</code>来说，编译器会为每个消息类型生成了一个<code>.cs</code>文件，<code>.proto</code>文件中的每一个消息有一个对应的类。</li>
</ul>
<h1 id="gRPC示例"><a href="#gRPC示例" class="headerlink" title="gRPC示例"></a>gRPC示例</h1><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>我们采用<code>Python</code>编译如下的<code>proto</code>文件：</p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 文件名 hello.proto</span></span><br><span class="line">syntax = <span class="string">&quot;proto3&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> hello;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The greeting service definition.</span></span><br><span class="line"><span class="class"><span class="keyword">service</span> <span class="title">Greeter</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Sends a greeting</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> SayHello (HelloRequest) <span class="keyword">returns</span> (HelloReply) </span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The request message containing the user&#x27;s name.</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">HelloRequest</span> </span>&#123;</span><br><span class="line">  <span class="built_in">string</span> name = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The response message containing the greetings</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">HelloReply</span> </span>&#123;</span><br><span class="line">  <span class="built_in">string</span> <span class="class"><span class="keyword">message</span> = 1;</span></span><br><span class="line"><span class="class">&#125;</span></span><br></pre></td></tr></table></figure>
<p>采取的命令为：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python -m grpc_tools.protoc -I./ --python_out=. --grpc_python_out=. ./hello.proto</span><br></pre></td></tr></table></figure>
<p>生成了两个文件：</p>
<ul>
<li><code>hello_pb2.py</code>：此文件包含生成的<code>request(HelloRequest)</code>和<code>response(HelloReply)</code>类。</li>
<li><code>hello_pb2_grpc.py</code>：此文件包含生成的客户端<code>(GreeterStub)</code>和服务端<code>(GreeterServicer)</code>类。</li>
</ul>
<h2 id="创建服务端代码"><a href="#创建服务端代码" class="headerlink" title="创建服务端代码"></a>创建服务端代码</h2><p>创建和运行<code>Greeter</code>服务可以分为两个部分：</p>
<ul>
<li>实现我们服务定义的生成的服务接口：做我们的服务的实际的“工作”的函数。</li>
<li>运行一个<code>gRPC</code>服务器，监听来自客户端的请求并传输服务的响应。</li>
</ul>
<p>在当前目录，打开文件<code>greeter_server.py</code>，实现一个新的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2024/5/22 23:01</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> concurrent <span class="keyword">import</span> futures</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hello_pb2</span><br><span class="line"><span class="keyword">import</span> hello_pb2_grpc</span><br><span class="line"></span><br><span class="line">_ONE_DAY_IN_SECONDS = <span class="number">60</span> * <span class="number">60</span> * <span class="number">24</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Greeter</span>(<span class="params">hello_pb2_grpc.GreeterServicer</span>):</span></span><br><span class="line">    <span class="comment"># 工作函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">SayHello</span>(<span class="params">self, request, context</span>):</span></span><br><span class="line">        <span class="keyword">return</span> hello_pb2.HelloReply(message=<span class="string">&#x27;Hello, %s!&#x27;</span> % request.name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">serve</span>():</span></span><br><span class="line">    <span class="comment"># gRPC 服务器</span></span><br><span class="line">    server = grpc.server(futures.ThreadPoolExecutor(max_workers=<span class="number">10</span>))</span><br><span class="line">    hello_pb2_grpc.add_GreeterServicer_to_server(Greeter(), server)</span><br><span class="line">    server.add_insecure_port(<span class="string">&#x27;[::]:50051&#x27;</span>)</span><br><span class="line">    server.start()  <span class="comment"># start() 不会阻塞，如果运行时你的代码没有其它的事情可做，你可能需要循环等待。</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            time.sleep(_ONE_DAY_IN_SECONDS)</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        server.stop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    serve()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="更新客户端代码"><a href="#更新客户端代码" class="headerlink" title="更新客户端代码"></a>更新客户端代码</h2><p>在当前目录，打开文件<code>greeter_client.py</code>，实现一个新的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2024/5/22 23:01</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hello_pb2</span><br><span class="line"><span class="keyword">import</span> hello_pb2_grpc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span>():</span></span><br><span class="line">    channel = grpc.insecure_channel(<span class="string">&#x27;localhost:50051&#x27;</span>)</span><br><span class="line">    stub = hello_pb2_grpc.GreeterStub(channel)</span><br><span class="line">    response = stub.SayHello(hello_pb2.HelloRequest(name=<span class="string">&#x27;goodspeed&#x27;</span>))</span><br><span class="line">    print(<span class="string">&quot;Greeter client received: &quot;</span> + response.message)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title>我的第一篇文章</title>
    <url>/2021/01/31/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</url>
    <content><![CDATA[<p>这是一篇测试文章，没有后续~~~</p>
]]></content>
  </entry>
  <entry>
    <title>大语言模型</title>
    <url>/2024/04/09/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>了解一下大语言模型的相关内容，主要参考清华刘知远团队的课程。</p>
<a id="more"></a>
<h1 id="NLP基础"><a href="#NLP基础" class="headerlink" title="NLP基础"></a>NLP基础</h1><p>自然语言处理：让计算机理解人类所说的语言。</p>
<p>相关综述：《Advances in Natural Language Processing》</p>
<h2 id="基本任务"><a href="#基本任务" class="headerlink" title="基本任务"></a>基本任务</h2><ul>
<li>词性标注：名词、动词、形容词的识别</li>
<li>命名实体的识别：人名、地名、机构名、日期的识别</li>
<li>共指消解：代词指向的是哪个实体</li>
<li>依赖关系：句子中成分的句法关系</li>
<li>中文的分词</li>
</ul>
<h2 id="词表示"><a href="#词表示" class="headerlink" title="词表示"></a>词表示</h2><h3 id="词表示的目标"><a href="#词表示的目标" class="headerlink" title="词表示的目标"></a>词表示的目标</h3><ul>
<li>词之间的相似度计算</li>
<li>词之间的语义关系</li>
</ul>
<h3 id="词表示的方法"><a href="#词表示的方法" class="headerlink" title="词表示的方法"></a>词表示的方法</h3><ul>
<li>相关词表示法：近义词、反义词、上位词（细微差异难以区分、新词义难以处理、主观性、数据吸收、大量人工）</li>
<li>独热表示法：每个词表示成独立的符号（表示词的时候假设不同的词之间是正交的）</li>
<li>上下文表示法：词用上下文出现的频度表示（需要大量存储空间、对于不经常出现的词表示变得稀疏）</li>
<li>词嵌入：将每个词学到低维稠密的向量空间当中</li>
</ul>
<h4 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h4><p>Word2Vec的主要作用是生成词向量，而词向量与语言模型有着密切的关系。Word2Vec的特点是能够将单词转化为向量来表示，这样词与词之间就可以定量的去度量他们之间的关系，挖掘词之间的联系。Word2Vec模型在自然语言处理中有着广泛的应用，包括词语相似度计算、文本分类、词性标注、命名实体识别、机器翻译、文本生成等。其主要目的是将所有词语投影到K维的向量空间，每个词语都可以用一个K维向量表示。</p>
<h5 id="One-Hot-Representation"><a href="#One-Hot-Representation" class="headerlink" title="One-Hot Representation"></a>One-Hot Representation</h5><p>一种最简单的词向量方式是One-Hot编码 ，就是用一个很长的向量来表示一个词，向量的长度为词典的大小，向量中只有一个1， 其他全为0，1的位置对应该词在词典中的位置。举个例子：I like writing code，那么转换成独热编码就是：I—&gt;1 0 0 0，like—&gt;0 1 0 0，writing—&gt;0 0 1 0，code—&gt;0 0 0 1。</p>
<p>这种One Hot编码如果采用稀疏方式存储，会是非常的简洁：也就是给每个 词分配一个数字ID。比如上面的例子中，code记为1，like记为4。 如果要编程实现的话，用Hash表给每个词分配一个编号就可以了。这么简洁的表示方法配 合上最大熵、SVM、CRF等等算法已经能很好地完成NLP领域的各种主流任务。</p>
<p>但这种词表示有几个缺点：</p>
<ul>
<li>容易受维数灾难的困扰，尤其是将其用于 Deep Learning的一些算法时；</li>
<li>词汇鸿沟，不能很好地刻画词与词之间的相似性；</li>
<li>强稀疏性。</li>
</ul>
<h5 id="Distributed-Representation"><a href="#Distributed-Representation" class="headerlink" title="Distributed Representation"></a>Distributed Representation</h5><p>Distributed Representation最早是Hinton于1986年提出的，可以克服One-Hot Representation的上述缺点。其基本想法是：通过训练将某种语言中的每一个词映射成一个固定长度的短向量（当然这里的“短”是相对于One-Hot Representation的“长”而言的），所有这些向量构成一个词向量空间，而每一个向量则可视为该空间中的一个点，在这个空间上引入“距离”，就可以根据词之间的距离来判断它们之间的语法、语义上的相似性了。Word2Vec中采用的就是这种Distributed Representation的词向量。</p>
<h5 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h5><p>Word2Vec是轻量级的神经网络，其模型仅仅包括输入层、隐藏层和输出层，模型框架根据输入输出的不同。Word2Vec包括两种模型：主要包括CBOW和Skip-gram模型。 CBOW的方式是在知道词$w_{t}$的上下文$w_{t-2}$、$w_{t-1}$、$w_{t+1}$、$w_{t+2}$的情况下预测当前词$w_{t}$。而Skip-gram是在知道了词$w_{t}$的情况下，对词$w_{t}$的上下文$w_{t-2}$、$w_{t-1}$、$w_{t+1}$、$w_{t+2}$进行预测，如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505301717085.png" alt=""></p>
<h6 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h6><p>为了更好的了解模型深处的原理，我们先从Simple CBOW model（仅输入一个词，输出一个词）框架说起。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505301726970.png" alt=""></p>
<ul>
<li>input layer输入的$X$是单词的one-hot representation（考虑一个词表$V$，里面的每一个词 $w_{i}$ 都有一个编号$i\in{1,\cdots,|V|}$，那么词 $w_{i}$ 的one-hot表示就是一个维度为$|V|$的向量，其中第$i$个元素值非零，其余元素全为0，例如：$w_{2}=[0,1,0,\cdots,0]^{T}$）；</li>
<li>输入层到隐藏层之间有一个权重矩阵$W$，隐藏层得到的值是由输入$X$乘上权重矩阵得到的（0-1向量乘上一个矩阵，就相当于选择了权重矩阵的某一行，如图：输入的向量$X$是$[0,0,1,0,0,0]$，$W$的转置乘上$X$就相当于从矩阵中选择第$3$行$[2,1,3]$作为隐藏层的值）;</li>
<li>隐藏层到输出层也有一个权重矩阵$W^{\prime}$，因此，输出层向量$y$的每一个值，其实就是隐藏层的向量点乘权重向量$W^{\prime}$的每一列，比如输出层的第一个数$7$，就是向量$[2,1,3]$和列向量$[1,2,1]$点乘之后的结果；</li>
<li>最终的输出需要经过softmax函数，将输出向量中的每一个元素归一化到0-1之间的概率，概率最大的，就是预测的词。</li>
</ul>
<p>了解了Simple CBOW model之后，扩展到CBOW就很容易了，只是把单个输入换成多个输入（划红线部分）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505301727312.png" alt=""></p>
<p>对比可以发现，和simple CBOW不同之处在于，输入由1个词变成了$C$个词，每个输入$X_{ik}$到达隐藏层都会经过相同的权重矩阵$W$，隐藏层$h$的值变成了多个词乘上权重矩阵之后加和求平均值。</p>
<h6 id="Skip-gram-Model"><a href="#Skip-gram-Model" class="headerlink" title="Skip-gram Model"></a>Skip-gram Model</h6><p>有了CBOW的介绍，那么Skip-gram model 就更好理解了。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505301728530.png" alt=""></p>
<p>如上图所示，Skip-gram model是通过输入一个词去预测多个词的概率。输入层到隐藏层的原理和simple CBOW一样，不同的是隐藏层到输出层，损失函数变成了$C$个词损失函数的总和，权重矩阵$W^{\prime}$还是共享的。</p>
<p>一般神经网络语言模型在预测的时候，输出的是预测目标词的概率，也就是说我每一次预测都要基于全部的数据集进行计算，这无疑会带来很大的时间开销。不同于其他神经网络，Word2Vec提出两种加快训练速度的方式，一种是Hierarchical softmax，另一种是Negative Sampling。</p>
<h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><h3 id="语言模型的任务"><a href="#语言模型的任务" class="headerlink" title="语言模型的任务"></a>语言模型的任务</h3><ul>
<li>计算一个词的序列成为一句合法的话的概率（Joint probability）</li>
<li>根据前面的词预测后面的词（conditional probability）</li>
</ul>
<h3 id="N-gram-model"><a href="#N-gram-model" class="headerlink" title="N-gram model"></a>N-gram model</h3><p>考虑连续出现N个词的概率（马尔可夫假设）：例如 $P(w_{j}|nerver \ too \ late \ to)=\frac{count(too \ late \ to \ w_{j})}{count(too \ late \ to)}$</p>
<h4 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h4><ul>
<li>N-gram model在实际使用时很少考虑比较长的上下文，因为前文越长，统计结果会越稀疏</li>
<li>N-gram model无法计算相似度</li>
</ul>
<h3 id="Neural-Language-Model"><a href="#Neural-Language-Model" class="headerlink" title="Neural Language Model"></a>Neural Language Model</h3><p>首先将上下文的每个词表示为低维的向量，然后将这些向量拼接成一个上下文向量，最后经过非线性变换预测下一个词。</p>
<h1 id="Transformer和预训练语言模型"><a href="#Transformer和预训练语言模型" class="headerlink" title="Transformer和预训练语言模型"></a>Transformer和预训练语言模型</h1><h2 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h2><p>通过求注意力分数来进行加权求和，得到一个与隐向量维度相同的输出向量，该向量包含decoder需要的所有encoder的信息。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404101742998.png" alt=""></p>
<h3 id="注意力机制特点"><a href="#注意力机制特点" class="headerlink" title="注意力机制特点"></a>注意力机制特点</h3><ul>
<li>解决信息瓶颈问题</li>
<li>缓解梯度消失问题</li>
<li>提供了可解释性</li>
</ul>
<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><ul>
<li>RNN当中的顺序计算不利于GPU并行</li>
<li>RNN需要注意力机制来解决信息瓶颈等问题</li>
</ul>
<h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404101757934.png" alt=""></p>
<h3 id="输入编码"><a href="#输入编码" class="headerlink" title="输入编码"></a>输入编码</h3><h4 id="Byte-Pair-Encoding-BPE"><a href="#Byte-Pair-Encoding-BPE" class="headerlink" title="Byte Pair Encoding(BPE)"></a>Byte Pair Encoding(BPE)</h4><p>具体实现过程：</p>
<ol>
<li><p>首先统计每个单词的出现的频率；</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404101804232.png" alt=""></p>
</li>
<li><p>将语料库当中的单词按照字母切分构成最初的词典；</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404101806486.png" alt=""></p>
</li>
<li><p>统计语料库中每个Byte gram（连续两个相邻位置拼到一起，如lo、ow）出现的数量，把出现频度最高的Byte gram（es）抽象成新的词加入词表；</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404101809525.png" alt=""></p>
</li>
<li><p>去除不再出现的单词（s）；</p>
</li>
<li><p>重复上述步骤</p>
</li>
</ol>
<h4 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404101817772.png" alt=""></p>
<h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><ul>
<li>2个子层：多头注意力机制和前馈神经网络（2层的MLP）</li>
<li>2个技巧：残差连接和Layer normalization</li>
</ul>
<h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><ul>
<li>Masked self-attention：使得第i个位置不参考第i+1个位置的信息</li>
<li>Encoder-decoder attention：k向量和v向量来自encoder最后一层的输出，q向量来自decoder（decoder的生成关注和整合encoder每个位置的信息）</li>
</ul>
<h3 id="Tricks"><a href="#Tricks" class="headerlink" title="Tricks"></a>Tricks</h3><ul>
<li>Checkpoint averaging</li>
<li>Adam optimizer</li>
<li>Dropout</li>
<li>Label smoothing</li>
<li>Auto-regressive decoding</li>
</ul>
<h2 id="预训练语言模型-PLMs"><a href="#预训练语言模型-PLMs" class="headerlink" title="预训练语言模型(PLMs)"></a>预训练语言模型(PLMs)</h2><h3 id="两种主流方式"><a href="#两种主流方式" class="headerlink" title="两种主流方式"></a>两种主流方式</h3><ul>
<li>Feature-based approaches：预训练语言模型的输出作为下游任务模型的输入</li>
<li>Fine-tuning approaches：预训练好的模型作为下游任务的模型</li>
</ul>
<h3 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h3><p>只使用Transformer的Decoder进行文本的生成</p>
<h3 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h3><p>基于Transformer的Encoder，关注的任务是Masked LM和Next Sentence Prediction</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404102043123.png" alt=""></p>
<h3 id="MoE"><a href="#MoE" class="headerlink" title="MoE"></a>MoE</h3><p>MoE 应用于大模型，GPT-4并不是第一个。在2022年的时候，Google就提出了MoE大模型Switch Transformer，模型大小是1571B，Switch Transformer在预训练任务上显示出比 T5-XXL（11B）模型更高的样本效率。在相同的训练时间和计算资源下，Switch Transformer 能够达到更好的性能。</p>
<ul>
<li>稀疏MoE层：这些层代替了传统 Transformer 模型中的前馈网络 (FFN) 层。MoE 层包含若干“专家”(例如 8 个)，每个专家本身是一个独立的神经网络。在实际应用中，这些专家通常是前馈网络 (FFN)，但它们也可以是更复杂的网络结构。</li>
<li>门控网络或路由：这个部分用于决定哪些 token 被发送到哪个专家。例如，在下图中，“More”这个 token 可能被发送到第二个专家，而“Parameters”这个 token 被发送到第一个专家。有时，一个 token 甚至可以被发送到多个专家。token 的路由方式是 MoE 使用中的一个关键点，因为路由器由学习的参数组成，并且与网络的其他部分一同进行预训练。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404102105511.png" alt=""></p>
<h3 id="Transformers工具"><a href="#Transformers工具" class="headerlink" title="Transformers工具"></a>Transformers工具</h3><h4 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h4><p>Transformers中的pipeline函数自动使用一个预训练好的模型来执行下游任务</p>
<h4 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h4><p>不同预训练语言模型有不同的tokenization方式，Transformers中AutoTokenizer.from_pretrained函数可以自动进行tokenization</p>
<h4 id="Pre-trained-Model"><a href="#Pre-trained-Model" class="headerlink" title="Pre-trained Model"></a>Pre-trained Model</h4><p>AutoModelForSequenceClassification.from_pretrained函数就调用了一个做序列分类的预训练模型，随后我们就可以在这个模型基础之上进行微调</p>
<h1 id="Advanced-Adaptation"><a href="#Advanced-Adaptation" class="headerlink" title="Advanced Adaptation"></a>Advanced Adaptation</h1><h2 id="Prompt-learning"><a href="#Prompt-learning" class="headerlink" title="Prompt-learning"></a>Prompt-learning</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111510028.png" alt=""></p>
<p>对于生成式模型而言，prompt需要mask的地方可能在句子最后</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111514918.png" alt=""></p>
<p>而对于理解类的任务，prompt需要mask的地方可能在句子中间</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111516250.png" alt=""></p>
<h3 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111521912.png" alt=""></p>
<h3 id="Verbalizer"><a href="#Verbalizer" class="headerlink" title="Verbalizer"></a>Verbalizer</h3><p>verbalizer的本质上是将回答映射到不固定的标签</p>
<ul>
<li>文本构建</li>
<li>虚拟token构建</li>
</ul>
<h2 id="Delta-Tuning"><a href="#Delta-Tuning" class="headerlink" title="Delta Tuning"></a>Delta Tuning</h2><p>模型本身不变，优化其中一小部分的参数，从而驱动大模型</p>
<ul>
<li>Addition-based：引入额外可训练的神经模块</li>
<li>Specification-based：指定模型中的某些参数是可训练的</li>
<li>Reparameterization-based：假设模型的微调可以在一个低维子空间或者通过一个低秩的矩阵完成</li>
</ul>
<h3 id="Addition-based"><a href="#Addition-based" class="headerlink" title="Addition-based"></a>Addition-based</h3><h4 id="Adapter-Tuning"><a href="#Adapter-Tuning" class="headerlink" title="Adapter-Tuning"></a>Adapter-Tuning</h4><p>主要是在原有的attention当中加入了Adapter，并且只训练这些Adapter</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111645534.png" alt=""></p>
<h4 id="Prefix-Tuning"><a href="#Prefix-Tuning" class="headerlink" title="Prefix-Tuning"></a>Prefix-Tuning</h4><p>在hidden state前面加入soft token，并且只训练这些soft token</p>
<h3 id="Specification-based"><a href="#Specification-based" class="headerlink" title="Specification-based"></a>Specification-based</h3><h4 id="BitFit"><a href="#BitFit" class="headerlink" title="BitFit"></a>BitFit</h4><p>只微调所有的bias项</p>
<h3 id="Reparameterization-based"><a href="#Reparameterization-based" class="headerlink" title="Reparameterization-based"></a>Reparameterization-based</h3><h4 id="Intrinstic-Prompt-Tuning"><a href="#Intrinstic-Prompt-Tuning" class="headerlink" title="Intrinstic Prompt Tuning"></a>Intrinstic Prompt Tuning</h4><p>模型的优化被映射到一个低维的子空间</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111650060.png" alt=""></p>
<h4 id="LoRA"><a href="#LoRA" class="headerlink" title="LoRA"></a>LoRA</h4><p>不认为模型的优化是低维的，而是低秩的，因此将模型参数进行一个低秩分解</p>
<h1 id="训练优化"><a href="#训练优化" class="headerlink" title="训练优化"></a>训练优化</h1><h2 id="Data-Parallel"><a href="#Data-Parallel" class="headerlink" title="Data Parallel"></a>Data Parallel</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111743187.png" alt=""></p>
<h2 id="Model-Parallel"><a href="#Model-Parallel" class="headerlink" title="Model Parallel"></a>Model Parallel</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111749954.png" alt=""></p>
<h2 id="ZeRO"><a href="#ZeRO" class="headerlink" title="ZeRO"></a>ZeRO</h2><ul>
<li><p>Stage 1：每张卡只计算部分梯度</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111752088.png" alt=""></p>
</li>
<li><p>Stage 2：反向传播的过程中及时移除gradient</p>
</li>
<li><p>Stage 3：每张卡只保留部分模型参数</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111758180.png" alt=""></p>
</li>
</ul>
<h2 id="Pipeline-Parallel"><a href="#Pipeline-Parallel" class="headerlink" title="Pipeline Parallel"></a>Pipeline Parallel</h2><p>模型的不同层分给不同的显卡</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111802035.png" alt=""></p>
<h2 id="Tricks-1"><a href="#Tricks-1" class="headerlink" title="Tricks"></a>Tricks</h2><ul>
<li>Mixed precision：混合精度训练</li>
<li>Offloading：把optimizer的参数传给CPU进行计算</li>
<li>Overlapping：提前获取参数</li>
<li>Checkpointing：设置检查点</li>
</ul>
<h1 id="模型压缩"><a href="#模型压缩" class="headerlink" title="模型压缩"></a>模型压缩</h1><h2 id="Knowledge-Distillation"><a href="#Knowledge-Distillation" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111825707.png" alt=""></p>
<p>让学生模型和教师模型层与层之间的hidden states尽可能接近</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111828103.png" alt=""></p>
<h2 id="Model-Pruning"><a href="#Model-Pruning" class="headerlink" title="Model Pruning"></a>Model Pruning</h2><ul>
<li>Weight pruning（unstructured）：随机丢弃参数</li>
<li>Attention head pruning（structured）：丢弃某个head</li>
<li>Layer pruning（structured）：丢弃神经网络的某一层</li>
</ul>
<h2 id="Model-Quantization"><a href="#Model-Quantization" class="headerlink" title="Model Quantization"></a>Model Quantization</h2><p>浮点计算位数多，将浮点的表示转换为定精度的表示，有一个系数，有一个int值，每次将系数和int值相乘还原成浮点型</p>
<h2 id="Weight-Sharing"><a href="#Weight-Sharing" class="headerlink" title="Weight Sharing"></a>Weight Sharing</h2><p>不同层用同样的参数计算</p>
<h2 id="Low-rank-Approximation"><a href="#Low-rank-Approximation" class="headerlink" title="Low-rank Approximation"></a>Low-rank Approximation</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111857863.png" alt=""></p>
<h2 id="Architecture-Search"><a href="#Architecture-Search" class="headerlink" title="Architecture Search"></a>Architecture Search</h2><p>找到最优的神经网络模型</p>
<h1 id="模型推理"><a href="#模型推理" class="headerlink" title="模型推理"></a>模型推理</h1><ul>
<li>高显存占有</li>
<li>高计算能力要求</li>
</ul>
<h1 id="大模型应用"><a href="#大模型应用" class="headerlink" title="大模型应用"></a>大模型应用</h1><h2 id="信息检索"><a href="#信息检索" class="headerlink" title="信息检索"></a>信息检索</h2><h3 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h3><ol>
<li>定义一个query</li>
<li>给定文档的集合</li>
<li>IR系统计算相关性分数并根据分数进行排序</li>
</ol>
<h3 id="性能评测"><a href="#性能评测" class="headerlink" title="性能评测"></a>性能评测</h3><ul>
<li><p>MRR：考虑每个查询排名最靠前的第一个相关文档的位置</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111939534.png" alt=""></p>
</li>
<li><p>MAP：一组查询的平均准确率均值</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111942704.png" alt=""></p>
</li>
<li><p>NDCG：归一化的折损累计增益</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404111944309.png" alt=""></p>
</li>
</ul>
<h2 id="机器问答"><a href="#机器问答" class="headerlink" title="机器问答"></a>机器问答</h2><h3 id="阅读理解"><a href="#阅读理解" class="headerlink" title="阅读理解"></a>阅读理解</h3><p>类型：Multiple choice、Cloze test、Extractive</p>
<h3 id="开放域QA"><a href="#开放域QA" class="headerlink" title="开放域QA"></a>开放域QA</h3><p>类型：Task Definition、Generation-based Methods、Retrieval-based Methods</p>
<h2 id="文本生成"><a href="#文本生成" class="headerlink" title="文本生成"></a>文本生成</h2><h3 id="文本生成任务"><a href="#文本生成任务" class="headerlink" title="文本生成任务"></a>文本生成任务</h3><ul>
<li>Data-to-Text：图片、表格等生成文本</li>
<li>Dialogue：根据用户输入生成一些满足需求的对话</li>
<li>Machine Translation</li>
<li>Poetry Generation</li>
<li>Style Transfer</li>
<li>Storytelling</li>
<li>Summarization</li>
</ul>
<h2 id="生物医学"><a href="#生物医学" class="headerlink" title="生物医学"></a>生物医学</h2><ul>
<li>domain corpus：Sci-BERT，BioBERT，clinical BERT</li>
<li>special pretraining task：MC-BERT，KeBioLM</li>
</ul>
<h2 id="法律智能"><a href="#法律智能" class="headerlink" title="法律智能"></a>法律智能</h2><ul>
<li>Legal Judgement Prediction</li>
<li>Similar Cases Retrieval</li>
<li>Legal Documents Generation</li>
<li>Legal Information Recommendation</li>
<li>Legal Documents Translation</li>
<li>Legal Question Answering</li>
<li>Court View Generation</li>
<li>Risk Warming</li>
<li>Legal Text Mining</li>
<li>Compliance Review</li>
</ul>
<h1 id="微调方式"><a href="#微调方式" class="headerlink" title="微调方式"></a>微调方式</h1><h2 id="Adapter-Tuning-1"><a href="#Adapter-Tuning-1" class="headerlink" title="Adapter Tuning"></a>Adapter Tuning</h2><p>2019年谷歌的研究人员首次在论文《Parameter-Efficient Transfer Learning for NLP》提出针对 BERT 的 PEFT微调方式，拉开了 PEFT 研究的序幕。他们指出，在面对特定的下游任务时，如果进行 Full-Fintuning（即预训练模型中的所有参数都进行微调），太过低效；而如果采用固定预训练模型的某些层，只微调接近下游任务的那几层参数，又难以达到较好的效果。</p>
<p>于是他们设计了Adapter 结构，将其嵌入 Transformer 的结构里面，在训练时，固定住原来预训练模型的参数不变，只对新增的 Adapter 结构进行微调。同时为了保证训练的高效性（也就是尽可能少的引入更多参数），他们将 Adapter 设计为这样的结构：</p>
<ul>
<li>首先是一个 down-project 层将高维度特征映射到低维特征</li>
<li>然后过一个非线形层之后，再用一个 up-project 结构将低维特征映射回原来的高维特征</li>
<li>同时也设计了 skip-connection 结构，确保了在最差的情况下能够退化为identity（类似残差结构）</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404211636816.png" alt=""></p>
<h2 id="Prefix-Tuning-1"><a href="#Prefix-Tuning-1" class="headerlink" title="Prefix Tuning"></a>Prefix Tuning</h2><p>2021年斯坦福的研究人员在论文《Prefix-Tuning: Optimizing Continuous Prompts for Generation》中提出了 Prefix Tuning 方法。与Full-finetuning 更新所有参数的方式不同，该方法是在输入 token 之前（所有层的Transformer的输出）构造一段任务相关的 virtual tokens 作为 Prefix，然后训练的时候只更新 Prefix 部分的参数，而 Transformer 中的其他部分参数固定。该方法其实和构造 Prompt 类似，只是 Prompt 是人为构造的“显式”的提示，并且无法更新参数，而Prefix 则是可以学习的“隐式”的提示。</p>
<p>同时，为了防止直接更新 Prefix 的参数导致训练不稳定的情况，他们在 Prefix 层前面加了 MLP 结构(相当于将Prefix 分解为更小维度的 Input 与 MLP 的组合后输出的结果)，训练完成后，只保留 Prefix 的参数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404211641993.png" alt=""></p>
<h2 id="Prompt-Tuning"><a href="#Prompt-Tuning" class="headerlink" title="Prompt Tuning"></a>Prompt Tuning</h2><p>Prompt Tuning 是2021年谷歌在论文《The Power of Scale for Parameter-Efficient Prompt Tuning》中提出的微调方法。</p>
<p>该方法可以看作是 Prefix Tuning 的简化版本，<strong>只在输入层加入 prompt tokens</strong>，并不需要加入 MLP 进行调整来解决难训练的问题，主要在 T5 预训练模型上做实验。似乎只要预训练模型足够强大，其他的一切都不是问题。作者也做实验说明随着预训练模型参数量的增加，Prompt Tuning的方法会逼近 Fine-tune 的结果。</p>
<p>固定预训练参数，为每一个任务额外添加一个或多个 embedding，之后拼接 query 正常输入 LLM，并只训练这些 embedding。左图为单任务全参数微调，右图为 Prompt tuning。<br><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404211645462.png" alt=""></p>
<h2 id="P-Tuning"><a href="#P-Tuning" class="headerlink" title="P-Tuning"></a>P-Tuning</h2><p>P-Tuning 方法的提出主要是为了解决这样一个问题：大模型的 Prompt 构造方式严重影响下游任务的效果。</p>
<p>P-Tuning 提出将 Prompt 转换为可以学习的 Embedding 层，只是考虑到直接对 Embedding 参数进行优化会存在这样两个挑战：</p>
<ul>
<li>Discretenes： 对输入正常语料的 Embedding 层已经经过预训练，而如果直接对输入的 prompt embedding进行随机初始化训练，容易陷入局部最优。</li>
<li>Association：没法捕捉到 prompt embedding 之间的相关关系。</li>
</ul>
<p>P-Tuning 和 Prefix-Tuning 差不多同时提出，做法其实也有一些相似之处，主要区别在：</p>
<ul>
<li>Prefix Tuning 是将额外的 embedding 加在开头，看起来更像是模仿 Instruction 指令；而 P-Tuning 的位置则不固定。</li>
<li>Prefix Tuning 通过在每个 Attention 层都加入 Prefix Embedding 来增加额外的参数，通过 MLP 来初始化；而 P-Tuning 只是在输入的时候加入 Embedding，并通过 LSTM+MLP 来初始化。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404211650387.png" alt=""></p>
<h2 id="P-Tuning-v2"><a href="#P-Tuning-v2" class="headerlink" title="P-Tuning v2"></a>P-Tuning v2</h2><p>P-Tuning 的问题是在小参数量模型上表现差。于是就有了v2版本：《P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks》。</p>
<p>从标题就可以看出，P-Tuning v2 的目标就是要让 Prompt Tuning 能够在不同参数规模的预训练模型、针对不同下游任务的结果上都达到匹敌 Fine-tuning 的结果。</p>
<p>那也就是说当前 Prompt Tuning 方法在这两个方面都存在局限性。</p>
<ul>
<li>不同模型规模：Prompt Tuning 和 P-tuning 这两种方法都是在预训练模型参数规模够足够大时，才能达到和Fine-tuning 类似的效果，而参数规模较小时效果则很差。</li>
<li>不同任务类型：Prompt Tuning 和 P-tuning 这两种方法在 sequence tagging 任务上表现都很差。</li>
</ul>
<p>相比 Prompt Tuning 和 P-tuning 的方法， P-tuning v2 方法在多层加入了 Prompts tokens 作为输入，带来两个方面的好处：</p>
<ul>
<li>带来更多可学习的参数（从 P-tuning 和 Prompt Tuning 的0.1%增加到0.1%-3%），同时也足够 parameter-efficient。</li>
<li>加入到更深层结构中的 Prompt 能给模型预测带来更直接的影响。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404211651675.png" alt=""></p>
<h2 id="LoRA-1"><a href="#LoRA-1" class="headerlink" title="LoRA"></a>LoRA</h2><p>LoRA，英文全称Low-RankAdaptation of Large Language Models，直译为大语言模型的低阶适应，是一种PEFT（Parameter-Efficient Tuning，简称PEFT），这是微软的研究人员为了解决大语言模型微调而开发的一项技术。</p>
<p>LoRA的基本原理是冻结预训练好的模型权重参数，在冻结原模型参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。由于这些新增参数数量较少，这样不仅 finetune 的成本显著下降，还能获得和全模型微调类似的效果。<br><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404211653204.png" alt=""></p>
<h2 id="QLoRA"><a href="#QLoRA" class="headerlink" title="QLoRA"></a>QLoRA</h2><p>QLoRA 是由 Tim Dettmers 等人提出的量化 LoRA 的缩写。QLoRA 是一种在微调过程中进一步减少内存占用的技术。在反向传播过程中，QLoRA 将预训练的权重量化为 4-bit，并使用分页优化器来处理内存峰值。</p>
<p>使用LoRA时可以节省33%的GPU内存。然而，由于QLoRA中预训练模型权重的额外量化和去量化，训练时间增加了39%。</p>
<p>首先分析下LoRA微调中的痛点：</p>
<ul>
<li>参数空间小：LoRA中参与训练的参数量较少，解空间较小，效果相比全量微调有一定的差距。</li>
<li>微调大模型成本高：对于上百亿参数量的模型，LoRA微调的成本还是很高。</li>
<li>精度损失：针对第二点，可以采用int8或int4量化，进一步对模型基座的参数进行压缩。但是又会引发精度损失的问题，降低模型性能。</li>
</ul>
<p>QLoRA优点：</p>
<ul>
<li>4-bit NormalFloat：提出一种理论最优的4-bit的量化数据类型，优于当前普遍使用的FP4与Int4。对于正态分布权重而言，一种信息理论上最优的新数据类型，该数据类型对正态分布数据产生比 4 bit整数和 4bit 浮点数更好的实证结果。QLORA包含一种低精度存储数据类型（通常为4-bit）和一种计算数据类型（通常为BFloat16）。在实践中，QLORA权重张量使用时，需要将将张量去量化为BFloat16，然后在16位计算精度下进行矩阵乘法运算。模型本身用4bit加载，训练时把数值反量化到bf16后进行训练。</li>
<li>Double Quantization：对第一次量化后的那些常量再进行一次量化，减少存储空间。相比于当前的模型量化方法，更加节省显存空间。每个参数平均节省0.37bit，对于65B的LLaMA模型，大约能节省3GB显存空间。</li>
<li>Paged Optimizers：使用NVIDIA统一内存特性，该特性可以在在GPU偶尔OOM的情况下，进行CPU和GPU之间自动分页到分页的传输，以实现无错误的 GPU 处理。该功能的工作方式类似于 CPU 内存和磁盘之间的常规内存分页。使用此功能为优化器状态（Optimizer）分配分页内存，然后在 GPU 内存不足时将其自动卸载到 CPU 内存，并在优化器更新步骤需要时将其加载回 GPU 内存。</li>
<li>增加Adapter：4-bit的NormalFloat与Double Quantization，节省了很多空间，但带来了性能损失，作者通过插入更多adapter来弥补这种性能损失。在LoRA中，一般会选择在query和value的全连接层处插入adapter。而QLoRA则在所有全连接层处都插入了adapter，增加了训练参数，弥补精度带来的性能损失。</li>
</ul>
<h2 id="LoRA-MoE"><a href="#LoRA-MoE" class="headerlink" title="LoRA+MoE"></a>LoRA+MoE</h2><p>由于大模型全量微调时的显存占用过大，LoRA、Adapter、IA 3 这些参数高效微调方法便成为了资源有限的机构和研究者微调大模型的标配。PEFT方法的总体思路是冻结住大模型的主干参数，引入一小部分可训练的参数作为适配模块进行训练，以节省模型微调时的显存和参数存储开销。</p>
<p>传统上，LoRA这类适配模块的参数和主干参数一样是稠密的，每个样本上的推理过程都需要用到所有的参数。近来，大模型研究者们为了克服稠密模型的参数效率瓶颈，开始关注以Mistral、DeepSeek MoE为代表的混合专家（Mixure of Experts，简称MoE）模型框架。在该框架下，模型的某个模块（如Transformer的某个FFN层）会存在多组形状相同的权重（称为专家），另外有一个路由模块（Router）接受原始输入、输出各专家的激活权重。<br><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404211655500.png" alt=""></p>
<h3 id="MOE"><a href="#MOE" class="headerlink" title="MOE"></a>MOE</h3><h4 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h4><p>MoE全称是“混合专家”，它由多个专家网络和一个门控网络组成。整个MoE完全复用了Transformer的结构，只是将其中的FFN层替换成了MoE层。MoE层里的门控网络其实就是个专家分类器，每次根据输入Token生成专家的概率分布，然后选择排序靠前的K个专家进行Token处理，最后再将K个专家的结果加权汇总输出给下一层网络。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502171548920.png" alt=""></p>
<p>其中，$E_{i}(x)$是输入Token经过第i个专家处理输出的结果；$G_{i}(x)$是第i个专家的输出权重（0~1之间）。</p>
<p>例如，当前MoE模型有4个专家，针对输入“More”，输出的概率可能为0.1、0.65、0.15、0.1，这意味着第一个专家对处理此数据的贡献为10%，第二个专家为65%，第三个专家为15%，第四个专家为10%，如果此时的K设置为1，就可以认为专家2模型的建议会更好，直接选择专家2处理输入Token “More”。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502171552916.png" alt=""></p>
<h4 id="主流架构"><a href="#主流架构" class="headerlink" title="主流架构"></a>主流架构</h4><p>目前主流的MoE架构分为两种，一种是全替换，就是将所有Transformer模块的FFN层替换成MoE层，虽说简单粗暴效果好，但是模型参数量可能会急剧膨胀。像Google在2022年发布的Switch-Transformer，就是在T5模型的基础上加入了MoE设计，将Transformer Encoder或Decoder的FFN模块替换成MoE，总的参数量有1.6万亿。虽说拥有2048个专家，但每次推理仅激活1个。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502171610773.png" alt=""></p>
<p>还有一类就是折中的仅替换部分，比如谷歌之前发布的GShard和Glam，只替换了一半，将Transformer的Encoder和Decoder中每隔一个的FFN层，替换成MoE层，使用的都是Top-2 gating network。在成本和性能之间找到一个平衡。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502171610074.png" alt=""></p>
<p>剩下就是一些专家设计上的优化，比如元象之前推出的XVERSE-MoE-A4.2B模型，将专家分为共享专家（Shared Expert）和非共享专家（Non-shared Expert）两类。共享专家在计算过程中始终保持激活状态，而非共享专家则根据需要选择性激活，这种设计有利于将通用知识压缩至共享专家参数中，减少非共享专家参数间的知识冗余。</p>
<p>还有就是腾讯混元团队2024年提出了混合异构专家模型（HMoE），MoE层中的每个专家的大小不再相同，从而赋予了每个专家不同的表达能力，这种差异化设计使得路由可以根据专家的实际能力动态分配不同难度的token，有效解决了专家专业化程度不足的问题。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502171611934.png" alt=""></p>
<h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><p>KeepTopK：一种负载均衡路由器的方法是通过一个简单的扩展，称为 KeepTopK。通过引入可训练的高斯噪声，有助于打破对特定专家的偏好，使选择更加随机化，这样我们可以防止总是选择相同的专家。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502172320465.png" alt=""></p>
<p>Token Choice：KeepTopK 策略将每个词路由到几个选定的专家。这种方法称为 Token Choice，允许给定的词被发送到一个专家（top-1 路由）或多个专家（top-k 路由）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502172321701.png" alt=""></p>
<p>辅助损失：一个主要的好处是，它允许对各个专家的贡献进行加权和整合。为了在训练过程中实现专家的更均匀分布，辅助损失（也称为负载均衡损失）被添加到了网络的常规损失中。它增加了一个约束，迫使专家具有相等的重要性。 这个辅助损失的第一个组成部分是在整个批次中对每个专家的路由器值进行求和。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502172323096.png" alt=""></p>
<p>deepseek v3 的负载均衡策略：首先是Auxiliary-Loss-Free Load Balancing（辅助无损负载均衡），另一种负载均衡方式则是添加了Complementary Sequence-Wise Auxiliary Loss（互补序列辅助损失）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502172325090.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502172325251.png" alt=""></p>
<h1 id="DeepSeek-V3"><a href="#DeepSeek-V3" class="headerlink" title="DeepSeek-V3"></a>DeepSeek-V3</h1><ul>
<li>Multi-head Latent Attention (MLA)</li>
<li>DeepSeekMoE architectures,  additionally introduce an auxiliary-loss-free load balancing strategy.<ul>
<li>Auxiliary-Loss-Free Load Balancing</li>
<li>Complementary Sequence-Wise Auxiliary Loss</li>
<li>Node-Limited Routing</li>
<li>No Token-Dropping</li>
</ul>
</li>
<li>Multi-Token Prediction</li>
</ul>
<h1 id="DeepSeek-R1-Zero"><a href="#DeepSeek-R1-Zero" class="headerlink" title="DeepSeek-R1-Zero"></a>DeepSeek-R1-Zero</h1><ul>
<li>Group Relative Policy Optimization</li>
<li>Reward Modeling<ul>
<li>Accuracy rewards</li>
<li>Format rewards</li>
</ul>
</li>
</ul>
<h1 id="DeepSeek-R1"><a href="#DeepSeek-R1" class="headerlink" title="DeepSeek-R1"></a>DeepSeek-R1</h1><ul>
<li>Cold Start</li>
<li>Reasoning-oriented Reinforcement Learning</li>
<li>Rejection Sampling and Supervised Fine-Tuning</li>
<li>Distillation: Smaller Models Can Be Powerful Too</li>
</ul>
<h1 id="RLHF-PPO"><a href="#RLHF-PPO" class="headerlink" title="RLHF-PPO"></a>RLHF-PPO</h1><p>RLHF的概念比较复杂，简单来说它将一个LLM的训练分成以下三个阶段：</p>
<ul>
<li>预训练一个语言模型 (LM) ；</li>
<li>聚合问答数据并训练一个奖励模型 (Reward Model，RM) ；</li>
<li>用强化学习方式（我们这里使用PPO）微调 LM。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502190026552.png" alt=""></p>
<h2 id="奖励模型的训练"><a href="#奖励模型的训练" class="headerlink" title="奖励模型的训练"></a>奖励模型的训练</h2><p>我们首先需要构建人类偏好数据集，这个数据集的构建非常关键，我们对模型的要求全部蕴含在这一个数据里了，之后的PPO训练不再需要任何标注，完全是LLM自由探索环境（根据prompt自主采样response并交给RM打分）完成强化学习。</p>
<p>每条样本包含一个chosen回复和一个reject回复，RM的网络结构实际上就是普通的语言模型在最后增加了一个value head输出每个位置的分数（一个句子的分数=last token的分数）。它的训练目标是尽可能增大chosen回复和reject回复的分数差。</p>
<h2 id="Reference-model的作用"><a href="#Reference-model的作用" class="headerlink" title="Reference model的作用"></a>Reference model的作用</h2><p>我们已经知道训练好的奖励模型可以对LLM输出的回复进行打分，但是RM的训练机制决定了其打分是对一个完整的response的打分，那我们怎么获得每一个动作（输出一个token）的即时奖励呢，这里就引出了Reference model的作用了。</p>
<p>Reference model和Actor的初始权重 $\pi_{ref}$ 和 $\pi_{old}$ 一致，都来自LLM预训练之后，但在之后的整个过程中，Reference model不再继续训练，它的作用是在RLHF阶段给语言模型增加一些“约束”，防止语言模型偏离原模型太远，为了满足人类偏好而丧失太多基础能力。我们用KL散度衡量训练后的模型与原模型的距离：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502190028316.png" alt=""></p>
<p>具体来说，我们是这么计算整个轨迹（整个response）的即时奖励的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502190029363.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502190029896.png" alt=""></p>
<h2 id="更为详细的流程"><a href="#更为详细的流程" class="headerlink" title="更为详细的流程"></a>更为详细的流程</h2><p>RLHF-PPO过程：</p>
<ol>
<li>prompt输入给Actor模型，会得到动作$A_t$ 。同时，也将prompt输入给Reference模型，得到参考的$A_t$  。</li>
<li>将得到的动作 $A_t$  输入给 Critic模型和 Reward模型分别得到 $V_t$  和 $R_t$ 。</li>
<li>将Actor模型的 $A_t$ 和Peference模型的 $A_t$ 进行比较，得到一个KL散度分数。</li>
<li>结合 $R_t$ 、$V_t$ 和KL散度分数，对Actor模型和Critic模型进行联合优化更新Loss。</li>
<li>更新 Actor模型和 Critic模型。</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502190033893.png" alt=""></p>
<h1 id="GRPO"><a href="#GRPO" class="headerlink" title="GRPO"></a>GRPO</h1><p>Group Relative Policy Optimization (GRPO)避免了像 PPO 那样使用额外的价值函数近似，而是使用同一问题下多个采样输出的平均奖励作为基线。算法全流程如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502190035659.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502190035879.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502190036520.png" alt=""></p>
]]></content>
      <categories>
        <category>大语言模型</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>大语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建个人博客</title>
    <url>/2021/03/31/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>新手上路，多多指教</p>
<a id="more"></a>
<h1 id="搭建个人博客"><a href="#搭建个人博客" class="headerlink" title="搭建个人博客"></a>搭建个人博客</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ol>
<li><p>安装<code>Git</code></p>
</li>
<li><p>安装<code>Nodejs</code></p>
<p>安装完成后查看<code>node</code>版本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure>
<p>查看<code>npm</code>包管理器版本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm -v</span><br></pre></td></tr></table></figure>
<p>国内安装镜像源很慢，所以可以利用<code>npm</code>安装<code>cnpm</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Hexo框架搭建博客"><a href="#Hexo框架搭建博客" class="headerlink" title="Hexo框架搭建博客"></a>Hexo框架搭建博客</h2><ol>
<li><p>安装<code>hexo</code>框架</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cnpm install -g hexo-cli</span><br></pre></td></tr></table></figure></li>
<li><p>查看是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo -v</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_1.png" alt="pic_1"></p>
</li>
<li><p><code>Hexo</code>框架初始化：选择存放博客所有内容的文件夹，命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_2.png" alt="pic_2"></p>
</li>
<li><p>本地启动博客</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure></li>
<li><p>浏览器访问<a href="http://localhost:4000">http://localhost:4000</a> ，可以看到搭建成功</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_4.png" alt="pic_4"></p>
</li>
</ol>
<h2 id="博客进阶"><a href="#博客进阶" class="headerlink" title="博客进阶"></a>博客进阶</h2><h3 id="新建文章"><a href="#新建文章" class="headerlink" title="新建文章"></a>新建文章</h3><ol>
<li><p>命令行输入：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo new &quot;我的第一篇文章&quot;</span><br></pre></td></tr></table></figure></li>
<li><p>查看是否新建文章成功</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_5.png" alt="pic_5"></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_6.png" alt="pic_6"></p>
</li>
<li><p>接着输入以下命令，浏览器访问<a href="http://localhost:4000">http://localhost:4000</a> ，可以看到新建的文章已经上传</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo cl</span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>
<p><strong>注：如果\source\_posts文件夹下没有任何文章，则访问会报错</strong></p>
</li>
</ol>
<h3 id="博客部署到GitHub"><a href="#博客部署到GitHub" class="headerlink" title="博客部署到GitHub"></a>博客部署到GitHub</h3><ol>
<li><p>新建<code>GitHub</code>仓库</p>
<p>注：一定要以<code>username.github.io</code>创建。假如我没有用<code>tankmanbeta.github.io</code>而是用了<code>jeeby.github.io</code>，那么当我浏览器访问博客的时候会出现404错误。这里并不是没有部署成功，而是把它部署在了这里:<code>http://tankmanbeta.github.io/jeeby.github.io</code>。所以，如果想直接<code>tankmanbeta.github.io</code>访问，那么就需要和用户名保持一致。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_7.png" alt="pic_7"></p>
</li>
<li><p>修改本地<code>Hexo</code>目录下文件<code>_config.yml</code>，在最后添加如下代码</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">    <span class="attr">repository:</span> <span class="string">https://github.com/TankManBeta/tankmanbeta.github.io</span></span><br><span class="line">    <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure>
<p>注：2020年10月1日起，<code>GitHub</code>把<code>master</code>分支换成<code>main</code>分支，据说与种族歧视有关。</p>
</li>
<li><p>安装<code>Git</code>部署的插件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cnpm install --save hexo-deployer-git</span><br></pre></td></tr></table></figure></li>
<li><p>输入以下命令，完成博客在<code>GitHub</code>上的部署</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo cl</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></li>
<li><p>浏览器访问<code>tankmanbeta.github.io</code>，成功访问</p>
<p><strong>注：每次部署都需要输入<code>GitHub</code>账号密码的解决方法：修改本地<code>Hexo</code>目录下文件<code>_config.yml</code>的<code>deploy</code>属性：（需要先设置<code>SSH-key</code>）</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:TankManBeta/tankmanbeta.github.io</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="博客主题更改"><a href="#博客主题更改" class="headerlink" title="博客主题更改"></a>博客主题更改</h3><ol>
<li><p>主题选取地址：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a></p>
</li>
<li><p>在博客根目录下的<code>themes</code>文件夹下克隆主题：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/next-theme/hexo-theme-next</span><br></pre></td></tr></table></figure></li>
<li><p>打开本地<code>Hexo</code>目录下文件<code>_config.yml</code>，修改<code>theme</code>属性：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">hexo-theme-next</span></span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_8.png" alt="pic_8"></p>
</li>
<li><p>输入以下命令，更新博客在<code>GitHub</code>上的部署</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g -d</span><br></pre></td></tr></table></figure></li>
<li><p>浏览器访问<code>tankmanbeta.github.io</code>，可以看到主题更新成功</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_9.png" alt="pic_9"></p>
</li>
</ol>
<h3 id="Next主题切换"><a href="#Next主题切换" class="headerlink" title="Next主题切换"></a>Next主题切换</h3><ol>
<li>打开<code>next</code>主题下的<code>_config.yml</code>文件，修改<code>theme</code>属性，将其选择成自己想要的</li>
<li>重新部署，步骤同上</li>
</ol>
<h3 id="中英文切换"><a href="#中英文切换" class="headerlink" title="中英文切换"></a>中英文切换</h3><ol>
<li>打开博客根目录下的<code>_config.yml</code>文件，修改<code>Site</code>属性下的<code>language</code>，将其改成<code>zh-CN</code>即可</li>
<li>重新部署，步骤同上</li>
<li>同理可以更改<code>title</code>、<code>author</code>等</li>
</ol>
<h3 id="添加标签页面"><a href="#添加标签页面" class="headerlink" title="添加标签页面"></a>添加标签页面</h3><ol>
<li><p>在博客根目录下打开<code>cmd</code>，使用<code>hexo new page tags</code>新建一个页面</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_10.png" alt="pic_10"></p>
</li>
<li><p>打开新建的页面，将页面的类型设置为<code>tags</code></p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">title: tags</span></span><br><span class="line"><span class="section">date: 2021-03-31 11:20:38</span></span><br><span class="line"><span class="section">type: &quot;tags&quot;</span></span><br></pre></td></tr></table></figure></li>
<li><p>修改Next主题下的<code>_config.yml</code>，将<code>tags</code>添加到<code>menu</code>属性当中</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="attr">home:</span> <span class="string">/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-home</span></span><br><span class="line">  <span class="comment">#about: /about/ || fa fa-user</span></span><br><span class="line">  <span class="attr">tags:</span> <span class="string">/tags/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-tags</span></span><br><span class="line">  <span class="attr">categories:</span> <span class="string">/categories/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-th</span></span><br><span class="line">  <span class="attr">archives:</span> <span class="string">/archives/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-archive</span></span><br><span class="line">  <span class="comment">#schedule: /schedule/ || fa fa-calendar</span></span><br><span class="line">  <span class="comment">#sitemap: /sitemap.xml || fa fa-sitemap</span></span><br><span class="line">  <span class="comment">#commonweal: /404/ || fa fa-heartbeat</span></span><br></pre></td></tr></table></figure></li>
<li><p>重新部署，步骤同上，刷新页面后的结果</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_11.png" alt="pic_11"></p>
</li>
<li><p><code>home</code>、<code>categories</code>、<code>archives</code>等操作也是相同的</p>
</li>
</ol>
<h3 id="添加搜索功能"><a href="#添加搜索功能" class="headerlink" title="添加搜索功能"></a>添加搜索功能</h3><ol>
<li><p>打开博客根目录，添加博客搜索插件，在<code>cmd</code>中输入以下命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cnpm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>
<p>安装成功：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_12.png" alt="pic_12"></p>
</li>
<li><p>打开博客根目录下的<code>_config.yml</code>，在任意位置添加以下配置（有教程说新版的<code>hexo</code>中，<code>search.xml</code>需要改成<code>search.json</code>，否则部署到服务器搜索图标不能正常显示）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Search Config</span></span><br><span class="line"><span class="attr">search:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">search.xml</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">post</span></span><br><span class="line">  <span class="attr">format:</span> <span class="string">html</span></span><br><span class="line">  <span class="attr">limit:</span> <span class="number">1000</span></span><br></pre></td></tr></table></figure></li>
<li><p>修改Next主题下的<code>_config.yml</code>，修改<code>local_search</code>属性下的<code>enable</code>，将其改为<code>true</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Local Search</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/next-theme/hexo-generator-searchdb</span></span><br><span class="line"><span class="attr">local_search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># If auto, trigger search by changing input.</span></span><br><span class="line">  <span class="comment"># If manual, trigger search by pressing enter key or search button.</span></span><br><span class="line">  <span class="attr">trigger:</span> <span class="string">auto</span></span><br><span class="line">  <span class="comment"># Show top n results per article, show all results by setting to -1</span></span><br><span class="line">  <span class="attr">top_n_per_article:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment"># Unescape html strings to the readable one.</span></span><br><span class="line">  <span class="attr">unescape:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Preload the search data when the page loads.</span></span><br><span class="line">  <span class="attr">preload:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></li>
<li>重新部署，步骤同上</li>
</ol>
<h3 id="使用外链图片"><a href="#使用外链图片" class="headerlink" title="使用外链图片"></a>使用外链图片</h3><ol>
<li><p>注册腾讯云账号，选择对象存储</p>
</li>
<li><p>创建存储桶</p>
</li>
<li><p>创建成功之后上传文件</p>
</li>
<li><p>修改安全管理中的防盗链设置</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_13.png" alt="pic_13"></p>
</li>
<li><p>修改权限管理中的存储桶访问权限</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_14.png" alt="pic_14"></p>
</li>
<li><p>上传图片至存储桶，复制详情中的对象地址</p>
</li>
<li><p>在文章中使用外链</p>
</li>
<li><p>重新部署，步骤同上</p>
</li>
</ol>
<h3 id="增加统计信息"><a href="#增加统计信息" class="headerlink" title="增加统计信息"></a>增加统计信息</h3><ol>
<li><p>打开博客根目录，添加博客搜索插件，在<code>cmd</code>中输入以下命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cnpm install hexo-symbols-count-time --save</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>打开博客根目录下的<code>_config.yml</code>，在任意位置添加以下配置</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">symbols:</span> <span class="literal">true</span> <span class="comment"># 文章字数</span></span><br><span class="line">  <span class="attr">time:</span> <span class="literal">true</span> <span class="comment"># 阅读时长</span></span><br><span class="line">  <span class="attr">total_symbols:</span> <span class="literal">false</span> <span class="comment"># 所有文章总字数</span></span><br><span class="line">  <span class="attr">total_time:</span> <span class="literal">false</span> <span class="comment"># 所有文章阅读中时长</span></span><br><span class="line">  <span class="attr">awl:</span> <span class="number">4</span></span><br><span class="line">  <span class="attr">wpm:</span> <span class="number">275</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>修改Next主题下的<code>_config.yml</code>，修改如下配置</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">separated_meta:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">item_text_total:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">item_text_post:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li>
<li>重新部署，步骤同上</li>
</ol>
<h3 id="使用PicGo上传图片至图床"><a href="#使用PicGo上传图片至图床" class="headerlink" title="使用PicGo上传图片至图床"></a>使用PicGo上传图片至图床</h3><ol>
<li><p>下载PicGo，下载地址<a href="https://github.com/Molunerfinn/PicGo/releases">https://github.com/Molunerfinn/PicGo/releases </a> </p>
</li>
<li><p>腾讯云新建密钥：[访问密钥]—&gt;[API密钥管理]—&gt;[新建密钥]</p>
</li>
<li><p>打开安装完成后的PicGo，进行图床设置，设置后的结果为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_15.png" alt="pic_15"></p>
</li>
<li><p>点击确定并设置为默认图床，拖动本地图片上传，即可成功</p>
</li>
<li>文章中可以直接使用刚刚产生的外链</li>
<li>重新部署，步骤同上</li>
</ol>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习</title>
    <url>/2023/10/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>开新坑啦，强化学习搞起。</p>
<a id="more"></a>
<h1 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h1><h2 id="强化学习概述"><a href="#强化学习概述" class="headerlink" title="强化学习概述"></a>强化学习概述</h2><p>强化学习<code>(Reinforcement Learning, RL)</code>是机器学习的一种重要方法，它通过智能体<code>(agent)</code>与环境<code>(environment)</code>的交互来实现自主学习和决策。在强化学习中，智能体会采取一系列的行动，环境会根据智能体的行动给出奖励或惩罚，智能体的目标是最大化累积奖励。强化学习在许多实际应用中都有着广泛的应用，例如自动驾驶、机器人控制、金融交易、游戏等。<strong>智能体的目的就是尽可能多地从环境中获取奖励。</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202310081106986.png" alt=""></p>
<h3 id="强化学习与监督学习"><a href="#强化学习与监督学习" class="headerlink" title="强化学习与监督学习"></a>强化学习与监督学习</h3><p>监督学习：</p>
<ul>
<li>输入的数据应该是没有关联的（独立同分布）</li>
<li>我们告诉学习器正确的标签是什么</li>
</ul>
<p>强化学习：</p>
<ul>
<li>观测<code>(observation)</code>不是独立同分布的</li>
<li>并没有立刻获得反馈</li>
</ul>
<h3 id="强化学习的特征"><a href="#强化学习的特征" class="headerlink" title="强化学习的特征"></a>强化学习的特征</h3><ul>
<li>强化学习会试错探索，它通过探索环境来获取对环境的理解。</li>
<li>强化学习智能体会从环境里面获得延迟的奖励。</li>
<li>在强化学习的训练过程中，时间非常重要。</li>
<li>智能体的动作会影响它随后得到的数据。</li>
</ul>
<h2 id="序列决策"><a href="#序列决策" class="headerlink" title="序列决策"></a>序列决策</h2><h3 id="智能体和环境"><a href="#智能体和环境" class="headerlink" title="智能体和环境"></a>智能体和环境</h3><p>强化学习研究的问题是智能体与环境交互的问题。智能体把它的动作输出给环境，环境取得这个动作后会进行下一步，把下一步的观测与这个动作带来的奖励返还给智能体。这样的交互会产生很多观测，智能体的目的是从这些观测之中学到能最大化奖励的策略。</p>
<h3 id="奖励"><a href="#奖励" class="headerlink" title="奖励"></a>奖励</h3><p>奖励是由环境给的一种标量的反馈信号<code>(scalar feedback signal)</code>，这种信号可显示智能体在某一步采取某个策略的表现如何。强化学习的目的就是最大化智能体可以获得的奖励，智能体在环境里面存在的目的就是最大化它的期望的累积奖励<code>(expected cumulative reward)</code>。</p>
<h3 id="序列决策-1"><a href="#序列决策-1" class="headerlink" title="序列决策"></a>序列决策</h3><p>在一个强化学习环境里面，智能体的目的就是选取一系列的动作来最大化奖励，所以这些选取的动作必须有长期的影响。但在这个过程里面，智能体的奖励其实是被延迟了的，就是我们现在选取的某一步动作，可能要等到很久后才知道这一步到底产生了什么样的影响。</p>
<p><strong>状态</strong>是对世界的完整描述，不会隐藏世界的信息。 <strong>观测</strong>是对状态的部分描述，可能会遗漏一些信息。</p>
<p>当智能体的状态与环境的状态等价的时候，即当智能体能够观察到环境的所有状态时，我们称这个环境是<strong>完全可观测的<code>(fully observed)</code></strong>。在这种情况下面，强化学习通常被建模成一个<strong>马尔可夫决策过程<code>(Markov decision process, MDP)</code></strong>的问题。</p>
<p>当智能体只能看到部分的观测，我们就称这个环境是<strong>部分可观测的<code>(partially observed)</code></strong>。在这种情况下，强化学习通常被建模成<strong>部分可观测马尔可夫决策过程<code>(partially observable Markov decision process, POMDP)</code></strong>的问题。</p>
<h2 id="动作空间"><a href="#动作空间" class="headerlink" title="动作空间"></a>动作空间</h2><p>在给定的环境中，有效动作的集合经常被称为<strong>动作空间<code>(action space)</code></strong>。像雅达利游戏和围棋这样的环境有<strong>离散动作空间<code>(discrete action space)</code></strong>，在这个动作空间里，智能体的动作数量是有限的。在其他环境，比如在物理世界中控制一个智能体，在这个环境中就有<strong>连续动作空间<code>(continuous action space)</code></strong>。在连续动作空间中，动作是实值的向量。</p>
<h2 id="强化学习智能体的组成成分和类型"><a href="#强化学习智能体的组成成分和类型" class="headerlink" title="强化学习智能体的组成成分和类型"></a>强化学习智能体的组成成分和类型</h2><ul>
<li>策略<code>(policy)</code>：智能体会用策略来选取下一步的动作。</li>
<li>价值函数<code>(value function)</code>：我们用价值函数来对当前状态进行评估。价值函数用于评估智能体进入某个状态后，可以对后面的奖励带来多大的影响。价值函数值越大，说明智能体进入这个状态越有利。</li>
<li>模型<code>(model)</code>：模型表示智能体对环境的状态进行理解，它决定了环境中世界的运行方式。</li>
</ul>
<h3 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h3><p>策略是智能体的动作模型，它决定了智能体的动作。它其实是一个函数，用于把输入的状态变成动作。策略可分为两种：随机性策略和确定性策略。<br><strong>随机性策略<code>(stochastic policy)</code></strong>就是 $\pi$ 函数，即 $\pi(a|s) = p (a_{t} = a|s_{t} = s)$ 。输入一个状态 $s$ ，输出一个概率。这个概率是智能体所有动作的概率，然后对这个概率分布进行采样，可得到智能体将采取的动作。比如可能是有 $0.7$ 的概率往左， $0.3$ 的概率往右，那么通过采样就可以得到智能体将采取的动作。<br><strong>确定性策略<code>(deterministic policy)</code></strong>就是智能体直接采取最有可能的动作，即 $a^{\ast} = \mathop{\mathrm{argmax}}\limits_{a}{\pi(a | s)}$ 。  </p>
<p>通常情况下，强化学习一般使用随机性策略，随机性策略有很多优点。</p>
<ul>
<li>在学习时可以通过引入一定的随机性来更好地探索环境；</li>
<li>随机性策略的动作具有多样性，这一点在多个智能体博弈时非常重要；</li>
<li>采用确定性策略的智能体总是对同样的状态采取相同的动作，这会导致它的策略很容易被对手预测。</li>
</ul>
<h3 id="价值函数"><a href="#价值函数" class="headerlink" title="价值函数"></a>价值函数</h3><p>价值函数的值是对未来奖励的预测，我们用它来评估状态的好坏。价值函数里面有一个折扣因子<code>(discount factor)</code>，我们希望在尽可能短的时间里面得到尽可能多的奖励。</p>
<p>因此，我们可以把折扣因子放到价值函数的定义里面，价值函数的定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202310241533701.png" alt=""></p>
<p>我们还有一种价值函数： $Q$ 函数。 $Q$ 函数里面包含两个变量：状态和动作。其定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202310241535831.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404181459777.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404181458188.png" alt=""></p>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>模型决定了下一步的状态。下一步的状态取决于当前的状态以及当前采取的动作。它由状态转移概率和奖励函数两个部分组成。状态转移概率即：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202310241550023.png" alt=""></p>
<p>奖励函数是指我们在当前状态采取了某个动作，可以得到多大的奖励，即：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202310241551667.png" alt=""></p>
<h3 id="强化学习智能体的类型"><a href="#强化学习智能体的类型" class="headerlink" title="强化学习智能体的类型"></a>强化学习智能体的类型</h3><h4 id="基于价值的智能体与基于策略的智能体"><a href="#基于价值的智能体与基于策略的智能体" class="headerlink" title="基于价值的智能体与基于策略的智能体"></a>基于价值的智能体与基于策略的智能体</h4><p><strong>基于价值的智能体<code>(value-based agent)</code></strong>显式地学习价值函数，隐式地学习它的策略。策略是其从学到的价值函数里面推算出来的。<strong>基于策略的智能体<code>(policy-based agent)</code></strong> 直接学习策略，我们给它一个状态，它就会输出对应动作的概率。基于策略的智能体并没有学习价值函数。把基于价值的智能体和基于策略的智能体结合起来就有了<strong>演员-评论员智能体<code>(actor-critic agent)</code></strong>。这一类智能体把策略和价值函数都学习了，然后通过两者的交互得到最佳的动作。</p>
<h4 id="有模型强化学习智能体与免模型强化学习智能体"><a href="#有模型强化学习智能体与免模型强化学习智能体" class="headerlink" title="有模型强化学习智能体与免模型强化学习智能体"></a>有模型强化学习智能体与免模型强化学习智能体</h4><p><strong>有模型<code>(model-based)</code>强化学习智能体</strong>通过学习状态的转移来采取动作。<strong>免模型<code>(model-free)</code>强化学习智能体</strong>没有去直接估计状态的转移，也没有得到环境的具体转移变量，它通过学习价值函数和策略函数进行决策。免模型强化学习智能体的模型里面没有环境转移的模型。</p>
<h2 id="学习与规划"><a href="#学习与规划" class="headerlink" title="学习与规划"></a>学习与规划</h2><p>在规划中，环境是已知的，智能体被告知了整个环境的运作规则的详细信息。</p>
<h2 id="探索和利用"><a href="#探索和利用" class="headerlink" title="探索和利用"></a>探索和利用</h2><p><strong>探索</strong>即我们去探索环境，通过尝试不同的动作来得到最佳的策略（带来最大奖励的策略）。<strong>利用</strong>即我们不去尝试新的动作，而是采取已知的可以带来很大奖励的动作。</p>
<h1 id="马尔可夫决策过程"><a href="#马尔可夫决策过程" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h1><h2 id="马尔可夫过程"><a href="#马尔可夫过程" class="headerlink" title="马尔可夫过程"></a>马尔可夫过程</h2><h3 id="马尔可夫性质"><a href="#马尔可夫性质" class="headerlink" title="马尔可夫性质"></a>马尔可夫性质</h3><p>在随机过程中， 马尔可夫性质<code>(Markov property)</code>是指一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202310301135977.jpg" alt=""></p>
<h3 id="马尔可夫链"><a href="#马尔可夫链" class="headerlink" title="马尔可夫链"></a>马尔可夫链</h3><p>离散时间的马尔可夫过程也称为马尔可夫链<code>(Markov chain)</code>。  </p>
<h2 id="马尔可夫奖励过程"><a href="#马尔可夫奖励过程" class="headerlink" title="马尔可夫奖励过程"></a>马尔可夫奖励过程</h2><p>马尔可夫奖励过程<code>(Markov reward process, MRP)</code>是马尔可夫链加上奖励函数。</p>
<h3 id="回报与价值函数"><a href="#回报与价值函数" class="headerlink" title="回报与价值函数"></a>回报与价值函数</h3><p>范围<code>(horizon)</code>是指一个回合的长度（每个回合最大的时间步数），它是由有限个步数决定的。</p>
<p>回报<code>(return)</code> 可以定义为奖励的逐步叠加，假设时刻 $t$ 后的奖励序列为 $r_{t+1}, r_{t+2}, r_{t+3}, \cdots ，$ 则回报为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202310311129686.png" alt=""></p>
<p>对于马尔可夫奖励过程，状态价值函数被定义成回报的期望：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202310311130831.png" alt=""></p>
<h3 id="贝尔曼方程"><a href="#贝尔曼方程" class="headerlink" title="贝尔曼方程"></a>贝尔曼方程</h3><p>贝尔曼方程定义了当前状态与未来状态之间的关系。未来奖励的折扣总和加上即时奖励，就组成了贝尔曼方程。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061010578.png" alt=""></p>
<h4 id="全期望公式"><a href="#全期望公式" class="headerlink" title="全期望公式"></a>全期望公式</h4><p>在推导贝尔曼方程之前，首先需要仿照全期望公式<code>(law of total expectation)</code> 的证明过程来证明：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061026274.png" alt=""></p>
<p>为了表达方便，我们令 $s = s_{t}$ ，$ g^{\prime} = G_{t+1}$ ， $s^{\prime} = s_{t+1}$ ，那么我们可以得到如下推导，其中第二步根据全概率公式和期望的线性性，可以对外部的期望$\mathbb{E}[\cdot | s]$展开未对中间变量$s^{\prime}$的求和（或积分）：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061027021.png" alt=""></p>
<h4 id="贝尔曼方程推导"><a href="#贝尔曼方程推导" class="headerlink" title="贝尔曼方程推导"></a>贝尔曼方程推导</h4><p>贝尔曼方程的推导过程如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061041371.png" alt=""></p>
<p>上式的进一步推导如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411152225752.png" alt=""></p>
<p>我们可以把贝尔曼方程写成矩阵的形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061045825.png" alt=""></p>
<p>当我们把贝尔曼方程写成矩阵形式后，可以直接求解：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061045446.png" alt=""></p>
<h3 id="计算马尔可夫奖励过程价值的迭代算法"><a href="#计算马尔可夫奖励过程价值的迭代算法" class="headerlink" title="计算马尔可夫奖励过程价值的迭代算法"></a>计算马尔可夫奖励过程价值的迭代算法</h3><p>我们可以将迭代的方法应用于状态非常多的马尔可夫奖励过程<code>(large MRP)</code>，比如：动态规划的方法，蒙特卡洛的方法（通过采样的办法计算它），时序差分学习<code>(temporal-difference learning， TD learning)</code>的方法（时序差分学习是动态规划和蒙特卡洛方法的一个结合）。</p>
<p>蒙特卡洛方法就是当得到一个马尔可夫奖励过程后，我们可以从某个状态开始，把小船放到状态转移矩阵里面，让它“随波逐流”，这样就会产生一个轨迹。产生一个轨迹之后，就会得到一个奖励，那么直接把折扣的奖励即回报 $g$ 算出来。算出来之后将它积累起来，得到回报 $G_{t}$。当积累了一定数量的轨迹之后，我们直接用 $G_{t}$ 除以轨迹数量，就会得到某个状态的价值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061059726.png" alt=""></p>
<p>动态规划方法就是一直迭代贝尔曼方程，直到价值函数收敛，我们就可以得到某个状态的价值。我们通过自举<code>(bootstrapping)</code>的方法不停地迭代贝尔曼方程，当最后更新的状态与我们上一个状态的区别并不大的时候，更新就可以停止，我们就可以输出最新的 $V^{\prime}(s)$ 作为它当前的状态的价值。这里就是把贝尔曼方程变成一个贝尔曼更新<code>(Bellman update)</code>，这样就可以得到状态的价值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061103338.png" alt=""></p>
<h2 id="马尔可夫决策过程-1"><a href="#马尔可夫决策过程-1" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h2><p>相对于马尔可夫奖励过程，马尔可夫决策过程多了决策（决策是指动作），其他的定义与马尔可夫奖励过程的是类似的。此外，状态转移也多了一个条件，变成了 $p (s_{t+1}=s^{\prime}|s_{t}=s, a_{t}=a)$。未来的状态不仅依赖于当前的状态，也依赖于在当前状态智能体采取的动作。</p>
<h3 id="马尔可夫决策过程中的策略"><a href="#马尔可夫决策过程中的策略" class="headerlink" title="马尔可夫决策过程中的策略"></a>马尔可夫决策过程中的策略</h3><p>策略定义了在某一个状态应该采取什么样的动作。知道当前状态后，我们可以把当前状态代入策略函数来得到一个概率，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061115977.png" alt=""></p>
<p>已知马尔可夫决策过程和策略 $\pi$，我们可以把马尔可夫决策过程转换成马尔可夫奖励过程。在马尔可夫决策过程里面，状态转移函数 $P(s^{\prime}|s, a)$ 基于它当前的状态以及它当前的动作。因为我们现在已知策略函数，也就是已知在每一个状态下，可能采取的动作的概率，所以我们就可以直接把动作进行加和，去掉 $a$，这样我们就可以得到对于马尔可夫奖励过程的转移，这里就没有动作，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061123723.png" alt=""></p>
<p>对于奖励函数，我们也可以把动作去掉，这样就会得到类似于马尔可夫奖励过程的奖励函数，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061124112.png" alt=""></p>
<h3 id="马尔可夫决策过程中的价值函数"><a href="#马尔可夫决策过程中的价值函数" class="headerlink" title="马尔可夫决策过程中的价值函数"></a>马尔可夫决策过程中的价值函数</h3><p>马尔可夫决策过程中的价值函数的定义如下，其中，期望基于我们采取的策略。当策略决定后，我们通过对策略进行采样来得到一个期望，计算出它的价值函数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061151736.png" alt=""></p>
<p>这里另外引入了一个 $Q$ 函数。 $Q$ 函数也被称为动作价值函数<code>(action-value function)</code>。 $Q$ 函数定义的是在某一个状态采取某一个动作，它有可能得到的回报的一个期望，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061344602.png" alt=""></p>
<p>状态价值函数可以理解为在状态 $s$ 的情况下，未采取动作之前期望的回报值，即所有可能动作的奖励之和。那么我们可以得到如下转化关系公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061423882.png" alt=""></p>
<p>动作价值函数可以理解为在状态 $s$ 下，采取动作 $a$ 之后，转变到下一个状态 $s^{\prime}$ 产生的奖励与下一个状态的期望奖励 $v_{\pi}(s^{\prime})$ 之和。那么我们可以得到如下转化关系公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061426853.png" alt=""></p>
<h3 id="贝尔曼期望方程"><a href="#贝尔曼期望方程" class="headerlink" title="贝尔曼期望方程"></a>贝尔曼期望方程</h3><p>我们可以把状态价值函数和 $Q$ 函数拆解成两个部分：即时奖励和后续状态的折扣价值<code>(discounted value of successor state)</code>。通过对状态价值函数进行分解，我们就可以得到一个类似于之前马尔可夫奖励过程的贝尔曼方程——贝尔曼期望方程<code>(Bellman expectation equation)</code>：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061432650.png" alt=""></p>
<p>对于 $Q$ 函数，我们也可以做类似的分解，得到 $Q$ 函数的贝尔曼期望方程：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061433344.png" alt=""></p>
<p>同时根据上一节得到的状态价值函数和动作价值函数的表达式，我们可以得到贝尔曼期望方程的另一种形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061441622.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061441784.png" alt=""></p>
<h3 id="备份图"><a href="#备份图" class="headerlink" title="备份图"></a>备份图</h3><p>备份图用来定义未来下一时刻的状态价值函数（动作价值函数）与上一时刻的状态价值函数（动作价值函数）之间的关联。</p>
<p>状态价值函数 $V_{\pi}$ 的备份图和计算分解：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061456984.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061459433.png" alt=""></p>
<p>  动作价值函数 $Q_{\pi}$ 的备份图和计算分解：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061458839.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061458666.png" alt=""></p>
<h3 id="策略评估"><a href="#策略评估" class="headerlink" title="策略评估"></a>策略评估</h3><p>已知马尔可夫决策过程以及要采取的策略 $\pi$ ，计算价值函数 $V_{\pi}(s)$ 的过程就是策略评估。</p>
<h3 id="预测与控制"><a href="#预测与控制" class="headerlink" title="预测与控制"></a>预测与控制</h3><p>预测<code>(prediction)</code>和控制<code>(control)</code>是马尔可夫决策过程里面的核心问题。<br>预测（评估一个给定的策略）的输入是马尔可夫决策过程 $&lt; S, A, P, R, \gamma &gt;$ 和策略 $\pi$，输出是价值函数 $V_{\pi}$。预测是指给定一个马尔可夫决策过程以及一个策略 $\pi$ ，计算它的价值函数，也就是计算每个状态的价值。<br>控制（搜索最佳策略）的输入是马尔可夫决策过程 $&lt; S, A, P, R, \gamma &gt;$，输出是最佳价值函数<code>(optimal value function)</code> $V^{\ast}$ 和最佳策略<code>(optimal policy)</code> $\pi^{\ast}$。控制就是我们去寻找一个最佳的策略，然后同时输出它的最佳价值函数以及最佳策略。</p>
<h3 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h3><p>动态规划<code>(dynamic programming, DP)</code>适合解决满足最优子结构<code>(optimal substructure)</code>和重叠子问题<code>(overlapping subproblem)</code>两个性质的问题。</p>
<h3 id="马尔可夫决策过程中的策略评估"><a href="#马尔可夫决策过程中的策略评估" class="headerlink" title="马尔可夫决策过程中的策略评估"></a>马尔可夫决策过程中的策略评估</h3><p>  策略评估就是给定马尔可夫决策过程和策略，评估我们可以获得多少价值，即对于当前策略，我们可以得到多大的价值。</p>
<h3 id="马尔可夫决策过程控制"><a href="#马尔可夫决策过程控制" class="headerlink" title="马尔可夫决策过程控制"></a>马尔可夫决策过程控制</h3><p>策略评估是指给定马尔可夫决策过程和策略，我们可以估算出价值函数的值。如果我们只有马尔可夫决策过程，那么应该如何寻找最佳的策略，从而得到最佳价值函数<code>(optimal value function)</code>呢？  </p>
<p>最佳价值函数的定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061546075.png" alt=""></p>
<p>最佳价值函数是指，我们搜索一种策略 $\pi$ 让每个状态的价值最大。 $V^{\ast}$ 就是到达每一个状态，它的值的最大化情况。在这种最大化情况中，我们得到的策略就是最佳策略，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061547490.png" alt=""></p>
<p>最佳策略使得每个状态的价值函数都取得最大值。我们可以通过策略迭代和价值迭代来解决马尔可夫决策过程的控制问题。</p>
<h3 id="策略迭代"><a href="#策略迭代" class="headerlink" title="策略迭代"></a>策略迭代</h3><p>历程：迭代执行 $\pi \rightarrow V_{\pi} \rightarrow Q_{\pi} \rightarrow \pi^{\prime}$ ，最终得到 $V^{\ast}$</p>
<p>策略迭代由两个步骤组成：策略评估和策略改进。第一个步骤是策略评估，当前我们在优化策略 $\pi$，在优化过程中得到一个最新的策略。我们先保证这个策略不变，然后估计它的价值，即给定当前的策略函数来估计状态价值函数。第二个步骤是策略改进，得到状态价值函数后，我们可以进一步推算出它的 $Q$ 函数。得到 $Q$ 函数后，我们直接对 $Q$ 函数进行最大化，通过在 $Q$ 函数做一个贪心的搜索来进一步改进策略。这两个步骤一直在迭代进行。</p>
<h4 id="贝尔曼最优方程"><a href="#贝尔曼最优方程" class="headerlink" title="贝尔曼最优方程"></a>贝尔曼最优方程</h4><p>当我们一直采取 $\arg \max$ 操作的时候，我们会得到一个单调的递增。通过采取这种贪心操作，我们就会得到更好的或者不变的策略，而不会使价值函数变差。所以当改进停止后，我们就会得到一个最佳策略。当改进停止后，我们取让 $Q$ 函数值最大化的动作， $Q$ 函数就会直接变成价值函数，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061626343.png" alt=""></p>
<p>我们也就可以得到贝尔曼最优方程<code>(Bellman optimality equation)</code>。贝尔曼最优方程表明：最佳策略下的一个状态的价值必须等于在这个状态下采取最好动作得到的回报的期望。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061637403.png" alt=""></p>
<h3 id="价值迭代"><a href="#价值迭代" class="headerlink" title="价值迭代"></a>价值迭代</h3><p>历程：迭代执行 $Q_{\pi} \rightarrow V_{\pi}$ ，最终得到 $\pi^{\ast}$</p>
<h4 id="最优性原理"><a href="#最优性原理" class="headerlink" title="最优性原理"></a>最优性原理</h4><p>最优性原理定理<code>(principle of optimality theorem)</code>：一个策略 $\pi(a|s)$ 在状态 $s$ 达到了最优价值，也就是 $V_{\pi}(s) = V^{\ast}(s)$ 成立，当且仅当对于任何能够从 $s$ 到达的 $s^{\prime}$ ，都已经达到了最优价值。也就是对于所有的 $s^{\prime}$，$ V_{\pi}(s^{\prime}) = V^{\ast}(s^{\prime})$ 恒成立。</p>
<h4 id="确认性价值迭代"><a href="#确认性价值迭代" class="headerlink" title="确认性价值迭代"></a>确认性价值迭代</h4><p>如果我们知道子问题 $V^{\ast}(s^{\prime})$ 的最优解，就可以通过价值迭代来得到最优的 $V^{\ast}(s)$ 的解。价值迭代就是把贝尔曼最优方程当成一个更新规则来进行，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311061736922.png" alt=""></p>
<p>上式只有当整个马尔可夫决策过程已经达到最佳的状态时才满足。我们可以把它转换成一个备份的等式。备份的等式就是一个迭代的等式。我们不停地迭代贝尔曼最优方程，价值函数就能逐渐趋向于最佳的价值函数，这是价值迭代算法的精髓。</p>
<h1 id="表格型方法"><a href="#表格型方法" class="headerlink" title="表格型方法"></a>表格型方法</h1><h2 id="马尔可夫决策过程-2"><a href="#马尔可夫决策过程-2" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h2><p>状态转移概率是具有马尔可夫性质的（系统下一时刻的状态仅由当前时刻的状态决定，不依赖于以往任何状态）。状态、动作、状态转移概率和奖励，这 $4$ 个合集就构成了强化学习马尔可夫决策过程的四元组，后面也可能会再加上折扣因子构成五元组。</p>
<h3 id="有模型"><a href="#有模型" class="headerlink" title="有模型"></a>有模型</h3><p>我们与环境交互时，只能走一条完整的通路，这里面产生了一系列决策的过程，我们与环境交互产生了经验。我们会使用概率函数 $P [s_{t+1}, r_{t} | s_{t}, a_{t}]$ 和奖励函数 $R [s_{t}, a_{t}]$ 来描述环境。概率函数就是状态转移的概率，它反映的是环境的随机性。</p>
<h3 id="免模型"><a href="#免模型" class="headerlink" title="免模型"></a>免模型</h3><p>很多强化学习的经典算法都是免模型的，也就是环境是未知的。我们处在未知的环境里，也就是这一系列的决策的概率函数和奖励函数是未知的，这就是有模型与免模型的最大的区别。</p>
<h2 id="Q-表格"><a href="#Q-表格" class="headerlink" title="Q 表格"></a>Q 表格</h2><p>$Q$ 表格里面 $Q$ 函数的意义就是我们选择了某个动作后，最后能不能成功，就需要我们去计算在某个状态下选择某个动作，后续能够获得多少总奖励。如果可以预估未来的总奖励的大小，我们就知道在当前的状态下选择哪个动作价值更高。我们选择某个动作是因为这样未来可以获得的价值会更高。所以强化学习的目标导向性很强，环境给出的奖励是非常重要的反馈，它根据环境的奖励来做选择。</p>
<p>$Q$ 表格的更新是接下来要引入的强化概念。强化是指我们可以用下一个状态的价值来更新当前状态的价值，其实就是强化学习里面自举的概念。在强化学习里面，我们可以每走一步更新一次 $Q$ 表格，用下一个状态的 $Q$ 值来更新当前状态的 $Q$ 值，这种单步更新的方法被称为时序差分方法。</p>
<h2 id="免模型预测"><a href="#免模型预测" class="headerlink" title="免模型预测"></a>免模型预测</h2><h3 id="蒙特卡洛策略评估"><a href="#蒙特卡洛策略评估" class="headerlink" title="蒙特卡洛策略评估"></a>蒙特卡洛策略评估</h3><p>蒙特卡洛方法是基于采样的方法，给定策略 $\pi$ ，我们让智能体与环境进行交互，可以得到很多轨迹。每个轨迹都有对应的回报：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081352612.png" alt=""></p>
<p>我们求出所有轨迹的回报的平均值，就可以知道某一个策略对应状态的价值，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081353064.png" alt=""></p>
<p>假设现在有样本 $x_{1}, x_{2}, \cdots, x_{t}$，我们可以把经验均值转换成增量均值的形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081441872.png" alt=""></p>
<p>通过这种转换，我们就可以把上一时刻的平均值与现在时刻的平均值建立联系，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081442053.png" alt=""></p>
<p>基于此，我们可以把蒙特卡洛方法更新的方法写成增量式蒙特卡洛方法。我们采集数据，得到一个新的轨迹 $(s_{1}, a_{1}, r_{1}, \cdots, s_{t})$。对于这个轨迹，我们采用增量的方法进行更新：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081444676.png" alt=""></p>
<p><strong>动态规划方法和蒙特卡洛方法的差异</strong></p>
<p>在动态规划方法里面，我们使用了自举的思想。自举就是我们基于之前估计的量来估计一个量。此外，动态规划方法使用贝尔曼期望备份，通过上一时刻的值 $V_{i−1}(s^{\prime})$ 来更新当前时刻的值 $V_{i}(s)$ ，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081449238.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081500026.png" alt=""></p>
<p>蒙特卡洛方法通过一个回合的经验平均回报（实际得到的奖励）来进行更新，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081501924.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081501433.png" alt=""></p>
<h3 id="时序差分"><a href="#时序差分" class="headerlink" title="时序差分"></a>时序差分</h3><p>时序差分方法的目的是对于某个给定的策略 $\pi$，在线<code>(online)</code>地算出它的价值函数 $V_{\pi}$，即一步一步地<code>(step-by-step)</code>算。最简单的算法是一步时序差分<code>(one-step TD)</code>，即 <strong><code>TD(0)</code></strong>。每往前走一步，就做一步自举，用得到的估计回报 $r_{t+1}+ \gamma V (s_{t+1})$ 来更新上一时刻的值 $V (s_{t})$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081538081.png" alt=""></p>
<p><strong>蒙特卡洛方法和时间差分方法的对比</strong></p>
<ul>
<li>时序差分方法可以在线学习，每走一步就可以更新，效率高。蒙特卡洛方法必须等游戏结束时才可以学习。</li>
<li>时序差分方法可以从不完整序列上进行学习。蒙特卡洛方法只能从完整的序列上进行学习。</li>
<li>时序差分方法可以在连续的环境下（没有终止）进行学习。蒙特卡洛方法只能在有终止的情况下学习。</li>
<li>时序差分方法利用了马尔可夫性质，在马尔可夫环境下有更高的学习效率。蒙特卡洛方法没有假设环境具有马尔可夫性质，利用采样的价值来估计某个状态的价值，在不是马尔可夫的环境下更加有效。</li>
</ul>
<h3 id="动态规划方法、蒙特卡洛方法以及时序差分方法的自举和采样"><a href="#动态规划方法、蒙特卡洛方法以及时序差分方法的自举和采样" class="headerlink" title="动态规划方法、蒙特卡洛方法以及时序差分方法的自举和采样"></a>动态规划方法、蒙特卡洛方法以及时序差分方法的自举和采样</h3><p>自举是指更新时使用了估计。蒙特卡洛方法没有使用自举，因为它根据实际的回报进行更新。动态规划方法和时序差分方法使用了自举。</p>
<p>采样是指更新时通过采样得到一个期望。蒙特卡洛方法是纯采样的方法。动态规划方法没有使用采样，它是直接用贝尔曼期望方程来更新状态价值的。时序差分方法使用了采样。时序差分目标由两部分组成，一部分是采样，一部分是自举。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311081632154.png" alt=""></p>
<h2 id="免模型控制"><a href="#免模型控制" class="headerlink" title="免模型控制"></a>免模型控制</h2><p>在我们不知道马尔可夫决策过程模型的情况下，如何优化价值函数，得到最佳的策略呢？我们可以把策略迭代进行广义的推广，使它能够兼容蒙特卡洛和时序差分的方法，即带有蒙特卡洛方法和时序差分方法的广义策略迭代<code>(generalized policy iteration，GPI)</code>。</p>
<p><strong>当我们不知道奖励函数和状态转移时，如何进行策略的优化？</strong></p>
<p>针对上述情况，我们引入了广义的策略迭代的方法。我们对策略评估部分进行修改，使用蒙特卡洛的方法代替动态规划的方法估计 $Q$ 函数。我们首先进行策略评估，使用蒙特卡洛方法来估计策略 $Q = Q_{\pi}$，然后进行策略更新，即得到 $Q$ 函数后，我们就可以通过贪心的方法去改进它。</p>
<p>一个保证策略迭代收敛的假设是回合有探索性开始<code>(exploring start)</code>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311091108609.png" alt=""></p>
<p>为了确保蒙特卡洛方法能够有足够的探索，我们使用了 $\varepsilon$-贪心探索。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311091120042.png" alt=""></p>
<h3 id="Sarsa：同策略时序差分控制"><a href="#Sarsa：同策略时序差分控制" class="headerlink" title="Sarsa：同策略时序差分控制"></a>Sarsa：同策略时序差分控制</h3><p><code>Sarsa</code>所做出的改变很简单，它将原本时序差分方法更新 $V$ 的过程，变成了更新 $Q$，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311131348504.png" alt=""></p>
<p>算法由于每次更新值函数时需要知道当前的状态<code>(state)</code>、当前的动作<code>(action)</code>、奖励<code>(reward)</code>、下一步的状态<code>(state)</code>、下一步的动作<code>(action)</code>，即 $(s_{t}, a_{t}, r_{t+1}, s_{t+1}, a_{t+1})$ 这几个值，因此得名<code>Sarsa</code>算法。它走了一步之后，获取了 $(s_{t}, a_{t}, r_{t+1}, s_{t+1}, a_{t+1})$ 之后，就可以做一次更新。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311131355382.png" alt=""></p>
<h4 id="Sarsa-lambda"><a href="#Sarsa-lambda" class="headerlink" title="Sarsa($\lambda$)"></a>Sarsa($\lambda$)</h4><p>$\lambda$ 是脚步衰变值，取值为 $[0, 1]$。通过设定 $\lambda$ 可以让离奖励较近的选择获得较大的奖赏，离奖励较远的选择获得较小的奖赏。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404171543327.png" alt=""></p>
<h3 id="Q学习：异策略时序差分控制"><a href="#Q学习：异策略时序差分控制" class="headerlink" title="Q学习：异策略时序差分控制"></a>Q学习：异策略时序差分控制</h3><p><code>Sarsa</code>是一种<strong>同策略（on-policy）</strong>算法，它优化的是它实际执行的策略，它直接用下一步会执行的动作去优化$Q$表格。同策略在学习的过程中，只存在一种策略，它用一种策略去做动作的选取，也用一种策略去做优化。Q 学习是一种<strong>异策略（off-policy）</strong>算法。异策略在学习的过程中，有两种不同的策略：<strong>目标策略（target policy）</strong>和<strong>行为策略（behavior policy）</strong>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311131452578.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311131454910.png" alt=""></p>
<h3 id="同策略与异策略的区别"><a href="#同策略与异策略的区别" class="headerlink" title="同策略与异策略的区别"></a>同策略与异策略的区别</h3><p>$Q$学习是一个非常激进的方法，它希望每一步都获得最大的利益；Sarsa则相对较为保守，它会选择一条相对安全的迭代路线。</p>
<h1 id="策略梯度"><a href="#策略梯度" class="headerlink" title="策略梯度"></a>策略梯度</h1><h2 id="策略梯度算法"><a href="#策略梯度算法" class="headerlink" title="策略梯度算法"></a>策略梯度算法</h2><p>策略是一个网络；输入是游戏的画面，它通常是由像素组成的；输出是我们可以执行的动作，有几个动作，输出层就有几个神经元。假设我们现在可以执行的动作有 3 个，输出层就有 3 个神经元，每个神经元对应一个可以采取的动作。</p>
<p>环境是一个函数，我们可以把游戏的主机看成一个函数，虽然它不一定是神经网络，可能是基于规则的（rule-based）模型，但我们可以把它看作一个函数。这个函数一开始先“吐”出一个状态（游戏画面 $s_{1}$ ），接下来演员看到游戏画面 $s_{1}$ 以后，它“吐”出动作 $a_{1}$ 。环境把动作 $a_{1}$ 当作它的输入，再“吐”出新的游戏画面 $s_{2}$。演员看到新的游戏画面 $s_{2}$，再采取新的动作 $a_{2}$。环境看到 $a_{2}$，再“吐”出 $s_{3}$ …… 这个过程会一直持续下去，直到环境觉得应该要停止为止。在一场游戏里面，我们把环境输出的 $s$ 与演员输出的动作 $a$ 全部组合起来，就是一个轨迹，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311140944102.png" alt=""></p>
<p>给定演员的参数 $\theta$，我们可以计算某个轨迹 $\tau$ 发生的概率为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311140945562.png" alt=""></p>
<p>在某一场游戏的某一个回合里面，我们会得到 $R(\tau)$。我们要做的就是调整演员内部的参数 $\theta$，使得 $R(\tau)$ 的值越大越好。但实际上 $R(\tau)$ 并不只是一个标量，它是一个随机变量，因为演员在给定同样的状态下会采取什么样的动作，这是有随机性的。环境在给定同样的观测时要采取什么样的动作，要产生什么样的观测，本身也是有随机性的，所以 $R(\tau)$ 是一个随机变量。我们能够计算的是 $R(\tau)$ 的期望值。给定某一组参数 $\theta$，我们可计算 $r_{\theta}$ 的期望值为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311140955539.png" alt=""></p>
<p>总奖励使用 $\tau$ 出现的概率进行加权，对所有的 $\tau$ 进行求和，就是期望值。给定一个参数，我们可以计算期望值为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311140958839.png" alt=""></p>
<p>因为我们要让奖励越大越好，所以可以使用梯度上升来最大化期望奖励。要进行梯度上升，我们先要计算期望奖励 $\bar{R}_{\theta}$ 的梯度。我们对 $\bar{R}_{\theta}$ 做梯度运算</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141002272.png" alt=""></p>
<p>基于等式 $\nabla f(x)=f(x)\nabla \log f(x)$ ，我们可以得到：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141014067.png" alt=""></p>
<p>实际上期望值 $E_{\tau \sim p_{\theta}(\tau)} [R(\tau)\nabla \log p_{\theta}(\tau)]$ 无法计算，所以我们用采样的方式采样 $N$ 个 $\tau$ 并计算每一个的值，把每一个的值加起来，就可以得到梯度，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141020560.png" alt=""></p>
<p>策略梯度的具体执行示意图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141027355.png" alt=""></p>
<p>更新完模型以后，我们要重新采样数据再更新模型。注意，一般策略梯度采样的数据只会用一次。我们采样这些数据，然后用这些数据更新参数，再丢掉这些数据。接着重新采样数据，才能去更新参数。</p>
<h2 id="策略梯度实现技巧"><a href="#策略梯度实现技巧" class="headerlink" title="策略梯度实现技巧"></a>策略梯度实现技巧</h2><h3 id="技巧-1：添加基线"><a href="#技巧-1：添加基线" class="headerlink" title="技巧 1：添加基线"></a>技巧 1：添加基线</h3><p>假设我们在某一个状态有 3 个动作 a、 b、 c 可以执行，要把这3 个动作的概率，对数概率都提高。但是它们前面的权重 $R(\tau)$ 是不一样的。权重是有大有小的，权重小的，该动作的概率提高的就少；权重大的，该动作的概率提高的就多。因为对数概率是一个概率，所以动作 a、 b、 c 的对数概率的和是 $0$。所以提高少的，在做完归一化以后，动作 b 的概率就是下降的；提高多的，该动作的概率才会上升。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141110318.png" alt=""></p>
<p>这是一个理想的情况，但是实际上，我们是在做采样本来这边应该是一个期望，对所有可能的 $s$ 与 $a$ 的对进行求和。但我们真正在学习的时候，只是采样了少量的 $s$ 与 $a$ 的对。因为我们做的是采样，所以有一些动作可能从来都没有被采样到。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141113629.png" alt=""></p>
<p>为了解决奖励总是正的的问题，我们可以把奖励减 $b$，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141116781.png" alt=""></p>
<p>通过这种方法，我们就可以让 $R(\tau) - b$ 这一项有正有负。如果我们得到的总奖励 $R(\tau) &gt; b$，就让 $(s, a)$ 的概率上升。如果 $R(\tau) &lt; b$，就算 $R(\tau)$ 是正的，值很小也是不好的，我们就让 $(s, a)$ 的概率下降，让这个状态采取这个动作的分数下降。 $b$ 怎么设置呢？我们可以对 $\tau$ 的值取期望，计算 $\tau$ 的平均值，令 $b \approx E[R(\tau)]$。所以在训练的时候，我们会不断地把 $R(\tau)$ 的值记录下来，会不断地计算 $R(\tau)$ 的平均值，把这个平均值当作 $b$ 来使用。这样就可以让我们在训练的时候， $R(\tau) - b$ 是有正有负的，这是第一个技巧。</p>
<h3 id="技巧2：分配合适的分数"><a href="#技巧2：分配合适的分数" class="headerlink" title="技巧2：分配合适的分数"></a>技巧2：分配合适的分数</h3><p>第二个技巧：给每一个动作分配合适的分数。只要在同一个回合里面，在同一场游戏里面，所有的状态-动作对就使用同样的奖励项进行加权，这显然是不公平的。<strong>一个做法是计算某个状态-动作对的奖励的时候，不把整场游戏得到的奖励全部加起来，只计算从这个动作执行以后得到的奖励。</strong></p>
<p>分配合适的分数这一技巧可以表达为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141126407.png" alt=""></p>
<p>更进一步，我们把未来的奖励做一个折扣，因为虽然在某一时刻，执行某一个动作，会影响接下来所有的结果，但在一般的情况下，时间拖得越长，该动作的影响力就越小。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141127305.png" alt=""></p>
<p>实际上就是这么实现的。 $b$ 可以是依赖状态的，事实上 $b$ 通常是一个网络估计出来的，它是一个网络的输出。我们把 $R − b$ 这一项称为优势函数，用 $A^{\theta}(s_{t}, a_{t})$ 来表示优势函数。优势函数的意义是，假设我们在某一个状态 $s_{t}$ 执行某一个动作 $a_{t}$，相较于其他可能的动作， $a_{t}$ 有多好。优势函数在意的不是绝对的好，而是相对的好，即相对优势。因为在优势函数中，我们会减去一个基线 $b$，所以这个动作是相对的好，不是绝对的好。 $A^{\theta}(s_{t}, a_{t})$ 通常可以由一个网络估计出来，这个网络称为评论员。</p>
<h2 id="REINFORCE：蒙特卡洛策略梯度"><a href="#REINFORCE：蒙特卡洛策略梯度" class="headerlink" title="REINFORCE：蒙特卡洛策略梯度"></a>REINFORCE：蒙特卡洛策略梯度</h2><p>蒙特卡洛方法可以理解为算法完成一个回合之后，再利用这个回合的数据去学习，做一次更新。因为我们已经获得了整个回合的数据，所以也能够获得每一个步骤的奖励，我们可以很方便地计算每个步骤的未来总奖励，即回报 $G_{t}$ 。 $G_{t}$ 是未来总奖励，代表从这个步骤开始，我们能获得的奖励之和。 $G_{1}$ 代表我们从第一步开始，往后能够获得的总奖励。 $G_{2}$ 代表从第二步开始，往后能够获得的总奖励。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404182146893.png" alt=""></p>
<p>相比蒙特卡洛方法一个回合更新一次，时序差分方法是每个步骤更新一次，即每走一步，更新一次，时序差分方法的更新频率更高。时序差分方法使用 $Q$ 函数来近似地表示未来总奖励 $G_{t}$。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141151029.png" alt=""></p>
<p>REINFORCE 用的是回合更新的方式，它在代码上的处理上是先获取每个步骤的奖励，然后计算每个步骤的未来总奖励 $G_{t}$，将每个 $G_{t}$ 代入下式优化每一个动作的输出。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141336604.png" alt=""></p>
<p>未来总奖励可写成一个递推式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141345612.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141350439.png" alt=""></p>
<h1 id="近端策略优化"><a href="#近端策略优化" class="headerlink" title="近端策略优化"></a>近端策略优化</h1><h2 id="重要性采样"><a href="#重要性采样" class="headerlink" title="重要性采样"></a>重要性采样</h2><p>策略梯度是同策略的算法，因为在策略梯度中，我们需要一个智能体、一个策略和一个演员。演员去与环境交互搜集数据，搜集很多的轨迹 $\tau$，根据搜集到的数据按照策略梯度的公式更新策略的参数，所以策略梯度是一个同策略的算法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141356104.png" alt=""></p>
<p>$E_{\tau \sim p_{\theta}}(\tau)$ 是对策略 $\pi_{\theta}$ 采样的轨迹 $\tau$ 求期望。一旦更新了参数，从 $\theta$ 变成 $\theta^{\prime}$ ，概率 $p_{\theta}(\tau)$ 就不对了，之前采样的数据也不能用了。所以策略梯度是一个会花很多时间来采样数据的算法，其大多数时间都在采样数据。智能体与环境交互以后，接下来就要更新参数。我们只能更新参数一次，然后就要重新采样数据，才能再次更新参数。  </p>
<p>假设我们有一个函数 $f(x)$ ，要计算从分布 $p$ 采样 $x$ ，再把 $x$ 代入 $f$ ，得到 $f(x)$ 。我们该怎么计算 $f(x)$ 的期望值呢？假设我们不能对分布 $p$ 做积分，但可以从分布 $p$ 采样一些数据 $x^{i}$ 。把 $x^{i}$ 代入 $f(x)$ ，取它的平均值，就可以近似 $f(x)$ 的期望值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202311141652913.png" alt=""></p>
<p>现在有另外一个问题，假设我们不能从分布 $p$ 采样数据，只能从另外一个分布 $q$ 采样数据 $x$ ，其中 $q$ 可以是任何分布。如果我们从 $q$ 采样 $x^{i}$，就不能使用上式计算期望，因为上式是假设 $x$ 都是从 $p$ 采样出来的。我们做一个修正，期望值 $\mathbb{E}_{x\sim p}[f(x)]$ 就是 $\int f(x)p(x)dx$，我们对其做如下的变换：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312050900748.png" alt=""></p>
<p>就可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312050901310.png" alt=""></p>
<p>我们就可以写成对 $q$ 里面所采样出来的 $x$ 取期望值。我们从 $q$ 里面采样 $x$，再计算 $f(x)\frac{p(x)}{q(x)}$ ，再取期望值。所以就算我们不能从 $p$ 里面采样数据，但只要能从 $q$ 里面采样数据，就可以计算从 $p$ 采样 $x$ 代入 $f$ 以后的期望值。</p>
<p>$q(x)$ 可以是任何分布，唯一的限制就是 $q(x)$ 的概率是 $0$ 的时候， $p(x)$ 的概率不为 $0$，不然会没有定义。重要性采样有一些问题。虽然我们可以把 $p$ 换成任何的 $q$。但是在实现上， $p$ 和 $q$ 的差距不能太大。差距太大，会有一些问题（方差）。我们可以将 $f(x)$ 和 $f(x)\frac{p(x)}{q(x)}$ 代入方差的公式 $Var[X] = E [X^{2}] - (E[X])^{2}$，可得</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312050910515.png" alt=""></p>
<p>证明：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051018942.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051024229.png" alt=""></p>
<p>现在要做的就是把重要性采样用在异策略的情况中，把同策略训练的算法改成异策略训练的算法。之前我们用策略 $\pi_{\theta}$ 与环境交互，采样出轨迹 $\tau$，计算 $R(\tau)\nabla \log p_{\theta}(\tau)$。现在我们不用 $\theta$ 与环境交互，假设有另外一个策略 $\pi_{\theta}^{\prime}$ ，它就是另外一个演员，它的工作是做示范。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051048897.png" alt=""></p>
<p>$\theta^{\prime}$ 的工作是为 $\theta$ 做示范。它与环境交互，告诉 $\theta$ 它与环境交互会发生什么事，借此来训练 $\theta$。我们要训练的是 $\theta$ ， $\theta^{\prime}$ 只负责做示范，负责与环境交互。我们现在的 $\tau$ 是从 $\theta^{\prime}$ 采样出来的，是用 $\theta^{\prime}$ 与环境交互。所以采样出来的 $\tau$ 是从 $\theta^{\prime}$ 采样出来的，这两个分布不一样。但没有关系，假设我们本来是从 $p$ 采样，但发现不能从 $p$ 采样，所以我们不用 $\theta$ 与环境交互，可以把 $p$ 换成 $q$，在后面补上一个重要性权重。同理，我们把 $\theta$ 换成 $\theta^{\prime}$ 后，要补上一个重要性权重 $\frac{p_{\theta}(\tau)}{p_{\theta}^{\prime}(\tau)}$ 。这个重要性权重就是某一个轨迹 $\tau$ 用 $\theta$ 算出来的概率除以这个轨迹 $\tau$ 用 $\theta^{\prime}$ 算出来的概率。这一项是很重要的，因为我们要学习的是演员 $\theta$，而 $\theta$ 和 $\theta^{\prime}$ 是不太一样的， $\theta^{\prime}$ 见到的情形与 $\theta$ 见到的情形可能不是一样的，所以中间要有一个修正的项。</p>
<p>实际在做策略梯度的时候，我们并不是给整个轨迹 $\tau$ 一样的分数，而是将每一个状态-动作对分开计算。实际更新梯度的过程可写为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051121289.png" alt=""></p>
<p>我们可以通过重要性采样把同策略变成异策略，从 $\theta$ 变成 $\theta^{\prime}$。所以现在 $s_{t}$、 $a_{t}$ 是 $\theta^{\prime}$ 与环境交互以后所采样到的数据。但是训练时，要调整的参数是模型 $\theta$。因为 $\theta^{\prime}$ 与 $\theta$ 是不同的模型，所以我们要有一个修正的项。这个修正的项，就是用重要性采样的技术，把 $s_{t}$、 $a_{t}$ 用 $\theta$ 采样出来的概率除以 $s_{t}$、 $a_{t}$ 用 $\theta^{\prime}$ 采样出来的概率。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051133117.png" alt=""></p>
<p>接下来，我们可以拆解 $p_{\theta}(s_{t}, a_{t})$ 和 $p_{\theta^{\prime}} (s_{t}, a_{t})$，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051324772.png" alt=""></p>
<p>于是我们可得</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051324074.png" alt=""></p>
<p>这里需要做的一件事情是，假设模型是 $\theta$ 的时候，我们看到 $s_{t}$ 的概率，与模型是 $\theta^{\prime}$ 的时候，我们看到 $s_{t}$ 的概率是一样的，即 $p_{\theta}(s_{t}) = p_{\theta^{\prime}}(s_{t})$。因为 $p_{\theta}(s_{t})$ 和 $p_{\theta^{\prime}}(s_{t})$ 是一样的，所以我们可得</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051328636.png" alt=""></p>
<p>实际上，当我们使用重要性采样的时候，要去优化的目标函数为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051332093.png" alt=""></p>
<p>我们将其记为 $J^{\theta^{\prime}}(\theta)$，因为 $J^{\theta^{\prime}}(\theta)$ 括号里面的 $\theta$ 代表我们要去优化的参数。</p>
<p>根据PPO的原始论文建议，我们一般使用GAE来计算优势函数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411162249796.png" alt=""></p>
<p>其中，$\delta_{t}^{V}$的表达式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202411162250464.png" alt=""></p>
<h2 id="近端策略优化-1"><a href="#近端策略优化-1" class="headerlink" title="近端策略优化"></a>近端策略优化</h2><p>我们可以通过重要性采样把同策略换成异策略，但重要性采样有一个问题：如果 $p_{\theta}(a_{t}|s_{t})$ 与 $p_{\theta^{\prime}}(s_{t}|a_{t})$相差太多，即这两个分布相差太多，重要性采样的结果就会不好。怎么避免它们相差太多呢？这就是PPO要做的事情。</p>
<p>PPO 需要优化目标函数 $J_{\theta^{\prime}}(\theta)$ ，这个目标函数牵涉到重要性采样。在做重要性采样的时候， $p_{\theta}(a_{t}|s_{t})$ 不能与 $p_{\theta^{\prime}}(s_{t}|a_{t})$ 相差太多。做示范的模型不能与真正的模型相差太多，相差太多，重要性采样的结果就会不好。我们在训练的时候，应多加一个约束。这个约束是 $\theta$ 与 $\theta^{\prime}$ 输出的动作的 KL 散度，这一项用于衡量 $\theta$ 与 $\theta^{\prime}$ 的相似程度。<strong>注意，虽然 PPO 的优化目标涉及到了重要性采样，但其只用到了上一轮策略 $\theta^{\prime}$ 的数据。 PPO 目标函数中加入了 KL 散度的约束，行为策略 $\theta^{\prime}$ 和目标策略 $\theta$ 非常接近， PPO 的行为策略和目标策略可认为是同一个策略，因此 PPO 是同策略算法。</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051352706.png" alt=""></p>
<p>PPO 有一个前身： 信任区域策略优化（trust region policy optimization， TRPO）。TRPO可表示为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051358467.png" alt=""></p>
<p>TRPO 与 PPO 不一样的地方是约束所在的位置不一样， PPO 直接把约束放到要优化的式子里面，我们就可以用梯度上升的方法去最大化 $J_{PPO}^{\theta^{\prime}}(\theta)$。但 TRPO 是把 KL 散度当作约束，它希望 $\theta$ 与 $\theta^{\prime}$ 的 KL散度小于 $\delta$。如果我们使用的是基于梯度的优化，有约束是很难处理的。</p>
<h3 id="近端策略优化惩罚"><a href="#近端策略优化惩罚" class="headerlink" title="近端策略优化惩罚"></a>近端策略优化惩罚</h3><p>PPO 算法有两个主要的变种：<strong>近端策略优化惩罚（PPO-penalty）</strong>和<strong>近端策略优化裁剪（PPO-clip）</strong>。</p>
<p>先初始化一个策略的参数 $\theta^{0}$。在每一个迭代里面，我们用前一个训练的迭代得到的演员的参数 $\theta^{k}$ 与环境交互，采样到大量状态-动作对。根据 $\theta^{k}$ 交互的结果，我们估测 $A^{\theta^{k}}(s_{t},a_{t})$。我们使用 PPO 的优化公式。但与原来的策略梯度不一样，原来的策略梯度只能更新一次参数，更新完以后，我们就要重新采样数据。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051417680.png" alt=""></p>
<p>在 PPO 的论文里面还有一个自适应 KL 散度 。这里会遇到一个问题就，即 $\beta$ 要设置为多少。我们有一个动态调整 $\beta$ 的方法。在这个方法里面，我们先设一个可以接受的 KL 散度的最大值。假设优化完上式以后， KL 散度的值太大，这就代表后面惩罚的项 $\beta KL(\theta, \theta^{k})$ 没有发挥作用，我们就把 $\beta$ 增大。另外，我们设一个 KL 散度的最小值。如果优化完上式以后， KL 散度比最小值还要小，就代表后面这一项的效果太强了，我们怕他只优化后一项，使 $\theta$ 与 $\theta^{k}$ 一样，这不是我们想要的，所以我们要减小 $\beta$。 $\beta$ 是可以动态调整的，因此我们称之为自适应 KL 惩罚。</p>
<p>近端策略优化惩罚可表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051429446.png" alt=""></p>
<h3 id="近端策略优化裁剪"><a href="#近端策略优化裁剪" class="headerlink" title="近端策略优化裁剪"></a>近端策略优化裁剪</h3><p>如果我们觉得计算 KL 散度很复杂，那么还有一个 PPO2 算法， PPO2 即近端策略优化裁剪。近端策略优化裁剪的目标函数里面没有 KL 散度，其要最大化的目标函数为，其中裁剪函数是指，在括号里面有 3 项，如果第一项小于第二项，那就输出 $1-\varepsilon$；第一项如果大于第三项，那就输出 $1+\varepsilon$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312051437351.png" alt=""></p>
<h1 id="深度Q​网络"><a href="#深度Q​网络" class="headerlink" title="深度Q​网络"></a>深度Q​网络</h1><p>传统的强化学习算法会使用表格的形式存储状态价值函数 $V (s)$ 或动作价值函数 $Q(s, a)$ ，但是这样的方法存在很大的局限性。例如，现实中的强化学习任务所面临的状态空间往往是连续的，存在无穷多个状态，在这种情况下，就不能再使用表格对价值函数进行存储。价值函数近似利用函数直接拟合状态价值函数或动作价值函数，降低了对存储空间的要求，有效地解决了这个问题。</p>
<p>深度 $Q$ 网络（deep Q-network， DQN）是指基于深度学习的 $Q$ 学习算法，主要结合了价值函数近似与神经网络技术，并采用目标网络和经历回放的方法进行网络的训练。</p>
<h2 id="状态价值函数"><a href="#状态价值函数" class="headerlink" title="状态价值函数"></a>状态价值函数</h2><p>深度 $Q$ 网络是基于价值的算法，在基于价值的算法里面，我们学习的不是策略，而是评论员（critic）。评论员的任务是评价现在的动作有多好或有多不好。假设有一个演员，其要学习一个策略来得到尽量高的回报。评论员就是评价演员的策略 $\pi$ 好还是不好，即策略评估。例如，有一种评论员称为状态价值函数 $V_{\pi}$。状态价值函数是指，假设演员的策略是 $\pi$，用 $\pi$ 与环境交互，假设 $\pi$ 看到了某一个状态 $s$，例如在玩雅达利游戏，状态 $s$ 是某一个画面， $\pi$ 看到某一个画面，接下来一直到游戏结束，期望的累积奖励有多大。</p>
<p>怎么衡量状态价值函数 $V_{\pi}(s)$ 呢？有两种不同的方法：基于蒙特卡洛的方法和基于时序差分的方法。基于蒙特卡洛的方法就是让演员与环境交互，我们要看演员好不好，就让演员与环境交互，让评论员评价。基于时序差分的方法不需要玩到游戏结束，只需要在游戏的某一个状态 $s_{t}$ 的时候，采取动作 $a_{t}$ 得到奖励 $r_{t}$ ，接下来进入状态 $s_{t+1}$，就可以使用时序差分的方法。我们是这样训练的，我们把 $s_{t}$ 输入网络，因为把 $s_{t}$ 输入网络会得到 $V_{\pi}(s_{t})$，把 $s_{t+1}$ 输入网络会得到 $V_{\pi}(s_{t+1})$， $V_{\pi}(s_{t})$ 减 $V_{\pi}(s_{t+1})$ 的值应该是 $r_{t}$。我们希望它们相减的损失与 $r_{t}$ 接近，训练下去，更新 $V_{\pi}$ 的参数，我们就可以把 $V_{\pi}$ 函数学习出来。</p>
<p>蒙特卡洛方法与时序差分方法有什么差别呢？蒙特卡洛方法最大的问题就是方差很大。<strong>（时序差分就是将自举估计的回报代替蒙特卡洛更新式中的回报，这样我们不需要经过一个完整的episode就可以估算出回报）</strong></p>
<h2 id="动作价值函数"><a href="#动作价值函数" class="headerlink" title="动作价值函数"></a>动作价值函数</h2><p>状态价值函数的输入是一个状态，它根据状态计算出这个状态以后的期望的累积奖励是多少。动作价值函数的输入是一个状态-动作对，其指在某一个状态采取某一个动作，假设我们都使用策略 $\pi$ ，得到的累积奖励的期望值有多大。</p>
<p>$Q$ 函数有两种写法：</p>
<ul>
<li>输入是状态与动作，输出就是一个标量。这种 $Q$ 函数既适用于连续动作（动作是无法穷举的），又适用于离散动作。</li>
<li>输入是一个状态，输出就是多个值。这种 $Q$ 函数只适用于离散动作。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101521630.png" alt=""></p>
<p>有了 $Q$ 函数以后，我们把根据下式决定动作的策略称为 $\pi^{\prime}$，$\pi^{\prime}$ 一定比 $\pi$ 好。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101530257.png" alt=""></p>
<h2 id="目标网络"><a href="#目标网络" class="headerlink" title="目标网络"></a>目标网络</h2><p>所以我们会把其中一个 $Q$ 网络，通常是把下图右边的 $Q$ 网络固定住。在训练的时候，我们只更新左边的 $Q$ 网络的参数，而右边的 $Q$ 网络的参数会被固定。因为右边的 $Q$ 网络负责产生目标，所以被称为目标网络。因为目标网络是固定的，所以现在得到的目标 $r_{t} + Q_{\pi} (s_{t+1}, \pi (s_{t+1}))$ 的值也是固定的。我们只调整左边 $Q$ 网络的参数，它就变成一个回归问题。我们希望模型输出的值与目标越接近越好，这样会最小化它的均方误差（mean square error）</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101539738.png" alt=""></p>
<h2 id="探索"><a href="#探索" class="headerlink" title="探索"></a>探索</h2><p>像 $Q$ 函数中，如果我们采取的动作总是固定的，会遇到的问题就是这不是一个好的收集数据的方式。这个问题就是探索-利用窘境（exploration-exploitation dilemma） 问题，有两个方法可以解决这个问题： $\varepsilon$-贪心和玻尔兹曼探索（Boltzmann exploration）。</p>
<p>$\varepsilon$-贪心是指我们有 $1 − \varepsilon$ 的概率会按照 $Q$ 函数来决定动作，可写为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101543872.png" alt=""></p>
<p>还有一个方法称为玻尔兹曼探索。在玻尔兹曼探索中，我们假设对于任意的 $s$、 $a$， $Q(s, a) \geq 0$，因此 $a$ 被选中的概率与 $e^{Q(s,a)/T}$ 呈正比，其中， $T \gt 0$ 称为温度系数。如果 $T$ 很大，所有动作几乎以等概率选择（探索）；如果 $T$ 很小， $Q$ 值大的动作更容易被选中（利用）；如果 $T$ 趋于 $0$，我们就只选择最优动作。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101547561.png" alt=""></p>
<h2 id="经验回放"><a href="#经验回放" class="headerlink" title="经验回放"></a>经验回放</h2><p>经验回放会构建一个回放缓冲区（replay buffer），回放缓冲区又被称为回放内存（replay memory）。回放缓冲区是指现在有某一个策略 $\pi$ 与环境交互，它会去收集数据，我们把所有的数据放到一个数据缓冲区（buffer）里面，数据缓冲区里面存储了很多数据。</p>
<p>这么做有两个好处。第一个好处是，在进行强化学习的时候，往往最花时间的步骤是与环境交互，训练网络反而是比较快的。因为我们用 GPU 训练其实很快，真正花时间的往往是与环境交互。用回放缓冲区可以减少与环境交互的次数，因为在做训练的时候，经验不需要通通来自于某一个策略。一些过去的策略所得到的经验可以放在回放缓冲区里面被使用很多次，被反复的再利用，这样可以比较高效地采样经验。第二个好处是，在训练网络的时候，其实我们希望一个批量里面的数据越多样（diverse）越好。如果批量里面的数据都是同样性质的，我们训练下去，训练结果是容易不好的。如果批量里面都是一样的数据，训练的时候，性能会比较差。我们希望批量里的数据越多样越好。如果回放缓冲区里面的经验通通来自于不同的策略，我们采样到的一个批量里面的数据会是比较多样的。</p>
<h2 id="深度Q网络"><a href="#深度Q网络" class="headerlink" title="深度Q网络"></a>深度Q网络</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101552662.png" alt=""></p>
<h1 id="深度Q网络进阶技巧"><a href="#深度Q网络进阶技巧" class="headerlink" title="深度Q网络进阶技巧"></a>深度Q网络进阶技巧</h1><h2 id="双深度Q网络"><a href="#双深度Q网络" class="headerlink" title="双深度Q网络"></a>双深度Q网络</h2><p>在实现上， $Q$ 值往往是被高估的。</p>
<p>为什么 $Q$ 值总是被高估了？因为实际在训练的时候，如下式所示，我们要让左式与右式（目标）越接近越好。但目标的值很容易被设得太高，因为在计算目标的时候，我们实际上在做的，是看哪一个 $a$ 可以得到最大的 $Q$ 值，就把它加上去变成目标。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101601594.png" alt=""></p>
<p>例如，假设我们现在有 $4$ 个动作，本来它们得到的 $Q$ 值都是差不多的，它们得到的奖励也是差不多的。但是在估计的时候，网络是有误差的。如图（a）所示，假设是第一个动作被高估了，绿色代表是被高估的量，智能体就会选这个动作，就会选这个高估的 $Q$ 值来加上 $r_{t}$ 来当作目标。如图（b）所示，如果第四个动作被高估了，智能体就会选第四个动作来加上 $r_{t}$ 当作目标。所以智能体总是会选那个 $Q$ 值被高估的动作，总是会选奖励被高估的动作的 $Q$ 值当作最大的结果去加上 $r_{t}$ 当作目标，所以目标值总是太大。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101604354.png" alt=""></p>
<p>怎么解决目标值总是太大的问题呢？在DDQN里面，选动作的 $Q$ 函数与计算值的 $Q$ 函数不是同一个。在原来的深度 $Q$ 网络里面，我们穷举所有的 $a$，把每一个 $a$ 都代入 $Q$ 函数，看哪一个 $a$ 可以得到的 $Q$ 值最高，就把那个 $Q$ 值加上 $r_{t}$。但是在 DDQN 里面有两个 $Q$ 网络，第一个 $Q$ 网络 $Q$ 决定哪一个动作的 $Q$ 值最大（我们把所有的 $a$ 代入 $Q$ 函数中，看看哪一个 $a$ 的 $Q$ 值最大）。我们决定动作以后， $Q$ 值是用 $Q^{\prime}$ 算出来的。</p>
<p>DDQN 相较于原来的深度 $Q$ 网络的更改是最少的，它几乎没有增加任何的运算量，也不需要新的网络，因为原来就有两个网络。我们只需要做一件事：本来是用目标网络 $Q^{\prime}$ 找使 $Q$ 值最大的 $a$，现在改成用另外一个会更新的 $Q$ 网络来找使 $Q$ 值最大的 $a$。如果只选一个技巧，我们一般都会选 DDQN，因为其很容易实现。</p>
<h2 id="竞争深度Q网络"><a href="#竞争深度Q网络" class="headerlink" title="竞争深度Q网络"></a>竞争深度Q网络</h2><p>第二个技巧是竞争深度 $Q$ 网络（dueling DQN） ，相较于原来的深度 $Q$ 网络，它唯一的差别是改变了网络的架构。 $Q$ 网络输入状态，输出的是每一个动作的 $Q$ 值。原来的深度 $Q$ 网络直接输出 $Q$ 值，竞争深度 $Q$ 网络不直接输出 $Q$ 值，而是分成两条路径运算。第一条路径会输出一个标量 $V(s)$，因为它与输入 $s$ 是有关系的，所以称为 $V(s)$。第二条路径会输出一个向量 $A(s, a)$，它的每一个动作都有一个值。我们再把 $V(s)$ 和 $A(s, a)$ 加起来就可以得到 $Q$ 值 $Q(s, a)$。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101611233.png" alt=""></p>
<p>根据网络的参数， $V (s)$ 与 $A(s, a)$ 的值输出以后，就直接把它们加起来，所以其实不是修改 $Q$ 值。在学习网络的时候，假设我们希望 $Q$ 表格中的 $3$ 增加 $1$ 变成 $4$、 $−1$ 增加 $1$ 变成 $0$。最后我们在训练网络的时候，我们可能就不用修改 $A(s, a)$ 的值，就修改 $V (s)$ 的值，把 $V (s)$ 的值从 $0$ 变成 $1$。从 $0$ 变成 $1$ 有什么好处呢？本来只想修改两个值，但 $Q$ 表格中的第三个值也被修改了： $−2$ 变成了 $−1$。所以有可能我们在某一个状态下，只采样到这两个动作，没采样到第三个动作，但也可以更改第三个动作的 $Q$ 值。这样的好处就是我们不需要把所有的状态-动作对都采样，可以用比较高效的方式去估计 $Q$ 值。因为有时候我们更新的时候，不一定是更新 $Q$ 表格，而是只更新了 $V(s)$，但更新 $V(s)$ 的时候，只要修改 $V(s)$ 的值， $Q$ 表格的值也会被修改。竞争深度 $Q$ 网络是一个使用数据比较有效率的方法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101617996.png" alt=""></p>
<p>可能会有人认为使用竞争深度 $Q$ 网络会有一个问题，竞争深度 $Q$ 网络最后学习的结果可能是这样的：智能体就学到 $V(s)$ 等于 $0$， $A(s, a)$ 等于 $Q$，使用任何竞争深度 $Q$ 网络就没有任何好处，就和原来的深度 $Q$ 网络一样。为了避免这个问题出现，实际上我们要给 $A(s, a)$ 一些约束，让 $A(s, a)$ 的更新比较麻烦，让网络倾向于使用 $V (s)$ 来解决问题。<br>例如，我们有不同的约束，一个最直觉的约束是必须要让 $A(s, a)$ 的每一列的和都是 $0$，所以这边举的例子，列的和都是 $0$。如果这边列的和都是 $0$，我们就可以把 $V (s)$ 的值想成是上面 $Q$ 的每一列的平均值。这个平均值，加上 $A(s, a)$ 的值才会变成是 $Q$ 的值。所以假设在更新参数的时候，要让整个列一起被更新，更新 $A(s, a)$ 的某一列比较麻烦，所以我们就不会想要更新 $A(s, a)$ 的某一列。因为 $A(s, a)$ 的每一列的和都要是 $0$，所以我们无法让 $A(s, a)$ 的某列的值都加 $1$，这是做不到的，因为它的约束就是和永远都是 $0$，所以不可以都加 $1$，这时候就会强迫网络去更新 $V(s)$ 的值，让我们可以用比较有效率的方法去使用数据。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101625556.png" alt=""></p>
<h2 id="优先级经验回放"><a href="#优先级经验回放" class="headerlink" title="优先级经验回放"></a>优先级经验回放</h2><p>第三个技巧称为优先级经验回放（prioritized experience replay， PER）。假设有一些数据，我们之前采样过，发现这些数据的时序差分误差特别大（时序差分误差就是网络的输出与目标之间的差距），这代表我们在训练网络的时候，这些数据是比较不好训练的。既然比较不好训练，就应该给它们比较大的概率被采样到，即给它优先权（priority）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101626466.png" alt=""></p>
<h2 id="在蒙特卡洛方法和时序差分方法中取得平衡"><a href="#在蒙特卡洛方法和时序差分方法中取得平衡" class="headerlink" title="在蒙特卡洛方法和时序差分方法中取得平衡"></a>在蒙特卡洛方法和时序差分方法中取得平衡</h2><p>蒙特卡洛方法与时序差分方法各有优劣，因此我们可以在蒙特卡洛方法和时序差分方法中取得平衡，这个方法也被称为多步方法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101628249.png" alt=""></p>
<h2 id="噪声网络"><a href="#噪声网络" class="headerlink" title="噪声网络"></a>噪声网络</h2><p>噪声网络是指，每一次在一个回合开始的时候，在智能体要与环境交互的时候，智能体使用 $Q$ 函数来采取动作， $Q$ 函数里面就是一个网络，我们在网络的每一个参数上加上一个高斯噪声（Gaussian noise），就把原来的 $Q$ 函数变成 $\widetilde{Q}$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101630416.png" alt=""></p>
<p>这里要注意，在每个回合开始的时候，与环境交互之前，我们就采样噪声。接下来我们用固定的噪声网络玩游戏，直到游戏结束，才重新采样新的噪声，噪声在一个回合中是不能被改变的。 </p>
<h2 id="分布式Q函数"><a href="#分布式Q函数" class="headerlink" title="分布式Q函数"></a>分布式Q函数</h2><p>分布式 $Q$ 函数是对分布（distribution）建模，怎么做呢？如图a所示，在原来的 $Q$ 函数里面，假设我们只能采取 $a_{1}$、 $a_{2}$、 $a_{3}$ 这 $3$ 个动作，我们输入一个状态，输出 $3$ 个值。这 $3$ 个值分别代表 $3$ 个动作的 $Q$ 值，但是这些 $Q$ 值是一个分布的期望值。所以分布式 $Q$ 函数就是直接输出分布。实际上的做法如图b所示，假设分布的值就分布在某一个范围里面，比如 $−10 \sim 10$，把 $−10 \sim 10$ 拆成一个一个的长条。例如，每一个动作的奖励空间拆成 $5$ 个长条。假设奖励空间可以拆成 $5$ 个长条， $Q$ 函数的输出就是要预测我们在某一个状态采取某一个动作得到的奖励，其落在某一个长条里面的概率。所以绿色长条概率的和应该是 $1$，其高度代表在某一个状态采取某一个动作的时候，它落在某一个长条内的概率。绿色的代表动作 $a_{1}$，红色的代表动作 $a_{2}$，蓝色的代表动作 $a_{3}$。所以我们就可以用 $Q$ 函数去估计 $a_{1}$ 的分布、 $a_{2}$ 的分布、 $a_{3}$ 的分布。实际上在做测试的时候，我们选平均值最大的动作执行。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101638394.png" alt=""></p>
<h2 id="彩虹"><a href="#彩虹" class="headerlink" title="彩虹"></a>彩虹</h2><p>最后一个技巧称为彩虹（rainbow），如图所示，假设每个方法有一种自己的颜色（如果每一个单一颜色的线代表只用某一个方法），把所有的颜色组合起来，就变成“彩虹”，我们把原来的深度 $Q$ 网络也算作一种方法，故有 $7$ 种颜色。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101640614.png" alt=""></p>
<h1 id="针对连续动作的深度Q网络"><a href="#针对连续动作的深度Q网络" class="headerlink" title="针对连续动作的深度Q网络"></a>针对连续动作的深度Q网络</h1><p>深度 $Q$ 网络其实存在一些问题，最大的问题是它很难处理连续动作。 </p>
<h2 id="方案-1：对动作进行采样"><a href="#方案-1：对动作进行采样" class="headerlink" title="方案 1：对动作进行采样"></a>方案 1：对动作进行采样</h2><p>我们可以采样出 $N$ 个可能的 $a： \{a_{1}, a_{2}, · · · , a_{N}\}$ ，把它们一个一个地代入 $Q$ 函数，看谁的 $Q$ 值最大。这个方案不会太低效，因为我们在运算的时候会使用 GPU，一次把 $N$ 个连续动作都代入 $Q$ 函数，一次得到 $N$ 个 $Q$ 值，看谁最大。当然这不是一个非常精确的方案，因为我们没有办法进行太多的采样，所以估计出来的 $Q$ 值、最后决定的动作可能不是非常精确。</p>
<h2 id="方案-2：梯度上升"><a href="#方案-2：梯度上升" class="headerlink" title="方案 2：梯度上升"></a>方案 2：梯度上升</h2><p>既然要解决的是一个优化问题（optimization problem），我们就要最大化目标函数（objective function）。要最大化目标函数，我们就可以用梯度上升。我们把 $a$ 当作参数，要找一组 $a$ 去最大化 $Q$ 函数，就用梯度上升去更新 $a$ 的值，最后看看能不能找到一个 $a$ 最大化 $Q$ 函数（目标函数）。但我们会遇到全局最大值（global maximum）的问题，不一定能够找到最优的结果，而且运算量显然很大，因为要迭代地更新 $a$，训练一个网络就很花时间了。如果我们使用梯度上升的方案来处理连续的问题，每次决定采取哪一个动作的时候，还要训练一次网络，显然运算量是很大的。</p>
<h2 id="方案-3：设计网络架构"><a href="#方案-3：设计网络架构" class="headerlink" title="方案 3：设计网络架构"></a>方案 3：设计网络架构</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101649780.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312101649026.png" alt=""></p>
<p>我们要怎么找到一个 $a$ 来最大化 $Q$ 值呢？因为 $(a −\mu(s))^{T}\Sigma(s)(a −\mu(s))$ 一定是正的，它前面有一个负号，假设我们不看负号，所以第一项 $(a − \mu(s))^{T}\Sigma(s)(a − \mu(s))$ 的值越小，最终的 $Q$ 值就越大。因为我们是把 $V(s)$ 减掉第一项，所以第一项的值越小，最后的 $Q$ 值就越大。怎么让第一项的值最小呢？我们直接令 $\mu(s)$ 等于 $a$，让第一项变成 $0$，就可以让第一项的值最小。因此，令 $\mu(s)$ 等于 $a$，我们就可以得到最大值，解决 $\arg \max$ 操作的问题就变得非常容易。</p>
<h2 id="方案-4：不使用深度-Q-网络"><a href="#方案-4：不使用深度-Q-网络" class="headerlink" title="方案 4：不使用深度 Q 网络"></a>方案 4：不使用深度 Q 网络</h2><p>第 4 个方案就是不使用深度 $Q$ 网络，用深度 $Q$ 网络处理连续动作是比较麻烦的。我们将基于策略的方法——PPO 和基于价值的方法——深度 $Q$ 网络结合在一起，就可以得到演员-评论员的方法。</p>
<h1 id="演员-评论员算法"><a href="#演员-评论员算法" class="headerlink" title="演员-评论员算法"></a>演员-评论员算法</h1><p>演员-评论员算法是一种结合策略梯度和时序差分学习的强化学习方法，其中，演员是指策略函数 $\pi_{\theta}(a|s)$，即学习一个策略以得到尽可能高的回报。评论员是指价值函数 $V_{\pi}(s)$，对当前策略的值函数进行估计，即评估演员的好坏。借助于价值函数，演员-评论员算法可以进行单步参数更新，不需要等到回合结束才进行更新。在演员-评论员算法里面，最知名的算法就是异步优势演员-评论员算法。如果我们去掉异步，则为优势演员-评论员（advantage actor-critic，A2C）算法。 A2C 算法又被译作优势演员-评论员算法。如果我们加了异步，变成异步优势演员-评论员算法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404182238004.png" alt=""></p>
<h2 id="策略梯度回顾"><a href="#策略梯度回顾" class="headerlink" title="策略梯度回顾"></a>策略梯度回顾</h2><p>在更新策略参数 $\theta$ 的时候，我们可以通过下式来计算梯度：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112113051.png" alt=""></p>
<p>上式表示我们首先通过智能体与环境的交互，可以计算出在某一个状态 $s$ 采取某一个动作 $a$ 的概率 $p_{\theta}(a_{t}|s_{t})$。接下来，我们计算在某一个状态 $s$ 采取某一个动作 $a$ 之后直到游戏结束的累积奖励。</p>
<p>我们使用 $G$ 表示累积奖励， $G$ 是非常不稳定的。因为交互的过程本身具有随机性，所以在某一个状态 $s$ 采取某一个动作 $a$ 时计算得到的累积奖励，每次结果都是不同的，因此 $G$ 是一个随机变量。</p>
<h2 id="深度Q网络回顾"><a href="#深度Q网络回顾" class="headerlink" title="深度Q网络回顾"></a>深度Q网络回顾</h2><p>我们能不能让整个训练过程变得稳定，能不能直接估测随机变量 $G$ 的期望值？ 我们直接用一个网络去估测在状态 $s$ 采取动作 $a$ 时 $G$ 的期望值。如果这样是可行的，那么在随后的训练中我们就用期望值代替采样的值，这样就会让训练变得更加稳定。</p>
<p>怎么使用期望值代替采样的值呢？这里就需要引入基于价值的（value-based）的方法。基于价值的方法就是深度 $Q$ 网络。深度 $Q$ 网络有两种函数，有两种评论员。如下图所示，第一种评论员是 $V_{\pi}(s)$。即假设演员的策略是 $\pi$，使用 $\pi$ 与环境交互，当智能体看到状态 $s$ 时，接下来累积奖励的期望值是多少。第二种评论员是 $Q_{\pi}(s, a)$。 $Q_{\pi}(s, a)$ 把 $s$ 与 $a$ 当作输入，它表示在状态 $s$ 采取动作 $a$，接下来用策略 $\pi$ 与环境交互，累积奖励的期望值是多少。 $V_{\pi}$ 接收输入 $s$，输出一个标量。 $Q_{\pi}$ 接收输入 $s$，它会给每一个 $a$ 都分配一个 $Q$ 值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112155776.png" alt=""></p>
<h2 id="优势演员-评论员算法"><a href="#优势演员-评论员算法" class="headerlink" title="优势演员-评论员算法"></a>优势演员-评论员算法</h2><p>如图所示，随机变量 $G$ 的期望值正好就是 $Q$ 值，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112156592.png" alt=""></p>
<p>此也为 $Q$ 函数的定义。 $Q$ 函数的定义就是在某一个状态 $s$，采取某一个动作 $a$，假设策略是 $\pi$ 的情况下所能得到的累积奖励的期望值，即 $G$ 的期望值。累积奖励的期望值就是 $G$ 的期望值。</p>
<p>有不同的方法表示基线，一个常见的方法是用价值函数 $V_{\pi_{\theta}}(s^{n}_{t})$ 来表示基线。价值函数的定义为，假设策略是 $\pi$，其在某个状态 $s$ 一直与环境交互直到游戏结束，期望奖励有多大。 $V_{\pi_{\theta}}(s^{n}_{t})$ 没有涉及动作， $Q_{\pi_{\theta}}(s^{n}_{t},a^{n}_{t})$ 涉及动作。$V_{\pi_{\theta}}(s^{n}_{t})$ 是 $Q_{\pi_{\theta}}(s^{n}_{t},a^{n}_{t})$ 的期望值， $Q_{\pi_{\theta}}(s^{n}_{t},a^{n}_{t})-V_{\pi_{\theta}}(s^{n}_{t})$ 会有正有负，所以 $\sum_{t^{\prime}=t}^{T_{n}}\gamma^{t^{\prime}-t}r_{t^{\prime}}^{n}-b$ 这一项就会有正有负。所以我们就把策略梯度里面 $\sum_{t^{\prime}=t}^{T_{n}}\gamma^{t^{\prime}-t}r_{t^{\prime}}^{n}-b$ 这一项换成了优势函数 $A^{\theta}(s^{n}_{t},a^{n}_{t})$，即 $Q_{\pi_{\theta}}(s^{n}_{t},a^{n}_{t})-V_{\pi_{\theta}}(s^{n}_{t})$。因此该算法称为优势演员-评论员算法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112225437.png" alt=""></p>
<p>如果我们这么实现，有一个缺点，即我们需要估计两个网络——$Q$ 网络和 $V$ 网络，估计不准的风险就变成原来的两倍。事实上，在演员-评论员算法中，我们可以只估计网络 $V$，并利用 $V$ 的值来表示 $Q$ 的值， $Q_{\pi}(s^{n}_{t},a^{n}_{t})$ 可以写成 $r_{t}^{n}+V_{\pi}(s^{n}_{t+1})$ 的期望值，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112228101.png" alt=""></p>
<p>在状态 $s$ 采取动作 $a$，我们会得到奖励 $r$，进入状态 $s_{t+1}$。但是我们会得到什么样的奖励 $r$，进入什么样的状态 $s_{t+1}$，这件事本身是有随机性的。所以要把 $r_{t}^{n}+V_{\pi}(s^{n}_{t+1})$ 取期望值才会等于 $Q$ 函数的值。<strong>但我们现在把取期望值去掉</strong>，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112238182.png" alt=""></p>
<p>我们就可以把 $Q$ 函数的值用 $r_{t}^{n}+V_{\pi}(s^{n}_{t+1})$ 取代，可得</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112240086.png" alt=""></p>
<p>把取期望值去掉的好处就是我们不需要估计 $Q$ 了，只需要估计 $V$ 。但与此同时我们会引入一个随机的参数 $r$。 $r$ 是有随机性的，它是一个随机变量，但是 $r$ 相较于累积奖励 $G$ 是一个较小的值，因为它是某一个步骤得到的奖励，而 $G$ 是所有未来会得到的奖励的总和， $G$ 的方差比较大。 $r$ 虽然也有一些方差，但它的方差比 $G$ 的要小。所以把原来方差比较大的 $G$ 换成方差比较小的 $r$ 也是合理的。优势演员-评论员算法的流程如图所示。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112243886.png" alt=""></p>
<p>我们有一个 $\pi$，有个初始的演员与环境交互，先收集资料。在策略梯度方法里收集资料以后，就来更新策略。但是在演员-评论员算法里面，我们不是直接使用那些资料来更新策略。我们先用这些资料去估计价值函数，可以用时序差分方法或蒙特卡洛方法来估计价值函数。接下来，我们再基于价值函数，使用下式更新 $\pi$。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112244924.png" alt=""></p>
<p>实现优势演员-评论员算法的时候，有两个一定会用到的技巧。第一个技巧是，我们需要估计两个网络： $V$ 网络和策略的网络（也就是演员）。评论员网络 $V_{\pi}(s)$ 接收一个状态，输出一个标量。演员的策略 $\pi(s)$ 接收一个状态，如果动作是离散的，输出就是一个动作的分布，如果动作是连续的，输出就是一个连续的向量。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312112250310.png" alt=""></p>
<p>第二个技巧是我们需要探索的机制。在演员-评论员算法中，有一个常见的探索的方法是对 $\pi$ 输出的分布设置一个约束。这个约束用于使分布的熵（entropy）不要太小，也就是希望不同的动作被采用的概率平均一些。这样在测试的时候，智能体才会多尝试各种不同的动作，才会把环境探索得比较好，从而得到比较好的结果。</p>
<h3 id="REINFORCE和A2C的区别"><a href="#REINFORCE和A2C的区别" class="headerlink" title="REINFORCE和A2C的区别"></a>REINFORCE和A2C的区别</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404182204930.png" alt=""></p>
<h2 id="异步优势演员-评论员算法"><a href="#异步优势演员-评论员算法" class="headerlink" title="异步优势演员-评论员算法"></a>异步优势演员-评论员算法</h2><p>异步优势演员-评论员算法同时使用很多个进程（worker），每一个进程就像一个影分身，最后这些影分身会把所有的经验值集合在一起。如果我们没有很多 CPU，不好实现异步优势演员-评论员算法，但可以实现优势演员-评论员算法。</p>
<p>异步优势演员-评论员算法一开始有一个全局网络（global network）。全局网络包含策略网络和价值网络，这两个网络是绑定在一起的，它们的前几个层会被绑在一起。假设全局网络的参数是 $\theta_{1}$，我们使用多个进程，每个进程用一张 CPU 去跑。接下来演员就与环境交互，每一个演员与环境交互的时候，都要收集到比较多样的数据。每一个演员与环境交互完之后，我们就会计算出梯度。计算出梯度以后，要用梯度去更新参数。我们就计算一下梯度，用梯度去更新全局网络的参数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161337398.png" alt=""></p>
<h2 id="路径衍生策略梯度"><a href="#路径衍生策略梯度" class="headerlink" title="路径衍生策略梯度"></a>路径衍生策略梯度</h2><p>这个方法可以看成深度 $Q$ 网络解连续动作的一种特别的方法，也可以看成一种特别的演员-评论员的方法。一般的演员-评论员算法的评论员就是输入状态或输入状态-动作对，给演员一个值，所以对演员来说，它只知道它做的这个动作到底是好还是不好。但在路径衍生策略梯度里面，评论员会直接告诉演员采取什么样的动作才是好的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161356657.png" alt=""></p>
<p>路径衍生策略梯度算法如图所示，假设我们学习了一个 $Q$ 函数， $Q$ 函数的输入是 $s$ 与 $a$，输出是 $Q^{\pi}(s, a)$。接下来，我们要学习一个演员，这个演员的工作就是解决 $\arg \max$ 的问题，即输入一个状态 $s$，希望可以输出一个动作 $a$。 $a$ 被代入 $Q$ 函数以后，它可以让 $Q^{\pi}(s,a)$ 尽可能大，即</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161356414.png" alt=""></p>
<h2 id="与生成对抗网络的联系"><a href="#与生成对抗网络的联系" class="headerlink" title="与生成对抗网络的联系"></a>与生成对抗网络的联系</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161405257.png" alt=""></p>
<h1 id="稀疏奖励"><a href="#稀疏奖励" class="headerlink" title="稀疏奖励"></a>稀疏奖励</h1><p>如果环境中的奖励非常稀疏，强化学习的问题就会变得非常困难，但是人类可以在非常稀疏的奖励上去学习。人生通常多数的时候，就只是活在那里，都没有得到什么奖励或是惩罚。但是，人还是可以采取各种各样的行为。所以，一个真正厉害的人工智能应该能够在稀疏奖励的情况下也学到怎么与环境交互。</p>
<h2 id="设计奖励"><a href="#设计奖励" class="headerlink" title="设计奖励"></a>设计奖励</h2><p>第一个方向是设计奖励（reward shaping）。环境有一个固定的奖励，它是真正的奖励，但是为了让智能体学到的结果是我们想要的，所以我们刻意设计了一些奖励来引导智能体。</p>
<p>如果我们把小孩当成一个智能体，他可以采取两个动作：玩耍或者学习。如果他玩耍，在下一个时间点就会得到奖励 $1$。但是他在月考的时候，成绩可能会很差，所以在 $100$ 个小时之后，他会得到奖励 $−100$。他也可以决定要学习，在下一个时间点，因为他没有玩耍，所以觉得很不爽，所以得到奖励 $−1$。但是在 $100$ 个小时后，他可以得到奖励 $100$。对于一个小孩来说，他可能就会想要采取玩耍的动作而不是学习的动作。我们计算的是累积奖励，但也许对小孩来说，折扣因子会很大，所以他就不太在意未来的奖励。而且因为他是一个小孩，还没有很多经验，所以他的 $Q$ 函数估计是非常不精准的。所以要他去估计很远以后会得到的累积奖励，他是估计不出来的。这时候大人就要引导他，对他说：“如果你学习，我就给你一根棒棒糖。”对小孩来说，下一个时间点他得到的奖励就变成正的，他也许就会认为学习是比玩耍好的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161414768.png" alt=""></p>
<p>设计奖励是有问题的，因为我们需要领域知识（domain knowledge）。例如，如图所示，机器人想要学会把蓝色的板子从柱子穿过。机器人很难学会，我们可以设计奖励。一个貌似合理的说法是，蓝色的板子离柱子越近，奖励越大。但是机器人靠近的方式会有问题，它会用蓝色的板子打柱子。而机器人要把蓝色板子放在柱子上面，才能让蓝色板子穿过柱子。因此，这种设计奖励的方式是有问题的。至于哪种设计奖励的方式有问题，哪种设计奖励的方式没问题，会变成一个领域知识，是我们要去调整的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161417520.png" alt=""></p>
<h2 id="好奇心"><a href="#好奇心" class="headerlink" title="好奇心"></a>好奇心</h2><p>接下来介绍各种我们可以自己加入并且一般看起来是有用的奖励。例如，一种技术是给智能体加上好奇心（curiosity），称为好奇心驱动的奖励（curiosity driven reward）。如图所示，我们输入某个状态和某个动作到奖励函数中，奖励函数就会输出在这个状态采取这个动作会得到的奖励，总奖励越大越好。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161420949.png" alt=""></p>
<p>在好奇心驱动的技术里面，我们会加上一个新的奖励函数——内在好奇心模块（intrinsic curiosity module， ICM） ，它用于给智能体加上好奇心。内在好奇心模块需要 3 个输入：状态 $s_{1}$、动作 $a_{1}$ 和状态 $s_{2}$。根据输入，它会输出另外一个奖励 $r_{1}^{i}$。对智能体来说，总奖励并不是只有 $r$，还有 $r^{i}$。它不是只把所有的 $r$ 都加起来，它还把所有 $r^{i}$ 加起来当作总奖励。所以在与环境交互的时候，它不是只希望 $r$ 越大越好，它还同时希望 $r^{i}$ 越大越好，它希望从内在好奇心模块里面得到的奖励越大越好。内在好奇心模块代表一种好奇心。</p>
<p>在内在好奇心模块里面，我们有一个网络，这个网络会接收输入 $a_{t}$ 与 $s_{t}$，输出 $\hat{s}_{t+1}$，也就是这个网络根据 $a_{t}$ 和 $s_{t}$ 去预测 $\hat{s}_{t+1}$。然后再看这个网络的预测 $\hat{s}_{t+1}$ 与真实的情况 $s_{t+1}$ 的相似度，越不相似得到的奖励就越大。所以奖励 $r_{t}^{i}$ 的意思是，未来的状态越难被预测，得到的奖励就越大。这就是鼓励智能体去冒险、去探索，现在采取这个动作，未来会发生什么越难被预测，这个动作的奖励就越大。</p>
<p>怎么让智能体知道什么事情是真正重要的呢？我们要加上另外一个模块，我们要学习一个特征提取器（feature extractor）。如图所示，黄色的格子代表特征提取器，它输入一个状态，输出一个特征向量来代表这个状态，我们期待特征提取器可以把没有意义的画面，状态里面没有意义的东西过滤掉，比如风吹草动、白云的飘动以及树叶飘动。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161438521.png" alt=""></p>
<h2 id="课程学习"><a href="#课程学习" class="headerlink" title="课程学习"></a>课程学习</h2><p>第二个方向是课程学习（curriculum learning） 。具体来说，课程学习是指我们为智能体的学习做规划，给他“喂”的训练数据是有顺序的，通常都是由简单到难的。</p>
<p>有一个比较通用的方法： 逆向课程生成（reverse curriculum generation）。我们可以用一个比较通用的方法来帮智能体设计课程。假设我们一开始有一个状态 $s_{g}$，这是黄金状态（gold state），也就是最后最理想的结果。接下来我们根据黄金状态去找其他的状态，这些其他的状态与黄金状态是比较接近的，记为 $s_{1}$。接下来，智能体再从 $s_{1}$ 开始与环境交互，看它能不能够达到黄金状态 $s_{g}$，在每一个状态下，智能体与环境交互的时候，都会得到一个奖励。接下来，我们把奖励特别极端的情况去掉。奖励特别极端的情况的意思是这些情况太简单或是太难了。接下来，再根据这些奖励适中的情况采样出更多的状态。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161451592.png" alt=""></p>
<h2 id="分层强化学习"><a href="#分层强化学习" class="headerlink" title="分层强化学习"></a>分层强化学习</h2><p>第三个方向是分层强化学习（hierarchical reinforcement learning， HRL）。分层强化学习是指，我们有多个智能体，一些智能体负责比较高级的东西，它们负责定目标，定完目标以后，再将目标分配给其他的智能体，让其他智能体来执行目标。</p>
<p>分层强化学习是指将一个复杂的强化学习问题分解成多个小的、简单的子问题，每个子问题都可以单独用马尔可夫决策过程来建模。这样，我们可以将智能体的策略分为高层次策略和低层次策略，高层次策略根据当前状态决定如何执行低层次策略。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202312161456145.png" alt=""></p>
<h1 id="模仿学习"><a href="#模仿学习" class="headerlink" title="模仿学习"></a>模仿学习</h1><p>模仿学习（imitation learning，IL） 讨论的问题是，假设我们连奖励都没有，要怎么进行更新以及让智能体与环境交互呢？</p>
<h2 id="行为克隆"><a href="#行为克隆" class="headerlink" title="行为克隆"></a>行为克隆</h2><p>行为克隆与监督学习较为相似。专家做什么，智能体就做一模一样的事，这就称为行为克隆。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281429710.png" alt=""></p>
<p>行为克隆虽然非常简单，但它的问题是，如果我们只收集专家的示范，可能我们看过的观测以及状态是非常有限的。假设我们要学习自动驾驶一辆汽车通过弯道。如果是专家，它将顺着红线通过弯道。但假设智能体很笨，它开车的时候撞墙了，它永远不知道撞墙这种状况要怎么处理。因为训练数据里面从来没有撞墙相关的数据，所以它根本就不知道撞墙这种情况要怎么处理。打电玩也是一样的，让专家去玩《超级马里奥》，专家可能非常强，它从来不会跳不上水管，所以智能体根本不知道跳不上水管时要怎么处理。所以仅仅使用行为克隆是不够的，只观察专家的示范是不够的，还需要结合另一个方法：<strong>数据集聚合（dataset aggregation，DAgger）</strong>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281431999.png" alt=""></p>
<p>我们希望收集更多样的数据，而不是只收集专家所看到的观测。我们希望能够收集专家在各种极端的情况下所采取的行为。如图所示，以自动驾驶汽车为例，一开始我们有演员 $\theta_{1}$，并且让其去驾驶这辆车，同时车上坐了一个专家。这个专家会不断地告诉智能体，如果在这个情境里面，我会怎么样开。所以 $\theta_{1}$ 自己开自己的，但是专家会不断地表达它的想法。比如，一开始的时候，专家可能说往前走。在拐弯的时候，专家可能就会说往右转。但 $\theta_{1}$ 是不管专家的指令的，所以它会继续撞墙。虽然专家说往右转，但是不管他怎么下指令都是没有用的， $\theta_{1}$ 会做自己的事情，因为我们要做的记录的是说，专家在 $\theta_{1}$ 看到这种观测的情况下，它会做什么样的反应。这个方法显然是有一些问题的，因为我们每开一次自动驾驶汽车就会牺牲一个专家。我们用这个方法，牺牲一个专家以后，就会知道，人类在快要撞墙的时候，会采取什么样的行为。再用这些数据训练新的演员 $\theta_{2}$，并反复进行这个过程，这个方法称为数据集聚合。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281436975.png" alt=""></p>
<p>行为克隆还有一个问题：智能体会完全模仿专家的行为，不管专家的行为是否有道理，就算没有道理，没有什么用，就算这是专家本身的习惯，智能体也会把它记下来。例如，如图所示，在学习中文的时候，老师有语音、行为和知识，但其实只有语音部分是重要的，知识部分是不重要的。也许智能体只能学一件事，如果它只学到了语音，没有问题。如果它只学到了手势，这样就有问题了。所以让智能体学习什么东西是需要模仿的、什么东西是不需要模仿的，这件事情是很重要的。而单纯的行为克隆没有学习这件事情，因为智能体只是复制专家所有的行为而已，它不知道哪些行为是重要的，是对接下来有影响的，哪些行为是不重要的、是对接下来没有影响的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281438171.png" alt=""></p>
<p>行为克隆的问题还在于：我们使用行为克隆的时候，训练数据与测试数据是不匹配的。我们可以用数据集聚合的方法来缓解这个问题。</p>
<h2 id="逆强化学习"><a href="#逆强化学习" class="headerlink" title="逆强化学习"></a>逆强化学习</h2><p>为什么叫逆强化学习？因为原来的强化学习里，有一个环境和一个奖励函数。如图所示，根据环境和奖励函数，通过强化学习这一技术，我们会找到一个演员，并会学习出一个最优演员。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281441117.png" alt=""></p>
<p>但逆强化学习刚好是相反的，如图所示，它没有奖励函数，只有一些专家的示范，但还是有环境的。逆强化学习假设现在有一些专家的示范，用 $\widehat{\tau}$ 来代表专家的示范。如果是在玩电玩，每一个 $\tau$ 就是一个很会玩电玩的人玩一场游戏的记录。如果是自动驾驶汽车，就是人开自动驾驶汽车的记录。这些就是专家的示范，每一个 $\tau$ 是一个轨迹。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281457194.png" alt=""></p>
<p>把所有专家的示范收集起来，再使用逆强化学习这一技术。使用逆强化学习技术的时候，智能体是可以与环境交互的。但它得不到奖励，它的奖励必须从专家那里推出来。有了环境和专家的示范以后，可以反推出奖励函数。强化学习是由奖励函数反推出什么样的动作、演员是最好的。逆强化学习则反过来，我们有专家的示范，我们相信它是不错的，我就反推，专家是因为什么样的奖励函数才会采取这些行为。有了奖励函数以后，接下来，我们就可以使用一般的强化学习的方法去找出最优演员。所以逆强化学习是先找出奖励函数，找出奖励函数以后，再用强化学习找出最优演员。</p>
<p>逆强化学习实际上是怎么做的呢？如图所示，首先，我们有一个专家 $\widehat{ \theta}$，这个专家与环境交互，产生很多轨迹 $\{\hat{\tau}_{1}, \hat{\tau}_{2}, \cdots, \hat{\tau}_{N}\}$。如果我们玩游戏，就让某个电玩高手去玩 $N$ 场游戏，把 $N$ 场游戏的状态与动作的序列都记录下来。接下来，我们有一个演员 $\theta$，一开始演员很烂，这个演员也与环境交互。它也去玩了 $N$ 场游戏，它也有 $N$ 场游戏的记录。接下来，我们要反推出奖励函数。怎么反推出奖励函数呢？原则就是专家永远是最棒的，是先射箭，再画靶的概念。专家去玩一玩游戏，得到这些游戏的记录，演员也去玩一玩游戏，得到这些游戏的记录。接下来，我们要定一个奖励函数，这个奖励函数的原则就是专家得到的分数要比演员得到的分数高（先射箭，再画靶），所以我们就学习出一个奖励函数，这个奖励函数会使专家得到的奖励大于演员得到的奖励。有了新的奖励函数以后，我们就可以使用一般强化学习的方法学习一个演员，这个演员会针对奖励函数最大化它的奖励。它也会采取一些的动作。但是这个演员虽然可以最大化奖励函数，采取大量的动作，得到大量游戏的记录。<br>但接下来，我们更改奖励函数。这个演员就会很生气，它已经可以在这个奖励函数得到高分。但是它得到高分以后，我们就改奖励函数，仍然让专家可以得到比演员更高的分数。这就是逆强化学习。有了新的奖励函数以后，根据这个新的奖励函数，我们就可以得到新的演员，新的演员再与环境交互。它与环境交互以后，我们又会重新定义奖励函数，让专家得到的奖励比演员的大。<br>怎么让专家得到的奖励大过演员呢？如图所示，我们在学习的时候，奖励函数也许就是神经网络。神经网络的输入为 $\tau$，输出就是应该要给 $\tau$ 的分数。或者假设我们觉得输入整个 $\tau$ 太难了，因为 $\tau$ 是 $s$ 和 $a$ 的一个很长的序列。也许就向它输入一个 $s$ 和 $a$ 的对，它会输出一个实数。把整个 $\tau$ 会得到的实数加起来就得到 $R(\tau)$。在训练的时候，对于 $\{\hat{\tau}_{1}, \hat{\tau}_{2}, \cdots, \hat{\tau}_{N}\}$，我们希望它输出的 $R$ 值越大越好。对于$\{\tau_{1}, \tau_{2}, \cdots, \tau_{N}\}$，我们就希望 $R$ 值越小越好。<br>什么可以被称为一个最好的奖励函数呢？最后我们学习出来的奖励函数应该是专家和演员在这个奖励函数上都会得到一样高的分数。最终的奖励函数无法分辨出谁应该会得到比较高的分数。通常在训练的时候，我们会迭代地去做。最早的逆强化学习对奖励函数有些限制，它是假设奖励函数是线性的（linear）。如果奖励函数是线性，我们可以证明这个算法会收敛（converge）。但是如果奖励函数不是线性的，我们就无法证明它会收敛。</p>
<p>逆强化学习的框架如下图所示，其实我们只要把逆强化学习中的演员看成生成器，把奖励函数看成判别器，它就是生成对抗网络。所以逆强化学习会不会收敛就等于生成对抗网络会不会收敛。如果我们已经实现过，就会知道逆强化学习不一定会收敛。但除非我们对 $R$ 执行一个非常严格的限制，否则如果 $R$ 是一个一般的网络，我们就会有很大的麻烦。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281524563.png" alt=""></p>
<p>我们可以把逆强化学习与生成对抗网络详细地比较一下。如图所示，在生成对抗网络里面，我们有一系列很好的图、一个生成器和一个判别器。一开始，生成器不知道要产生什么样的图，它就会乱画。判别器的工作就是给画的图打分，专家画的图得高分，生成器画的图得低分。生成器会想办法去骗过判别器，生成器希望判别器也给它画的图打高分。整个过程与逆强化学习是一模一样的。专家画的图就是专家的示范。生成器就是演员，生成器画很多图，演员与环境交互，产生很多轨迹。演员与环境交互的记录其实就等价于生成对抗网络里面的这些图。然后我们学习一个奖励函数。奖励函数就是判别器。奖励函数要给专家的示范打高分，给演员交互的结果打低分。接下来，演员会想办法，从已经学习出的奖励函数中得到高分，然后迭代地循环。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281526816.png" alt=""></p>
<h2 id="第三人称视角模仿学习"><a href="#第三人称视角模仿学习" class="headerlink" title="第三人称视角模仿学习"></a>第三人称视角模仿学习</h2><p>机器人必须了解到当它是第三人称视角的时候，看到另外一个人在打高尔夫球，与它实际上自己去打高尔夫球的视角显然是不一样的。但它怎么把它是第三人视角所观察到的经验泛化到它是第一人称视角的时候所采取的行为，这就需要用到第三人称视角模仿学习（third person imitation learning）技术。</p>
<p>第三人称视角模仿学习技术其实不只用到了模仿学习，它还用到了领域对抗训练（domainadversarial training）。领域对抗训练也是一种生成对抗网络的技术。我们希望有一个特征提取器，有两幅不同领域（domain）的图像，通过特征提取器以后，无法分辨出图像来自哪一个领域。第一人称视角和第三人称视角模仿学习用的技术是一样的，希望学习一个特征提取器，智能体在第三人称的时候与它在第一人称的时候的视角其实是一样的，就是把最重要的东西抽出来就好了。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281532119.png" alt=""></p>
<h2 id="序列生成和聊天机器人"><a href="#序列生成和聊天机器人" class="headerlink" title="序列生成和聊天机器人"></a>序列生成和聊天机器人</h2><p>我们其实可以把句子生成（sentence generation）或聊天机器人理解为模仿学习。如图所示，机器在模仿人写句子，我们在写句子的时候，将写下的每一个字都想成一个动作，所有的字合起来就是一个回合。例如，句子生成里面，我们会给机器看很多人类写的字。如果要让机器学会写诗，就要给它看唐诗三百首。人类写的字其实就是专家的示范。每一个词汇其实就是一个动作。机器做句子生成的时候，其实就是在模仿专家的轨迹。聊天机器人也是一样的，在聊天机器人里面我们会收集到很多人交互对话的记录，这些就是专家的示范。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281535491.png" alt=""></p>
<p>如果我们单纯用最大似然（maximum likelihood）这个技术来最大化会得到似然（likelihood），这其实就是行为克隆。行为克隆就是看到一个状态，接下来预测我们会得到什么样的动作，有一个标准答案（ground truth）告诉机器什么样的动作是最好的。在做似然的时候也是一样的，给定句子已经产生的部分，接下来机器要预测写哪一个字才是最好的。所以，其实最大似然在做序列生成（sequence generation）的时候，它对应到模仿学习里面就是行为克隆。只有最大似然是不够的，我们想要用序列生成对抗网络（sequence GAN）。其实序列生成对抗网络对应逆强化学习，逆强化学习就是一种生成对抗网络的技术。我们把逆强化学习的技术放在句子生成、聊天机器人里面，其实就是序列生成对抗网络与它的种种变形。</p>
<h2 id="模仿学习和离线强化学习的区别"><a href="#模仿学习和离线强化学习的区别" class="headerlink" title="模仿学习和离线强化学习的区别"></a>模仿学习和离线强化学习的区别</h2><ul>
<li>现有的一些Offline RL算法建立在标准的off-policy RL算法之上，这些算法倾向于优化某种形式的Bellman方程或TD差分误差；而IL算法则更多是监督学习技巧的利用（也有一些工作结合了强化学习的优化方法）</li>
<li>大多数IL问题假设有一个最优的或一个高性能的专家来提供数据；而Offline RL可能需要从次优的数据中进行学习</li>
<li>大多数IL问题没有奖励（reward）的概念；而Offline RL需要显式考虑reward</li>
<li>一些IL问题要求数据被标记为专家经验和非专家经验，而Offline RL不做这个假设</li>
</ul>
<h1 id="深度确定性策略梯度"><a href="#深度确定性策略梯度" class="headerlink" title="深度确定性策略梯度"></a>深度确定性策略梯度</h1><h2 id="离散动作与连续动作的区别"><a href="#离散动作与连续动作的区别" class="headerlink" title="离散动作与连续动作的区别"></a>离散动作与连续动作的区别</h2><p>离散动作与连续动作是相对的概念，一个是可数的，一个是不可数的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281853834.png" alt=""></p>
<p>对于这些连续的动作， $Q$ 学习、深度 $Q$ 网络等算法是没有办法处理的。那我们怎么输出连续的动作呢？这个时候，“万能”的神经网络又出现了。如图所示，在离散动作的场景下，比如我们输出上、下或是停止这几个动作。有几个动作，神经网络就输出几个概率值，我们用 $\pi_{\theta}(a_{t}|s_{t})$ 来表示这个随机性的策略。在连续的动作场景下，比如我们要输出机械臂弯曲的角度，我们就输出一个具体的浮点数。我们用 $\mu_{\theta}(s_{t})$ 来代表这个确定性的策略。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281859845.png" alt=""></p>
<p>我们再对随机性策略与确定性策略进行解释。对随机性策略来说，输入某一个状态 $s$，采取某一个动作的可能性并不是百分之百的，而是有一个概率的（就好像抽奖一样），根据概率随机抽取一个动作。而对于确定性策略来说，它不受概率的影响。当神经网络的参数固定之后，输入同样的状态，必然输出同样的动作，这就是确定性策略。</p>
<p>要输出离散动作，我们就加一个 $softmax$ 层来确保所有的输出是动作概率，并且所有的动作概率和为 $1$。要输出连续动作，我们一般可以在输出层加一层 $tanh$ 函数。$tanh$ 函数的作用就是把输出限制到 $[−1,1]$ 。我们得到输出后，就可以根据实际动作的范围将其缩放，再输出给环境。比如神经网络输出一个浮点数 $2.8$，经过 $tanh$ 函数之后，它就可以被限制在 $[−1,1]$ 之间，输出 $0.99$。假设小车速度的范围是 $[−2,2]$ ，我们就按比例从 $[−1,1]$ 扩大到 $[−2,2]$， $0.99$ 乘 $2$，最终输出的就是 $1.98$，将其作为小车的速度或者推小车的推力输出给环境。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281904680.png" alt=""></p>
<h2 id="深度确定性策略梯度-1"><a href="#深度确定性策略梯度-1" class="headerlink" title="深度确定性策略梯度"></a>深度确定性策略梯度</h2><p>在连续控制领域，比较经典的强化学习算法就是深度确定性策略梯度（deep deterministic policy gradient，DDPG）。</p>
<p>深度是因为用了神经网络；确定性表示<code>DDPG</code>输出的是一个确定性的动作，可以用于有连续动作的环境；策略梯度代表的是它用到的是策略网络。<code>REINFORCE</code>算法每隔一个回合就更新一次，但<code>DDPG</code>是每个步骤都会更新一次策略网络，它是一个单步更新的策略网络。</p>
<p><code>DDPG</code>是深度<code>Q</code>网络的一个扩展版本，可以扩展到连续动作空间。在<code>DDPG</code>的训练中，它借鉴了深度<code>Q</code>网络的技巧：目标网络和经验回放。经验回放与深度<code>Q</code>网络是一样的，但目标网络的更新与深度<code>Q</code>网络的有点儿不一样。提出<code>DDPG</code>是为了让深度<code>Q</code>网络可以扩展到连续的动作空间，就是我们刚才提到的小车速度、角度和电压等这样的连续值。如图所示，<code>DDPG</code>在深度<code>Q</code>网络基础上加了一个策略网络来直接输出动作值，所以<code>DDPG</code>需要一边学习<code>Q</code>网络，一边学习策略网络。<code>Q</code>网络的参数用 $w$ 来表示。策略网络的参数用 $\theta$ 来表示。我们称这样的结构为演员-评论员的结构。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281921911.png" alt=""></p>
<p>深度<code>Q</code>网络与 <code>DDPG</code> 的联系如图所示。深度<code>Q</code>网络的最佳策略是想要学出一个很好的<code>Q</code>网络，学出这个网络之后，我们希望选取的那个动作使<code>Q</code>值最大。<code>DDPG</code>的目的也是求解让<code>Q</code>值最大的那个动作。演员只是为了迎合评委的打分而已，所以优化策略网络的梯度就是要最大化这个<code>Q</code>值，所以构造的损失函数就是让<code>Q</code>取一个负号。我们写代码的时候把这个损失函数放入优化器里面，它就会自动最小化损失，也就是最大化<code>Q</code>。<br>这里要注意，除了策略网络要做优化，<code>DDPG</code>还有一个<code>Q</code>网络也要优化。评论员一开始也不知道怎么评分，它也是在一步一步的学习当中，慢慢地给出准确的分数。我们优化<code>Q</code>网络的方法其实与深度<code>Q</code>网络优化<code>Q</code>网络的方法是一样的，我们用真实的奖励 $r$ 和下一步的 $Q$ 即 $Q^{\prime}$ 来拟合未来的奖励 $Q_{target}$。然后让<code>Q</code>网络的输出逼近 $Q_{target}$。所以构造的损失函数就是直接求这两个值的均方差。构造好损失函数后，我们将其放到优化器中，让它自动最小化损失。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401281949961.png" alt=""></p>
<p>如图所示，我们可以把两个网络的损失函数构造出来。策略网络的损失函数是一个复合函数。我们把 $a = \mu_{\theta}(s)$ 代入，最终策略网络要优化的是策略网络的参数 $\theta$ 。<code>Q</code>网络要优化的是 $Q_{w}(s, a)$ 和 $Q_{target}$ 之间的一个均方差。但是<code>Q</code>网络的优化存在一个和深度<code>Q</code>网络一模一样的问题就是它后面的 $Q_{target}$ 是不稳定的。此外，后面的 $Q_{\overline{w}}(s^{\prime}, a^{\prime})$ 也是不稳定的，因为 $Q_{\overline{w}}(s^{\prime}, a^{\prime})$ 也是一个预估的值。<br>为了使 $Q_{target}$ 更加稳定，<code>DDPG</code>分别给<code>Q</code>网络和策略网络搭建了目标网络，即 $target_{Q}$ 网络和 $target_{P}$ 策略网络。 $target_{Q}$ 网络是为了计算 $Q_{target}$ 中 $Q_{\overline{w}}(s^{\prime}, a^{\prime})$。 $Q_{\overline{w}}(s^{\prime}, a^{\prime})$ 里面的需要的下一个动作 $a^{\prime}$ 是通过 $target_{P}$ 网络输出的，即 $a^{\prime} = \mu_{\overline{\theta}}(s^{\prime})$。<code>Q</code>网络和策略网络的参数是 $w$， $target_{Q}$ 网络和 $target_{P}$ 策略网络的参数是 $\overline{w}$。<code>DDPG</code>有 $4$ 个网络，策略网络的目标网络和<code>Q</code>网络的目标网络是颜色比较深的这两个，它们只是为了让计算 $Q_{target}$ 更稳定。因为这两个网络也是固定一段时间的参数之后再与评估网络同步最新的参数。</p>
<p>这里训练需要用到的数据就是 $s$、 $a$、 $r$、 $s^{\prime}$，我们只需要用到这 $4$ 个数据。我们用回放缓冲区把这些数据存起来，然后采样进行训练。经验回放的技巧与深度<code>Q</code>网络中的是一样的。注意，因为<code>DDPG</code>使用了经验回放技巧，所以<code>DDPG</code>是一个异策略的算法。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401282031786.png" alt=""></p>
<p><code>DDPG</code>通过异策略的方式来训练一个确定性策略。因为策略是确定的，所以如果智能体使用同策略来探索，在一开始的时候，它很可能不会尝试足够多的动作来找到有用的学习信号。为了让<code>DDPG</code>的策略更好地探索，我们在训练的时候给它们的动作加了噪声。<code>DDPG</code>的原作者推荐使用时间相关的<code>OU</code>噪声，但最近的结果表明不相关的、均值为 $0$ 的高斯噪声的效果非常好。由于后者更简单，因此我们更喜欢使用它。为了便于获得更高质量的训练数据，我们可以在训练过程中把噪声变小。在测试的时候，为了查看策略利用它学到的东西的表现，我们不会在动作中加噪声。</p>
<h2 id="双延迟深度确定性策略梯度"><a href="#双延迟深度确定性策略梯度" class="headerlink" title="双延迟深度确定性策略梯度"></a>双延迟深度确定性策略梯度</h2><p>虽然<code>DDPG</code>有时表现很好，但它对于超参数和其他类型的调整方面经常很敏感。<code>DDPG</code>常见的问题是已经学习好的<code>Q</code>函数开始显著地高估<code>Q</code>值，然后导致策略被破坏，因为它利用了<code>Q</code>函数中的误差。</p>
<p>双延迟深度确定性策略梯度（twin delayed DDPG，TD3）通过引入 $3$ 个关键技巧来解决这个问题。</p>
<ul>
<li>截断的双<code>Q</code>学习（clipped double Q-learning）。<code>TD3</code>学习两个<code>Q</code>函数（因此名字中有“twin”）。<code>TD3</code>通过最小化均方差来同时学习两个<code>Q</code>函数： $Q_{\phi_{1}}$ 和 $Q_{\phi_{2}}$。两个<code>Q</code>函数都使用一个目标，两个<code>Q</code>函数中给出的较小的值会被作为如下的 <code>Q-target</code>：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401282042062.png" alt=""></p>
<ul>
<li>延迟的策略更新（delayed policy updates） 。相关实验结果表明，同步训练动作网络和评价网络，却不使用目标网络，会导致训练过程不稳定；但是仅固定动作网络时，评价网络往往能够收敛到正确的结果。<strong>因此TD3算法以较低的频率更新动作网络，以较高的频率更新评价网络，通常每更新两次评价网络就更新一次策略。</strong></li>
<li>目标策略平滑（target policy smoothing）。<code>TD3</code>引入了平滑化（smoothing）思想。<code>TD3</code>在目标动作中加入噪声，通过平滑<code>Q</code>沿动作的变化，使策略更难利用<code>Q</code>函数的误差。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401282045795.png" alt=""></p>
<h1 id="TRPO算法"><a href="#TRPO算法" class="headerlink" title="TRPO算法"></a>TRPO算法</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>回顾一下基于策略的方法：参数化智能体的策略，并设计衡量策略好坏的目标函数，通过梯度上升的方法来最大化这个目标函数，使得策略最优。具体来说，假设 $\theta$ 表示策略 $\pi_{\theta}$ 的参数，定义 $J(\theta)=\mathbb{E}_{s_0}[V^{\pi_\theta}(s_0)]=\mathbb{E}_{\pi_\theta}\left[\sum_{t=0}^{\infty}\gamma^tr(s_t,a_t)\right]$，基于策略的方法的目标是找到 $\theta^*=\arg\max_\theta J(\theta)$，策略梯度算法主要沿着 $\nabla_{\theta}J(\theta)$ 方向迭代更新策略参数 $\theta$。但是这种算法有一个明显的缺点：当策略网络是深度模型时，沿着策略梯度更新参数，很有可能由于步长太长，策略突然显著变差，进而影响训练效果。</p>
<p>针对以上问题，我们考虑在更新时找到一块<strong>信任区域</strong>（trust region），在这个区域上更新策略时能够得到某种策略性能的安全性保证，这就是<strong>信任区域策略优化</strong>（trust region policy optimization，TRPO）算法的主要思想。TRPO 算法在 2015 年被提出，它在理论上能够保证策略学习的性能单调性，并在实际应用中取得了比策略梯度算法更好的效果。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404191153648.png" alt=""></p>
<h2 id="策略目标"><a href="#策略目标" class="headerlink" title="策略目标"></a>策略目标</h2><p>假设当前策略为 $\pi_{\theta}$，参数为 $\theta$。我们考虑如何借助当前的 $\theta$ 找到一个更优的参数 $\theta^{\prime}$，使得 $J(\theta^{\prime})\geq J(\theta)$。具体来说，由于初始状态 $s_{0}$ 的分布和策略无关，因此上述策略 $\pi_{\theta}$ 下的优化目标 $J(\theta)$ 可以写成在新策略 $\pi_{\theta^{\prime}}$ 的期望形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292223186.png" alt=""></p>
<p>基于以上等式，我们可以推导新旧策略的目标函数之间的差距：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292224383.png" alt=""></p>
<p>将时序差分残差定义为优势函数 $A$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292230007.png" alt=""></p>
<p>最后一个等号的成立运用到了状态访问分布的定义： $\nu^\pi(s)=(1-\gamma)\sum_{t=0}^\infty\gamma^tP_t^\pi(s)$，所以只要我们能找到一个新策略，使得 $\mathbb{E}_{s\sim\nu^{\pi_{\theta^{\prime}}}}\mathbb{E}_{a\sim\pi_{\theta^{\prime}}(\cdot|s)}\left[A^{\pi_{\theta}}(s,a)\right]\geq0$，就能保证策略性能单调递增，即 $J(\theta^{\prime})\geq J(\theta)$。</p>
<p>但是直接求解该式是非常困难的，因为 $\pi_{\theta^{\prime}}$ 是我们需要求解的策略，但我们又要用它来收集样本。把所有可能的新策略都拿来收集数据，然后判断哪个策略满足上述条件的做法显然是不现实的。于是 TRPO 做了一步近似操作，对状态访问分布进行了相应处理。具体而言，忽略两个策略之间的状态访问分布变化，直接采用旧的策略 $\pi_{\theta}$ 的状态分布，定义如下替代优化目标：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292235376.png" alt=""></p>
<p>当新旧策略非常接近时，状态访问分布变化很小，这么近似是合理的。其中，动作仍然用新策略 $\pi_{\theta^{\prime}}$ 采样得到，我们可以用重要性采样对动作分布进行处理：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292237297.png" alt=""></p>
<p>这样，我们就可以基于旧策略 $\pi_{\theta}$ 已经采样出的数据来估计并优化新策略 $\pi_{\theta^{\prime}}$ 了。为了保证新旧策略足够接近，TRPO 使用了库尔贝克-莱布勒（Kullback-Leibler，KL）散度来衡量策略之间的距离，并给出了整体的优化公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292239973.png" alt=""></p>
<p>这里的不等式约束定义了策略空间中的一个 KL 球，被称为信任区域。在这个区域中，可以认为当前学习策略和环境交互的状态分布与上一轮策略最后采样的状态分布一致，进而可以基于一步行动的重要性采样方法使当前学习策略稳定提升。</p>
<h2 id="近似求解"><a href="#近似求解" class="headerlink" title="近似求解"></a>近似求解</h2><p>直接求解上式带约束的优化问题比较麻烦，TRPO 在其具体实现中做了一步近似操作来快速求解。为方便起见，我们在接下来的式子中用 $\theta_{k}$ 代替之前的 $\theta$，表示这是第 $k$ 次迭代之后的策略。首先对目标函数和约束在 $\theta_{k}$ 进行泰勒展开，分别用 1 阶、2 阶进行近似：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292242571.png" alt=""></p>
<p>其中 $g=\nabla_{\theta^{\prime}}\mathbb{E}_{s\sim\nu^{\pi_{\theta_{k}}}}\mathbb{E}_{a\sim\pi_{\theta_{k}}(\cdot|s)}\left[\frac{\pi_{\theta^{\prime}}(a|s)}{\pi_{\theta_k}(a|s)}A^{\pi_{\theta_k}}(s,a)\right]$，表示目标函数的梯度， $H=\mathbf{H}[\mathbb{E}_{s\sim\nu^{\pi_{\theta_k}}}[D_{KL}(\pi_{\theta_k}(\cdot|s),\pi_{\theta^{\prime}}(\cdot|s))]]$ 表示策略之间平均 KL 距离的<strong>黑塞矩阵</strong>（Hessian matrix）。</p>
<p>于是我们的优化目标变成了：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292307106.png" alt=""></p>
<p>此时，我们可以用卡罗需-库恩-塔克（Karush-Kuhn-Tucker，KKT）条件直接导出上述问题的解：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292308216.png" alt=""></p>
<h2 id="共轭梯度"><a href="#共轭梯度" class="headerlink" title="共轭梯度"></a>共轭梯度</h2><p>一般来说，用神经网络表示的策略函数的参数数量都是成千上万的，计算和存储黑塞矩阵 $H$ 的逆矩阵会耗费大量的内存资源和时间。TRPO 通过共轭梯度法（conjugate gradient method）回避了这个问题，它的核心思想是直接计算 $x=H^{-1}g$， $x$ 即参数更新方向。假设满足 KL 距离约束的参数更新时的最大步长为 $\beta$，于是，根据 KL 距离约束条件，有 $\frac{1}{2}(\beta x)^{T}H(\beta x)=\delta $。求解 $\beta$，得到 $\beta=\sqrt{\frac{2\delta}{x^{T}Hx}}$。因此，此时参数更新方式为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292312441.png" alt=""></p>
<p>因此，只要可以直接计算 $x=H^{-1}g$，就可以根据该式更新参数，问题转化为解 $Hx=g$。实际上 $H$ 为对称正定矩阵，所以我们可以使用共轭梯度法来求解。共轭梯度法的具体流程如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292317432.png" alt=""></p>
<p>在共轭梯度运算过程中，直接计算 $\alpha_{k}$ 和 $r_{k+1}$ 需要计算和存储海森矩阵 $H$。为了避免这种大矩阵的出现，我们只计算 $Hx$ 向量，而不直接计算和存储 $H$ 矩阵。这样做比较容易，因为对于任意的列向量 $v$，容易验证：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292319887.png" alt=""></p>
<p>即先用梯度和向量 $v$ 点乘后计算梯度。</p>
<h2 id="线性搜索"><a href="#线性搜索" class="headerlink" title="线性搜索"></a>线性搜索</h2><p>由于 TRPO 算法用到了泰勒展开的 1 阶和 2 阶近似，这并非精准求解，因此， $\theta^{\prime}$ 可能未必比 $\theta_{k}$ 好，或未必能满足 KL 散度限制。TRPO 在每次迭代的最后进行一次线性搜索（Line Search），以确保找到满足条件。具体来说，就是找到一个最小的非负整数 $i$，使得按照</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292321160.png" alt=""></p>
<p>求出的 $\theta_{k+1}$ 依然满足最初的 KL 散度限制，并且确实能够提升目标函数 $L_{\theta_{k}}$，这其中 $\alpha\in(0,1)$ 是一个决定线性搜索长度的超参数。</p>
<p>至此，我们已经基本上清楚了 TRPO 算法的大致过程，它具体的算法流程如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292324578.png" alt=""></p>
<h2 id="广义优势估计"><a href="#广义优势估计" class="headerlink" title="广义优势估计"></a>广义优势估计</h2><p>从上节中，我们尚未得知如何估计优势函数 $A$。目前比较常用的一种方法为广义优势估计（Generalized Advantage Estimation，GAE），接下来我们简单介绍一下 GAE 的做法。首先，用 $\delta_t=r_t+\gamma V(s_{t+1})-V(s_t)$ 表示时序差分误差，其中 $V$ 是一个已经学习的状态价值函数。于是，根据多步时序差分的思想，有：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292326710.png" alt=""></p>
<p>然后，GAE 将这些不同步数的优势估计进行指数加权平均：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202401292326672.png" alt=""></p>
<p>其中， $\lambda\in[0,1]$ 是在 GAE 中额外引入的一个超参数。当时 $\lambda=0$， $A_t^{GAE}=\delta_t=r_t+\gamma V(s_{t+1})-V(s_t)$，也即是仅仅只看一步差分得到的优势；当时 $\lambda=1$， $A_t^{GAE}=\sum_{l=0}^\infty\gamma^l\delta_{t+l}=\sum_{l=0}^\infty\gamma^lr_{t+l}-V(s_t)$，则是看每一步差分得到优势的完全平均值。</p>
<h1 id="SAC算法"><a href="#SAC算法" class="headerlink" title="SAC算法"></a>SAC算法</h1><p>柔性动作-评价（Soft Actor-Critic，SAC）算法的网络结构有5个。SAC算法解决的问题是离散动作空间和连续动作空间的强化学习问题，是<code>off-policy</code>的强化学习算法。</p>
<p>SAC的论文有两篇，一篇是《Soft Actor-Critic Algorithms and Applications》，它包括1个<code>Actor</code>网络，4个<code>Q Critic</code>网络。其具体流程如下：</p>
<ol>
<li>始化 Actor、Critic1、Critic2、TargetCritic1 、TargetCritic2 网络</li>
<li>Buffer中采样 (state, action, reward, next_state)</li>
<li>Actor 输入 next_state 对应输出 next_action 和 next_log_prob</li>
<li>Actor 输入 state 对应输出 new_action 和 log_prob</li>
<li>TargetCritic1 和 TargetCritic2 分别输入next_state 和 next_action 取其中较小输出经熵正则计算得 target_q_value</li>
<li>使用 MSE_loss(Critic1(state, action), target_q_value) 更新 Critic1</li>
<li>使用 MSE_loss(Critic2(state, action), target_q_value) 更新 Critic2</li>
<li>使用 (alpha * log_prob - critic1(state, new_action)).mean() 更新 Actor</li>
<li>软更新TargetCritic1和TargetCritic2</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505080048169.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505080103535.png" alt=""></p>
<p>一篇是《Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor》，它包括1个<code>Actor</code>网络，2个<code>V Critic</code>网络（1个<code>V Critic</code>网络，1个<code>Target V Critic</code>网络），2个<code>Q Critic</code>网络。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505080051698.png" alt=""></p>
<p>Q Critic网络的更新流程：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505080109956.png" alt=""></p>
<p>V Critic网络的更新流程：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505080109806.png" alt=""></p>
<p>Actor网络的更新流程，这里$Q_{0}$和$Q_{1}$是等价的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505080110232.png" alt=""></p>
<h1 id="多智能体强化学习"><a href="#多智能体强化学习" class="headerlink" title="多智能体强化学习"></a>多智能体强化学习</h1><h2 id="设定"><a href="#设定" class="headerlink" title="设定"></a>设定</h2><ul>
<li>合作（fully cooperative）</li>
<li>竞争（fully competitive）</li>
<li>合作竞争混合（mixed cooperative &amp; competitive）</li>
<li>利己主义（self-interest）</li>
</ul>
<h2 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404191203225.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404191203263.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404191204290.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404191205005.png" alt=""></p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><ul>
<li>完全去中心化</li>
<li>完全中心化</li>
<li>中心化训练，去中心化执行</li>
</ul>
<h3 id="Fully-Decentralized-Training"><a href="#Fully-Decentralized-Training" class="headerlink" title="Fully Decentralized Training"></a>Fully Decentralized Training</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404191219908.png" alt=""></p>
<h3 id="Centralized-Training"><a href="#Centralized-Training" class="headerlink" title="Centralized Training"></a>Centralized Training</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404191222752.png" alt=""></p>
<h3 id="Centralized-Training-with-Decentralized-Execution"><a href="#Centralized-Training-with-Decentralized-Execution" class="headerlink" title="Centralized Training with Decentralized Execution"></a>Centralized Training with Decentralized Execution</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404191235939.png" alt=""></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202404191237313.png" alt=""></p>
]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库面试题总结</title>
    <url>/2022/03/20/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>总结一下网上的数据库面试题</p>
<a id="more"></a>
<h1 id="事务四大特性"><a href="#事务四大特性" class="headerlink" title="事务四大特性"></a>事务四大特性</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">原子性，要么执行，要么不执行  </span><br><span class="line">隔离性，所有操作全部执行完以前其它会话不能看到过程</span><br><span class="line">一致性，事务前后，数据总额一致</span><br><span class="line">持久性，一旦事务提交，对数据的改变就是永久的</span><br></pre></td></tr></table></figure>
<h1 id="数据库隔离级别"><a href="#数据库隔离级别" class="headerlink" title="数据库隔离级别"></a>数据库隔离级别</h1><p>数据库事务的隔离级别有4个，由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">脏读</th>
<th style="text-align:center">不可重复读</th>
<th style="text-align:center">幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Read uncommitted</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center">Read committed（Sql Server，Oracle）</td>
<td style="text-align:center">×</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center">Repeatable read（Mysql）</td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center">Serializable</td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
</tr>
</tbody>
</table>
</div>
<p>脏读：事务 B 去查询了事务 A 修改过的数据，但是此时事务 A 还没提交，所以事务 A 随时会回滚导致事务 B 再次查询就读不到刚才事务 A 修改的数据了，这就是脏读。</p>
<p>不可重复读：假设一个前提是事务 A 只能在事务 B 提交之后读取到它修改的数据，所以此时必然是不会发生脏读的。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。</p>
<p>不可重复读和脏读的区别是，脏读读取到的是一个未提交的数据，而不可重复读读取到的是前一个事务提交的数据。</p>
<p>幻读：幻读就是你一个事务用一样的 SQL 多次查询，结果每次查询都会发现查到一些之前没看到过的数据。注意，幻读特指的是你查询到了之前查询没看到过的数据。此时说明你是幻读了。</p>
<p>幻读和不可重复读所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。</p>
<h1 id="Mysql的存储引擎以及区别"><a href="#Mysql的存储引擎以及区别" class="headerlink" title="Mysql的存储引擎以及区别"></a>Mysql的存储引擎以及区别</h1><p>Mysql默认支持九种存储引擎（数据用各种不同的技术存储在文件或内存中。这些技术中的每一种技术都使用不同的存储机制、索引技巧、锁定水平并且最终提供广泛的不同的功能和能力。通过选择不同的技术，你能够获得额外的速度或者功能，从而改善你的应用的整体功能。）</p>
<ol>
<li>MyISAM：适合读密集的表<ol>
<li>不支持行锁(MyISAM只有表锁)，读取时对需要读到的所有表加锁，写入时则对表加排他锁；MyISAM表进行读操作时，它不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写操作；而对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作。</li>
<li>不支持事务</li>
<li>不支持外键</li>
<li>不支持崩溃后的安全恢复</li>
<li>在表有读取查询的同时，支持往表中插入新记录</li>
<li>支持BLOB和TEXT的前500个字符索引，支持全文索引和空间索引</li>
<li>支持延迟更新索引，极大地提升了写入性能</li>
<li>对于不会进行修改的表，支持压缩表，极大地减少了磁盘空间的占用</li>
<li>存储表的总行数，执行select count(*) from table时只要简单的读出保存好的行数即可</li>
<li>采用非聚集索引，索引文件的数据域存储指向数据文件的指针。</li>
</ol>
</li>
<li>InnoDB：InnoDB是MySQL的默认数据库引擎（5.5版之后），适合写密集的表<ol>
<li>支持行锁，采用MVCC来支持高并发，有可能死锁</li>
<li>支持事务</li>
<li>支持外键</li>
<li>支持崩溃后的安全恢复</li>
<li>不支持全文索引</li>
<li>不存储表的总行数，执行select count(*) from table时，InnoDB要扫描一遍整个表来计算有多少行。注意的是，当count(*)语句包含 where条件时，两种表的操作是一样的</li>
<li>主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问主键索引；最好使用自增主键，防止插入数据时，为维持B+树结构，文件的大调整。</li>
<li>DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除</li>
<li>对于AUTO_INCREMENT类型的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中，可以和其他字段一起建立联合索引更好和更快的auto_increment处理</li>
</ol>
</li>
</ol>
<h1 id="B-索引和hash索引"><a href="#B-索引和hash索引" class="headerlink" title="B+索引和hash索引"></a>B+索引和hash索引</h1><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20181107184452575.png" alt=""></p>
<p>在MySQL中，只有HEAP/MEMORY引擎表才能显式支持哈希索引（NDB也支持，但这个不常用），InnoDB引擎的自适应哈希索引（adaptive hash index）不在此列，因为这不是创建索引时可指定的。</p>
<ul>
<li>如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；</li>
<li>如果是范围查询检索，这时候哈希索引就毫无用武之地了 ，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；</li>
<li>同理， 哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；</li>
<li>哈希索引也不支持多列联合索引的最左匹配规则；</li>
<li>B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大， 在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题 。</li>
</ul>
<h1 id="索引的优缺点，什么时候使用索引，什么时候不能使用索引"><a href="#索引的优缺点，什么时候使用索引，什么时候不能使用索引" class="headerlink" title="索引的优缺点，什么时候使用索引，什么时候不能使用索引"></a>索引的优缺点，什么时候使用索引，什么时候不能使用索引</h1><ul>
<li>索引最大的好处是提高查询速度</li>
<li>缺点是更新数据时效率低，因为要同时更新索引</li>
<li>对数据进行频繁查询进建立索引，如果要频繁更改数据不建议使用索引</li>
</ul>
<h1 id="InnoDB索引和MyISAM索引的区别"><a href="#InnoDB索引和MyISAM索引的区别" class="headerlink" title="InnoDB索引和MyISAM索引的区别"></a><strong>InnoDB索引</strong>和<strong>MyISAM索引</strong>的区别</h1><p>InnoDB的数据文件本身就是主索引文件。而MyISAM的主索引和数据是分开的。</p>
<p>InnoDB的辅助索引data域存储相应记录主键的值而不是地址。而MyISAM的辅助索引和主索引没有多大区别。</p>
<h1 id="索引的底层实现（B-树，为何不采用红黑树，B树）重点"><a href="#索引的底层实现（B-树，为何不采用红黑树，B树）重点" class="headerlink" title="索引的底层实现（B+树，为何不采用红黑树，B树）重点"></a>索引的底层实现（B+树，为何不采用红黑树，B树）重点</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">树</th>
<th style="text-align:center">区别</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">红黑树</td>
<td style="text-align:center">增加，删除，红黑树会进行频繁的调整，来保证红黑树的性质，浪费时间</td>
</tr>
<tr>
<td style="text-align:center">B树也就是B-树</td>
<td style="text-align:center">B树，查询性能不稳定，查询结果高度不致，每个结点保存指向真实数据的指针，相比B+树每一层每屋存储的元素更多，显得更高一点。</td>
</tr>
<tr>
<td style="text-align:center">B+树</td>
<td style="text-align:center">B+树相比较于另外两种树,显得更矮更宽，查询层次更浅</td>
</tr>
</tbody>
</table>
</div>
<h1 id="为什么使用B-树"><a href="#为什么使用B-树" class="headerlink" title="为什么使用B+树"></a>为什么使用B+树</h1><ol>
<li>B+树是多路平衡查找树（B-Tree）的变种（Plus版本），多路绝对平衡查找树，他拥有B-树的优势</li>
<li>B+树的扫库扫表能力更强。</li>
<li>B+树的磁盘读写能力更强。</li>
<li>B+树的排序能力更强。</li>
<li>B+树的查询效率更加稳定（仁者见仁，智者见智）</li>
</ol>
<h1 id="Sql的优化"><a href="#Sql的优化" class="headerlink" title="Sql的优化"></a>Sql的优化</h1><ol>
<li>sql尽量使用索引，而且查询要走索引</li>
<li>对sql语句优化<ul>
<li>子查询变成left join</li>
<li>limit 分布优化，先利用ID定位，再分页</li>
<li>or条件优化，多个or条件可以用union all对结果进行合并（union all结果可能重复）</li>
<li>不必要的排序</li>
<li>where代替having,having 检索完所有记录，才进行过滤</li>
<li>避免嵌套查询</li>
<li>对多个字段进行等值查询时，联合索引</li>
</ul>
</li>
</ol>
<h1 id="索引最左前缀问题"><a href="#索引最左前缀问题" class="headerlink" title="索引最左前缀问题"></a>索引最左前缀问题</h1><p>假设你在表的state、city和zip数据列上建立了复合索引。索引中的数据行按照state/city/zip次序排列，因此它们也会自动地按照state/city/zip次序排列。这意味着，即使你在查询中只指定了state值，或者指定state和city值，MySQL也可以使用这个索引。因此，这个索引可以被用于搜索如下所示的数据列组合：state/city/zip；state/city；state。</p>
<p>MySQL不能利用这个索引来搜索没有包含在最左前缀的内容。例如，如果你按照city或zip来搜索，<br>就不会使用到这个索引。如果你搜索给定的state和具体的ZIP代码（索引的1和3列），该索引也是不能用于这种组合值的，尽管MySQL可以利用索引来查找匹配的state从而缩小搜索的范围。</p>
<p>explain命令的结果需要考虑属性type：ref就是使用了索引，index是对所有索引树进行扫描，而all是对整个磁盘的数据进行全表扫描。</p>
<h1 id="索引分类及索引失效条件"><a href="#索引分类及索引失效条件" class="headerlink" title="索引分类及索引失效条件"></a>索引分类及索引失效条件</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">索引类型</th>
<th style="text-align:center">概念</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">普通索引</td>
<td style="text-align:center">最基本的索引，没有任何限制</td>
</tr>
<tr>
<td style="text-align:center">唯一索引</td>
<td style="text-align:center">与”普通索引”类似，不同的就是：索引列的值必须唯一，但允许有空值。</td>
</tr>
<tr>
<td style="text-align:center">主键索引</td>
<td style="text-align:center">它是一种特殊的唯一索引，不允许有空值。</td>
</tr>
<tr>
<td style="text-align:center">全文索引</td>
<td style="text-align:center">针对较大的数据，生成全文索引很耗时间空间。</td>
</tr>
<tr>
<td style="text-align:center">组合索引</td>
<td style="text-align:center">为了更多的提高mysql效率可建立组合索引，遵循”最左前缀“原则</td>
</tr>
</tbody>
</table>
</div>
<p>失效条件：</p>
<ol>
<li>如果条件中有or，即使其中有条件带索引也不会使用</li>
<li>对于多列索引，不是使用的第一部分，则不会使用索引</li>
<li>like查询是以%开头</li>
<li>如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引</li>
<li>如果mysql估计使用全表扫描要比使用索引快,则不使用索引</li>
<li>where中索引列有运算</li>
<li>where中索引列使用了函数（+，-，*，/，! ）</li>
<li>当变量采用的是times变量，而表的字段采用的是date变量时</li>
<li>隐式类型转换导致索引失效</li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统</title>
    <url>/2023/08/23/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一些推荐系统相关的知识。</p>
<a id="more"></a>
<h1 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p><strong>CTR(Click-Through-Rate)</strong>：即点击通过率，是互联网广告常用的术语，指网络广告的点击到达率，即该广告的实际点击次数（严格的来说，可以是到达目标页面的数量）除以广告的展现量。</p>
<p>点击量过小时，是由两种原因造成的，展现量过小，或点击数偏低。</p>
<ol>
<li>展现量低，进而点击数也小。展现量过低说明潜在受众搜索需求发生的较少，也即推广结果展现在潜在受众前的机会较少，推广商户可以通过拓展关键词来提高展现量，即提高推广信息展现的机会。</li>
<li>展现量高，但是点击数偏低，造成点击率偏低。这种情况可能的原因是：<ul>
<li>关键词与文案的相关性不高，所以无法满足潜在受众的需求，进而点击数小。可以通过改善文案写作，提高关键词与文案的相关性来提高点击率。</li>
<li>推广结果的平均排名较低，不具有竞争力。可以通过调高平均点击价格来提高排名。</li>
<li>关键词匹配模式的问题。例如，推广商户购买了“葡萄”等相关关键词，用户在搜索“葡萄牙”时商户的推广结果也可能会出现，这时推广结果就是无效展现，即为推广结果信息没有展现在潜在受众前。此种情况就需通过“否定匹配”模式来解决，将“葡萄牙”设置为否定匹配，即为用户在搜索“葡萄牙”时，推广商户的推广结果不会展现，降低了无效展现的风险。</li>
</ul>
</li>
</ol>
<h2 id="推荐系统架构"><a href="#推荐系统架构" class="headerlink" title="推荐系统架构"></a>推荐系统架构</h2><p>从<strong>系统架构</strong>和<strong>算法架构</strong>两个角度出发解析推荐系统通用架构。系统架构设计思想是大数据背景下如何有效利用海量和实时数据，将推荐系统按照对数据利用情况和系统响应要求出发，将整个架构分为<strong>离线层、近线层、在线层</strong>三个模块。而算法架构是从我们比较熟悉的<strong>召回、粗排、排序、重排</strong>等算法环节角度出发的，重要的是要去理解每个环节需要完成的任务，每个环节的评价体系，以及为什么要那么设计。</p>
<h3 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h3><p>推荐系统架构，首先从数据驱动角度，对于数据，最简单的方法是存下来，留作后续离线处理，<strong>离线层</strong>就是我们用来管理离线作业的部分架构。<strong>在线层</strong>能更快地响应最近的事件和用户交互，但必须实时完成。这会限制使用算法的复杂性和处理的数据量。离线计算对于数据数量和算法复杂度限制更少，因为它以批量方式完成，没有很强的时间要求。不过，由于没有及时加入最新的数据，所以很容易过时。个性化架构的关键问题，就是如何以无缝方式结合、管理在线和离线计算过程。<strong>近线层</strong>介于两种方法之间，可以执行类似于在线计算的方法，但又不必以实时方式完成。</p>
<h3 id="算法架构"><a href="#算法架构" class="headerlink" title="算法架构"></a>算法架构</h3><p>一个通用的算法架构，设计思想就是对数据层层建模，层层筛选，帮助用户从海量数据中找出其真正感兴趣的部分。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192001842.png" alt="img"></p>
<p><strong>召回</strong></p>
<p>召回层的主要目标时从推荐池中选取几千上万的item，送给后续的排序模块。由于召回面对的候选集十分大，且一般需要在线输出，故召回模块必须轻量快速低延迟。由于后续还有排序模块作为保障，召回不需要十分准确，但<strong>不可遗漏</strong>（特别是搜索系统中的召回模块）。</p>
<p>召回主要考虑的内容有：</p>
<ol>
<li><strong>考虑用户层面</strong>：用户兴趣的多元化，用户需求与场景的多元化：例如：新闻需求，重大要闻，相关内容沉浸阅读等等</li>
<li><strong>考虑系统层面</strong>：增强系统的鲁棒性；部分召回失效，其余召回队列兜底不会导致整个召回层失效；排序层失效，召回队列兜底不会导致整个推荐系统失效</li>
<li><strong>系统多样性内容分发</strong>：图文、视频、小视频；精准、试探、时效一定比例；召回目标的多元化，例如：相关性，沉浸时长，时效性，特色内容等等</li>
<li><strong>可解释性推荐一部分召回是有明确推荐理由的</strong>：很好的解决产品性数据的引入</li>
</ol>
<p><strong>粗排</strong></p>
<p>粗排的原因是有时候召回的结果还是太多，精排层速度还是跟不上，所以加入粗排。粗排可以理解为精排前的一轮过滤机制，减轻精排模块的压力。粗排介于召回和精排之间，要同时兼顾精准性和低延迟。目前粗排一般也都模型化了，其训练样本类似于精排，选取曝光点击为正样本，曝光未点击为负样本。但由于粗排一般面向上万的候选集，而精排只有几百上千，其解空间大很多。</p>
<p><strong>精排</strong></p>
<p>精排层，也是我们学习推荐入门最常常接触的层，我们所熟悉的算法很大一部分都来自精排层。这一层的任务是获取粗排模块的结果，对候选集进行打分和排序。精排需要在最大时延允许的情况下，保证打分的精准性，是整个系统中至关重要的一个模块，也是最复杂，研究最多的一个模块。</p>
<p>精排是推荐系统各层级中最纯粹的一层，他的目标比较单一且集中，一门心思的实现目标的调优即可。最开始的时候精排模型的常见目标是CTR,后续逐渐发展了CVR等多类目标。精排和粗排层的基本目标是一致的，都是对商品集合进行排序，但是和粗排不同的是，精排只需要对少量的商品(即粗排输出的商品集合的Top-N)进行排序即可。因此，精排中可以使用比粗排更多的特征，更复杂的模型和更精细的策略（用户的特征和行为在该层的大量使用和参与也是基于这个原因）。</p>
<p><strong>重排</strong></p>
<p>常见的有三种优化目标：Point Wise、Pair Wise 和 List Wise。重排序阶段对精排生成的Top-N个物品的序列进行重新排序，生成一个Top-K个物品的序列，作为排序系统最后的结果，直接展现给用户。重排序的原因是因为多个物品之间往往是相互影响的，而精排序是根据Point Wise得分，容易造成推荐结果同质化严重，有很多冗余信息。而重排序面对的挑战就是海量状态空间如何求解的问题，一般在精排层我们使用AUC作为指标，但是在重排序更多关注NDCG等指标。</p>
<p><strong>混排</strong></p>
<p>多个业务线都想在Feeds流中获取曝光，则需要对它们的结果进行混排。比如推荐流中插入广告、视频流中插入图文和banner等。可以基于规则策略（如广告定坑）和强化学习来实现。</p>
<h2 id="经典召回模型"><a href="#经典召回模型" class="headerlink" title="经典召回模型"></a>经典召回模型</h2><h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h3><ul>
<li>召回率：在模型召回预测的物品中，预测准确的物品占用户实际喜欢的物品的比例。对用户  推荐  个物品记为  , 令用户  在测试集上喜欢的物品集合为  ， 那么召回率定义为：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192101633.png" alt="img"></p>
<ul>
<li>准确率：推荐的物品中，对用户准确推荐的物品占总物品的比例。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192102103.png" alt="img"></p>
<ul>
<li>覆盖率：覆盖率反映了推荐算法发掘长尾的能力， 覆盖率越高， 说明推荐算法越能将长尾中的物品推荐给用户。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192115000.png" alt="img"></p>
<ul>
<li>新颖度：用推荐列表中物品的平均流行度度量推荐结果的新颖度。 如果推荐出的物品都很热门， 说明推荐的新颖度较低。 由于物品的流行度分布呈长尾分布， 所以为了流行度的平均值更加稳定， 在计算平均流行度时对每个物品的流行度取对数。</li>
</ul>
<h3 id="基于协同过滤的召回"><a href="#基于协同过滤的召回" class="headerlink" title="基于协同过滤的召回"></a>基于协同过滤的召回</h3><p>协同过滤算法<code>(Collaborative Filtering)</code>是比较经典常用的推荐算法，它是一种完全依赖用户和物品之间行为关系的推荐算法。我们从它的名字“协同过滤”中，也可以窥探到它背后的原理，就是 “协同大家的反馈、评价和意见，一起对海量的信息进行过滤，从中筛选出用户可能感兴趣的信息”。协同过滤算法的主要分类：</p>
<ul>
<li>基于物品的协同过滤算法：给用户推荐与他之前喜欢的物品相似的物品。</li>
<li>基于用户的协同过滤算法：给用户推荐与他兴趣相似的用户喜欢的物品。</li>
</ul>
<h4 id="基于物品的协同过滤算法"><a href="#基于物品的协同过滤算法" class="headerlink" title="基于物品的协同过滤算法"></a>基于物品的协同过滤算法</h4><p><strong>基于物品的协同过滤(ItemCF)</strong>的基本思想是预先根据所有用户的历史偏好数据计算物品之间的相似性，然后把与用户喜欢的物品相类似的物品推荐给用户。比如物品<code>a</code>和<code>c</code>非常相似，因为喜欢<code>a</code>的用户同时也喜欢<code>c</code>，而用户<code>A</code>喜欢<code>a</code>，所以把<code>c</code>推荐给用户<code>A</code>。<code>ItemCF</code>算法并不利用物品的内容属性计算物品之间的相似度， 主要通过分析用户的行为记录计算物品之间的相似度， 该算法认为， 物品<code>a</code>和物品<code>c</code>具有很大的相似度是因为喜欢物品<code>a</code>的用户大都喜欢物品<code>c</code>。</p>
<h5 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h5><p>基于物品的协同过滤算法主要分为两步：</p>
<ul>
<li>计算物品之间的相似度；</li>
<li>根据物品的相似度和用户的历史行为给用户生成推荐列表（购买了该商品的用户也经常购买的其他商品）。</li>
</ul>
<h5 id="相似度计算"><a href="#相似度计算" class="headerlink" title="相似度计算"></a>相似度计算</h5><p><strong>购买了该商品的用户也经常购买的其他商品</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202215784.png" alt="img"></p>
<p>分母   是喜欢物品  的用户数，而分子  是同时喜欢物品  和物品  的用户数。因此，上述公式可以理解为喜欢物品  的用户中有多少比例的用户也喜欢物品  。 上述公式虽然看起来很有道理，但是却存在一个问题。如果物品  很热门，很多人都喜欢，那么  就会很大，接近  。因此，该公式会造成任何物品都会和热门的物品有很大的相似度，这对于致力于挖掘长尾信息的推荐系统来说显然不是一个好的特性。为了避免推荐出热门的物品，可以用下面的公式，这个公式惩罚了物品  的权重，因此减轻了热门物品会和很多物品相似的可能性。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202218223.png" alt="img"></p>
<p>除了在计算物品之间相似度时可以对热门物品进行惩罚外，可以在此基础上，进一步引入参数  ，这样可以通过控制参数  来决定对热门物品的惩罚力度。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192140478.png" alt="img"></p>
<p><strong>相似度算法改进</strong></p>
<p>在协同过滤中两个物品产生相似度是因为它们共同出现在很多用户的兴趣列表中。也就是说，每个用户的兴趣列表都对物品的相似度产生贡献。那么是不是每个用户的贡献都相同呢?</p>
<p>假设有这么一个用户，他是开书店的，并且买了当当网上<code>80%</code>的书准备用来自己卖。那么他的购物车里包含当当网<code>80%</code>的书。假设当当网有<code>100</code>万本书，也就是说他买了<code>80</code>万本。从前面对<code>ItemCF</code>的讨论可以看到，这意味着因为存在这么一个用户，有<code>80</code>万本书两两之间就产生了相似度，也就是说，内存里即将诞生一个<code>80</code>万乘<code>80</code>万的稠密矩阵。</p>
<p><code>John S. Breese</code>中提出了一个称为<code>IUF(Inverse User Frequence)</code>，即<strong>用户活跃度</strong>对数的倒数的参数，他也认为活跃用户对物品相似度的贡献应该小于不活跃的用户，他提出应该增加<code>IUF</code>参数来修正物品相似度的计算公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210945142.png" alt="img"></p>
<p>上述公式对活跃用户做了一种软性的惩罚，但是对于很多过于活跃的用户，比如上面那位买了当当网<code>80%</code>图书的用户，为了避免相似度矩阵过于稠密，我们在实际计算中一般直接忽略他的兴趣列表，而不将其纳入到相似度计算的数据集中。</p>
<p><strong>相似度矩阵归一化处理</strong></p>
<p><code>Karypis</code>在研究中发现如果将<code>ItemCF</code>的相似度矩阵按最大值归一化，可以提高推荐的准确率。其研究表明，如果已经得到了物品相似度矩阵  ，那么可以用如下公式得到归一化之后的相似度矩阵  ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210948508.png" alt="img"></p>
<p>归一化的好处不仅仅在于增加推荐的准确度，它还可以提高推荐的覆盖率和多样性。</p>
<p><strong>实例讲解</strong></p>
<p>下表是一个简易的原始数据集，也称之为<code>User-Item</code>表，即用户-物品列表，记录了每个用户喜爱的物品，数据表格如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>用户</th>
<th>喜爱的物品</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>{a,b,d}</td>
</tr>
<tr>
<td>B</td>
<td>{b,c,e}</td>
</tr>
<tr>
<td>C</td>
<td>{c,d}</td>
</tr>
<tr>
<td>D</td>
<td>{b,c,d}</td>
</tr>
<tr>
<td>E</td>
<td>{a,d}</td>
</tr>
</tbody>
</table>
</div>
<p>接着，我们分别建立用户<code>A</code>-<code>E</code>的共现矩阵，并将他们累加起来。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202254827.png" alt="img"></p>
<p>接下来我们计算最终的物品相似度矩阵，以物品<code>a</code>和物品<code>b</code>的相似度计算为例，通过上面计算的计算可知  ，即同时喜欢物品<code>a</code>和物品<code>b</code>的用户有一位。根据<code>User-Item</code>表可以统计出  ，  ，那么物品<code>a</code>和物品<code>b</code>的相似度  计算如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210936324.png" alt="img"></p>
<h5 id="结果预测"><a href="#结果预测" class="headerlink" title="结果预测"></a>结果预测</h5><p>在得到物品之间的相似度后，<code>ItemCF</code>通过如下公式计算用户  对一个物品  的兴趣：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210950233.png" alt="img"></p>
<p>这里  是用户喜欢的物品的集合，  是和物品  最相似的 个物品的集合，  是物品  和  的相似度，  是用户  对物品  的兴趣。（对于隐反馈数据集，如果用户  对物品  有过行为，即可令  。）该公式的含义是，和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。</p>
<p><strong>实例讲解</strong></p>
<p>下图是一个基于物品推荐的简单例子。该例子中，用户喜欢《C++ Primer中文版》和《编程之美》两本书。然后<code>ItemCF</code>会为这两本书分别找出和它们最相似的  本书，然后根据公式的定义计算用户对每本书的感兴趣程度。比如，<code>ItemCF</code>给用户推荐《算法导论》，是因为这本书和《C++Primer中文版》相似，相似度为  ，而且这本书也和《编程之美》相似，相似度是  。考虑到用户对《C++ Primer中文版》的兴趣度是  ，对《编程之美》的兴趣度是  ，那么用户对《算法导论》的兴趣度就是  。 <img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210958573.png" alt="img"></p>
<h4 id="基于用户的协同过滤算法"><a href="#基于用户的协同过滤算法" class="headerlink" title="基于用户的协同过滤算法"></a>基于用户的协同过滤算法</h4><p><strong>基于用户的协同过滤(UserCF)</strong>，思想其实比较简单，当一个用户<code>A</code>需要个性化推荐的时候， 我们可以先找到和他有相似兴趣的其他用户， 然后把那些用户喜欢的， 而用户<code>A</code>没有听说过的物品推荐给<code>A</code>。</p>
<h5 id="算法步骤-1"><a href="#算法步骤-1" class="headerlink" title="算法步骤"></a>算法步骤</h5><p>基于用户的协同过滤算法分为两步骤：</p>
<ul>
<li>找到与当前用户<code>A</code>相似的用户<code>B</code>；</li>
<li>将相似用户<code>B</code>喜欢的物品而用户<code>A</code>没有见过的物品推荐给用户<code>A</code>。</li>
</ul>
<h5 id="相似度计算-1"><a href="#相似度计算-1" class="headerlink" title="相似度计算"></a>相似度计算</h5><p><strong>欧式距离</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202054636.png" alt="img"></p>
<p><strong>曼哈顿距离</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202055336.png" alt="img"></p>
<p><strong>杰卡德(Jaccard)相似系数</strong></p>
<p>两个集合<code>A</code>和<code>B</code>交集元素的个数在<code>A</code>、<code>B</code>并集中所占的比例，称为这两个集合的杰卡德系数，用符号<code>J(A,B)</code>表示。杰卡德相似系数是衡量两个集合相似度的一种指标（余弦距离也可以用来衡量两个集合的相似度），<code>Jaccard</code>值越大说明相似度越高。由于杰卡德相似系数一般无法反映具体用户的评分喜好信息，所以常用来<strong>评估用户是否会对某物品进行打分， 而不是预估用户会对某物品打多少分</strong>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202037061.png" alt="img"></p>
<p><strong>余弦相似度</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202037832.png" alt="img"></p>
<p><strong>皮尔逊相关系数</strong></p>
<p>相比余弦相似度，皮尔逊相关系数通过<strong>使用用户平均分对各独立评分进行修正，减小了用户评分偏置的影响</strong>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202048519.png" alt="img"></p>
<p>其中  表示用户  对物品  的评分，  表示用户  对所有物品评分的平均值，  代表所有物品的集合。</p>
<h5 id="结果预测-1"><a href="#结果预测-1" class="headerlink" title="结果预测"></a>结果预测</h5><p>根据上面的几种方法， 我们可以计算出向量之间的相似程度， 也就是可以计算出<code>Alice</code>和其他用户的相近程度， 这时候我们就可以选出与<code>Alice</code>最相近的前  个用户， 基于他们对某一物品的评价猜测出<code>Alice</code>的打分值。</p>
<p>这里最常用的方式是利用用户相似度和相似用户的评价的加权平均获得目标用户的评价预测。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202104133.png" alt="img"></p>
<p>其中  是用户  与用户  的相似度，  是用户  对物品  的评分，  是所有用户的集合。</p>
<p>还有一种方式打分方式， 这种方式考虑的更加全面， 依然是用户相似度作为权值， 但后面不单纯的是其他用户对物品的评分， 而是该物品的评分与此用户的所有评分的差值进行加权平均， 这时候考虑到了有的用户内心的评分标准不一的情况， 即有的用户喜欢打高分， 有的用户喜欢打低分的情况。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202135669.png" alt="img"></p>
<p>其中，  是用户  与用户  的相似度，  是用户  对物品  的评分，  是用户  对所有物品打分的平均值，  是用户  对所有物品打分的平均值，其实就是对真实值与平均值的误差进行重要性加权。</p>
<h4 id="Swing-Graph-based"><a href="#Swing-Graph-based" class="headerlink" title="Swing(Graph-based)"></a>Swing(Graph-based)</h4><h5 id="前述方法局限性"><a href="#前述方法局限性" class="headerlink" title="前述方法局限性"></a>前述方法局限性</h5><ul>
<li>基于 Cosine, Jaccard, 皮尔逊相关性等相似度计算的协同过滤算法，在计算邻居关联强度的时候只关注于 Item-based (常用，因为item相比于用户变化的慢，且新Item特征比较容易获得)，Item-based CF 只关注于 Item-User-Item 的路径，把所有的User-Item交互都平等得看待，从而忽视了 User-Item 交互中的大量噪声，推荐精度存在局限性。</li>
<li>对互补性产品的建模不足，可能会导致用户购买过手机之后还继续推荐手机，但用户短时间内不会再继续购买手机，因此产生无效曝光。</li>
</ul>
<h5 id="Swing算法"><a href="#Swing算法" class="headerlink" title="Swing算法"></a>Swing算法</h5><p>Swing 通过利用 User-Item-User 路径中所包含的信息，考虑 User-Item 二部图中的鲁棒内部子结构计算相似性。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192157333.png" alt="img"></p>
<ul>
<li>什么是内部子结构？ 以经典的啤酒尿布故事为例，张三同时购买了啤酒和尿布，这可能是一种巧合。但两个甚至多个顾客都同时购买了啤酒尿布，这就证明啤酒和尿布具有相关关系。这样共同购买啤酒和尿布的用户越多，啤酒和尿布的相关度就会越高。</li>
<li>通俗解释：若用户  和用户  之间除了购买过  外，还购买过商品  ，则认为两件商品是具有某种程度上的相似的。也就是说，商品与商品之间的相似关系，是通过用户关系来传递的。为了衡量物品  和  的相似性，比较同时购买了物品  和  的用户  和用户  ， 如果这两个用户共同购买的物品越少，即这两个用户原始兴趣不相似，但仍同时购买了两个相同的物品  和  ， 则物品  和  的相似性越高。</li>
<li>计算公式如下，其中  是点击过商品  的用户集合， 是用户  点击过的商品集合，  是平滑系数。  ，  是用户权重参数，来降低活跃用户的影响。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192205012.png" alt="img"></p>
<h5 id="Surprise算法"><a href="#Surprise算法" class="headerlink" title="Surprise算法"></a>Surprise算法</h5><p>Surprise 算法利用商品分类信息和用户共同购买图上的聚类技术来建模产品之间的组合关系。</p>
<p>首先在行为相关性中引入连续时间衰减因子，然后引入基于交互数据的聚类方法解决数据稀疏的问题，旨在帮助用户找到互补商品。互补相关性主要从三个层面考虑，类别层面，商品层面和聚类层面。</p>
<ul>
<li>类别层面 首先通过商品和类别的映射关系，我们可以得到 user-category 矩阵。随后使用简单的相关性度量可以计算出类别  ，  的相关性。  为在购买过  之后购买  类的数量，  为购买  类的数量。（）</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192210225.png" alt="img"></p>
<ul>
<li><p>商品层面 商品层面的相关性挖掘主要有两个关键设计：</p>
<ul>
<li>商品的购买顺序是需要被考虑的，例如在用户购买手机后推荐充电宝是合理的，但在用户购买充电宝后推荐手机是不合理的。</li>
<li>两个商品购买的时间间隔也是需要被考虑的，时间间隔越短越能证明两个商品的互补关系。</li>
</ul>
<p>最终商品层面的互补相关性被定义为如下，其中  属于  的相关类，且  的购买时间晚于  。</p>
</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192217890.png" alt="img"></p>
<ul>
<li>聚类层面<ul>
<li>如何聚类？传统的聚类算法（基于密度和k-means）在数十亿产品规模下的淘宝场景中不可行，所以作者采用了标签传播算法。</li>
<li>在哪里标签传播？Item-item 图，其中把Swing计算的排名靠前item为邻居，边的权重就是Swing分数。</li>
<li>表现如何？快速而有效，15分钟即可对数十亿个项目进行聚类。最终聚类层面的相关度计算同上面商品层面的计算公式。</li>
</ul>
</li>
<li>线性组合：  ，其中是  作者设置的权重超参数。Surprise算法通过利用类别信息和标签传播技术解决了用户共同购买图上的稀疏性问题。</li>
</ul>
<h4 id="基于模型的协同过滤算法"><a href="#基于模型的协同过滤算法" class="headerlink" title="基于模型的协同过滤算法"></a>基于模型的协同过滤算法</h4><p>基于模型的协同过滤作为目前最主流的协同过滤类型，我们的问题是这样的：  个物品，  个用户的数据，只有部分用户和部分数据之间是有评分数据的，其它部分评分是空白。此时我们要用已有的部分稀疏数据来预测那些空白的物品和数据之间的评分关系，找到最高评分的物品推荐给用户。</p>
<p>对于这个问题，用机器学习的思想来建模解决，主流的方法可以分为：用关联算法，聚类算法，分类算法，回归算法，矩阵分解，神经网络，图模型以及隐语义模型来解决。</p>
<p><strong>用关联算法做协同过滤</strong></p>
<p>一般我们可以找出用户购买的所有物品数据里频繁出现的项集活序列，来做频繁集挖掘，找到满足支持度值的关联物品的频繁  项集或者序列。如果用户购买了频繁  项集或者序列里的部分物品，那么我们可以将频繁项集或序列里的其他物品按一定的评分准则推荐给用户，这个评分准则可以包括支持度，置信度和提升度等。</p>
<p><strong>用聚类算法做协同过滤</strong></p>
<p>用聚类算法做协同过滤就和前面的基于用户或者项目的协同过滤有些类似了。我们可以按照用户或者按照物品基于一定的距离度量来进行聚类。如果基于用户聚类，则可以将用户按照一定距离度量方式分成不同的目标人群，将同样目标人群评分高的物品推荐给目标用户。基于物品聚类的话，则是将用户评分高物品的相似同类物品推荐给用户。</p>
<p><strong>用分类算法做协同过滤</strong></p>
<p>如果我们根据用户评分的高低，将分数分成几段的话，则这个问题变成分类问题。比如最直接的，设置一份评分阈值，评分高于阈值的就是推荐，评分低于阈值就是不推荐，我们将问题变成了一个二分类问题。虽然分类问题的算法多如牛毛，但是目前使用最广泛的是逻辑回归。为啥是逻辑回归而不是看起来更加高大上的比如支持向量机呢？因为逻辑回归的解释性比较强，每个物品是否推荐我们都有一个明确的概率放在这，同时可以对数据的特征做工程化，得到调优的目的。</p>
<p><strong>用回归算法做协同过滤</strong></p>
<p>用回归算法做协同过滤比分类算法看起来更加的自然。我们的评分可以是一个连续的值而不是离散的值，通过回归模型我们可以得到目标用户对某商品的预测打分。</p>
<p><strong>用神经网络做协同过滤</strong></p>
<p>用神经网络乃至深度学习做协同过滤应该是以后的一个趋势。目前比较主流的用两层神经网络来做推荐算法的是限制玻尔兹曼机<code>(RBM)</code>。在目前的<code>Netflix</code>算法比赛中，<code>RBM</code>算法的表现很牛。当然如果用深层的神经网络来做协同过滤应该会更好，大厂商用深度学习的方法来做协同过滤应该是将来的一个趋势。</p>
<p><strong>用图模型做协同过滤</strong></p>
<p>用图模型做协同过滤，则将用户之间的相似度放到了一个图模型里面去考虑，常用的算法是<code>SimRank</code>系列算法和马尔科夫模型算法。对于<code>SimRank</code>系列算法，它的基本思想是被相似对象引用的两个对象也具有相似性。算法思想有点类似于大名鼎鼎的<code>PageRank</code>。而马尔科夫模型算法当然是基于马尔科夫链了，它的基本思想是基于传导性来找出普通距离度量算法难以找出的相似性。</p>
<p><strong>用隐语义模型做协同过滤</strong></p>
<p>隐语义模型主要是基于<code>NLP</code>的，涉及到对用户行为的语义分析来做评分推荐，主要方法有隐性语义分析<code>LSA</code>和隐含狄利克雷分布<code>LDA</code>。</p>
<p><strong>用矩阵分解做协同过滤</strong></p>
<p>用矩阵分解做协同过滤是目前使用也很广泛的一种方法。由于传统的奇异值分解<code>SVD</code>要求矩阵不能有缺失数据，必须是稠密的，而我们的用户物品评分矩阵是一个很典型的稀疏矩阵，直接使用传统的<code>SVD</code>到协同过滤是比较复杂的。目前主流的矩阵分解推荐算法主要是<code>SVD</code>的一些变种，比如<code>FunkSVD</code>，<code>BiasSVD</code>和<code>SVD++</code>。</p>
<h5 id="矩阵分解"><a href="#矩阵分解" class="headerlink" title="矩阵分解"></a>矩阵分解</h5><p>  矩阵分解是指将一个矩阵分解成两个或者多个矩阵的乘积，实际推荐计算时不再使用大矩阵，而是用分解得到的两个小矩阵：一个是由代表用户偏好的用户隐因子向量组成，另一个是由代表物品语义主题的隐因子向量组成。</p>
<p>对于下图的<code>User-Item</code>矩阵（评分矩阵），记为  。可以将其分解成两个或者多个矩阵的乘积，假设分解成两个矩阵  和  ，我们要使得矩阵  和  的乘积能够还原原始的矩阵  ，即  。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231131422.png" alt="img"></p>
<p>在我们得到用户对每个标的物的评分后，从该评分中过滤掉用户已经操作过的标的物，针对剩下的标的物得分做降序排列取<code>topN</code>推荐给用户。矩阵分解算法的核心思想是将用户行为矩阵分解为两个低秩矩阵的乘积，通过分解，我们分别将用户和标的物嵌入到了同一个  维的向量空间（  一般很小，几十到上百），用户向量和标的物向量的内积代表了用户对标的物的偏好度。所以，矩阵分解算法本质上也是一种<strong>嵌入方法</strong>。上面提到的k维向量空间的每一个维度是<strong>隐因子(latent factor)</strong>，之所以叫隐因子，是因为每个维度不具备与现实场景对应的具体的可解释的含义，所以矩阵分解算法也是一类隐因子算法。这  个维度代表的是某种行为特性，但是这个行为特性又是无法用具体的特征解释的，从这点也可以看出，矩阵分解算法的可解释性不强，我们比较难以解释矩阵分解算法为什么这么推荐。</p>
<h6 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h6><p>通过矩阵分解将用户  和标的物  嵌入如下的  维隐式特征空间向量：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231137649.png" alt="img"></p>
<p>那么用户  对标的物  的预测评分为  ，真实值与预测值之间的误差为  。如果预测得越准，那么  越小，针对所有用户评分过的  对，如果我们可以保证这些误差之和尽量小，那么有理由认为我们的预测是精准的。有了上面的分析，我们就可以将矩阵分解转化为一个机器学习问题，这也就是<strong>Funk-SVD(Basic SVD/LFM)</strong>的思想。在Funk-SVD的基础之上加上正则化项，也就成了<strong>RSVD</strong>。具体地说，我们可以将矩阵分解转化为如下等价的求最小值的最优化问题。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231146383.png" alt="img"></p>
<p>其中  是超参数，  是正则化项。</p>
<h6 id="求解方法"><a href="#求解方法" class="headerlink" title="求解方法"></a>求解方法</h6><p>对于上一节讲到的最优化问题，在工程上一般有两种求解方法，<code>SGD(Stochastic Gradient Descent)</code>和<code>ALS(Alternating Least Squares)</code>。</p>
<ul>
<li>利用SGD来求解矩阵分解</li>
</ul>
<p>我们定义真实评分和预测评分的误差为：  ，我们可以将上面的优化问题改写成如下函数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231152053.png" alt="img"></p>
<p>对  和  求偏导数，我们可以得到：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231153530.png" alt="img"></p>
<p>有了偏导数，我们沿着导数(梯度)相反的方向更新：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231154583.png" alt="img"></p>
<ul>
<li>利用ALS来求解矩阵分解</li>
</ul>
<p><code>ALS</code>方法是一个高效的求解矩阵分解的算法，目前<code>Spark Mllib</code>中的协同过滤算法就是基于<code>ALS</code>求解的矩阵分解算法，它可以很好地拓展到分布式计算场景，轻松应对大规模训练数据的情况。下面对ALS算法原理及特点做一个简单介绍。<code>ALS</code>算法的原理基本就是名字表达的意思，通过交替优化求得极值。</p>
<p>一般过程是先固定  ，那么上述优化问题就变成了一个关于  的二次函数，可以作为最小二乘问题来解决，求出最优的  后，固定  ，再解关于  的最小二乘问题，交替进行直到收敛。</p>
<p><code>ALS</code>算法有如下两个优势：</p>
<ul>
<li><p><strong>可以并行处理</strong></p>
<p>当固定某一个参数时，另一个参数的迭代更新只依赖自己，不依赖于其他的标的物的特征向量，所以可以将不同的参数更新放到不同的服务器上执行。<code>Spark</code>的<code>ALS</code>算法就是采用这样的方式做到并行化的。</p>
</li>
<li><p><strong>对于隐式特征问题比较合适</strong></p>
<p>用户真正的评分是很稀少的，所以利用隐式行为是更好的选择（其实也是不得已的选择）。当利用了隐式行为，那么用户行为矩阵就不会那么稀疏了，即有非常多的  对是非空的，计算量会更大，这时采用<code>ALS</code>算法是更合适的，因为固定  或者  ，让整个计算问题更加简单，容易求目标函数的极值。</p>
</li>
</ul>
<h6 id="矩阵分解推荐算法的拓展与优化"><a href="#矩阵分解推荐算法的拓展与优化" class="headerlink" title="矩阵分解推荐算法的拓展与优化"></a>矩阵分解推荐算法的拓展与优化</h6><p>矩阵分解算法是一个非常容易理解并易于分布式实现的算法。不光如此，矩阵分解算法的框架还是一个非常容易拓展的框架，可以整合非常多的其他信息及特性到该框架之下，从而丰富模型的表达空间，提升预测的准确度。本节我们就来总结和梳理一下矩阵分解算法可以进行哪些拓展与优化。</p>
<p><strong>整合偏差(bias)项</strong></p>
<p>不同的人对标的物的评价可能是不一样的，有的人倾向于给更高的评分，而有的人倾向于给更低的评分。对于同一个标的物，也会受到外界其他信息的干扰，影响人们对它的评价（比如视频，可能由于主演的热点事件导致该视频突然变火），这两种情况是由于用户和标的物引起的偏差。我们可以在这里引入<code>Bias</code>项，将评分表中观察到的值分解为  个部分：全局均值<code>(global average)</code>，标的物偏差<code>(item bias)</code>，用户偏差<code>(user bias)</code>和用户标的物交叉项<code>(user-item interaction)</code>。这时，我们可以用如下公式来预测用户  对标的物  的评分：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231206104.png" alt="img"></p>
<p><strong>增加更多的用户信息输入</strong></p>
<p>由于用户一般只对很少的标的物评分，导致评分过少，可能无法给该用户做出较好的推荐，这时可以通过引入更多的信息来缓解评分过少的问题。具体来说，我们可以整合用户隐式反馈（收藏、点赞、分享等）和用户人口统计学信息（年龄、性别、地域、收入等）到矩阵分解模型中。</p>
<p><strong>整合时间因素</strong></p>
<p>到目前为止，我们的模型都是静态的。实际上，用户的偏好、用户对标的物的评分趋势、以及标的物的受欢迎程度都是随着时间变化的。拿电影来说，用户可能原来喜欢爱情类的电影，后面可能会转而喜欢科幻喜剧类电影，所以我们用包含时间的  来表示用户的偏好特性向量。用户开始对某个视频偏向于打高分，经过一段时间后，用户看的电影多了起来，用户的审美越来越挑剔，所以一般不会再对一个电影打很高的分数了，除非他觉得真的特别好，因此，我们可以用包含时间的  来表示用户的偏差随着时间而变化。对于标的物偏差也一样，一个电影可能开始不是很火，但是如果它的主演后面演了一部非常火的电影，也会将原来的电影热度带到一个新的高度。比如，前两年比较火的李现演的《亲爱的，热爱的》，导致李现人气高涨，他原来演的《南方有乔木》的百度搜索指数在《亲爱的，热爱的》播出期间高涨。因此，我们可以用包含时间的  来表示标的物偏差随着时间的变化而变化的趋势。标的物本身的特征  ，我们可以认为是稳定的，它代表的是标的物本身的固有属性或者品质，所以不会随着时间而变化。</p>
<p>基于上面的分析，我们最终的预测用户评分的公式整合时间因素后可以表达为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231212913.png" alt="img"></p>
<p><strong>整合用户对评分的置信度</strong></p>
<p>一般来说，用户对不同标的物的评分不是完全一样可信的，可能会受到外界其他因素的影响，比如某个视频播出后，主播发生了热点事件，肯定会影响用户对该视频的评价，节假日，特殊事件也会影响用户的评价。对于隐式反馈，一般我们用  和  来表示用户是否喜欢该标的物，多少有点绝对，更好的方式是引入一个喜欢的概率/置信度，用户对该标的物操作次数越多、时间越长、付出越大，相应的置信度也越大。因此，我们可以在用户对标的物的评分中增加一个置信度的因子  ，那么最终的优化公式就变为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231213243.png" alt="img"></p>
<p><strong>隐式反馈</strong></p>
<p>用二元变量  表示用户  对标的物的偏好，  表示用户  对标的物  有兴趣，  表示对标的物  无兴趣。  是用户  对标的物的隐式反馈，如观看视频的时长，点击次数等等。  和  的关系见下面公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231220341.png" alt="img"></p>
<p> 越大，有理由认为用户对标的物兴趣的置信度越高，比如一个文章读者看了好几篇，肯定比看一遍更能反映出读者对这篇文章的喜爱。具体可以用下面的公式来衡量用户  对标的物  的置信度，其中  是一个超参数，作者建议取  。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231221419.png" alt="img"></p>
<p>于是我们可以定义如下公式</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231225576.png" alt="img"></p>
<p>将用户的操作  分解为置信度  和偏好  能够更好地反映隐式行为的特征，并且从实践上可以大幅提升预测的准确度。同时，通过该分解，利用代数上的一些技巧及该模型的巧妙设计，该算法的时间复杂度与用户操作行为总次数线性相关，不依赖于用户数和标的物数，因此非常容易并行化。</p>
<p>隐式反馈也有一些缺点，不像明确的用户评分，无法很好地表达负向反馈，用户购买一个物品可能是作为礼物送给别人的，他自己可能不喜欢这个物品，用户观看了某个视频，有可能是产品进入视频详情页时是自动起播的，这些行为是包含很多噪音的。</p>
<p><strong>整合用户和标的物metadata信息</strong></p>
<p>利用特征的嵌入向量之和来表示用户或者标的物向量，这就很好地将<code>metadata</code>信息整合到了用户和标的物向量中了，再利用用户向量   和标的物向量  的内积加上<code>bias</code>项，通过一个<code>logistic</code>函数来获得用户  对标的物  的偏好概率/得分，从这里的介绍可以看到，该模型很好地将矩阵分解和<code>metadata</code>信息整合到了一个框架之下。</p>
<h3 id="基于向量的召回"><a href="#基于向量的召回" class="headerlink" title="基于向量的召回"></a>基于向量的召回</h3><h4 id="FM召回"><a href="#FM召回" class="headerlink" title="FM召回"></a>FM召回</h4><p>FM用于排序详细介绍见后文经典排序模型。由于需要将 FM 模型用在召回，故将二阶特征交互项拆分为用户和物品项。有：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202004566.png" alt="img"></p>
<p>在比较用户与不同物品之间的匹配分时，只需要比较：（1）物品内部之间的特征交互得分；（2）用户和物品之间的特征交互得分。因此合并 FM 的一阶、二阶特征交互项，得到基于 FM 召回的匹配分计算公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202035154.png" alt="img"></p>
<h4 id="item2vec召回系列"><a href="#item2vec召回系列" class="headerlink" title="item2vec召回系列"></a>item2vec召回系列</h4><h5 id="Word2vec基础"><a href="#Word2vec基础" class="headerlink" title="Word2vec基础"></a>Word2vec基础</h5><p>Word2vec(Mikolov et al. 2013)是一个用来学习dense word vector的算法：</p>
<ol>
<li>我们使用<strong>大量的文本语料库</strong></li>
<li>词汇表中的每个单词都由一个<strong>词向量dense word vector</strong>表示</li>
<li>遍历文本中的每个位置 t，都有一个<strong>中心词 c（center） 和上下文词 o（“outside”）</strong>，如图1中的banking</li>
<li>在整个语料库上使用数学方法<strong>最大化单词o在单词c周围出现了这一事实</strong>，从而得到单词表中每一个单词的dense vector</li>
<li>不断调整词向量dense word vector以达到最好的效果</li>
</ol>
<p>Word2vec包含两个模型，<strong>Skip-gram与CBOW</strong>。我们希望<strong>最大化单词o在单词c周围出现了这一事实</strong>，而我们需要用数学语言表示“单词o在单词c周围出现了”这一事件，如此才能进行词向量的不断调整。很自然地，我们需要<strong>使用概率工具描述事件的发生</strong>，我们想到用条件概率  表示“给定中心词c,它的上下文词o在它周围出现了”。</p>
<p>下图展示了以“into”为中心词，窗口大小为2的情况下它的上下文词。以及相对应的 </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202054590.png" alt="img"></p>
<p>我们滑动窗口，再以banking为中心词</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202054939.png" alt="img"></p>
<p>那么，如果我们在整个语料库上不断地滑动窗口，我们可以得到所有位置的  ，我们希望在所有位置上<strong>最大化单词o在单词c周围出现了这一事实</strong>，由极大似然法可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202058666.png" alt="img"></p>
<p>此式还可以写为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202059177.png" alt="img"></p>
<p>加log，加负号，缩放大小可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202100516.png" alt="img"></p>
<p>上式即为<strong>skip-gram的损失函数</strong>，最小化损失函数，就可以得到合适的词向量</p>
<p>得到上式后，产生了两个问题：</p>
<ol>
<li>怎么表示？</li>
<li>为何最小化损失函数能够得到良好表示的词向量dense word vector？</li>
</ol>
<p>回答1：我们使用<strong>中心词c和上下文词o的相似性</strong>来计算  ，更具体地，相似性由<strong>词向量的点积</strong>表示：  。使用词向量的点积表示  的原因：（1）计算简单（1）出现在一起的词向量意义相关，则希望它们相似。又因为  是一个概率，所以我们在整个语料库上使用<strong>softmax</strong>将点积的值映射到概率：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202104262.png" alt="img"></p>
<p>注：注意到上图，中心词词向量为  ，而上下文词词向量为  。也就是说每个词会对应两个词向量，<strong>在词w做中心词时</strong>，使用  作为词向量，而在它做上下文词时，使用  作为词向量。这样做的原因是为了求导等操作时计算上的简便。当整个模型训练完成后，我们既可以使用  作为词  的词向量，也可以使用  作为词  的词向量，亦或是将二者平均。在下一部分的模型结构中，我们将更清楚地看到两个词向量究竟在模型的哪个位置。</p>
<p>回答2：由上文所述，  。所以损失函数是关于  和  的函数，我们通过梯度下降法调整  和  的值，最小化损失函数，即得到了良好表示的词向量。</p>
<h5 id="Word2vec模型结构"><a href="#Word2vec模型结构" class="headerlink" title="Word2vec模型结构"></a>Word2vec模型结构</h5><p>这是一个输入为  维的one-hot向量（V为整个词汇表的长度，这个向量只有一个1值，其余为0值表示一个词），单隐藏层（<strong>隐藏层的维度为N，这里是一个超参数，这个参数由我们定义，也就是词向量的维度</strong>），输出为  维的softmax层的模型。</p>
<p>为  的参数矩阵，为  的参数矩阵。</p>
<p>模型的输入为 形状的one-hot向量（V为整个词汇表的长度，这个向量只有一个1值，其余为0值表示一个词）。隐藏层的维度为N，这里是一个超参数，这个参数由我们定义，也就是词向量的维度。为  的参数矩阵。</p>
<p>我们这里，考虑Skip-gram算法，输入为中心词c的one-hot表示</p>
<p>由输入层到隐藏层，根据矩阵乘法规则，可知，<strong>的每一行即为词汇表中的每一个单词的词向量v</strong>， 的 inputs 乘上  的，隐藏层即为  维的  。</p>
<p>而中的每一列即为词汇表中的每一个单词的词向量u。根据乘法规则， 的隐藏层乘上  的参数矩阵，得到的  的输出层的每一个值即为 ，加上softmax变化即为 ，其中  的每一列就是周围词向量  。</p>
<p>有V个w,其中的P(o|c)即实际样本中的上下文词的概率，为我们最为关注的值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202111969.png" alt="img"></p>
<p>如上文所述，Skip-gram为给定中心词，预测周围的词，即求  ，如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202113543.png" alt="img"></p>
<p>而CBOW为给定周围的词，预测中心词，即求  ,如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202113829.png" alt="img"></p>
<h5 id="item2Vec模型"><a href="#item2Vec模型" class="headerlink" title="item2Vec模型"></a>item2Vec模型</h5><p>Item2Vec 的原理十分简单，它是基于 Skip-Gram 模型的物品向量训练方法。但又存在一些区别，如下：</p>
<ul>
<li>词向量的训练是基于句子序列（sequence），但是物品向量的训练是基于物品集合（set）。</li>
<li>因此，物品向量的训练丢弃了空间、时间信息。</li>
</ul>
<p>Item2Vec 论文假设对于一个集合的物品，它们之间是相似的，与用户购买它们的顺序、时间无关。当然，该假设在其他场景下不一定使用，但是原论文只讨论了该场景下它们实验的有效性。由于忽略了空间信息，原文将共享同一集合的每对物品视为正样本。目标函数如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202119928.png" alt="img"></p>
<p>在 Skip-Gram 模型中，提到过每个单词  有2个特征表示。在 Item2Vec 中同样如此，论文中是将物品的中心词向量  作为物品的特征向量。作者还提到了其他两种方式来表示物品向量：</p>
<ul>
<li><strong>add</strong>：</li>
<li><strong>concat</strong>：</li>
</ul>
<h5 id="Airbnb召回"><a href="#Airbnb召回" class="headerlink" title="Airbnb召回"></a>Airbnb召回</h5><p>Airbnb 描述了两种 Embedding 的构建方法，分别为：</p>
<ul>
<li>用于描述短期实时性的个性化特征 Embedding：<strong>listing Embeddings</strong></li>
<li>用于描述长期的个性化特征 Embedding：<strong>user-type &amp; listing type Embeddings</strong></li>
</ul>
<h4 id="YouTubeDNN召回"><a href="#YouTubeDNN召回" class="headerlink" title="YouTubeDNN召回"></a>YouTubeDNN召回</h4><p>召回模型的结构如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202146491.png" alt="img"></p>
<p>它的输入主要是用户侧的特征，包括用户观看的历史video序列， 用户搜索的历史tokens， 然后就是用户的人文特征，比如地理位置， 性别，年龄这些。</p>
<ul>
<li><p>用户历史序列，历史搜索tokens这种序列性的特征: 一般长这样<code>[item_id5, item_id2, item_id3, ...]</code>， 这种id特征是高维稀疏，首先会通过一个embedding层，转成低维稠密的embedding特征，即历史序列里面的每个id都会对应一个embedding向量，这样历史序列就变成了多个embedding向量的形式， 这些向量一般会进行融合，常见的是average pooling，即每一维求平均得到一个最终向量来表示用户的历史兴趣或搜索兴趣。论文里面使用了用户最近的50次观看历史，用户最近50次搜索历史token，embedding维度是256维， 采用的average pooling。  当然，这里还可以把item的类别信息也隐射到embedding，与前面的concat起来。</p>
</li>
<li><p>用户人文特征， 这种特征处理方式就是离散型的依然是labelEncoder，然后embedding转成低维稠密， 而连续型特征，一般是先归一化操作，然后直接输入，当然有的也通过分桶，转成离散特征，这里不过多整理，特征工程做的事情了。  当然，这里还有一波操作值得注意，就是连续型特征除了用了本身，还用了  ，  这种， 可以加入更多非线性，增加模型表达能力。这些特征对新用户的推荐会比较有帮助，常见的用户的地理位置， 设备， 性别，年龄等。</p>
</li>
<li><p>这里一个比较特色的特征是example age。我们知道，视频有明显的生命周期，例如刚上传的视频比之后更受欢迎，也就是用户往往喜欢看最新的东西，而不管它是不是和用户相关，所以视频的流行度随着时间的分布是高度非稳态变化的（下面图中的绿色曲线）。但是我们模型训练的时候，是基于历史数据训练的（历史观看记录的平均），所以模型对播放某个视频预测值的期望会倾向于其在训练数据时间内的平均播放概率（平均热度），图中蓝色线。但如图中绿色线，实际上该视频在训练数据时间窗口内热度很可能不均匀， 用户本身就喜欢新上传的内容。所以，为了让模型学习到用户这种对新颖内容的bias，作者引入了”example age”这个特征来捕捉视频的生命周期。</p>
<p>“example age”定义为， 其中  是训练数据中所有样本的时间最大值，而  为当前样本的时间。<strong>线上预测时， 直接把example age全部设为0或一个小的负值，这样就不依赖于各个视频的上传时间了</strong>。 </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202158449.png" alt="img"></p>
<p><code>example age</code>这个特征到这里还没完， 原来加入这种时间bias的传统方法是使用<code>video age</code>， 即一个video上传到样本生成的这段时间跨度，对于某个视频的不同样本，其实这两种定义是等价的，因为他们的和是一个常数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202201783.png" alt="img"></p>
</li>
</ul>
<h4 id="双塔召回"><a href="#双塔召回" class="headerlink" title="双塔召回"></a>双塔召回</h4><h5 id="经典双塔"><a href="#经典双塔" class="headerlink" title="经典双塔"></a>经典双塔</h5><h6 id="经典双塔模型"><a href="#经典双塔模型" class="headerlink" title="经典双塔模型"></a>经典双塔模型</h6><p>在推荐系统中，最为关键的问题是如何做好用户与item的匹配问题，因此对于推荐系统中DSSM模型的则是为 user 和 item 分别构建独立的子网络塔式结构，利用user和item的曝光或点击日期进行训练，最终得到user侧的embedding和item侧的embedding。因此在推荐系统中，常见的模型结构如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211446441.png" alt="img"></p>
<p>从模型结构上来看，主要包括两个部分：user侧塔和item侧塔，对于每个塔分别是一个DNN结构。通过两侧的特征输入，通过DNN模块到user和item的embedding，然后计算两者之间的相似度(常用內积或者余弦值，下面会说这两种方式的联系和区别)，因此对于user和item两侧最终得到的embedding维度需要保持一致，即最后一层全连接层隐藏单元个数相同。</p>
<p>在召回模型中，将这种检索行为视为多类分类问题，类似于YouTubeDNN模型。将物料库中所有的item视为一个类别，因此损失函数需要计算每个类的概率值：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211448528.png" alt="img"></p>
<p>其中表示两个向量的相似度，表示预测类别的概率，表示物料库所有的item。但是在实际场景中，由于物料库中的item数量巨大，在计算上式时会十分的耗时，因此会采样一定的数量的负样本来近似计算，后面针对负样本的采样做一些简单介绍。</p>
<p>以上就是推荐系统中经典的双塔模型，之所以在实际应用中非常常见，是因为<strong>在海量的候选数据进行召回的场景下，速度很快，效果说不上极端好，但一般而言效果也够用了</strong>。之所以双塔模型在服务时速度很快，是因为模型结构简单(两侧没有特征交叉)，但这也带来了问题，双塔的结构无法考虑两侧特征之间的交互信息，<strong>在一定程度上牺牲掉模型的部分精准性</strong>。例如在精排模型中，来自user侧和item侧的特征会在第一层NLP层就可以做细粒度的特征交互，而对于双塔模型，user侧和item侧的特征只会在最后的內积计算时发生，这就导致很多有用的信息在经过DNN结构时就已经被其他特征所模糊了，因此双塔结构由于其结构问题先天就会存在这样的问题。下面针对这个问题来看看一下现有模型的解决思路。</p>
<h6 id="SENet双塔模型"><a href="#SENet双塔模型" class="headerlink" title="SENet双塔模型"></a>SENet双塔模型</h6><p>SENet由Momenta在2017年提出，当时是一种应用于图像处理的新型网络结构。后来张俊林大佬将SENet引入了精排模型<strong>FiBiNET</strong>中，其作用是为了将大量长尾的低频特征抛弃，弱化不靠谱低频特征embedding的负面影响，强化高频特征的重要作用。那SENet结构到底是怎么样的呢，为什么可以起到特征筛选的作用？</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211452527.png" alt="img"></p>
<p>从上图可以看出SENET主要分为三个步骤Squeeze, Excitation, Re-weight：</p>
<ul>
<li><p>Squeeze阶段：我们对每个特征的Embedding向量进行数据压缩与信息汇总，即在Embedding维度计算均值：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211453721.png" alt="img"></p>
<p>其中k表示Embedding的维度，Squeeze阶段是将每个特征的Squeeze转换成单一的数值。</p>
</li>
<li><p>Excitation阶段：这阶段是根据上一阶段得到的向量进行缩放，即将上阶段的得到的  的向量先压缩成  长度，然后在放回到   的维度，其中表示压缩的程度。这个过程的具体操作就是经过两层DNN。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211454010.png" alt="img"></p>
<p>该过程可以理解为：对于当前所有输入的特征，通过相互发生关联，来动态地判断哪些特征重要，哪些特征不重要，而这体现在Excitation阶段的输出结果 ，其反应每个特征对应的重要性权重。</p>
</li>
<li><p>Re-weight阶段：是将Excitation阶段得到的每个特征对应的权重  再乘回到特征对应的Embedding里，就完成了对特征重要性的加权操作。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211454382.png" alt="img"></p>
</li>
</ul>
<p>以上简单的介绍了一下SENet结构，可以发现这种结构可以通过对特征embedding先压缩，再交互，再选择，进而实现特征选择的效果。</p>
<p>此外张俊林大佬还将SENet应用于双塔模型中<strong>（SENet双塔模型）</strong>，模型结构如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211518409.png" alt="img"></p>
<p>从上图可以发现，具体地是将双塔中的user塔和Item侧塔的特征输入部分加上一个SENet模块，通过SENet网络，动态地学习这些特征的重要性，通过小权重抑制噪音或者无效低频特征，通过大权重放大重要特征影响的目的。</p>
<p>之所以SENet双塔模型是有效的呢？张俊林老师的解释是：双塔模型的问题在于User侧特征和Item侧特征交互太晚，在高层交互，会造成细节信息，也就是具体特征信息的损失，影响两侧特征交叉的效果。而SENet模块在最底层就进行了特征的过滤，使得很多无效低频特征即使被过滤掉，这样更多有用的信息被保留到了双塔的最高层，使得两侧的交叉效果很好；同时由于SENet模块选择出更加重要的信息，使得User侧和Item侧特征之间的交互表达方面增强了DNN双塔的能力。</p>
<p>因此SENet双塔模型主要是从特征选择的角度，提高了两侧特征交叉的有效性，减少了噪音对有效信息的干扰，进而提高了双塔模型的效果。此外，除了这样的方式，还可以通过增加通道的方式来增强两侧的信息交互。即对于user和item两侧不仅仅使用一个DNN结构，而是可以通过不同结构(如FM，DCN等)来建模user和item的自身特征交叉，例如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211523344.png" alt="img"></p>
<p>这样对于user和item侧会得到多个embedding，类似于多兴趣的概念。通过得到的多个user和item的embedding，然后分别计算余弦值再相加（两侧的Embedding维度需要对齐），进而增加了双塔两侧的信息交互。而这种方法在腾讯进行过尝试，他们提出的“并联”双塔就是按照这样的思路。</p>
<h6 id="多目标的双塔模型"><a href="#多目标的双塔模型" class="headerlink" title="多目标的双塔模型"></a>多目标的双塔模型</h6><p>现如今多任务学习在实际的应用场景也十分的常见，主要是因为实际场景中业务复杂，往往有很多的衡量指标，例如点击，评论，收藏，关注，转发等。在多任务学习中，往往会针对不同的任务使用一个独有的tower，然后优化不同任务损失。那么针对双塔模型应该如何构建多任务学习框架呢？</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211528560.png" alt="img"></p>
<p>如上图所示，在user侧和item侧分别通过多个通道(DNN结构)为每个任务得到一个user embedding和item embedding，然后针对不同的目标分别计算user 和 item 的相似度，并计算各个目标的损失，最后的优化目标可以是多个任务损失之和，或者使用多任务学习中的动态损失权重。</p>
<p>这种模型结构，可以针对多目标进行联合建模，通过多任务学习的结构，一方面可以利用不同任务之间的信息共享，为一些稀疏特征提供其他任务中的迁移信息，另一方面可以在召回时，直接使用一个模型得到多个目标预测，解决了多个模型维护困难的问题。也就是说，在线上通过这一个模型就可以同时得到多个指标，例如视频场景，一个模型就可以直接得到点赞，品论，转发等目标的预测值，进而通过这些值计算分数获得最终的Top-K召回结果。</p>
<h6 id="模型的应用"><a href="#模型的应用" class="headerlink" title="模型的应用"></a>模型的应用</h6><p>在实际的工业应用场景中，分为离线训练和在线服务两个环节。</p>
<ul>
<li>在离线训练阶段，同过训练数据，训练好模型参数。然后将候选库中所有的item集合离线计算得到对应的embedding，并存储进ANN检索系统，比如faiss。为什么将离线计算item集合，主要是因为item的会相对稳定，不会频繁的变动，而对于用户而言，如果将用户行为作为user侧的输入，那么user的embedding会随着用户行为的发生而不断变化，因此对于user侧的embedding需要实时的计算。</li>
<li>在线服务阶段，正是因为用户的行为变化需要被即使的反应在用户的embedding中，以更快的反应用户当前的兴趣，即可以实时地体现用户即时兴趣的变化。因此在线服务阶段需要实时的通过拼接用户特征，输入到user侧的DNN当中，进而得到user embedding，在通过user embedding去 faiss中进行ANN检索，召回最相似的K个item embedding。</li>
</ul>
<p>可以看到双塔模型结构十分的适合实际的应用场景，在快速服务的同时，还可以更快的反应用户即时兴趣的变化。</p>
<h5 id="Youtube双塔"><a href="#Youtube双塔" class="headerlink" title="Youtube双塔"></a>Youtube双塔</h5><p><strong>文章核心思想</strong></p>
<ul>
<li>在大规模的推荐系统中，利用双塔模型对user-item对的交互关系进行建模，学习 ， 向量与  向量.</li>
<li>针对大规模流数据，提出in-batch softmax损失函数与流数据频率估计方法(Streaming Frequency Estimation)，可以更好的适应item的多种数据分布。</li>
</ul>
<p><strong>文章主要贡献</strong></p>
<ul>
<li>提出了改进的流数据频率估计方法：针对流数据来估计item出现的频率，利用实验分析估计结果的偏差与方差，模拟实验证明该方法在数据动态变化时的功效</li>
<li>提出了双塔模型架构：提供了一个针对大规模的检索推荐系统，包括了 in-batch softmax 损失函数与流数据频率估计方法，减少了负采样在每个batch中可能会出现的采样偏差问题。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211603934.png" alt="img"></p>
<p>模型结构如上图所示，论文旨在对用户和物品建立两个不同的模型，将它们投影到相同维度的空间：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211605627.png" alt="img"></p>
<p>模型的输出为用户与物品向量的内积：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211606515.png" alt="img"></p>
<p>模型的目标是为了学习参数 ， 样本集被表示为如下格式 ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211606561.png" alt="img"></p>
<ul>
<li>在推荐系统中， 可以扩展来捕获用户对不同候选物品的参与度。</li>
<li>例如，在新闻推荐中  可以是用户在某篇文章上花费的时间。</li>
</ul>
<h6 id="模型流程"><a href="#模型流程" class="headerlink" title="模型流程"></a>模型流程</h6><ol>
<li><p>给定用户 ，基于 softmax 函数从物料库  中选中候选物品  的概率为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211612604.png" alt="img"></p>
<ul>
<li><p>考虑到相关奖励  ，加权对数似然函数的定义如下：  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211612034.png" alt="img"></p>
</li>
</ul>
</li>
<li><p>原表达式  中的分母需要遍历物料库中所有的物品，计算成本太高，故对分母中的物品要进行负采样。为了提高负采样的速度，一般是直接从训练样本所在 Batch 中进行负样本选择。于是有：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211613957.png" alt="img"></p>
<ul>
<li>其中， 表示与样本  同在一个 Batch 的物品集合。</li>
<li>举例来说，对于用户1，Batch 内其他用户的正样本是用户1的负样本。</li>
</ul>
</li>
<li><p>一般而言，负采样分为 <strong>Easy Negative Sample</strong> 和 <strong>Hard Negative Sample</strong> 。</p>
<ul>
<li><p>这里的 Easy Negative Sample 一般是直接从<strong>全局物料库</strong>中随机选取的负样本，由于每个用户感兴趣的物品有限，而物料库又往往很大，故即便从物料库中随机选取负样本，也大概率是用户不感兴趣的。</p>
</li>
<li><p>在真实场景中，热门物品占据了绝大多数的购买点击。而这些热门物品往往只占据物料库物品的少部分，绝大部分物品是冷门物品。</p>
<ul>
<li>在物料库中随机选择负样本，往往被选中的是冷门物品。这就会造成马太效应，热门物品更热，冷门物品更冷。</li>
<li>一种解决方式时，在对训练样本进行负采样时，提高热门物品被选为负样本的概率，工业界的经验做法是物品被选为负样本的概率正比于物品点击次数的 0.75 次幂。</li>
</ul>
</li>
<li><p>前面提到 Batch 内进行负采样，热门物品出现在一个 Batch 的概率正比于它的点击次数。问题是，热门物品被选为负样本的概率过高了（一般正比于点击次数的 0.75 次幂），导致热门物品被过度打压。</p>
</li>
<li><p>在本文中，为了避免对热门物品进行过度惩罚，进行了纠偏。公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211616699.png" alt="img"></p>
<ul>
<li>在内积  的基础上，减去了物品  的采样概率的对数。</li>
</ul>
</li>
</ul>
</li>
<li><p>纠偏后，物品  被选中的概率为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211617066.png" alt="img"></p>
<ul>
<li>此时，batch loss function 的表示式如下：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211617038.png" alt="img"></p>
<ul>
<li>通过 SGD 和学习率，来优化模型参数  ：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211617296.png" alt="img"></p>
</li>
<li><p>Normalization and Temperature</p>
<ul>
<li><p>最后一层，得到用户和物品的特征 Embedding 表示后，再进行进行  归一化：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211618509.png" alt="img"></p>
<ul>
<li>本质上，其实就是将用户和物品的向量内积转换为了余弦相似度。</li>
</ul>
</li>
<li><p>对于内积的结果，再除以温度参数 ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211618888.png" alt="img"></p>
<ul>
<li>论文提到，这样有利于提高预测准确度。</li>
<li>从实验结果来看，温度参数  一般小于 ，所以感觉就是放大了内积结果。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="基于图的召回"><a href="#基于图的召回" class="headerlink" title="基于图的召回"></a>基于图的召回</h3><h4 id="EGES"><a href="#EGES" class="headerlink" title="EGES"></a>EGES</h4><p><strong>Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba</strong></p>
<p>在电商领域，推荐已经是不可或缺的一部分，旨在为用户的喜好提供有趣的物品，并且成为淘宝和阿里巴巴收入的重要引擎。尽管学术界和产业界的各种推荐方法都取得了成功，如协同过滤、基于内容的方法和基于深度学习的方法，但由于用户和项目的数十亿规模，传统的方法已经不能满足于实际的需求，主要的问题体现在三个方面：</p>
<ul>
<li>可扩展性：现有的推荐方法无法扩展到在拥有十亿的用户和二十亿商品的淘宝中。</li>
<li>稀疏性：存在大量的物品与用户的交互行为稀疏。即用户的交互到多集中于以下部分商品，存在大量商品很少被用户交互。</li>
<li>冷启动：在淘宝中，每分钟会上传很多新的商品，由于这些商品没有用户行为的信息（点击、购买等），无法进行很好的预测。</li>
</ul>
<p><strong>思路</strong></p>
<p>根据上述所面临的三个问题，本文针对性的提出了三个模型予以解决：Base Graph Embedding（BGE）；Graph Embedding with Side Information（GES）；Enhanced Graph Embedding with Side Information（EGES）。</p>
<p>考虑可扩展性的问题，图嵌入的随机游走方式可以在物品图上捕获<strong>物品之间高阶相似性</strong>，即Base Graph Embedding（BGE）方法。其不同于CF方法，除了考虑物品的共现，还考虑到了行为的序列信息。</p>
<p>考虑到稀疏性和冷启物品问题，在图嵌入的基础上，考虑了节点的属性信息。希望具有相似属性的物品可以在空间上相似，即希望通过头部物品，提高属性信息的泛化能力，进而帮助尾部和冷启物品获取更加准确的embedding，即Graph Embedding with Side Information（GES）方法。</p>
<p>考虑到不同属性信息对于学习embedding的贡献不同，因此在聚合不同的属性信息时，动态的学习不同属性对于学习节点的embedding所参与的重要性权重，即Enhanced Graph Embedding with Side Information（EGES）。</p>
<h5 id="构建物品图"><a href="#构建物品图" class="headerlink" title="构建物品图"></a>构建物品图</h5><p>在介绍三个模型之前，我们首先需要构建好item-item图。由于基于CF的方法仅考虑物品之间的共现，忽略了行为的序列信息(即序列中相邻的物品之间的语义信息)，因此item-item图的构建方式如下图所示。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211633299.png" alt="img"></p>
<p>首先根据用户的session行为序列构建网络结构，即序列中相邻两个item之间在存在边，并且是有向带权图。物品图边上的权重为所有用户行为序列中两个 item 共现的次数，最终构造出来简单的有向有权图。</p>
<p>值得注意的是，本文通过行为序列中物品的共现来表示其中的<strong>语义信息</strong>，并将这种语义信息理解为<strong>物品之间的相似性</strong>，并将共现频次作为相似性的一个度量值。其次基于用户的历史行为序列数据，一般不太可能取全量的历史序列数据，一方面行为数据量过大，一方面用户的兴趣会随时间发生演变，因此在处理行为序列时会设置了一个窗口来截断历史序列数据，切分出来的序列称为session。</p>
<p>由于实际中会存在一些现实因素，数据中会有一些噪音，需要特殊处理，主要分为三个方面：</p>
<ul>
<li>从行为方面考虑，用户在点击后停留的时间少于1秒，可以认为是误点，需要移除。</li>
<li>从用户方面考虑，淘宝场景中会有一些过度活跃用户。本文对活跃用户的定义是三月内购买商品数超过1000，或者点击数超过3500，就可以认为是一个无效用户，需要去除。</li>
<li>从商品方面考虑，存在一些商品频繁的修改，即ID对应的商品频繁更新，这使得这个ID可能变成一个完全不同的商品，这就需要移除与这个ID相关的这个商品。</li>
</ul>
<h5 id="图嵌入-BGE"><a href="#图嵌入-BGE" class="headerlink" title="图嵌入(BGE)"></a>图嵌入(BGE)</h5><p>对于图嵌入模型，第一步先进行随机游走得到物品序列；第二步通过skip-gram为图上节点生成embedding。那么对于随机游走的思想：如何利用随机游走在图中生成的序列？不同于DeepWalk中的随机游走，本文的采样策略使用的是带权游走策略，不同权重的游走到的概率不同，（其本质上就是node2vec），传统的node2vec方法可以直接支持有向带权图。因此在给定图的邻接矩阵M后(表示节点之间的边权重)，随机游走中每次转移的概率为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211638065.png" alt="img"></p>
<p>其中为边上的权重，表示节点所有邻居节点集合，并且随机游走的转移概率的对每个节点所有邻接边权重的归一化结果。在随机游走之后，每个item得到一个序列。</p>
<p>然后类似于word2vec，为每个item学习embedding，于是优化目标如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211639379.png" alt="img"></p>
<p>其中，w 为窗口大小。考虑独立性假设的话，上面的式子可以进一步化简：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211640294.png" alt="img"></p>
<p>这样看起来就很直观了，在已知物品 i 时，最大化序列中(上下文)其他物品 j 的条件概率。为了近似计算，采样了Negative sampling，上面的优化目标可以化简得到如下式子：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211640558.png" alt="img"></p>
<p>其中表示负样本集合，负采样个数越多，结果越好。</p>
<h5 id="基于side-information的图嵌入（GES）"><a href="#基于side-information的图嵌入（GES）" class="headerlink" title="基于side information的图嵌入（GES）"></a>基于side information的图嵌入（GES）</h5><p>尽管BGE将行为序列关系编码进物品的embedding中，从而从用户行为中捕捉高阶相似性。但是这里有个问题，对于新加入的商品，由于未和用户产生过交互，所以不会出现在item-item图上，进而模型无法学习到其embedding，即无法解决冷启动问题。</p>
<p>为了解决冷启问题，本文通过使用side information（ 类别，店铺, 价格等）加入模型的训练过程中，使得模型最终的泛化能力体现在商品的side information上。这样通过<strong>side information学习到的embedding来表示具体的商品</strong>，使得相似side information的物品可以得到在空间上相近的表示，进而来增强 BGE。</p>
<p>那么对于每个商品如何通过side information的embedidng来表示呢？对于随机游走之后得到的商品序列，其中每个商品由其id和属性(品牌，价格等)组成。用公式表示，对于序列中的每一个物品可以得到,（n+1）个向量表示，表示物品v，剩下是side information的embedding。然后将所有的side information聚合成一个整体来表示物品，聚合方式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211642022.png" alt="img"></p>
<p>其中，是商品 v 的聚合后的 embedding 向量。</p>
<h5 id="增强型EGS（EGES）"><a href="#增强型EGS（EGES）" class="headerlink" title="增强型EGS（EGES）"></a>增强型EGS（EGES）</h5><p>尽管 GES 相比 BGE 在性能上有了提升，但是在聚合多个属性向量得到商品的embedding的过程中，不同 side information的聚合依然存在问题。在GES中采用 average-pooling 是在假设不同种类的 side information 对商品embedding的贡献是相等的，但实际中却并非如此。例如，购买 Iphone 的用户更可能倾向于 Macbook 或者 Ipad，相比于价格属性，品牌属性相对于苹果类商品具有更重要的影响。因此，根据实际现状，不同类型的 side information 对商品的表示是具有不同的贡献值的。</p>
<p>针对上述问题，作者提出了weight pooling方法来聚合不同类型的 side information。具体地，EGES 与 GES 的区别在聚合不同类型 side information计算不同的权重，根据权重聚合 side information 得到商品的embedding，如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211645673.png" alt="img"></p>
<p>其中  表示每个side information 用于计算权重的参数向量，最终通过下面的公式得到商品的embedding：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211646357.png" alt="img"></p>
<p>这里对参数  先做指数变换，目的是为了保证每个边界信息的贡献都能大于0，然后通过归一化为每个特征得到一个o-1之内的权重。最终物品的embedding通过权重进行加权聚合得到，进而优化损失函数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211646534.png" alt="img"></p>
<p> y是标签符号，等于1时表示正样本，等于0时表示负样本。表示商品 v 的最终的隐层表示，表示训练数据中的上下文节点的embedding。</p>
<h4 id="PinSAGE"><a href="#PinSAGE" class="headerlink" title="PinSAGE"></a>PinSAGE</h4><p><strong>Graph Convolutional Neural Networks for Web-Scale Recommender Systems</strong></p>
<p>该论文是斯坦福大学和Pinterest公司与2018年联合发表与KDD上的一篇关于GCN成功应用于工业级推荐系统的工作。该论文提到的PinSage模型，是在GraphSAGE的理论基础进行了更改，以适用于实际的工业场景。下面将简单介绍一下GraphSAGE的原理，以及Pinsage的核心和细节。</p>
<h5 id="GraphSAGE原理"><a href="#GraphSAGE原理" class="headerlink" title="GraphSAGE原理"></a>GraphSAGE原理</h5><p>GraphSAGE提出的前提是因为基于直推式(transductive)学习的图卷积网络无法适应工业界的大多数业务场景。我们知道的是，基于直推式学习的图卷积网络是通过拉普拉斯矩阵直接为图上的每个节点学习embedding表示，每次学习是针对于当前图上所有的节点。然而在实际的工业场景中，图中的结构和节点都不可能是固定的，会随着时间的变化而发生改变。例如在Pinterest公司的场景下，每分钟都会上传新的照片素材，同时也会有新用户不断的注册，那么图上的节点会不断的变化。在这样的场景中，直推式学习的方法就需要不断的重新训练才能够为新加入的节点学习embedding，导致在实际场景中无法投入使用。</p>
<p>在这样的背景下，斯坦福大学提出了一种归纳(inductive)学习的GCN方法——GraphSAGE，即<strong>通过聚合邻居信息的方式为给定的节点学习embedding</strong>。不同于直推式(transductive)学习，GraphSAGE是通过学习聚合节点邻居生成节点Embedding的函数的方式，为任意节点学习embedding，进而将GCN扩展成归纳学习任务。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211711238.png" alt="img"></p>
<p>上面这个公式可以非常直观的让我们理解GraphSAGE的原理。</p>
<ul>
<li>表示图上节点的初始化表示，等同于节点自身的特征。</li>
<li>表示第k层卷积后的节点表示，其来源于两个部分：<ul>
<li>第一部分来源于节点v的邻居节点集合，利用邻居节点的第k-1层卷积后的特征进行 （  ）后，在进行线性变换。这里<strong>借助图上的边将邻居节点的信息通过边关系聚合到节点表示中(简称卷积操作)</strong>。</li>
<li>第二部分来源于节点v的第k-1层卷积后的特征，进行线性变换。总的来说图卷积的思想是<strong>在对自身做多次非线性变换时，同时利用边关系聚合邻居节点信息。</strong></li>
</ul>
</li>
<li>最后一次卷积结果作为节点的最终表示，以用于下游任务(节点分类，链路预测或节点召回)。</li>
</ul>
<p>可以发现相比传统的方法(MLP，CNN，DeepWalk 或 EGES)，GCN或GraphSAGE存在一些优势：</p>
<ol>
<li>相比于传统的深度学习方法(MLP,CNN)，GCN在对自身节点进行非线性变换时，同时考虑了图中的邻接关系。从CNN的角度理解，GCN通过堆叠多层结构在图结构数据上拥有更大的<strong>感受野</strong>，利用更加广域内的信息。</li>
<li>相比于图嵌入学习方法(DeepWalk，EGES)，GCN在学习节点表示的过程中，在利用节点自身的属性信息之外，更好的利用图结构上的边信息。相比于借助随机采样的方式来使用边信息，GCN的方式能从全局的角度利用的邻居信息。此外，类似于GraphSAGE这种归纳(inductive)学习的GCN方法，通过学习聚合节点邻居生成节点Embedding的函数的方式，更适用于图结构和节点会不断变化的工业场景。</li>
</ol>
<p>在采样得到目标节点的邻居集之后，那么如何聚合邻居节点的信息来更新目标节点的嵌入表示呢？下面就来看看GraphSAGE中提及的四个聚合函数。</p>
<h5 id="GraphSAGE的采样和聚合"><a href="#GraphSAGE的采样和聚合" class="headerlink" title="GraphSAGE的采样和聚合"></a>GraphSAGE的采样和聚合</h5><p>通过上面的公式可以知道，得到节点的表示主要依赖于两部分，其中一部分其邻居节点。因此对于GraphSAGE的关键主要分为两步：Sample采样和Aggregate聚合。其中Sample的作用是从庞大的邻居节点中选出用于聚合的邻居节点集合以达到降低迭代计算复杂度，而聚合操作就是如何利用邻居节点的表示来更新节点v的表示，已达到聚合作用。具体的过程如下伪代码所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211716358.png" alt="img"></p>
<p>GraphSAGE的minibatch算法的思路是针对Batch内的所有节点，通过采样和聚合节点，为每一个节点学习一个embedding。</p>
<p><strong>邻居采样</strong></p>
<p>GraphSAGE的具体采样过程是，首先根据中心节点集合，对集合中每个中心节点通过随机采样的方式对其邻居节点采样固定数量S个(如果邻居节点数量大于S，采用无放回抽样；如果小于S，则采用有放回抽样)，形成的集合表示为；以此类推每次都是为前一个得到的集合的每个节点随机采样S个邻居，最终得到第k层的所有需要参与计算的节点集合。值得注意的有两点：<strong>为什么需要采样并且固定采样数量S？</strong> <strong>为什么第k层所采样的节点集合表示为？</strong></p>
<p>进行邻居采样并固定采样数量S主要是因为：1. 采样邻居节点避免了在全图的搜索以及使用全部邻居节点所导致计算复杂度高的问题；2. 可以通过采样使得部分节点更同质化，即两个相似的节点具有相同表达形式。3. 采样固定数量是保持每个batch的计算占用空间是固定的，方便进行批量训练。</p>
<p>第k层所采样的节点集合表示为主要是因为：采样和聚合过程是相反的，即采样时我们是从中心节点组层进行采样，而聚合的过程是从中心节点的第k阶邻居逐层聚合得到前一层的节点表示。因此可以认为聚合阶段是：将k阶邻居的信息聚合到k-1阶邻居上，k-1阶邻居的信息聚合到k-2阶邻居上，….，1阶邻居的信息聚合到中心节点上的过程。</p>
<p><strong>聚合函数</strong></p>
<p>如何对于采样到的节点集进行聚合，介绍的4种方式：Mean 聚合、Convolutional 聚合、LSTM聚合以及Pooling聚合。由于邻居节点是无序的，所以希望构造的聚合函数具有<strong>对称性(即输出的结果不因输入排序的不同而改变)</strong>，同时拥有<strong>较强的表达能力</strong>。</p>
<ul>
<li>Mean 聚合：首先会对邻居节点按照<strong>element-wise</strong>进行均值聚合，然后将当前节点k-1层得到特征与邻居节点均值聚合后的特征 <strong>分别</strong>送入全连接网络后<strong>相加</strong>得到结果。</li>
<li>Convolutional 聚合：这是一种基于GCN聚合方式的变种，首先对邻居节点特征和自身节点特征求均值，得到的聚合特征送入到全连接网络中。与Mean不同的是，这里<strong>只经过一个全连接层</strong>。</li>
<li>LSTM聚合：由于LSTM可以捕捉到序列信息，因此相比于Mean聚合，这种聚合方式的<strong>表达能力更强</strong>；但由于LSTM对于输入是有序的，因此该方法不具备<strong>对称性</strong>。作者对于无序的节点进行随机排列以调整LSTM所需的有序性。</li>
<li>Pooling聚合：对于邻居节点和中心节点进行一次非线性转化，将结果进行一次基于<strong>element-wise</strong>的<strong>最大池化</strong>操作。该种方式具有<strong>较强的表达能力</strong>的同时还具有<strong>对称性</strong>。</li>
</ul>
<p>综上，可以发现GraphSAGE之所以可以用于大规模的工业场景，主要是因为模型主要是通过学习聚合函数，通过归纳式的学习方法为节点学习特征表示。</p>
<h5 id="PinSAGE-1"><a href="#PinSAGE-1" class="headerlink" title="PinSAGE"></a>PinSAGE</h5><p>PinSAGE 模型是Pinterest 在GraphSAGE 的基础上实现的可以应用于实际工业场景的召回算法。Pinterest 公司的主要业务是采用瀑布流的形式向用户展现图片，无需用户翻页，新的图片会自动加载。因此在Pinterest网站上，有大量的图片(被称为pins)，而用户可以将喜欢的图片分类，即将pins钉在画板 boards上。可以发现基于这样的场景，pin相当于普通推荐场景中item，用户<strong>钉</strong>的行为可以认为是用于的交互行为。于是PinSAGE 模型主要应用的思路是，基于GraphSAGE 的原理学习到聚合方法，并为每个图片(pin)学习一个向量表示，然后基于pin的向量表示做<strong>item2item的召回</strong>。</p>
<p>可以知道的是，PinSAGE 是在GraphSAGE的基础上进行改进以适应实际的工业场景，因此除了改进卷积操作中的邻居采样策略以及聚合函数的同时还有一些工程技巧上的改进，使得在大数据场景下能更快更好的进行模型训练。因此在了解GraphSAGE的原理后，我们详细的了解一下本文的主要改进以及与GraphSAGE的区别。</p>
<p><strong>重要性采样</strong></p>
<p>在实际场景当中，一个item可能被数以百万，千万的用户交互过，所以不可能聚合所有邻居节点是不可行的，只可能是采样部分邻居进行信息聚合。但是如果采用GraphSAGE中随机采样的方法，由于采样的邻居有限(这里是相对于所有节点而言)，会存在一定的偏差。因此PinSAGE 在采样中考虑了更加重要的邻居节点，即卷积时只注重部分重要的邻居节点信息，已达到高效计算的同时又可以消除偏置。</p>
<p>PinSAGE使用重要性采样方法，即需要为每个邻居节点计算一个重要性权重，根据权重选取top-t的邻居作为聚合时的邻居集合。其中计算重要性的过程是，以目标节点为起点，进行random-walk，采样结束之后计算所有节点访问数的L1-normalized作为重要性权重，同时这个权重也会在聚合过程中加以使用(<strong>加权聚合</strong>)。</p>
<p>这里对于<strong>计算权重之后如何得到top-t的邻居节点，</strong>原文并没有直接的叙述。这里可以有两种做法，第一种就是直接采用重要权重，这种方法言简意赅，比较直观。第二种做法就是对游走得到的所有邻居进行随机抽样，而计算出的权重可以用于聚合阶段。个人理解第二种做法的可行性出于两点原因，其一是这样方法可以避免存在一些item由于权重系数低永远不会被选中的问题；其二可能并不是将所有重要性的邻居进行聚合更合理，毕竟重要性权重是通过随机采样而得到的，具有一定的随机性。当然以上两种方法都是可行的方案，可以通过尝试看看具体哪种方法会更有效。</p>
<p><strong>聚合函数</strong></p>
<p>PinSAGE中提到的Convolve算法（单层图卷积操作）相当于GraphSAGE算法的聚合过程，在实际执行过程中通过对每一层执行一次图卷积操作以得到不同阶邻居的信息，具体过程如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211728762.png" alt="img"></p>
<p>上述的单层图卷积过程如下三步：</p>
<ol>
<li>聚合邻居： 先将所有的邻居节点经过一次非线性转化(一层DNN)，再由聚合函数(Pooling聚合) （如元素平均，<strong>加权和</strong>等）将所有邻居信息聚合成目标节点的embedding。这里的加权聚合采用的是通过random-walk得到的重要性权重。</li>
<li>更新当前节点的embedding：将目标节点当前的向量  与步骤1中聚合得到的邻居向量  进行拼接，在通过一次非线性转化。</li>
<li>归一化操作：对目标节点向量  归一化。</li>
</ol>
<p>Convolve算法的聚合方法与GraphSAGE的Pooling聚合函数相同，主要区别在于对更新得到的向量  进行归一化操作，<strong>可以使训练更稳定，以及在近似查找最近邻的应用中更有效率。</strong></p>
<p><strong>基于mini-batch堆叠多层图卷积</strong></p>
<p>与GraphSAGE类似，采用的是基于mini-batch 的方式进行训练。之所以这么做的原因是因为什么呢？在实际的工业场景中，由于用户交互图非常庞大，无法对于所有的节点同时学习一个embedding，因此需要从原始图上寻找与 mini-batch 节点相关的子图。具体地是说，对于mini-batch内的所有节点，会通过采样的方式逐层的寻找相关邻居节点，再通过对每一层的节点做一次图卷积操作，以从k阶邻居节点聚合信息。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211730740.png" alt="img"></p>
<p>如上图所示：对于batch内的所有节点(图上最顶层的6个节点)，依次根据权重采样，得到batch内所有节点的一阶邻居(图上第二层的所有节点)；然后对于所有一阶邻居再次进行采样，得到所有二阶邻居(图上的最后一层)。节点采样阶段完成之后，与采样的顺序相反进行聚合操作。首先对二阶邻居进行单次图卷积，将二阶节点信息聚合已更新一阶节点的向量表示(其中小方块表示的是一层非线性转化)；其次对一阶节点再次进行图卷积操作，将一阶节点的信息聚合已更新batch内所有节点的向量表示。仅此对于一个batch内的所有的样本通过卷积操作学习到一个embedding，而每一个batch的学习过程中仅<strong>利用与mini-batch内相关节点的子图结构。</strong></p>
<p><strong>训练过程</strong></p>
<p>PinSage在训练时采用的是 Margin Hinge Loss 损失函数，主要的思想是最大化正例embedding之间的相关性，同时还要保证负例之间相关性相比正例之间的相关性小于某个阈值(Margin)。具体的公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211731896.png" alt="img"></p>
<p>其中是学习得到的目标节点embedding，是与目标节点相关item的embedding，是与目标节点不相关item的embedding，为margin值，具体大小需要调参。那么对于相关节点i，以及不相关节点nk，具体都是如何定义的，这对于召回模型的训练意义重大，让我们看看具体是如何定义的。</p>
<p>对于正样本而言，文中的定义是如果用户在点击的 item q之后立即点击了 item i，即认为 &lt; q, i &gt;构成正样本对。直观的我们很好理解这句话，不过在参考DGL中相关代码实现时，发现这部分的内容和原文中有一定的出入。具体地，代码中将所有的训练样本构造成用户-项目二部图，然后对batch内的每个 item q，根据item-user-item的元路径进行随机游走，得到被同一个用户交互过的 item i，因此组成<q,i>正样本对。对于负样本部分，相对来说更为重要，因此内容相对比较多，将在下面的负样本生成部分详细介绍。</p>
<p>这里还有一个比较重要的细节需要注意，由于模型是用于 item to item的召回，因此优化目标是与正样本之间的表示尽可能的相近，与负样本之间的表示尽可能的远。而图卷积操作会使得具有邻接关系的节点表示具有同质性，因此结合这两点，就需要在构建图结构的时，要将<strong>训练样本之间可能存在的边在二部图上删除</strong>，避免因为边的存在使得因卷积操作而导致的信息泄露。</p>
<p><strong>工程技巧</strong></p>
<ol>
<li><p>负样本的生成</p>
<p>召回模型最主要的任务是从候选集合中选出用户可能感兴趣的item，直观的理解就是让模型将用户喜欢的和不喜欢的进行区分。然而由于候选集合的庞大数量，许多item之间十分相似，导致模型划分出来用户喜欢的item中会存在一些难以区分的item(即与用户非常喜欢item比较相似的那一部分)。因此对于召回模型不仅能区分用户喜欢和不喜欢的 item，同时还能区分与用户喜欢的 item 十分相似的那一部分item。那么如果做到呢？这主要是交给 easy negative examples 和 hard negative examples 两种负样本给模型学习。</p>
<ul>
<li>easy 负样本：这里对于mini-batch内的所有pair(训练样本对)会共享500负样本，这500个样本从batch之外的所有节点中随机采样得到。这么做可以减少在每个mini-batch中因计算所有节点的embedding所需的时间，文中指出这和为每个item采样一定数量负样本无差异。</li>
<li>hard 负样本：这里使用hard 负样本的原因是根据实际场景的问题出发，模型需要从20亿的物品item集合中识别出最相似的1000个，即模型需要从2百万 item 中识别出最相似的那一个 item。也就是说模型的区分能力不够细致，为了解决这个问题，加入了一些hard样本。对于hard 负样本，应该是与 q 相似 以及和 i 不相似的物品，具体地的生成方式是将图上的节点计算相对节点 q 的个性化PageRank分值，根据分值的排序随机从2000~5000的位置选取节点作为负样本。</li>
</ul>
</li>
<li><p>渐进式训练(Curriculum training)</p>
<p>由于hard 负样本的加入，模型的训练时间加长（由于与q过于相似，导致loss比较小，导致梯度更新的幅度比较小，训练起来比较慢），那么渐进式训练就是为了来解决这个问题。</p>
<p>如何渐进式：先在第一轮训练使用easy 负样本，帮助模型先快速收敛(先让模型有个最基本的分辨能力)到一定范围，然后在逐步分加入hard负样本(方式是在第n轮训练时给每个物品的负样本集合增加n-1个 hard 负样本)，以调整模型细粒度的区分能力(让模型能够区分相似的item)。</p>
</li>
<li><p>节点特征(side information)</p>
<p>这里与EGES的不同，这里的边信息不是端到端训练得到，而是通过事前的预处理得到的。对于每个节点(即 pin)，都会有一个图片和一点文本信息。因此对于每个节点使用图片的向量、文字的向量以及节点的度拼接得到。这里其实也解释了为什么在图卷积操作时，会先进行一个非线性转化，其实就是将不同空间的特征进行转化(融合)。</p>
</li>
<li><p>构建 mini-batch</p>
<p>不同于常规的构建方式，PinSAGE中构建mini-batch的方式是基于生产者消费者模式。什么意思的，就是将CPU和GPU分开工作，让CPU负责取特征，重建索引，邻接列表，负采样等工作，让GPU进行矩阵运算，即CPU负责生产每个batch所需的所有数据，GPU则根据CPU生产的数据进行消费(运算)。这样由于考虑GPU的利用率，无法将所有特征矩阵放在GPU，只能存在CPU中，然而每次查找会导致非常耗时，通过上面的方式使得图卷积操作过程中就没有GPU与CPU的通信需求。</p>
</li>
<li><p>多GPU训练超大batch</p>
<p>前向传播过程中，各个GPU等分minibatch，共享一套模型参数；反向传播时，将每个GPU中的参数梯度都聚合到一起，同步执行SGD。为了保证因海量数据而使用的超大batchsize的情况下模型快速收敛以及泛化精度，采用warmup过程，即在第一个epoch中将学习率线性提升到最高，后面的epoch中再逐步指数下降。</p>
</li>
<li><p>使用MapReduce高效推断</p>
<p>在模型训练结束之后，需要为所有节点计算一个embedding，如果按照训练过程中的前向传播过程来生成，会存在大量重复的计算。因为当计算一个节点的embedding的时候，其部分邻居节点已经计算过了，同时如果该节点作为其他节点邻居时，也会被再次计算。针对这个问题，本文采用MapReduce的方法进行推断。该过程主要分为两步，具体如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211735181.png" alt="img"></p>
<ol>
<li>将item的embedding进行聚合，即利用item的图片、文字和度等信息的表示进行join(拼接)，在通过一层dense后得到item的低维向量。</li>
<li>然后根据item来匹配其一阶邻居(join)，然后根据item进行pooling(其实就是GroupBy pooling)，得到一次图卷积操作。通过堆叠多次直接得到全量的embedding。</li>
</ol>
<p>其实这块主要就是通过MapReduce的大数据处理能力，直接对全量节点进行一次运算得到其embedding，避免了分batch所导致的重复计算。</p>
</li>
</ol>
<h3 id="基于序列的召回"><a href="#基于序列的召回" class="headerlink" title="基于序列的召回"></a>基于序列的召回</h3><h4 id="MIND"><a href="#MIND" class="headerlink" title="MIND"></a>MIND</h4><p>MIND模型(Multi-Interest Network with Dynamic Routing)， 是阿里团队2019年在CIKM上发的一篇paper，该模型依然是用在召回阶段的一个模型，解决的痛点是之前在召回阶段的模型，比如双塔，YouTubeDNN召回模型等，在模拟用户兴趣的时候，总是基于用户的历史点击，最后通过pooling的方式得到一个兴趣向量，用该向量来表示用户的兴趣，但是该篇论文的作者认为，<strong>用一个向量来表示用户的广泛兴趣未免有点太过于单一</strong>，这是作者基于天猫的实际场景出发的发现，每个用户每天与数百种产品互动， 而互动的产品往往来自于很多个类别，这就说明用户的兴趣极其广泛，<strong>用一个向量是无法表示这样广泛的兴趣的</strong>，于是乎，就自然而然的引出一个问题，<strong>有没有可能用多个向量来表示用户的多种兴趣呢？</strong> </p>
<p>这篇paper的核心是胶囊网络，<strong>该网络采用了动态路由算法能非常自然的将历史商品聚成多个集合，每个集合的历史行为进一步推断对应特定兴趣的用户表示向量。这样，对于一个特定的用户，MND输出了多个表示向量，它们代表了用户的不同兴趣。当用户再有新的交互时，通过胶囊网络，还能实时的改变用户的兴趣表示向量，做到在召回阶段的实时个性化</strong>。那么，胶囊网络究竟是怎么做到的呢？ 胶囊网络又是什么原理呢？</p>
<h5 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h5><p>本章是基于天猫APP的背景来探索十亿级别的用户个性化推荐。天猫的推荐的流程主要分为召回阶段和排序阶段。召回阶段负责检索数千个与用户兴趣相关的候选物品，之后，排序阶段预测用户与这些候选物品交互的精确概率。这篇文章做的是召回阶段的工作，来对满足用户兴趣的物品的有效检索。</p>
<p>作者这次的出发点是基于场景出发，在天猫的推荐场景中，作者发现<strong>用户的兴趣存在多样性</strong>。平均上，10亿用户访问天猫，每个用户每天与数百种产品互动。交互后的物品往往属于不同的类别，说明用户兴趣的多样性。 一张图片会更加简洁直观：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212023626.png" alt="img"></p>
<p>因此如果能在<strong>召回阶段建立用户多兴趣模型来模拟用户的这种广泛兴趣</strong>，那么作者认为是非常有必要的，因为召回阶段的任务就是根据用户兴趣检索候选商品嘛。</p>
<p>那么，如何能基于用户的历史交互来学习用户的兴趣表示呢？  以往的解决方案如下：</p>
<ul>
<li>协同过滤的召回方法(itemcf和usercf)是通过历史交互过的物品或隐藏因子直接表示用户兴趣，但会遇到<strong>稀疏或计算问题</strong></li>
<li>基于深度学习的方法用低维的embedding向量表示用户，比如YoutubeDNN召回模型，双塔模型等，都是把用户的基本信息，或者用户交互过的历史商品信息等，过一个全连接层，最后编码成一个向量，用这个向量来表示用户兴趣，但作者认为，<strong>这是多兴趣表示的瓶颈</strong>，因为需要压缩所有与用户多兴趣相关的信息到一个表示向量，所有用户多兴趣的信息进行了混合，导致这种多兴趣并无法体现，所以往往召回回来的商品并不是很准确，除非向量维度很大，但是大维度又会带来高计算。</li>
<li>DIN模型在Embedding的基础上加入了Attention机制，来选择的捕捉用户兴趣的多样性，但采用Attention机制，<strong>对于每个目标物品，都需要重新计算用户表示</strong>，这在召回阶段是行不通的（海量），所以DIN一般是用于排序。</li>
</ul>
<p>所以，作者想在召回阶段去建模用户的多兴趣，但以往的方法都不好使，为了解决这个问题，就提出了动态路由的多兴趣网络MIND。为了推断出用户的多兴趣表示，提出了一个多兴趣提取层，该层使用动态路由机制自动的能将用户的历史行为聚类，然后每个类簇中产生一个表示向量，这个向量能代表用户某种特定的兴趣，而多个类簇的多个向量合起来，就能表示用户广泛的兴趣了。</p>
<p>这就是MIND的提出动机以及初步思路了，这里面的核心是Multi-interest extractor layer，而这里面重点是动态路由与胶囊网络，所以接下来先补充这方面的相关知识。</p>
<h5 id="胶囊网络与动态路由机制"><a href="#胶囊网络与动态路由机制" class="headerlink" title="胶囊网络与动态路由机制"></a>胶囊网络与动态路由机制</h5><h6 id="胶囊网络初识"><a href="#胶囊网络初识" class="headerlink" title="胶囊网络初识"></a>胶囊网络初识</h6><p>Hinton大佬在2011年的时候，就首次提出了”胶囊”的概念， “胶囊”可以看成是一组聚合起来输出整个向量的小神经元组合，这个向量的每个维度(每个小神经元)，代表着某个实体的某个特征。</p>
<p>胶囊网络其实可以和神经网络对比着看可能更好理解，我们知道神经网络的每一层的神经元输出的是单个的标量值，接收的输入，也是多个标量值，所以这是一种value to value的形式，而胶囊网络每一层的胶囊输出的是一个向量值，接收的输入也是多个向量，所以它是vector to vector形式的。来个图对比下就清楚了：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212029715.png" alt="img"></p>
<p>左边的图是普通神经元的计算示意，而右边是一个胶囊内部的计算示意图。 神经元这里不过多解释，这里主要是剖析右边的这个胶囊计算原理。从上图可以看出， 输入是两个向量，首先经过了一个线性映射，得到了两个新向量，然后呢，经过了一个向量的加权汇总，这里的,可以先理解成权重，具体计算后面会解释。 得到汇总后的向量，接下来进行了Squash操作，整体的计算公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212030357.png" alt="img"></p>
<p>这里的Squash操作可以简单看下，主要包括两部分，右边的那部分其实就是向量归一化操作，把norm弄成1，而左边那部分算是一个非线性操作，如果的norm很大，那么这个整体就接近1， 而如果这个norm很小，那么整体就会接近0， 和sigmoid很像有没有？</p>
<p>这样就完成了一个胶囊的计算，但有两点需要注意：</p>
<ol>
<li>这里的参数是可学习的，和神经网络一样， 通过BP算法更新</li>
<li>这里的参数不是BP算法学习出来的，而是采用动态路由机制现场算出来的，这个非常类似于pooling层，我们知道pooling层的参数也不是学习的，而是根据前面的输入现场取最大或者平均计算得到的。</li>
</ol>
<p>所以这里的问题，就是怎么通过动态路由机制得到，下面是动态路由机制的过程。</p>
<h6 id="动态路由机制原理"><a href="#动态路由机制原理" class="headerlink" title="动态路由机制原理"></a>动态路由机制原理</h6><p>我们先来一个胶囊结构: </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212035441.png" alt="img"></p>
<p>这个是通过动态路由机制计算得到，那么动态路由机制究竟是啥子意思？  其实就是通过迭代的方式去计算，没有啥神秘的，迭代计算的流程如下图:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212035613.png" alt="img"></p>
<p>首先我们先初始化，与每一个输入胶囊进行对应，这哥们有个名字叫做”routing logit”， 表示的是输出的这个胶囊与输入胶囊的相关性，和注意力机制里面的score值非常像。由于一开始不知道这个哪个胶囊与输出的胶囊有关系，所以默认相关性分数都一样，然后进入迭代。</p>
<p>在每一次迭代中，首先把分数转成权重，然后加权求和得到，这个很类似于注意力机制的步骤，得到之后，通过归一化操作，得到，接下来要通过和输入胶囊的相关性以及上一轮的来更新。</p>
<p>通过若干次迭代之后，得到最后的输出胶囊向量会慢慢的走到与它更相关的那些附近，而远离那些与它不相干的。所以上面的这个迭代过程有点像<strong>排除异常输入胶囊的感觉</strong>。</p>
<p>而从另一个角度来考虑，这个过程其实像是聚类的过程，因为胶囊的输出向量经过若干次迭代之后，会最终停留到与其非常相关的那些输入胶囊里面，而这些输入胶囊，其实就可以看成是某个类别了，因为既然都共同的和输出胶囊比较相关，那么彼此之间的相关性也比较大，于是乎，经过这样一个动态路由机制之后，就不自觉的，把输入胶囊实现了聚类。把和与其他输入胶囊不同的那些胶囊给排除了出去。</p>
<p>所以，这个动态路由机制的计算设计的还是比较巧妙的， 下面是上述过程的展开计算过程， 这个和RNN的计算有点类似：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212037262.png" alt="img"></p>
<p>这样就完成了一个胶囊内部的计算过程了。</p>
<p>Ok， 有了上面的这些铺垫，再来看MIND就会比较简单了。下面正式对MIND模型的网络架构剖析。</p>
<h5 id="MIND模型的网络结构与细节剖析"><a href="#MIND模型的网络结构与细节剖析" class="headerlink" title="MIND模型的网络结构与细节剖析"></a>MIND模型的网络结构与细节剖析</h5><h6 id="网络整体结构"><a href="#网络整体结构" class="headerlink" title="网络整体结构"></a>网络整体结构</h6><p>MIND网络的架构如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212044848.png" alt="img"></p>
<p>初步先分析这个网络结构的运作： 首先接收的输入有三类特征，用户base属性，历史行为属性以及商品的属性，用户的历史行为序列属性过了一个多兴趣提取层得到了多个兴趣胶囊，接下来和用户base属性拼接过DNN，得到了交互之后的用户兴趣。然后在训练阶段，用户兴趣和当前商品向量过一个label-aware attention，然后求softmax损失。 在服务阶段，得到用户的向量之后，就可以直接进行近邻检索，找候选商品了。 这就是宏观过程，但是，多兴趣提取层以及这个label-aware attention是在做什么事情呢？  如果单独看这个图，感觉得到多个兴趣胶囊之后，直接把这些兴趣胶囊以及用户的base属性拼接过全连接，那最终不就成了一个用户向量，此时label-aware attention的意义不就没了？ 所以这个图初步感觉画的有问题，和论文里面描述的不符。所以下面先以论文为主，正式开始描述具体细节。</p>
<h6 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h6><p>召回任务的目标是对于每一个用户从十亿规模的物品池检索出包含与用户兴趣相关的上千个物品集。</p>
<p><strong>模型的输入</strong></p>
<p>对于模型，每个样本的输入可以表示为一个三元组：，其中代表与用户交互过的物品集，即用户的历史行为；表示用户的属性，例如性别、年龄等；定义为目标物品的一些特征，例如物品id和种类id等。</p>
<p><strong>任务描述</strong></p>
<p>MIND的核心任务是学习一个从原生特征映射到<strong>用户表示</strong>的函数，用户表示定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212048618.png" alt="img"></p>
<p>其中，是用户的表示向量，是embedding的维度，表示向量的个数，即兴趣的数量。如果，那么MIND模型就退化成YouTubeDNN的向量表示方式了。</p>
<p>目标物品的embedding函数为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212049445.png" alt="img"></p>
<p>其中，表示一个embedding&amp;pooling层。</p>
<p><strong>最终结果</strong></p>
<p>根据评分函数检索（根据<strong>目标物品与用户表示向量的内积的最大值作为相似度依据</strong>，DIN的Attention部分也是以这种方式来衡量两者的相似度），得到top-N个候选项：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212049720.png" alt="img"></p>
<h6 id="Embedding-amp-Pooling层"><a href="#Embedding-amp-Pooling层" class="headerlink" title="Embedding &amp; Pooling层"></a>Embedding &amp; Pooling层</h6><p>Embedding层的输入由三部分组成，用户属性、用户行为和目标物品标签。每一部分都由多个id特征组成，则是一个高维的稀疏数据，因此需要Embedding技术将其映射为低维密集向量。具体来说，</p>
<ul>
<li>对于的id特征（年龄、性别等）是将其Embedding的向量进行Concat，组成用户属性Embedding；</li>
<li>目标物品通常包含其他分类特征id（品牌id、店铺id等） ，这些特征有利于物品的冷启动问题，需要将所有的分类特征的Embedding向量进行平均池化，得到一个目标物品向量；</li>
<li>对于用户行为，由物品的Embedding向量组成用户行为Embedding列表， 当然这里不仅只有物品embedding哈，也可能有类别，品牌等其他的embedding信息。</li>
</ul>
<h6 id="Multi-Interest-Extractor-Layer-核心"><a href="#Multi-Interest-Extractor-Layer-核心" class="headerlink" title="Multi-Interest Extractor Layer(核心)"></a>Multi-Interest Extractor Layer(核心)</h6><p>作者认为，单一的向量不足以表达用户的多兴趣。所以作者采用<strong>多个表示向量</strong>来分别表示用户不同的兴趣。通过这个方式，在召回阶段，用户的多兴趣可以分别考虑，对于兴趣的每一个方面，能够更精确的进行物品检索。</p>
<p>为了学习多兴趣表示，作者利用胶囊网络表示学习的动态路由将用户的历史行为分组到多个簇中。来自一个簇的物品应该密切相关，并共同代表用户兴趣的一个特定方面。</p>
<p>由于多兴趣提取器层的设计灵感来自于胶囊网络表示学习的动态路由，所以这里作者回顾了动态路由机制。当然，如果之前对胶囊网络或动态路由不了解，这里读起来就会有点艰难，但由于我上面进行了铺垫，这里就直接拿过原文并解释即可。</p>
<p><strong>动态路由</strong></p>
<p>动态路由是胶囊网络中的迭代学习算法，用于学习低水平胶囊和高水平胶囊之间的路由对数（logit），来得到高水平胶囊的表示。</p>
<p>我们假设胶囊网络有两层，即低水平胶囊和高水平胶囊，其中表示胶囊的个数， 表示胶囊的维度。 路由对数计算公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212050370.png" alt="img"></p>
<p>其中表示待学习的双线性映射矩阵【在胶囊网络的原文中称为转换矩阵】</p>
<p>通过计算路由对数，将高阶胶囊的候选向量计算为所有低阶胶囊的加权和：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212050471.png" alt="img"></p>
<p>其中定义为连接低阶胶囊和高阶胶囊的权重【称为耦合系数】，而且其通过对路由对数执行softmax来计算：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212051995.png" alt="img"></p>
<p>最后，应用一个非线性的“压缩”函数来获得一个高阶胶囊的向量【胶囊网络向量的模表示由胶囊所代表的实体存在的概率】</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212051641.png" alt="img"></p>
<p>路由过程重复进行3次达到收敛。当路由结束，高阶胶囊值固定，作为下一层的输入。</p>
<p>Ok，下面我们开始解释，其实上面说的这些就是胶囊网络的计算过程，只不过和之前所用的符号不一样了。这里拿个图： <img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212051116.png" alt="img"> 首先，论文里面也是个两层的胶囊网络，低水平层-&gt;高水平层。 低水平层有个胶囊，每个胶囊向量维度是，用表示的，高水平层有个胶囊，每个胶囊维，用表示。</p>
<p>单独拿出每个，其计算过程如上图所示。首先，先随机初始化路由对数，然后开始迭代，对于每次迭代：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212052434.png" alt="img"></p>
<p>只不过这里的符合和上图中的不太一样，这里的对应的是每个输入胶囊的权重， 这里的对应上图中的， 这里的对应的是输入胶囊的加权组合。这里的对应上图中的，这里的对应的是上图的权重，只不过这个可以换成矩阵运算。 和上图中不同的是路由对数更新那里，没有了上一层的路由对数值，但感觉这样会有问题。</p>
<p>所以，这样解释完之后就会发现，其实上面的一顿操作就是说的传统的动态路由机制。</p>
<p><strong>B2I动态路由</strong></p>
<p>作者设计的多兴趣提取层就是就是受到了上述胶囊网络的启发。</p>
<p>如果把用户的行为序列看成是行为胶囊， 把用户的多兴趣看成兴趣胶囊，那么多兴趣提取层就是利用动态路由机制学习行为胶囊<code>-&gt;</code>兴趣胶囊的映射关系。但是原始路由算法无法直接应用于处理用户行为数据。因此，提出了<strong>行为(Behavior)到兴趣(Interest)（B2I）动态路由</strong>来自适应地将用户的行为聚合到兴趣表示向量中，它与原始路由算法有三个不同之处：</p>
<ol>
<li><strong>共享双向映射矩阵</strong>。在初始动态路由中，使用固定的或者说共享的双线性映射矩阵而不是单独的双线性映射矩阵， 在原始的动态路由中，对于每个输出胶囊，都会有对应的，而这里是每个输出胶囊，都共用一个矩阵。 原因有两个：<ol>
<li>一方面，用户行为是可变长度的，从几十个到几百个不等，因此使用共享的双线性映射矩阵是有利于泛化。</li>
<li>另一方面，希望兴趣胶囊在同一个向量空间中，但不同的双线性映射矩阵将兴趣胶囊映射到不同的向量空间中。因为映射矩阵的作用就是对用户的行为胶囊进行线性映射嘛， 由于用户的行为序列都是商品，所以希望经过映射之后，到统一的商品向量空间中去。路由对数计算如下：</li>
</ol>
</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212052546.png" alt="img"></p>
<p>​        其中，是历史物品的embedding，表示兴趣胶囊的向量。是每一对行为胶囊(低价)到兴趣胶囊(高阶)之间        的共享映射矩阵。</p>
<ol>
<li><strong>随机初始化路由对数</strong>。由于利用共享双向映射矩阵，如果再初始化路由对数为0将导致相同的初始的兴趣胶囊。随后的迭代将陷入到一个不同兴趣胶囊在所有的时间保持相同的情景。因为每个输出胶囊的运算都一样了嘛(除非迭代的次数不同，但这样也会导致兴趣胶囊都很类似)，为了减轻这种现象，作者通过高斯分布进行随机采样来初始化路由对数，让初始兴趣胶囊与其他每一个不同，其实就是希望在计算每个输出胶囊的时候，通过随机化的方式，希望这几个聚类中心离得远一点，这样才能表示出广泛的用户兴趣(我们已经了解这个机制就仿佛是聚类，而计算过程就是寻找聚类中心)。</li>
<li><strong>动态的兴趣数量</strong>，兴趣数量就是聚类中心的个数，由于不同用户的历史行为序列不同，那么相应的，其兴趣胶囊有可能也不一样多，所以这里使用了一种启发式方式自适应调整聚类中心的数量，即值。</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212053113.png" alt="img"></p>
<p>这种调整兴趣胶囊数量的策略可以为兴趣较小的用户节省一些资源，包括计算和内存资源。这个公式不用多解释，与行为序列长度成正比。</p>
<p>最终的B2I动态路由算法如下： <img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212053253.png" alt="img"> 应该很好理解了吧。</p>
<h6 id="Label-aware-Attention-Layer"><a href="#Label-aware-Attention-Layer" class="headerlink" title="Label-aware Attention Layer"></a>Label-aware Attention Layer</h6><p> 通过多兴趣提取器层，从用户的行为embedding中生成多个兴趣胶囊。不同的兴趣胶囊代表用户兴趣的不同方面，相应的兴趣胶囊用于评估用户对特定类别的偏好。所以，在训练的期间，最后需要设置一个Label-aware的注意力层，对于当前的商品，根据相关性选择最相关的兴趣胶囊。这里其实就是一个普通的注意力机制，和DIN里面的那个注意力层基本上是一模一样，计算公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212054677.png" alt="img"></p>
<p>首先这里的表示当前的商品向量，表示用户的多兴趣向量组合，里面有个向量，表示用户的的兴趣。用户的各个兴趣向量与目标商品做内积，然后softmax转成权重，然后反乘到多个兴趣向量进行加权求和。 但是这里需要注意的一个小点，就是这里做内积求完相似性之后，先做了一个指数操作，<strong>这个操作其实能放大或缩小相似程度</strong>，至于放大或者缩小的程度，由控制。 比如某个兴趣向量与当前商品非常相似，那么再进行指数操作之后，如果也很大，那么显然这个兴趣向量就占了主导作用。是一个可调节的参数来调整注意力分布。当接近0，每一个兴趣胶囊都得到相同的关注。当大于1时，随着的增加，具有较大值的点积将获得越来越多的权重。考虑极限情况，当趋近于无穷大时，注意机制就变成了一种硬注意，选关注最大的值而忽略其他值。在实验中，发现使用硬注意导致更快的收敛。</p>
<h6 id="训练与服务"><a href="#训练与服务" class="headerlink" title="训练与服务"></a>训练与服务</h6><p>得到用户向量和标签物品embedding后，计算用户与标签物品交互的概率：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212054847.png" alt="img"></p>
<p>目标函数是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212054640.png" alt="img"></p>
<p>其中是训练数据包含用户物品交互的集合。因为物品的数量可伸缩到数十亿，所以不能直接算。因此。使用采样的softmax技术，并且选择Adam优化来训练MIND。</p>
<p>训练结束后，抛开label-aware注意力层，MIND网络得到一个用户表示映射函数。在服务期间，用户的历史序列与自身属性喂入到，每个用户得到多兴趣向量。然后这个表示向量通过一个近似邻近方法来检索top N物品。</p>
<p>这就是整个MIND模型的细节了。</p>
<h4 id="SDM"><a href="#SDM" class="headerlink" title="SDM"></a>SDM</h4><p>SDM模型(Sequential Deep Matching Model)，是阿里团队在2019年CIKM上的一篇paper。和MIND模型一样，是一种序列召回模型，研究的依然是如何通过用户的历史行为序列去学习到用户的丰富兴趣。 对于MIND，我们已经知道是基于胶囊网络的动态路由机制，设计了一个动态兴趣提取层，把用户的行为序列通过路由机制聚类，然后映射成了多个兴趣胶囊，以此来获取到用户的广泛兴趣。而SDM模型，是先把用户的历史序列根据交互的时间分成了短期和长期两类，然后从<strong>短期会话</strong>和<strong>长期行为</strong>中分别采取<strong>相应的措施（短期的RNN+多头注意力，长期的Att Net）</strong> 去学习到用户的短期兴趣和长期行为偏好，并<strong>巧妙的设计了一个门控网络有选择的将长短期兴趣进行融合</strong>，以此得到用户的最终兴趣向量。 这篇paper中的一些亮点，比如长期偏好的行为表示，多头注意力机制学习多兴趣，长短期兴趣的融合机制等，又给了一些看待问题的新角度，同时，给出了我们一种利用历史行为序列去捕捉用户动态偏好的新思路。 </p>
<p>这篇paper依然是从引言开始， 介绍SDM模型提出的动机以及目前方法存在的不足(why)， 接下来就是SDM的网络模型架构(what)， 这里面的关键是如何从短期会话和长期行为两个方面学习到用户的短期长期偏好(how)。</p>
<h5 id="背景与动机-1"><a href="#背景与动机-1" class="headerlink" title="背景与动机"></a>背景与动机</h5><p> 这里要介绍该模型提出的动机，即why要有这样的一个模型？</p>
<p>一个好的推荐系统应该是能精确的捕捉用户兴趣偏好以及能对他们当前需求进行快速响应的，往往工业上的推荐系统，为了能快速响应， 一般会把整个推荐流程分成召回和排序两个阶段，先通过召回，从海量商品中得到一个小的候选集，然后再给到排序模型做精确的筛选操作。 这也是目前推荐系统的一个范式了。在这个过程中，召回模块所检索到的候选对象的质量在整个系统中起着至关重要的作用。</p>
<p>淘宝目前的召回模型是一些基于协同过滤的模型， 这些模型是通过用户与商品的历史交互建模，从而得到用户的物品的表示向量，但这个过程是<strong>静态的</strong>，而用户的行为或者兴趣是时刻变化的， 对于协同过滤的模型来说，并不能很好的捕捉到用户整个行为序列的动态变化。</p>
<p>那我们知道了学习用户历史行为序列很重要， 那么假设序列很长呢？这时候直接用模型学习长序列之间的演进可能不是很好，因为很长的序列里面可能用户的兴趣发生过很大的转变，很多商品压根就没有啥关系，这样硬学，反而会导致越学越乱，就别提这个演进了。所以这里是以会话为单位，对长序列进行切分。作者这里的依据就是用户在同一个Session下，其需求往往是很明确的， 这时候，交互的商品也往往都非常类似。 但是Session与Session之间，可能需求改变，那么商品类型可能骤变。 所以以Session为单位来学习商品之间的序列信息，感觉要比整个长序列学习来的靠谱。 </p>
<p>作者首先是先把长序列分成了多个会话， 然后<strong>把最近的一次会话，和之前的会话分别视为了用户短期行为和长期行为分别进行了建模，并采用不同的措施学习用户的短期兴趣和长期兴趣，然后通过一个门控机制融合得到用户最终的表示向量</strong>。这就是SDM在做的事情，</p>
<p>长短期行为序列联合建模，其实是在给我们提供一种新的学习用户兴趣的新思路， 那么究竟是怎么做的呢？以及为啥这么做呢？</p>
<ul>
<li><p>对于短期用户行为， 首先作者使用了LSTM来学习序列关系， 而接下来是用一个Multi-head attention机制，学习用户的多兴趣。 </p>
<p>先分析分析作者为啥用多头注意力机制，作者这里依然是基于实际的场景出发，作者发现，<strong>用户的兴趣点在一个会话里面其实也是多重的</strong>。这个可能之前的很多模型也是没考虑到的，但在商品购买的场景中，这确实也是个事实， 顾客在买一个商品的时候，往往会进行多方比较， 考虑品牌，颜色，商店等各种因素。作者认为用普通的注意力机制是无法反映广泛的兴趣了，所以用多头注意力网络。 </p>
<p>多头注意力机制从某个角度去看，也有类似聚类的功效，首先它接收了用户的行为序列，然后从多个角度学习到每个商品与其他商品的相关性，然后根据与其他商品的相关性加权融合，这样，相似的item向量大概率就融合到了一块组成一个向量，所谓用户的多兴趣，可能是因为这些行为商品之间，可以从多个空间或者角度去get彼此之间的相关性，这里面有着用户多兴趣的表达信息。</p>
</li>
<li><p>用户的长期行为也会影响当前的决策，作者在这里举了一个NBA粉丝的例子，说如果一个是某个NBA球星的粉丝，那么他可能在之前会买很多有关这个球星的商品，如果现在这个时刻想买鞋的时候，大概率会考虑和球星相关的。所以作者说<strong>长期偏好和短期行为都非常关键</strong>。但是长期偏好或者行为往往是复杂广泛的，就像刚才这个例子里面，可能长期行为里面，买的与这个球星相关商品只占一小部分，而就只有这一小部分对当前决策有用。  这个也是之前的模型利用长期偏好方面存在的问题，那么如何选择出长期偏好里面对于当前决策有用的那部分呢？  作者这里设计了一个门控的方式融合短期和长期，这个想法还是很巧妙的，后面介绍这个东西的时候说下我的想法。 </p>
</li>
</ul>
<p>所以下面总结动机以及本篇论文的亮点：</p>
<ul>
<li>动机： 召回模型需要捕获用户的动态兴趣变化，这个过程中利用好用户的长期行为和短期偏好非常关键，而以往的模型有下面几点不足：<ul>
<li>协同过滤模型： 基于用户的交互进行静态建模，无法感知用户的兴趣变化过程，易召回同质性的商品</li>
<li>早期的一些序列推荐模型: 要么是对整个长序列直接建模，但这样太暴力，没法很好的学习商品之间的序列信息，有些是把长序列分成会话，但忽视了一个会话中用户的多重兴趣</li>
<li>有些方法在考虑用户的长期行为方面，只是简单的拼接或者加权求和，而实际上用户长期行为中只有很少一小部分对当前的预测有用，这样暴力融合反而会适得其反，起不到效果。另外还有一些多任务或者对抗方法， 在工业场景中不适用等。 </li>
<li>这些我只是通过我的理解简单总结，详细内容看原论文相关工作部分。</li>
</ul>
</li>
<li>亮点: <ul>
<li>SDM模型， 考虑了用户的短期行为和长期兴趣，以会话的形式进行分割，并对这两方面分别建模</li>
<li>短期会话由于对当前决策影响比较大，那么我们就学习的全面一点， 首先RNN学习序列关系，其次通过多头注意力机制捕捉多兴趣，然后通过一个Attention Net加权得到短期兴趣表示</li>
<li>长期会话通过Attention Net融合，然后过DNN，得到用户的长期表示</li>
<li>我们设计了一个门控机制，类似于LSTM的那种门控，能巧妙的融合这两种兴趣，得到用户最终的表示向量</li>
</ul>
</li>
</ul>
<p>这就是动机与背景总结啦。 那么接下来，SDM究竟是如何学习短期和长期表示，又是如何融合的？ 为什么要这么玩？</p>
<h5 id="SDM的网络结构与细节剖析"><a href="#SDM的网络结构与细节剖析" class="headerlink" title="SDM的网络结构与细节剖析"></a>SDM的网络结构与细节剖析</h5><h6 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h6><p>这里本来直接看模型结构，但感觉还是先过一下问题定义吧，毕竟这次涉及到了会话，还有几个小规则。</p>
<p>表示用户集合，表示item集合，模型考虑在时间，是否用户会对产生交互。 对于， 我们能够得到它的历史行为序列，那么先说一下如何进行会话的划分， 这里有三个规则：</p>
<ol>
<li>相同会话ID的商品(后台能获取)算是一个会话</li>
<li>相邻的商品，时间间隔小于10分钟(业务自己调整)算一个会话</li>
<li>同一个会话中的商品不能超过50个，多出来的放入下一个会话</li>
</ol>
<p>这样划分开会话之后， 对于用户的短期行为定义是离目前最近的这次会话， 用表示，是序列长度。 而长期的用户行为是过去一周内的会话，但不包括短期的这次会话， 这个用表示。网络推荐架构如下： <img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212059483.png" alt="img"> 这个感觉并不用过多解释。看过召回的应该都能懂， 接收了用户的短期行为和长期行为，然后分别通过两个盲盒得到表示向量，再通过门控融合就得到了最终的用户表示。 </p>
<p>下面要开那三个盲盒操作，即短期行为学习，长期行为学习以及门控融合机制。但在这之前，得先说一个东西，就是输入层这里， 要带物品的side infomation，比如物品的item ID, 物品的品牌ID，商铺ID， 类别ID等等， 那你说，为啥要单独说呢？ 之前的模型不也有，但是这里在利用方式上有些不一样需要注意。</p>
<h6 id="Input-Embedding-with-side-Information"><a href="#Input-Embedding-with-side-Information" class="headerlink" title="Input Embedding with side Information"></a>Input Embedding with side Information</h6><p>在淘宝的推荐场景中，作者发现， 顾客与物品产生交互行为的时候，不仅考虑特定的商品本身，还考虑产品， 商铺，价格等，这个显然。所以，这里对于一个商品来说，不仅要用到Item ID，还用了更多的side info信息，包括<code>leat category, fist level category, brand,shop</code>。 </p>
<p>所以，假设用户的短期行为是， 这里面的每个商品其实有5个属性表示了，每个属性本质是ID，但转成embedding之后，就得到了5个embedding， 所以这里就涉及到了融合问题。 这里用  来表示每个，但这里不是embedding的pooling操作，而是Concat</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212101984.png" alt="img"></p>
<p>其中，， 这个公式看着负责，其实就是每个side info的id过embedding layer得到各自的embedding。这里embedding的维度是， 等拼接起来之后，就是维了。</p>
<p>另外就是用户的base表示向量了，这个很简单， 就是用户的基础画像，得到embedding，直接也是Concat，这个常规操作不解释：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212101121.png" alt="img"></p>
<p>是特征的embedding。</p>
<p>Ok，输入这里说完了之后，就直接开盲盒， 不按照论文里面的顺序来了。想看更多细节的就去看原论文吧，感觉那里面说的有些啰嗦。不如直接上图解释来的明显：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212101061.png" alt="img"> 这里正好三个框把盒子框住了，下面剖析出每个来就行啦。</p>
<h6 id="短期用户行为建模"><a href="#短期用户行为建模" class="headerlink" title="短期用户行为建模"></a>短期用户行为建模</h6><p>这里短期用户行为是下面的那个框，接收的输入，首先是用户最近的那次会话，里面各个商品加入了side info信息之后，有了最终的embedding表示。 </p>
<p>这个东西，首先要过LSTM，学习序列信息，这个感觉不用多说，直接上公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212103361.png" alt="img"></p>
<p>这里采用的是多输入多输出， 即每个时间步都会有一个隐藏状态输出出来，那么经过LSTM之后，原始的序列就有了序列相关信息，得到了, 把这个记为。这里的表示时间的序列偏好表示。</p>
<p>接下来， 这个东西要过Multi-head self-attention层，这个东西的原理我这里就不多讲了，这个东西可以学习到系列之间的相关性，这个操作从某种角度看，也很像聚类， 因为我们这里是先用多头矩阵把系列映射到多个空间，然后从各个空间中互求相关性</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212104750.png" alt="img"></p>
<p>得到权重后，对原始的向量加权融合。 让， ，， 背后计算是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212104358.png" alt="img"></p>
<p>这是一个头的计算， 接下来每个头都这么算，假设有个头，这里会通过上面的映射矩阵系列，先把原始的向量映射到维度，然后计算也是维，这样个head进行拼接，正好是维， 接下来过一个全连接或者线性映射得到MultiHead的输出。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212104590.png" alt="img"></p>
<p>这样就相当于更相似的融合到了一块，而这个更相似又是从多个角度得到的，于是乎， 作者认为，这样就能学习到用户的多兴趣。</p>
<p>得到这个东西之后，接下来再过一个User Attention， 因为作者发现，对于相似历史行为的不同用户，其兴趣偏好也不太一样。 所以加入这个用户Attention层，想挖掘更细粒度的用户个性化信息。 当然，这个就是普通的embedding层了， 用户的base向量作为query，与的每个向量做Attention，然后加权求和得最终向量：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212105264.png" alt="img"></p>
<p>其中，这样短期行为兴趣就修成了正果。</p>
<h6 id="用户长期行为建模"><a href="#用户长期行为建模" class="headerlink" title="用户长期行为建模"></a>用户长期行为建模</h6><p>从长期的视角来看，用户在不同的维度上可能积累了广泛的兴趣，用户可能经常访问一组类似的商店，并反复购买属于同一类别的商品。 所以长期行为来自于不同的特征尺度。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212105990.png" alt="img"></p>
<p>这里面包含了各种side特征。这里就和短期行为那里不太一样了，长期行为这里，是从特征的维度进行聚合，也就是把用户的历史长序列分成了多个特征，比如用户历史点击过的商品，历史逛过的店铺，历史看过的商品的类别，品牌等，分成了多个特征子集，然后这每个特征子集里面有对应的id，比如商品有商品id, 店铺有店铺id等，对于每个子集，过user Attention layer，和用户的base向量求Attention， 相当于看看用户喜欢逛啥样的商店， 喜欢啥样的品牌，啥样的商品类别等等，得到每个子集最终的表示向量。每个子集的计算过程如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212105910.png" alt="img"></p>
<p>每个子集都会得到一个加权的向量，把这个东西拼起来，然后过DNN。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212106394.png" alt="img"></p>
<p>这里的， 这样就得到了用户的长期兴趣表示。</p>
<h6 id="短长期兴趣融合"><a href="#短长期兴趣融合" class="headerlink" title="短长期兴趣融合"></a>短长期兴趣融合</h6><p>长短期兴趣融合这里，作者发现之前模型往往喜欢直接拼接起来，或者加和，注意力加权等，但作者认为这样不能很好的将两类兴趣融合起来，因为长期序列里面，其实只有很少的一部分行为和当前有关。那么这样的话，直接无脑融合是有问题的。所以这里作者用了一种较为巧妙的方式，即门控机制：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212106342.png" alt="img"></p>
<p>这个和LSTM的这种门控机制很像，首先门控接收的输入有用户画像，用户短期兴趣， 用户长期兴趣，经过sigmoid函数得到了，用来决定在时刻短期和长期兴趣的贡献程度。然后根据这个贡献程度对短期和长期偏好加权进行融合。</p>
<p>为啥这东西就有用了呢？  实验中证明了这个东西有用，但这里给出我的理解哈，我们知道最终得到的短期或者长期兴趣都是维的向量， 每一个维度可能代表着不同的兴趣偏好，比如第一维度代表品牌，第二个维度代表类别，第三个维度代表价格，第四个维度代表商店等等，当然假设哈，真实的向量不可解释。</p>
<p>那么如果我们是直接相加或者是加权相加，其实都意味着长短期兴趣这每个维度都有很高的保留， 但其实上，万一长期兴趣和短期兴趣维度冲突了呢？ 比如短期兴趣里面可能用户喜欢这个品牌，长期用户里面用户喜欢那个品牌，那么听谁的？ 你可能说短期兴趣这个占更大权重呗，那么普通加权可是所有向量都加的相同的权重，品牌这个维度听短期兴趣的，其他维度比如价格，商店也都听短期兴趣的？本身存在不合理性。那么反而直接相加或者加权效果会不好。</p>
<p>而门控机制的巧妙就在于，我会给每个维度都学习到一个权重，而这个权重非0即1(近似哈)， 那么接下来融合的时候，我通过这个门控机制，取长期和短期兴趣向量每个维度上的其中一个。比如在品牌方面听谁的，类别方面听谁的，价格方面听谁的，只会听短期和长期兴趣的其中一个的。这样就不会有冲突发生，而至于具体听谁的，交给网络自己学习。这样就使得用户长期兴趣和短期兴趣融合的时候，每个维度上的信息保留变得<strong>有选择</strong>。使得兴趣的融合方式更加的灵活。</p>
<p> <strong>这其实又给我们提供了一种两个向量融合的一种新思路，并不一定非得加权或者拼接或者相加了，还可以通过门控机制让网络自己学</strong></p>
<h3 id="基于树模型的召回"><a href="#基于树模型的召回" class="headerlink" title="基于树模型的召回"></a>基于树模型的召回</h3><h4 id="TDM"><a href="#TDM" class="headerlink" title="TDM"></a>TDM</h4><p>召回早前经历的第一代协同过滤技术，让模型可以在数量级巨大的item集中找到用户潜在想要看到的商品。这种方式有很明显的缺点，一个是对于用户而言，只能通过他历史行为去构建候选集，并且会基于算力的局限做截断。所以推荐结果的多样性和新颖性比较局限，导致推荐的有可能都是用户看过的或者买过的商品。之后在Facebook开源了FASSI库之后，基于内积模型的向量检索方案得到了广泛应用，也就是第二代召回技术。这种技术通过将用户和物品用向量表示，然后用内积的大小度量兴趣，借助向量索引实现大规模的全量检索。这里虽然改善了第一代的无法全局检索的缺点，然而这种模式下存在索引构建和模型优化目标不一致的问题，索引优化是基于向量的近似误差，而召回问题的目标是最大化topK召回率。且这类方法也不方便在用户和物品之间做特征组合。</p>
<p>所以阿里开发了一种可以承载各种深度模型来检索用户潜在兴趣的推荐算法解决方案。这个TDM模型是基于树结构，利用树结构对全量商品进行检索，将复杂度由O(N)下降到O(logN)。</p>
<h5 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h5><p><strong>树结构</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211740339.png" alt="img"></p>
<p>如上图，树中的每一个叶子节点对应一个商品item，非叶子结点表示的是item的集合<strong>（这里的树不限于二叉树）</strong>。这种层次化结构体现了粒度从粗到细的item架构。</p>
<p><strong>整体结构</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211741089.png" alt="img"></p>
<h5 id="算法详解"><a href="#算法详解" class="headerlink" title="算法详解"></a>算法详解</h5><ol>
<li><p>基于树的高效检索</p>
<p>算法通常采用beam-search的方法，根据用户对每层节点挑选出topK，将挑选出来的这几个topK节点的子节点作为下一层的候选集，最终会落到叶子节点上。 这么做的理论依据是当前层的最有优topK节点的父亲必然属于上次的父辈节点的最优topK：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211743079.png" alt="img"></p>
<p>其中表示用户u对j层节点n感兴趣的概率，表示归一化因子。</p>
</li>
<li><p>对兴趣进行建模</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211744832.png" alt="img"></p>
<p>如上图，用户对叶子层item6感兴趣，可以认为它的兴趣是1，同层别的候选节点的兴趣为0，顺着着绿色线路上去的节点都标记为1，路线上的同层别的候选节点都标记为0。这样的操作就可以根据1和0构建用于每一层的正负样本。</p>
<p>样本构建完成后，可以在模型结构左侧采用任意的深度学习模型来承担用户兴趣判别器的角色，输入就是当前层构造的正负样本，输出则是（用户，节点）对的兴趣度，这个将被用作检索过程中选取topK的评判指标。<strong>在整体结构图中，我们可以看到节点特征方面，使用的是node embedding</strong>，说明在进入模型前已经向量化了。</p>
</li>
<li><p>训练过程</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211745271.png" alt="img"></p>
<p>整体联合训练的方式如下：</p>
<ol>
<li>构造随机二叉树</li>
<li>基于树模型生成样本</li>
<li>训练DNN模型直到收敛</li>
<li>基于DNN模型得到样本的Embedding，重新构造聚类二叉树</li>
<li>循环上述2～4过程</li>
</ol>
<p>具体的，在初始化树结构的时候，首先借助商品的类别信息进行排序，将相同类别的商品放到一起，然后递归的将同类别中的商品等量的分到两个子类中，直到集合中只包含一项，利用这种自顶向下的方式来初始化一棵树。基于该树采样生成深度模型训练所需的样本，然后进一步训练模型，训练结束之后可以得到每个树节点对应的Embedding向量，利用节点的Embedding向量，采用K-Means聚类方法来重新构建一颗树，最后基于这颗新生成的树，重新训练深层网络。</p>
</li>
</ol>
<h2 id="经典排序模型"><a href="#经典排序模型" class="headerlink" title="经典排序模型"></a>经典排序模型</h2><h3 id="GBDT-LR"><a href="#GBDT-LR" class="headerlink" title="GBDT+LR"></a>GBDT+LR</h3><p>前面介绍的协同过滤和矩阵分解存在的劣势就是仅利用了用户与物品相互行为信息进行推荐，忽视了用户自身特征，物品自身特征以及上下文信息等，导致生成的结果往往会比较片面。而这次介绍的这个模型是2014年由Facebook提出的GBDT+LR模型，该模型利用GBDT自动进行特征筛选和组合，进而生成新的离散特征向量，再把该特征向量当做LR模型的输入，来产生最后的预测结果，该模型能够综合利用用户、物品和上下文等多种不同的特征，生成较为全面的推荐结果，在CTR点击率预估场景下使用较为广泛。</p>
<h4 id="逻辑回归模型"><a href="#逻辑回归模型" class="headerlink" title="逻辑回归模型"></a>逻辑回归模型</h4><p>逻辑回归是在线性回归的基础上加了一个 Sigmoid 函数（非线形）映射，使得逻辑回归成为了一个优秀的分类算法，学习逻辑回归模型，首先应该记住一句话：<strong>逻辑回归假设数据服从伯努利分布,通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的。</strong>  </p>
<p>相比于协同过滤和矩阵分解利用用户的物品“相似度”进行推荐， 逻辑回归模型将问题看成了一个分类问题， 通过预测正样本的概率对物品进行排序。这里的正样本可以是用户“点击”了某个商品或者“观看”了某个视频， 均是推荐系统希望用户产生的“正反馈”行为， 因此<strong>逻辑回归模型将推荐问题转化成了一个点击率预估问题</strong>。而点击率预测就是一个典型的二分类， 正好适合逻辑回归进行处理， 那么逻辑回归是如何做推荐的呢？ 过程如下：</p>
<ol>
<li>将用户年龄、性别、物品属性、物品描述、当前时间、当前地点等特征转成数值型向量</li>
<li>确定逻辑回归的优化目标，比如把点击率预测转换成二分类问题， 这样就可以得到分类问题常用的损失作为目标， 训练模型</li>
<li>在预测的时候， 将特征向量输入模型产生预测， 得到用户“点击”物品的概率</li>
<li>利用点击概率对候选物品排序， 得到推荐列表</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221652189.png" alt="img"></p>
<p>这里的关键就是每个特征的权重参数， 我们一般是使用梯度下降的方式， 首先会先随机初始化参数， 然后将特征向量（也就是我们上面数值化出来的特征）输入到模型， 就会通过计算得到模型的预测概率， 然后通过对目标函数求导得到每个的梯度， 然后进行更新 ，这里的目标函数长下面这样：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221654279.png" alt="img"></p>
<p>求导之后的方式长这样：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221655094.png" alt="img"></p>
<p><strong>优点：</strong></p>
<ol>
<li>LR模型形式简单，可解释性好，从特征的权重可以看到不同的特征对最后结果的影响。</li>
<li>训练时便于并行化，在预测时只需要对特征进行线性加权，所以<strong>性能比较好</strong>，往往适合处理<strong>海量id类特征</strong>，用id类特征有一个很重要的好处，就是<strong>防止信息损失</strong>（相对于范化的 CTR 特征），对于头部资源会有更细致的描述</li>
<li>资源占用小,尤其是内存。在实际的工程应用中只需要存储权重比较大的特征及特征对应的权重。</li>
<li>方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类)</li>
</ol>
<p><strong>当然， 逻辑回归模型也有一定的局限性</strong></p>
<ol>
<li>表达能力不强， 无法进行特征交叉， 特征筛选等一系列“高级“操作（这些工作都得人工来干， 这样就需要一定的经验， 否则会走一些弯路）， 因此可能造成信息的损失</li>
<li>准确率并不是很高。因为这毕竟是一个线性模型加了个sigmoid， 形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布</li>
<li>处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据， 如果想处理非线性， 首先对连续特征的处理需要先进行<strong>离散化</strong>（离散化的目的是为了引入非线性），如上文所说，人工分桶的方式会引入多种问题。</li>
<li>LR 需要进行<strong>人工特征组合</strong>，这就需要开发者有非常丰富的领域经验，才能不走弯路。这样的模型迁移起来比较困难，换一个领域又需要重新进行大量的特征工程。</li>
</ol>
<p>所以如何<strong>自动发现有效的特征、特征组合，弥补人工经验不足，缩短LR特征实验周期</strong>，是亟需解决的问题， 而GBDT模型， 正好可以<strong>自动发现特征并进行有效组合</strong></p>
<h4 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h4><p>GBDT全称梯度提升决策树，在传统机器学习算法里面是对真实分布拟合的最好的几种算法之一，在前几年深度学习还没有大行其道之前，gbdt在各种竞赛是大放异彩。原因大概有几个，一是效果确实挺不错。二是即可以用于分类也可以用于回归。三是可以筛选特征， 所以这个模型依然是一个非常重要的模型。 </p>
<h4 id="GBDT-LR模型"><a href="#GBDT-LR模型" class="headerlink" title="GBDT+LR模型"></a>GBDT+LR模型</h4><p>2014年， Facebook提出了一种利用GBDT自动进行特征筛选和组合， 进而生成新的离散特征向量， 再把该特征向量当做LR模型的输入， 来产生最后的预测结果， 这就是著名的GBDT+LR模型了。GBDT+LR 使用最广泛的场景是CTR点击率预估，即预测当给用户推送的广告会不会被用户点击，模型的总体结构长下面这样：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221737318.png" alt="img"></p>
<p><strong>训练时</strong>，GBDT 建树的过程相当于自动进行的特征组合和离散化，然后从根结点到叶子节点的这条路径就可以看成是不同特征进行的特征组合，用叶子节点可以唯一的表示这条路径，并作为一个离散特征传入 LR 进行<strong>二次训练</strong>。</p>
<p>比如上图中， 有两棵树，x为一条输入样本，遍历两棵树后，x样本分别落到两颗树的叶子节点上，每个叶子节点对应LR一维特征，那么通过遍历树，就得到了该样本对应的所有LR特征。构造的新特征向量是取值0/1的。 比如左树有三个叶子节点，右树有两个叶子节点，最终的特征即为五维的向量。对于输入x，假设他落在左树第二个节点，编码[0,1,0]，落在右树第二个节点则编码[0,1]，所以整体的编码为[0,1,0,0,1]，这类编码作为特征，输入到线性分类模型（LR or FM）中进行分类。</p>
<p><strong>预测时</strong>，会先走 GBDT 的每棵树，得到某个叶子节点对应的一个离散特征(即一组特征组合)，然后把该特征以 one-hot 形式传入 LR 进行线性加权预测。</p>
<p>这个方案应该比较简单了， 下面有几个关键的点我们需要了解：</p>
<ol>
<li><strong>通过GBDT进行特征组合之后得到的离散向量是和训练数据的原特征一块作为逻辑回归的输入， 而不仅仅全是这种离散特征</strong></li>
<li>建树的时候用ensemble建树的原因就是一棵树的表达能力很弱，不足以表达多个有区分性的特征组合，多棵树的表达能力更强一些。GBDT每棵树都在学习前面棵树尚存的不足，迭代多少次就会生成多少棵树。</li>
<li>RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。</li>
<li>在CRT预估中， GBDT一般会建立两类树(非ID特征建一类， ID类特征建一类)， AD，ID类特征在CTR预估中是非常重要的特征，直接将AD，ID作为feature进行建树不可行，故考虑为每个AD，ID建GBDT树。<ol>
<li>非ID类树：不以细粒度的ID建树，此类树作为base，即便曝光少的广告、广告主，仍可以通过此类树得到有区分性的特征、特征组合</li>
<li>ID类树：以细粒度 的ID建一类树，用于发现曝光充分的ID对应有区分性的特征、特征组合</li>
</ol>
</li>
</ol>
<h3 id="特征交叉"><a href="#特征交叉" class="headerlink" title="特征交叉"></a>特征交叉</h3><h4 id="FM模型"><a href="#FM模型" class="headerlink" title="FM模型"></a>FM模型</h4><p><code>FM(Factorization Machine)</code>，即因式分解机。</p>
<h5 id="为什么需要FM模型"><a href="#为什么需要FM模型" class="headerlink" title="为什么需要FM模型"></a>为什么需要FM模型</h5><ol>
<li>特征组合是许多机器学习建模过程中遇到的问题，如果对特征直接建模，很有可能会忽略掉特征与特征之间的关联信息，因此，可以通过构建新的交叉特征这一特征组合方式提高模型的效果。</li>
<li>高维的稀疏矩阵是实际工程中常见的问题，并直接会导致计算量过大，特征权值更新缓慢。试想一个  的表，每一列都有  种元素，经过<code>One-Hot</code>独热编码之后，会产生一个  的表。因此表中每行元素只有  个值为  ，  个值为  。</li>
</ol>
<p>而<code>FM</code>的优势就在于对这两方面问题的处理。首先是特征组合，通过对两两特征组合，引入交叉项特征，提高模型得分；其次是高维灾难，通过引入隐向量（对参数矩阵进行矩阵分解），完成对特征的参数估计。</p>
<h5 id="FM模型的应用场景"><a href="#FM模型的应用场景" class="headerlink" title="FM模型的应用场景"></a>FM模型的应用场景</h5><p>我们已经知道了<code>FM</code>可以解决特征组合以及高维稀疏矩阵问题，而实际业务场景中，电商、豆瓣等推荐系统的场景是使用最广的领域，打个比方，小王只在豆瓣上浏览过  部电影，而豆瓣上面有  部电影，如果构建一个基于小王的电影矩阵，毫无疑问，里面将有  个元素全为  。而类似于这样的问题就可以通过<code>FM</code>来解决。</p>
<h5 id="FM模型的具体形式"><a href="#FM模型的具体形式" class="headerlink" title="FM模型的具体形式"></a>FM模型的具体形式</h5><p>首先我们回顾一下最常见的线性表达式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304191959346.png" alt="img"></p>
<p>其中  为初始权值，或者理解为偏置项，  为每个特征  对应的权值。可以看到，这种线性表达式只描述了每个特征与输出的关系。</p>
<p><code>FM</code>的表达式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192002037.png" alt="img"></p>
<p>可观察到，只是在线性表达式后面加入了新的交叉项特征及对应的权值。这里  和  分别表示两个不同的特征取值，对于  维的特征来说，这样的组合应该一共有  种，也就意味着我们需要同样数量的权重参数。</p>
<h5 id="FM模型的解决方法"><a href="#FM模型的解决方法" class="headerlink" title="FM模型的解决方法"></a>FM模型的解决方法</h5><p><code>FM</code>解决这个问题的方法非常简单，它不再是简单地为交叉之后的特征对设置参数，而是设置了一种计算特征参数的方法。<code>FM</code>模型引入了新的矩阵 ，矩阵  是一个  的二维矩阵。这里的  是我们设置的参数，一般不会很大，比如  、  之类。对于特征每一个维度  ，我们都可以找到一个  ，它表示一个  的向量。于是我们可以用  和  来计算得出上式中的  ，即  。也就是说我们<strong>用向量的内积来计算得到了就交叉特征的系数</strong>，相比于原先  量级的参数而言，我们将参数的量级降低到了  。</p>
<p>有了上面的方法，我们就能表示出交叉项，具体过程如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192107149.png" alt="img"></p>
<h5 id="FM模型的训练"><a href="#FM模型的训练" class="headerlink" title="FM模型的训练"></a>FM模型的训练</h5><p>经过上述步骤，我们能够得到变形之后的原式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192121730.png" alt="img"></p>
<p>首先需要明确的是我们想要优化的参数是  ，  和  ，所以我们对损失函数求导即可得到：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192201890.png" alt="img"></p>
<p>其中  和  是独立的，所以它是可以提前算好的，这样一来对于所有参数项，我们都可以在  的时间内计算出它们的梯度。</p>
<h5 id="FM模型的高维扩展"><a href="#FM模型的高维扩展" class="headerlink" title="FM模型的高维扩展"></a>FM模型的高维扩展</h5><p>我们仿照刚才的公式，可以写出<code>FM</code>模型推广到  维的方程：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192209525.png" alt="img"></p>
<p>前面两项都很好理解，我们着重来看第三项。第三项当中包含了从  维到  维交叉特征的情况，我们以  为例，那么这一项当中应该包含二维的交叉项以及三维的交叉项，应该是这样的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192210293.png" alt="img"></p>
<p>这个式子<strong>整体上和之前的形式是一样的</strong>，我们不难分析出它的复杂度是  。当  的时候，我们通过一系列变形将它的复杂度优化到了  ，而当  的时候，没有很好的优化方法，而且三重特征的交叉往往没有意义，并且会过于稀疏，所以我们一般情况下只会使用  的情况。</p>
<h4 id="FFM模型"><a href="#FFM模型" class="headerlink" title="FFM模型"></a>FFM模型</h4><p><code>FFM(Field-aware Factorization Machine)</code>其实就是<code>FM</code>的进阶版，<code>FFM</code>将隐向量  又进一步细化（引入了<code>field</code>的概念，即将特征所在的不同的<code>field</code>这个信息也考虑进去），其公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201650996.png" alt="img"></p>
<p>其中，  是第  个特征所属的<code>field</code>。如果隐向量的长度为  ，那么<code>FFM</code>的二次参数有  个，远多于<code>FM</code>模型的  个。此外，由于隐向量与<code>field</code>相关，<code>FFM</code>二次项并不能够化简，其预测复杂度是  。</p>
<h5 id="FFM模型的特征组合方式"><a href="#FFM模型的特征组合方式" class="headerlink" title="FFM模型的特征组合方式"></a>FFM模型的特征组合方式</h5><p>举一个例子进行辅助说明：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>User</th>
<th>Movie</th>
<th>Genre</th>
<th>Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>YuChin</td>
<td>3Idiots</td>
<td>Comedy, Drama</td>
<td>$9.99</td>
</tr>
</tbody>
</table>
</div>
<p>对上面出现的信息进行分类标注，<strong>红字代表所在的field,蓝字代表特征,绿字代表特征的值。</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201703206.png" alt="img"></p>
<p><strong>FM的特征组合方式为：</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201704698.png" alt="img"></p>
<p><strong>FFM的特征组合方式为：</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201707323.png" alt="img"></p>
<p>不难看出，<code>FM</code>中有  ，  ，  ，  ， 五个隐向量，但到了<code>FFM</code>中有  个，选  与  对应的域  对应的隐向量  进行交叉。</p>
<h5 id="FFM模型的应用场景"><a href="#FFM模型的应用场景" class="headerlink" title="FFM模型的应用场景"></a>FFM模型的应用场景</h5><p>和<code>FM</code>算法一样，<code>FFM</code>主要应用在推荐算法中的<code>CTR</code>点击率预估（排序）问题，推荐系统一般可以分成两个模块，召回和排序。比如对于电影推荐，召回模块会针对用户生成一个推荐电影列表，而排序模块则负责对这个电影列表根据用户的兴趣做排序。当把<code>FFM</code>算法应用到推荐系统中时，具体地是应用在排序模块。</p>
<h4 id="PNN"><a href="#PNN" class="headerlink" title="PNN"></a>PNN</h4><p>在特征交叉的相关模型中FM, FFM都证明了特征交叉的重要性，FNN将神经网络的高阶隐式交叉加到了FM的二阶特征交叉上，一定程度上说明了DNN做特征交叉的有效性。但是对于DNN这种“add”操作的特征交叉并不能充分挖掘类别特征的交叉效果。PNN虽然也用了DNN来对特征进行交叉组合，但是并不是直接将低阶特征放入DNN中，而是设计了Product层先对低阶特征进行充分的交叉组合之后再送入到DNN中去。</p>
<p>PNN模型其实是对IPNN和OPNN的总称，两者分别对应的是不同的Product实现方法，前者采用的是inner product，后者采用的是outer product。在PNN的算法方面，比较重要的部分就是Product Layer的简化实现方法，需要在数学和代码上都能够比较深入的理解。</p>
<h5 id="模型结构及原理"><a href="#模型结构及原理" class="headerlink" title="模型结构及原理"></a>模型结构及原理</h5><p>PNN模型的整体架构如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221912175.png" alt="img"></p>
<p>一共分为五层，其中除了Product Layer别的layer都是比较常规的处理方法，均可以从前面的章节进一步了解。模型中最重要的部分就是通过Product层对embedding特征进行交叉组合，也就是上图中红框所显示的部分。</p>
<p>Product层主要有线性部分和非线性部分组成，分别用和来表示，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221914930.png" alt="img"></p>
<ol>
<li>线性模块，一阶特征(未经过显示特征交叉处理)，对应论文中的</li>
<li>非线性模块，高阶特征(经过显示特征交叉处理)，对应论文中的</li>
</ol>
<p><strong>线性部分</strong></p>
<p>先来解释一下是如何计算得到的，在介绍计算之前先介绍一下矩阵内积计算, 如下公式所示，用一句话来描述就是两个矩阵对应元素相称，然后将相乘之后的所有元素相加</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221916770.png" alt="img"></p>
<p>的计算就是矩阵内积，而是有个组成，所以需要个矩阵求得，但是在代码实现的时候不一定是定义个矩阵，可以将这些矩阵Flatten。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221917878.png" alt="img"></p>
<p>总之这一波操作就是将所有的embedding向量中的所有元素都乘以一个矩阵的对应元素，最后相加即可，这一部分比较简单(N表示的是特征的数量，M表示的是所有特征转化为embedding之后维度，也就是N*emb_dim)</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221919755.png" alt="img"></p>
<p><strong>非线性部分</strong></p>
<p>上面介绍了线性部分的计算，非线性部分的计算相比线性部分要复杂很多，先从整体上看的计算</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221925847.png" alt="img"></p>
<p>从上述公式中可以发现，和类似需要个矩阵计算内积得到，重点就是如何求这个，这里作者提出了两种方式，一种是使用内积计算，另一种是使用外积计算。</p>
<ul>
<li>IPNN</li>
</ul>
<p>使用内积实现特征交叉就和FM是类似的(两两向量计算内积)，下面将向量内积操作表示如下表达式</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221951440.png" alt="img"></p>
<p>将内积的表达式带入的计算表达式中有：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221951074.png" alt="img"></p>
<p>上面就提到了这里使用的内积是计算两两特征之间的内积，然而向量a和向量b的内积与向量b和向量a的内积是相同的，其实是没必要计算的，看一下下面FM的计算公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221952139.png" alt="img"></p>
<p>也就是说计算的内积矩阵是对称的，那么与其对应元素做矩阵内积的矩阵也是对称的，对于可学习的权重来说如果是对称的是不是可以只使用其中的一半就行了呢，所以基于这个思考，对Inner Product的权重定义及内积计算进行优化，首先将权重矩阵分解,此时（参数从原来的变成了）,将分解后的带入的计算公式有：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221952937.png" alt="img"></p>
<p>所以优化后的的计算公式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221952743.png" alt="img"></p>
<p>这里为了好理解不做过多的解释，其实这里对于矩阵分解省略了一些细节，感兴趣的可以去看原文，最后模型实现的时候就是基于上面的这个公式计算的（给出的代码也是基于优化之后的实现）。</p>
<ul>
<li>OPNN</li>
</ul>
<p>使用外积实现相比于使用内积实现，唯一的区别就是使用向量的外积来计算矩阵,首先定义向量的外积计算</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221953919.png" alt="img"></p>
<p>从外积公式可以发现两个向量的外积得到的是一个矩阵，与上面介绍的内积计算不太相同，内积得到的是一个数值。内积实现的Product层是将计算得到的内积矩阵，乘以一个与其大小一样的权重矩阵，然后求和，按照这个思路的话，通过外积得到的计算相当于之前的内积值乘以权重矩阵对应位置的值求和就变成了，外积矩阵乘以权重矩阵中对应位置的子矩阵然后将整个相乘得到的大矩阵对应元素相加，用公式表示如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221953829.png" alt="img"></p>
<p>需要注意的是此时的表示的是一个矩阵，而不是一个值，此时计算的复杂度是, 其中表示的是特征的组合数量，表示的是计算外积的复杂度。这样的复杂度肯定是无法接受的，所以为了优化复杂度，PNN的作者重新定义了的计算方式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221954360.png" alt="img"></p>
<p>需要注意，这里新定义的外积计算与传统的外积计算时不等价的，这里是为了优化计算效率重新定义的计算方式，从公式中可以看出，相当于先将原来的embedding向量在特征维度上先求和，变成一个向量之后再计算外积。加入原embedding向量表示为，其中表示特征的数量，M表示的是所有特征的总维度，即, 在特征维度上进行求和就是将矩阵压缩成了, 然后两个维的向量计算外积得到最终所有特征的外积交叉结果，最终的可以表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221954996.png" alt="img"></p>
<p>最终的计算方式和的计算方式看起来差不多，但是需要注意外积优化后的的维度是的，表示的是特征矩阵的维度，即。</p>
<h4 id="DCN"><a href="#DCN" class="headerlink" title="DCN"></a>DCN</h4><p>Wide&amp;Deep模型的提出不仅综合了“记忆能力”和“泛化能力”， 而且开启了不同网络结构融合的新思路。 所以后面就有各式各样的模型改进Wide部分或者Deep部分， 而Deep&amp;Cross模型(DCN)就是其中比较典型的一个，这是2017年斯坦福大学和谷歌的研究人员在ADKDD会议上提出的， 该模型针对W&amp;D的wide部分进行了改进， 因为Wide部分有一个不足就是需要人工进行特征的组合筛选， 过程繁琐且需要经验， 而2阶的FM模型在线性的时间复杂度中自动进行特征交互，但是这些特征交互的表现能力并不够，并且随着阶数的上升，模型复杂度会大幅度提高。于是乎，作者用一个Cross Network替换掉了Wide部分，来自动进行特征之间的交叉，并且网络的时间和空间复杂度都是线性的。 通过与Deep部分相结合，构成了深度交叉网络（Deep &amp; Cross Network），简称DCN。</p>
<h5 id="模型结构及原理-1"><a href="#模型结构及原理-1" class="headerlink" title="模型结构及原理"></a>模型结构及原理</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222002416.png" alt="img"></p>
<h5 id="Embedding和Stacking-层"><a href="#Embedding和Stacking-层" class="headerlink" title="Embedding和Stacking 层"></a>Embedding和Stacking 层</h5><p>Embedding层我们已经非常的熟悉了吧， 这里的作用依然是把稀疏离散的类别型特征变成低维密集型。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222003410.png" alt="img"></p>
<p>其中对于某一类稀疏分类特征（如id），是第个分类值（id序号）的embedding向量。是embedding矩阵， 维度， 是embedding维度， 是该类特征的唯一取值个数。属于该特征的二元稀疏向量(one-hot)编码的。 【实质上就是在训练得到的Embedding参数矩阵中找到属于当前样本对应的Embedding向量】。其实绝大多数基于深度学习的推荐模型都需要Embedding操作，参数学习是通过神经网络进行训练。</p>
<p>最后，该层需要将所有的密集型特征与通过embedding转换后的特征进行联合（Stacking）：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222003825.png" alt="img"></p>
<p>一共个类别特征， dense是数值型特征， 两者在特征维度拼在一块。 上面的这两个操作如果是看了前面的模型的话，应该非常容易理解了。</p>
<h5 id="Cross-Network"><a href="#Cross-Network" class="headerlink" title="Cross Network"></a>Cross Network</h5><p>这个就是本模型最大的亮点了【Cross网络】， 这个思路感觉非常Nice。设计该网络的目的是增加特征之间的交互力度。交叉网络由多个交叉层组成， 假设第层的输出向量， 那么对于第层的输出向量表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222005263.png" alt="img"></p>
<p>可以看到， 交叉层的二阶部分非常类似PNN提到的外积操作， 在此基础上增加了外积操作的权重向量， 以及原输入向量和偏置向量。 交叉层的可视化如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222006335.png" alt="img"></p>
<p>可以看到， 每一层增加了一个维的权重向量（n表示输入向量维度）， 并且在每一层均保留了输入向量， 因此输入和输出之间的变化不会特别明显。关于这一层， 原论文里面有个具体的证明推导Cross Network为啥有效， 不过比较复杂，这里我拿一个式子简单的解释下上面这个公式的伟大之处：</p>
<p><strong>我们根据上面这个公式， 尝试的写前面几层看看:</strong></p>
<p>我们暂且写到第3层的计算， 我们会发现什么结论呢？  给大家总结一下：</p>
<ol>
<li><p>中包含了所有的的1,2阶特征的交互， 包含了所有的的1、2、3阶特征的交互，中包含了所有的, 与的交互，的1、2、3、4阶特征交互。 因此， 交叉网络层的叉乘阶数是有限的。 <strong>第层特征对应的最高的叉乘阶数</strong></p>
</li>
<li><p>Cross网络的参数是共享的， 每一层的这个权重特征之间共享， 这个可以使得模型泛化到看不见的特征交互作用， 并且对噪声更具有鲁棒性。 例如两个稀疏的特征， 它们在数据中几乎不发生交互， 那么学习的权重对于预测没有任何的意义。</p>
</li>
<li><p>计算交叉网络的参数数量。 假设交叉层的数量是， 特征的维度是， 那么总共的参数是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222009493.png" alt="img"></p>
<p>这个就是每一层会有和。且维度和的维度是一致的。</p>
</li>
<li><p>交叉网络的时间和空间复杂度是线性的。这是因为， 每一层都只有和， 没有激活函数的存在，相对于深度学习网络， 交叉网络的复杂性可以忽略不计。</p>
</li>
<li><p>Cross网络是FM的泛化形式，在FM模型中，特征  的权重 ，那么交叉项  的权重为。在DCN中，的权重为, 交叉项的权重是参数和的乘积，这个看上面那个例子展开感受下。因此两个模型都各自学习了独立于其他特征的一些参数，并且交叉项的权重是相应参数的某种组合。FM只局限于2阶的特征交叉(一般)，而DCN可以构建更高阶的特征交互， 阶数由网络深度决定，并且交叉网络的参数只依据输入的维度线性增长。</p>
</li>
<li><p>还有一点我们也要了解，对于每一层的计算中， 都会跟着, 这个是咱们的原始输入， 之所以会乘以一个这个，是为了保证后面不管怎么交叉，都不能偏离我们的原始输入太远，别最后交叉交叉都跑偏了。</p>
</li>
<li><p>, 这个东西其实有点跳远连接的意思，也就是和ResNet也有点相似，无形之中还能有效的缓解梯度消失现象。</p>
</li>
</ol>
<p>好了， 关于本模型的交叉网络的细节就介绍到这里了。这应该也是本模型的精华之处了，后面就简单了。</p>
<h5 id="Deep-Network"><a href="#Deep-Network" class="headerlink" title="Deep Network"></a>Deep Network</h5><p>这个就和上面的D&amp;W的全连接层原理一样。这里不再过多的赘述。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222013355.png" alt="img"></p>
<p>具体的可以参考W&amp;D模型。</p>
<h5 id="组合输出层"><a href="#组合输出层" class="headerlink" title="组合输出层"></a>组合输出层</h5><p>这个层负责将两个网络的输出进行拼接， 并且通过简单的Logistics回归完成最后的预测：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222014011.png" alt="img"></p>
<p>其中和分别表示交叉网络和深度网络的输出。 最后二分类的损失函数依然是交叉熵损失：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222014360.png" alt="img"></p>
<p>Cross&amp;Deep模型的原理就是这些了，其核心部分就是Cross Network， 这个可以进行特征的自动交叉， 避免了更多基于业务理解的人工特征组合。 该模型相比于W&amp;D，Cross部分表达能力更强， 使得模型具备了更强的非线性学习能力。</p>
<h4 id="AutoInt"><a href="#AutoInt" class="headerlink" title="AutoInt"></a>AutoInt</h4><h5 id="动机和原理"><a href="#动机和原理" class="headerlink" title="动机和原理"></a>动机和原理</h5><p>这篇文章的前言部分依然是说目前模型的不足，以引出模型的动机所在， 简单的来讲，就是两句话：</p>
<ol>
<li>浅层的模型会受到交叉阶数的限制，没法完成高阶交叉</li>
<li>深层模型的DNN在学习高阶隐性交叉的效果并不是很好， 且不具有可解释性</li>
</ol>
<p>于是乎：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222018983.png" alt="img"></p>
<p>那么是如何做到的呢？ 引入了transformer， 做成了一个特征交互层， 原理如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222018848.png" alt="img"></p>
<h5 id="AutoInt模型的前向过程梳理"><a href="#AutoInt模型的前向过程梳理" class="headerlink" title="AutoInt模型的前向过程梳理"></a>AutoInt模型的前向过程梳理</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222019899.png" alt="img"></p>
<h6 id="Input-Layer"><a href="#Input-Layer" class="headerlink" title="Input Layer"></a>Input Layer</h6><p>输入层这里， 用到的特征主要是离散型特征和连续性特征， 这里不管是哪一类特征，都会过embedding层转成低维稠密的向量，是的， <strong>连续性特征，这里并没有经过分桶离散化，而是直接走embedding</strong>。这个是怎么做到的呢？就是就是类似于预训练时候的思路，先通过item_id把连续型特征与类别特征关联起来，最简单的，就是把item_id拿过来，过完embedding层取出对应的embedding之后，再乘上连续值即可， 所以这个连续值事先一定要是归一化的。 当然，这个玩法，我也是第一次见。 学习到了， 所以模型整体的输入如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222021880.png" alt="img"></p>
<p>这里的表示特征的个数, 这是离散型特征， one-hot的形式， 而在这里是连续性特征。过embedding层的细节应该是我上面说的那样。</p>
<h6 id="Embedding-Layer"><a href="#Embedding-Layer" class="headerlink" title="Embedding Layer"></a>Embedding Layer</h6><p>embedding层的作用是把高维稀疏的特征转成低维稠密， 离散型的特征一般是取出对应的embedding向量即可， 具体计算是这样：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222024864.png" alt="img"></p>
<p>对于第个离散特征，直接第个嵌入矩阵乘one-hot向量就取出了对应位置的embedding。 当然，如果输入的时候不是个one-hot， 而是个multi-hot的形式，那么对应的embedding输出是各个embedding求平均得到的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222023574.png" alt="img"></p>
<p>比如， 推荐里面用户的历史行为item。过去点击了多个item，最终的输出就是这多个item的embedding求平均。 而对于连续特征， 我上面说的那样， 也是过一个embedding矩阵取相应的embedding， 不过，最后要乘一个连续值</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222025480.png" alt="img"></p>
<p>这样，不管是连续特征，离散特征还是变长的离散特征，经过embedding之后，都能得到等长的embedding向量。 我们把这个向量拼接到一块，就得到了交互层的输入。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222025399.png" alt="img"></p>
<h6 id="Interacting-Layer"><a href="#Interacting-Layer" class="headerlink" title="Interacting Layer"></a>Interacting Layer</h6><p>这个是本篇论文的核心了，其实这里说的就是transformer块的前向传播过程，所以这里我就直接用比较白话的语言简述过程了，不按照论文中的顺序展开了。</p>
<p>通过embedding层， 我们会得到M个向量，假设向量的维度是维， 那么这个就是一个的矩阵， 我们定一个符号。 接下来我们基于这个矩阵，做三次变换，也就是分别乘以三个矩阵， 这三个矩阵的维度是的话， 那么我们就会得到三个结果：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222028818.png" alt="img"></p>
<p>这三个矩阵都是的。这其实就完成了一个Head的操作。所谓的自注意力， 就是通过三次变换得到的结果之间，通过交互得到相关性，并通过相关性进行加权汇总，全是自发的。 那么是怎么做到的呢？首先， 先进行这样的操作：  这个结果得到的是一个的矩阵， 那么这个操作到底是做了一个什么事情呢？</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222029092.png" alt="img"></p>
<p>假设这里的是我们的6个特征， 而每一行代表每个特征的embedding向量，这样两个矩阵相乘，相当于得到了当前特征与其它特征两两之间的內积值， 而內积可以表示两个向量之间的相似程度。所以得到的结果每一行，就代表当前这个特征与其它特征的相似性程度。</p>
<p>接下来，我们对， 在最后一个维度上进行softmax，就根据相似性得到了权重信息，这其实就是把相似性分数归一化到了0-1之间 接下来， 我们再进行这样的一步操作 这样就得到了的矩阵， 这步操作，其实就是一个加权汇总的过程， 对于每个特征， 先求与其它特征的相似度，然后得到一个权重，再回乘到各自的特征向量再求和。 只不过这里的特征是经过了一次线性变化的过程，降维到了。</p>
<p>上面是我从矩阵的角度又过了一遍， 这个是直接针对所有的特征向量一部到位。 论文里面的从单个特征的角度去描述的，只说了一个矩阵向量过多头注意力的操作。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222030271.png" alt="img"></p>
<p>这里会更好懂一些， 就是相当于上面矩阵的每一行操作拆开了， 首先，整个拼接起来的embedding矩阵还是过三个参数矩阵得到， 然后是每一行单独操作的方式，对于某个特征向量，与其它的特征两两內积得到权重，然后在softmax，回乘到对应向量，然后进行求和就得到了融合其它特征信息的新向量。 具体过程如图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222030314.png" alt="img"></p>
<p>上面的过程是用了一个头，理解的话就类似于从一个角度去看特征之间的相关关系，用论文里面的话讲，这是从一个子空间去看， 如果是想从多个角度看，这里可以用多个头，即换不同的矩阵得到不同的然后得到不同的， 每个是的。</p>
<p>然后，多个头的结果concat起来</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222031199.png" alt="img"></p>
<p>这是一个的向量， 假设有个头。 </p>
<p>接下来， 过一个残差网络层，这是为了保留原始的特征信息</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222031359.png" alt="img"></p>
<p>这里的是的向量， 是的矩阵， 最后得到的是的向量， 这是其中的一个特征，如果是个特征堆叠的话，最终就是的矩阵， 这个就是Interacting Layer的结果输出。</p>
<h6 id="Output-Layer"><a href="#Output-Layer" class="headerlink" title="Output Layer"></a>Output Layer</h6><p>输出层就非常简单了，加一层全连接映射出输出值即可：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222032295.png" alt="img"></p>
<p>这里的是的， 这样最终得到的是一个概率值了， 接下来交叉熵损失更新模型参数即可。</p>
<h5 id="AutoInt的分析"><a href="#AutoInt的分析" class="headerlink" title="AutoInt的分析"></a>AutoInt的分析</h5><p>这里论文里面分析了为啥AutoInt能建模任意的高阶交互以及时间复杂度和空间复杂度的分析。我们一一来看。</p>
<p>关于建模任意的高阶交互， 我们这里拿一个transformer块看下， 对于一个transformer块， 我们发现特征之间完成了一个2阶的交互过程，得到的输出里面我们还保留着1阶的原始特征。 </p>
<p>那么再经过一个transformer块呢？ 这里面就会有2阶和1阶的交互了， 也就是会得到3阶的交互信息。而此时的输出，会保留着第一个transformer的输出信息特征。再过一个transformer块的话，就会用4阶的信息交互信息， 其实就相当于， 第个transformer里面会建模出阶交互来， 这个与CrossNet其实有异曲同工之妙的，无法是中间交互时的方式不一样。 前者是bit-wise级别的交互，而后者是vector-wise的交互。 </p>
<p>所以， AutoInt是可以建模任意高阶特征的交互的，并且这种交互还是显性。</p>
<p>关于时间复杂度和空间复杂度，空间复杂度是级别的， 这个也很好理解，看参数量即可， 3个W矩阵， H个head，再假设L个transformer块的话，参数量就达到这了。 时间复杂度的话是的，论文说如果d和d’很小的话，其实这个模型不算复杂。</p>
<h4 id="FiBiNet"><a href="#FiBiNet" class="headerlink" title="FiBiNet"></a>FiBiNet</h4><h5 id="模型原理及细节"><a href="#模型原理及细节" class="headerlink" title="模型原理及细节"></a>模型原理及细节</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222035784.png" alt="img"></p>
<h6 id="Embedding-Layer-1"><a href="#Embedding-Layer-1" class="headerlink" title="Embedding Layer"></a>Embedding Layer</h6><p>这个不多讲， 整理这个是为了后面统一符号。</p>
<p>假设我们有个离散特征，经过embedding层之后，会得到， 其中，表示第个离散特征对应的embedding向量，维。</p>
<h6 id="SENET-Layer"><a href="#SENET-Layer" class="headerlink" title="SENET Layer"></a>SENET Layer</h6><p>这是第一个重点，首先这个网络接收的输入是上面的， 网络的输出也是个同样大小的张量<code>(None, f, k)</code>矩阵。 结构如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222038251.png" alt="img"></p>
<p>SENet由自动驾驶公司Momenta在2017年提出，在当时，是一种应用于图像处理的新型网络结构。它基于CNN结构，<strong>通过对特征通道间的相关性进行建模，对重要特征进行强化来提升模型准确率，本质上就是针对CNN中间层卷积核特征的Attention操作</strong>。SENet仍然是效果最好的图像处理网络结构之一。</p>
<p>把SENet放在Embedding层之上，通过SENet网络，动态地学习这些特征的重要性。<strong>对于每个特征学会一个特征权重，然后再把学习到的权重乘到对应特征的Embedding里，这样就可以动态学习特征权重，通过小权重抑制噪音或者无效低频特征，通过大权重放大重要特征影响的目的</strong>。在推荐系统里面， 结构长这个样子：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222040735.png" alt="img"></p>
<p>下面看下这个网络里面的具体计算过程， SENET主要分为三个步骤Squeeze, Excitation, Re-weight。</p>
<ul>
<li><p><strong>在Squeeze阶段</strong>，我们对每个特征的Embedding向量进行数据压缩与信息汇总，如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222041255.png" alt="img"></p>
<p>假设某个特征是维大小的，那么我们对里包含的维数字求均值，得到能够代表这个特征汇总信息的数值 ，也就是说，把第个特征的里的信息压缩到一个数值。原始版本的SENet，在这一步是对CNN的二维卷积核进行操作的，这里等于对某个特征Embedding元素求均值。我们试过，在推荐领域均值效果比效果好，这也很好理解，因为<strong>图像领域对卷积核元素求，等于找到最强的那个特征，而推荐领域的特征，每一位的数字都是有意义的，所以求均值能更好地保留和融合信息</strong>。通过Squeeze阶段，对于每个特征 ，都压缩成了单个数值，假设特征Embedding层有个特征，就形成Squeeze向量，向量大小。</p>
</li>
<li><p><strong>Excitation阶段</strong>，这个阶段引入了中间层比较窄的两层MLP网络，作用在Squeeze阶段的输出向量上，如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222042251.png" alt="img"></p>
<p>非线性激活函数，一般。本质上，这是在做特征的交叉，也就是说，每个特征以一个来表征，通过MLP来进行交互，通过交互，得出这么个结果：对于当前所有输入的特征，通过相互发生关联，来动态地判断哪些特征重要，哪些特征不重要。</p>
<p>其中，第一个MLP的作用是做特征交叉，第二个MLP的作用是为了保持输出的大小维度。因为假设Embedding层有个特征，那么我们需要保证输出个权重值，而第二个MLP就是起到将大小映射到个数值大小的作用。</p>
<p>这样，经过两层MLP映射，就会产生个权重数值，第个数值对应第个特征Embedding的权重 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222043024.png" alt="img"></p>
<p>下面再分析下维度， SENet的输入是，这个是<code>(None, f, k)</code>的维度， 通过Squeeze阶段，得到了<code>(None, f)</code>的矩阵，这个也就相当于Layer L1的输入(当然这里没有下面的偏置哈)，接下来过MLP1， 这里的, 这里的叫做reduction ratio， 这个就是中间层神经元的个数， 表示了压缩的程度。</p>
</li>
<li><p><strong>Re-Weight</strong>，我们把Excitation阶段得到的每个特征对应的权重，再乘回到特征对应的Embedding里，就完成了对特征重要性的加权操作。  , and 。数值大，说明SENet判断这个特征在当前输入组合里比较重要， 数值小，说明SENet判断这个特征在当前输入组合里没啥用。如果非线性函数用Relu，会发现大量特征的权重会被Relu搞成0，也就是说，其实很多特征是没啥用的。</p>
</li>
</ul>
<p>这样，就可以将SENet引入推荐系统，用来对特征重要性进行动态判断。注意，<strong>所谓动态，指的是比如对于某个特征，在某个输入组合里可能是没用的，但是换一个输入组合，很可能是重要特征。它重要不重要，不是静态的，而是要根据当前输入，动态变化的</strong>。</p>
<p>这里正确的理解，算是一种特征重要性选择的思路， SENET和AFM的Attention网络是起着同样功效的一个网络。只不过那个是在特征交互之后进行特征交互重要性的选择，而这里是从embedding这里先压缩，再交互，再选择，去掉不太重要的特征。 <strong>考虑特征重要性上的两种考虑思路，难以说孰好孰坏，具体看应用场景</strong>。 不过如果分析下这个东西为啥会有效果， 就像张俊林老师提到的那样， 在Excitation阶段， 各个特征过了一个MLP进行了特征组合， 这样就真有可能过滤掉对于当前的交互不太重要的特征。 至于是不是， 那神经网络这东西就玄学了，让网络自己去学吧。</p>
<h6 id="Bilinear-Interaction-Layer"><a href="#Bilinear-Interaction-Layer" class="headerlink" title="Bilinear-Interaction Layer"></a>Bilinear-Interaction Layer</h6><p>特征重要性选择完事， 接下来就是研究特征交互， 这里作者直接就列出了目前的两种常用交互以及双线性交互:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222048779.png" alt="img"></p>
<p>这个图其实非常了然了。以往模型用的交互， 内积的方式(FM,FFM)这种或者哈达玛积的方式(NFM,AFM)这种。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222048554.png" alt="img"></p>
<p>所谓的双线性，其实就是组合了内积和哈达玛积的操作，看上面的右图。就是在和之间先加一个矩阵， 这个矩阵的维度是, 是的向量。 先让与内积，得到的向量，这时候先仔细体会下这个<strong>新向量的每个元素，相当于是原来向量在每个维度上的线性组合了</strong>。这时候再与进行哈达玛积得到结果。</p>
<p>这里我不由自主的考虑了下双线性的功效，也就是为啥作者会说双线性是细粒度，下面是我自己的看法哈。</p>
<ul>
<li>如果我们单独先看内积操作，特征交互如果是两个向量直接内积，这时候， 结果大的，说明两个向量相似或者特征相似， 但向量内积，其实是相当于向量的各个维度先对应位置元素相乘再相加求和。 这个过程中认为的是向量的各个维度信息的重要性是一致的。类似于， 但真的一致吗？ —- <strong>内积操作没有考虑向量各个维度的重要性</strong></li>
<li>如果我们单独看哈达玛积操作， 特征交互如果是两个向量哈达玛积，这时候，是各个维度对应位置元素相乘得到一个向量， 而这个向量往往后面会进行线性或者非线性交叉的操作， 最后可能也会得到具体某个数值，但是这里经过了线性或者非线性交叉操作之后， 有没有感觉把向量各个维度信息的重要性考虑了进来？   就类似于。 如果模型认为重要性相同，那么哈达玛积还有希望退化成内积，所以哈达玛积感觉考虑的比内积就多了一些。 —- <strong>哈达玛积操作自身也没有考虑各个维度重要性，但通过后面的线性或者非线性操作，有一定的维度重要性在里面</strong></li>
<li>再看看这个双线性， 是先内积再哈达玛积。这个内积操作不是直接和内积，而是中间引入了个矩阵，参数可学习。 那么和做内积之后，虽然得到了同样大小的向量，但是这个向量是各个维度元素的线性组合，相当于变成了， 这时候再与哈达玛积的功效，就变成了， 这时候，就可以看到，如果这里的是个对角矩阵，那么这里就退化成了哈达玛积。  所以双线性感觉考虑的又比哈达玛积多了一些。如果后面再走一个非线性操作的话，就会发现这里同时考虑了两个交互向量各个维度上的重要性。—-<strong>双线性操作同时可以考虑交互的向量各自的各个维度上的重要性信息， 这应该是作者所说的细粒度，各个维度上的重要性</strong></li>
</ul>
<p><strong>当然思路是思路，双线性并不一定见得一定比哈达玛积有效， SENET也不一定就会比原始embedding要好，一定要辩证看问题</strong></p>
<p>这里还有个厉害的地方在于这里的W有三种选择方式，也就是三种类型的双线性交互方式。</p>
<ol>
<li>Field-All Type</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222049946.png" alt="img"></p>
<p>也就是所有的特征embedding共用一个矩阵，这也是Field-All的名字来源。。这种方式最简单</p>
<ol>
<li>Field-Each Type</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222050330.png" alt="img"></p>
<p>每个特征embedding共用一个矩阵， 那么如果有个特征的话，这里的需要个。所以这里的参数个数， 这里的是因为两两组合之后，比如<code>[0,1,2]</code>， 两两组合<code>[0,1], [0,2], [1,2]</code>。 这里用到的域是0和1。</p>
<ol>
<li>Field-Interaction Type</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222050837.png" alt="img"></p>
<p>每组特征交互的时候，用一个矩阵， 那么这里如果有个特征的话，需要是个。参数个数个。</p>
<p>不知道看到这里，这种操作有没有种似曾相识的感觉， 有没有想起FM和FFM， 反正我是不自觉的想起了哈哈，不知道为啥。总感觉FM的风格和上面的Field-All很像， 而FFM和下面的Field-Interaction很像。</p>
<p>我们的原始embedding和SKNET-like embedding都需要过这个层，那么得到的就是一个双线性两两组合的矩阵， 维度是的矩阵。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222051074.png" alt="img"></p>
<h6 id="Combination-Layer"><a href="#Combination-Layer" class="headerlink" title="Combination Layer"></a>Combination Layer</h6><p>这个层的作用就是把目前得到的特征拼起来</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222051287.png" alt="img"></p>
<p>这里他直拼了上面得到的两个离散特征通过各种交互之后的形式，如果是还有连续特征的话，也可以在这里拼起来，然后过DNN，不过这里其实还省略了一步操作就是Flatten，先展平再拼接。</p>
<h6 id="DNN和输出层"><a href="#DNN和输出层" class="headerlink" title="DNN和输出层"></a>DNN和输出层</h6><p> DNN的话普通的全连接网络， 再捕捉一波高阶的隐性交互。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222052753.png" alt="img"></p>
<p>而输出层</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222052222.png" alt="img"></p>
<p>分类问题损失函数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222053977.png" alt="img"></p>
<h3 id="Wide-amp-Deep系列"><a href="#Wide-amp-Deep系列" class="headerlink" title="Wide&amp;Deep系列"></a>Wide&amp;Deep系列</h3><h4 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide&amp;Deep"></a>Wide&amp;Deep</h4><h5 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h5><p>在CTR预估任务中利用手工构造的交叉组合特征来使线性模型具有“记忆性”，使模型记住共现频率较高的特征组合，往往也能达到一个不错的baseline，且可解释性强。但这种方式有着较为明显的缺点：</p>
<ol>
<li>特征工程需要耗费太多精力。</li>
<li>模型是强行记住这些组合特征的，对于未曾出现过的特征组合，权重系数为0，无法进行泛化。</li>
</ol>
<p>为了加强模型的泛化能力，研究者引入了DNN结构，将高维稀疏特征编码为低维稠密的Embedding vector，这种基于Embedding的方式能够有效提高模型的泛化能力。但是，基于Embedding的方式可能因为数据长尾分布，导致长尾的一些特征值无法被充分学习，其对应的Embedding vector是不准确的，这便会造成模型泛化过度。</p>
<p>Wide&amp;Deep模型就是围绕记忆性和泛化性进行讨论的，模型能够从历史数据中学习到高频共现的特征组合的能力，称为是模型的Memorization。能够利用特征之间的传递性去探索历史数据中从未出现过的特征组合，称为是模型的Generalization。Wide&amp;Deep兼顾Memorization与Generalization并在Google Play store的场景中成功落地。</p>
<h5 id="模型结构及原理-2"><a href="#模型结构及原理-2" class="headerlink" title="模型结构及原理"></a>模型结构及原理</h5><p>其实wide&amp;deep模型本身的结构是非常简单的，对于有点机器学习基础和深度学习基础的人来说都非常的容易看懂，但是如何根据自己的场景去选择那些特征放在Wide部分，哪些特征放在Deep部分就需要理解这篇论文提出者当时对于设计该模型不同结构时的意图了，所以这也是用好这个模型的一个前提。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222057071.png" alt="img"></p>
<p><strong>如何理解Wide部分有利于增强模型的“记忆能力”，Deep部分有利于增强模型的“泛化能力”？</strong></p>
<ul>
<li><p>wide部分是一个广义的线性模型，输入的特征主要有两部分组成，一部分是原始的部分特征，另一部分是原始特征的交叉特征(cross-product transformation)，对于交互特征可以定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222059178.png" alt="img"></p>
<p>是一个布尔变量，当第i个特征属于第k个特征组合时，的值为1，否则为0，是第i个特征的值，大体意思就是两个特征都同时为1这个新的特征才能为1，否则就是0，说白了就是一个特征组合。</p>
<p>对于wide部分训练时候使用的优化器是带正则的FTRL算法(Follow-the-regularized-leader)，而L1 FTLR是非常注重模型稀疏性质的，也就是说W&amp;D模型采用L1 FTRL是想让Wide部分变得更加的稀疏，即Wide部分的大部分参数都为0，这就大大压缩了模型权重及特征向量的维度。<strong>Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现”直接的”，“暴力的”，“显然的”关联规则的能力。</strong>例如Google W&amp;D期望wide部分发现这样的规则：<strong>用户安装了应用A，此时曝光应用B，用户安装应用B的概率大。</strong></p>
</li>
<li><p>Deep部分是一个DNN模型，输入的特征主要分为两大类，一类是数值特征(可直接输入DNN)，一类是类别特征(需要经过Embedding之后才能输入到DNN中)，Deep部分的数学形式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222100079.png" alt="img"></p>
<p><strong>我们知道DNN模型随着层数的增加，中间的特征就越抽象，也就提高了模型的泛化能力。</strong>对于Deep部分的DNN模型作者使用了深度学习常用的优化器AdaGrad，这也是为了使得模型可以得到更精确的解。</p>
</li>
</ul>
<p><strong>Wide部分与Deep部分的结合</strong></p>
<p>W&amp;D模型是将两部分输出的结果结合起来联合训练，将deep和wide部分的输出重新使用一个逻辑回归模型做最终的预测，输出概率值。联合训练的数学形式如下：需要注意的是，因为Wide侧的数据是高维稀疏的，所以作者使用了FTRL算法优化，而Deep侧使用的是 Adagrad。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222100694.png" alt="img"></p>
<h4 id="NFM"><a href="#NFM" class="headerlink" title="NFM"></a>NFM</h4><h5 id="动机-1"><a href="#动机-1" class="headerlink" title="动机"></a>动机</h5><p>NFM(Neural Factorization Machines)是2017年由新加坡国立大学的何向南教授等人在SIGIR会议上提出的一个模型，传统的FM模型仅局限于线性表达和二阶交互， 无法胜任生活中各种具有复杂结构和规律性的真实数据， 针对FM的这点不足， 作者提出了一种将FM融合进DNN的策略，通过引进了一个特征交叉池化层的结构，使得FM与DNN进行了完美衔接，这样就组合了FM的建模低阶特征交互能力和DNN学习高阶特征交互和非线性的能力，形成了深度学习时代的神经FM模型(NFM)。</p>
<p>那么NFM具体是怎么做的呢？ 首先看一下NFM的公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222103700.png" alt="img"></p>
<p>我们对比FM， 就会发现变化的是第三项，前两项还是原来的， 因为我们说FM的一个问题，就是只能到二阶交叉， 且是线性模型， 这是他本身的一个局限性， 而如果想突破这个局限性， 就需要从他的公式本身下点功夫， 于是乎，作者在这里改进的思路就是<strong>用一个表达能力更强的函数来替代原FM中二阶隐向量内积的部分</strong>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222104051.png" alt="img"></p>
<h5 id="模型结构与原理"><a href="#模型结构与原理" class="headerlink" title="模型结构与原理"></a>模型结构与原理</h5><h6 id="Input-和Embedding层"><a href="#Input-和Embedding层" class="headerlink" title="Input 和Embedding层"></a>Input 和Embedding层</h6><p>输入层的特征， 文章指定了稀疏离散特征居多， 这种特征我们也知道一般是先one-hot, 然后会通过embedding，处理成稠密低维的。 所以这两层还是和之前一样，假设为第个特征的embedding向量， 那么表示的下一层的输入特征。这里带上了是因为很多转成了One-hot之后，出现很多为0的， 这里的是不等于0的那些特征向量。  </p>
<h6 id="Bi-Interaction-Pooling-layer"><a href="#Bi-Interaction-Pooling-layer" class="headerlink" title="Bi-Interaction Pooling layer"></a>Bi-Interaction Pooling layer</h6><p>在Embedding层和神经网络之间加入了特征交叉池化层是本网络的核心创新了，正是因为这个结构，实现了FM与DNN的无缝连接， 组成了一个大的网络，且能够正常的反向传播。假设是所有特征embedding的集合， 那么在特征交叉池化层的操作：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222106689.png" alt="img"></p>
<p>表示两个向量的元素积操作，即两个向量对应维度相乘得到的元素积向量（可不是点乘呀），其中第维的操作：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222106134.png" alt="img"></p>
<p>这便定义了在embedding空间特征的二阶交互，这个不仔细看会和感觉FM的最后一项很像，但是不一样，一定要注意这个地方不是两个隐向量的内积，而是元素积，也就是这一个交叉完了之后k个维度不求和，最后会得到一个维向量，而FM那里内积的话最后得到一个数， 在进行两两Embedding元素积之后，对交叉特征向量取和， 得到该层的输出向量， 很显然， 输出是一个维的向量。</p>
<p>注意， 之前的FM到这里其实就完事了， 上面就是输出了，而这里很大的一点改进就是加入特征池化层之后， 把二阶交互的信息合并， 且上面接了一个DNN网络， 这样就能够增强FM的表达能力了， 因为FM只能到二阶， 而这里的DNN可以进行多阶且非线性，只要FM把二阶的学习好了， DNN这块学习来会更加容易， 作者在论文中也说明了这一点，且通过后面的实验证实了这个观点。</p>
<p>如果不加DNN， NFM就退化成了FM，所以改进的关键就在于加了一个这样的层，组合了一下二阶交叉的信息，然后又给了DNN进行高阶交叉的学习，成了一种“加强版”的FM。</p>
<p>Bi-Interaction层不需要额外的模型学习参数，更重要的是它在一个线性的时间内完成计算，和FM一致的，即时间复杂度为，为embedding向量的数量。参考FM，可以将上式转化为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222107108.png" alt="img"></p>
<h6 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h6><p>这一层就是全连接的神经网络， DNN在进行特征的高层非线性交互上有着天然的学习优势，公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222109689.png" alt="img"></p>
<p>这里的是第层的激活函数，可不要理解成sigmoid激活函数。</p>
<h6 id="预测层"><a href="#预测层" class="headerlink" title="预测层"></a>预测层</h6><p>这个就是最后一层的结果直接过一个隐藏层，但注意由于这里是回归问题，没有加sigmoid激活：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222110388.png" alt="img"></p>
<p>所以， NFM模型的前向传播过程总结如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222111207.png" alt="img"></p>
<p>这就是NFM模型的全貌， NFM相比较于其他模型的核心创新点是特征交叉池化层，基于它，实现了FM和DNN的无缝连接，使得DNN可以在底层就学习到包含更多信息的组合特征，这时候，就会减少DNN的很多负担，只需要很少的隐藏层就可以学习到高阶特征信息。NFM相比之前的DNN， 模型结构更浅，更简单，但是性能更好，训练和调参更容易。集合FM二阶交叉线性和DNN高阶交叉非线性的优势，非常适合处理稀疏数据的场景任务。在对NFM的真实训练过程中，也会用到像Dropout和BatchNormalization这样的技术来缓解过拟合和在过大的改变数据分布。</p>
<h4 id="AFM"><a href="#AFM" class="headerlink" title="AFM"></a>AFM</h4><h5 id="AFM提出的动机"><a href="#AFM提出的动机" class="headerlink" title="AFM提出的动机"></a>AFM提出的动机</h5><p>AFM的全称是Attentional Factorization Machines, 从模型的名称上来看是在FM的基础上加上了注意力机制，FM是通过特征隐向量的内积来对交叉特征进行建模，从公式中可以看出所有的交叉特征都具有相同的权重也就是1，没有考虑到不同的交叉特征的重要性程度：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222115177.png" alt="img"></p>
<p>如何让不同的交叉特征具有不同的重要性就是AFM核心的贡献，在谈论AFM交叉特征注意力之前，对于FM交叉特征部分的改进还有FFM，其是考虑到了对于不同的其他特征，某个指定特征的隐向量应该是不同的（相比于FM对于所有的特征只有一个隐向量，FFM对于一个特征有多个不同的隐向量）。</p>
<h5 id="AFM模型原理"><a href="#AFM模型原理" class="headerlink" title="AFM模型原理"></a>AFM模型原理</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222115513.png" alt="img"></p>
<p>上图表示的就是AFM交叉特征部分的模型结构(非交叉部分与FM是一样的，图中并没有给出)。AFM最核心的两个点分别是Pair-wise Interaction Layer和Attention-based Pooling。前者将输入的非零特征的隐向量两两计算element-wise product(哈达玛积，两个向量对应元素相乘，得到的还是一个向量)，假如输入的特征中的非零向量的数量为m，那么经过Pair-wise Interaction Layer之后输出的就是个向量，再将前面得到的交叉特征向量组输入到Attention-based Pooling，该pooling层会先计算出每个特征组合的自适应权重(通过Attention Net进行计算)，通过加权求和的方式将向量组压缩成一个向量，由于最终需要输出的是一个数值，所以还需要将前一步得到的向量通过另外一个向量将其映射成一个值，得到最终的基于注意力加权的二阶交叉特征的输出。(对于这部分如果不是很清楚，可以先看下面对两个核心层的介绍)</p>
<h6 id="Pair-wise-Interaction-Layer"><a href="#Pair-wise-Interaction-Layer" class="headerlink" title="Pair-wise Interaction Layer"></a>Pair-wise Interaction Layer</h6><p>FM二阶交叉项：所有非零特征对应的隐向量两两点积再求和，输出的是一个数值</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222116327.png" alt="img"></p>
<p>AFM二阶交叉项(无attention)：所有非零特征对应的隐向量两两对应元素乘积，然后再向量求和，输出的还是一个向量。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222116575.png" alt="img"></p>
<p>上述写法是为了更好的与FM进行对比，下面将公式变形方便与原论文中保持一致。首先是特征的隐向量。从上图中可以看出，作者对数值特征也对应了一个隐向量，不同的数值乘以对应的隐向量就可以得到不同的隐向量，相对于onehot编码的特征乘以1还是其本身(并没有什么变化)，其实就是为了将公式进行统一。</p>
<p>按照论文的意思，特征的embedding可以表示为：，经过Pair-wise Interaction Layer输出可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222116226.png" alt="img"></p>
<p>表示的是有效特征集合。此时的表示的是一个向量集合，所以需要先将这些向量集合聚合成一个向量，然后在转换成一个数值：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222117210.png" alt="img"></p>
<p>上式中的求和部分就是将向量集合聚合成一个维度与隐向量维度相同的向量，通过向量再将其转换成一个数值，b表示的是偏置。</p>
<p>从开始介绍Pair-wise Interaction Layer到现在解决的一个问题是，如何将使用哈达玛积得到的交叉特征转换成一个最终输出需要的数值，到目前为止交叉特征之间的注意力权重还没有出现。在没有详细介绍注意力之前先感性的认识一下如果现在已经有了每个交叉特征的注意力权重，那么交叉特征的输出可以表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222117026.png" alt="img"></p>
<p>就是在交叉特征得到的新向量前面乘以一个注意力权重, 那么这个注意力权重如何计算得到呢？</p>
<h6 id="Attention-based-Pooling"><a href="#Attention-based-Pooling" class="headerlink" title="Attention-based Pooling"></a>Attention-based Pooling</h6><p>对于神经网络注意力相关的基础知识大家可以去看一下邱锡鹏老师的《神经网络与深度学习》第8章注意力机制与外部记忆。这里简单的叙述一下使用MLP实现注意力机制的计算。假设现在有n个交叉特征(假如维度是k)，将nxk的数据输入到一个kx1的全连接网络中，输出的张量维度为nx1，使用softmax函数将nx1的向量的每个维度进行归一化，得到一个新的nx1的向量，这个向量所有维度加起来的和为1，每个维度上的值就可以表示原nxk数据每一行(即1xk的数据)的权重。用公式表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222117989.png" alt="img"></p>
<p>使用softmax归一化可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222118339.png" alt="img"></p>
<p>这样就得到了AFM二阶交叉部分的注意力权重，如果将AFM的一阶项写在一起，AFM模型用公式表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222118174.png" alt="img"></p>
<h6 id="AFM模型训练"><a href="#AFM模型训练" class="headerlink" title="AFM模型训练"></a>AFM模型训练</h6><p>AFM从最终的模型公式可以看出与FM的模型公式是非常相似的，所以也可以和FM一样应用于不同的任务，例如分类、回归及排序（不同的任务的损失函数是不一样的），AFM也有对防止过拟合进行处理：</p>
<ol>
<li>在Pair-wise Interaction Layer层的输出结果上使用dropout防止过拟合，因为并不是所有的特征组合对预测结果都有用，所以随机的去除一些交叉特征，让剩下的特征去自适应的学习可以更好的防止过拟合。</li>
<li>对Attention-based Pooling层中的权重矩阵使用L2正则，作者没有在这一层使用dropout的原因是发现同时在特征交叉层和注意力层加dropout会使得模型训练不稳定，并且性能还会下降。</li>
</ol>
<p>加上正则参数之后的回归任务的损失函数表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222119465.png" alt="img"></p>
<h4 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h4><h5 id="动机-2"><a href="#动机-2" class="headerlink" title="动机"></a>动机</h5><p>对于CTR问题，被证明的最有效的提升任务表现的策略是特征组合(Feature Interaction), 在CTR问题的探究历史上来看就是如何更好地学习特征组合，进而更加精确地描述数据的特点。可以说这是基础推荐模型到深度学习推荐模型遵循的一个主要的思想。而组合特征大牛们研究过组合二阶特征，三阶甚至更高阶，但是面临一个问题就是随着阶数的提升，复杂度就成几何倍的升高。这样即使模型的表现更好了，但是推荐系统在实时性的要求也不能满足了。所以很多模型的出现都是为了解决另外一个更加深入的问题：如何更高效的学习特征组合？</p>
<p>为了解决上述问题，出现了FM和FFM来优化LR的特征组合较差这一个问题。并且在这个时候科学家们已经发现了DNN在特征组合方面的优势，所以又出现了FNN和PNN等使用深度网络的模型。但是DNN也存在局限性。</p>
<ul>
<li><strong>DNN局限</strong> 当我们使用DNN网络解决推荐问题的时候存在网络参数过于庞大的问题，这是因为在进行特征处理的时候我们需要使用one-hot编码来处理离散特征，这会导致输入的维度猛增。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222138309.png" alt="img"></p>
<p>这样庞大的参数量也是不实际的。为了解决DNN参数量过大的局限性，可以采用非常经典的Field思想，将OneHot特征转换为Dense Vector</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222138450.png" alt="img"></p>
<p>此时通过增加全连接层就可以实现高阶的特征组合，如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222139876.png" alt="img"></p>
<p>但是仍然缺少低阶的特征组合，于是增加FM来表示低阶的特征组合。</p>
<ul>
<li><strong>FNN和PNN</strong> 结合FM和DNN其实有两种方式，可以并行结合也可以串行结合。这两种方式各有几种代表模型。在DeepFM之前有FNN，虽然在影响力上可能并不如DeepFM，但是了解FNN的思想对我们理解DeepFM的特点和优点是很有帮助的。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222139053.png" alt="img"></p>
<p>FNN是使用预训练好的FM模块，得到隐向量，然后把隐向量作为DNN的输入，但是经过实验进一步发现，在Embedding layer和hidden layer1之间增加一个product层（如上图所示）可以提高模型的表现，所以提出了PNN，使用product layer替换FM预训练层。</p>
<ul>
<li><strong>Wide&amp;Deep</strong> FNN和PNN模型仍然有一个比较明显的尚未解决的缺点：对于低阶组合特征学习到的比较少，这一点主要是由于FM和DNN的串行方式导致的，也就是虽然FM学到了低阶特征组合，但是DNN的全连接结构导致低阶特征并不能在DNN的输出端较好的表现。看来我们已经找到问题了，将串行方式改进为并行方式能比较好的解决这个问题。于是Google提出了Wide&amp;Deep模型（将前几章），但是如果深入探究Wide&amp;Deep的构成方式，虽然将整个模型的结构调整为了并行结构，在实际的使用中Wide Module中的部分需要较为精巧的特征工程，换句话说人工处理对于模型的效果具有比较大的影响（这一点可以在Wide&amp;Deep模型部分得到验证）。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222140078.png" alt="img"></p>
<p>如上图所示，该模型仍然存在问题：<strong>在output Units阶段直接将低阶和高阶特征进行组合，很容易让模型最终偏向学习到低阶或者高阶的特征，而不能做到很好的结合。</strong></p>
<p>综上所示，DeepFM模型横空出世。</p>
<h5 id="模型的结构与原理"><a href="#模型的结构与原理" class="headerlink" title="模型的结构与原理"></a>模型的结构与原理</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222140551.png" alt="img"></p>
<p>前面的Field和Embedding处理是和前面的方法是相同的，如上图中的绿色部分；DeepFM将Wide部分替换为了FM layer如上图中的蓝色部分</p>
<p>这幅图其实有很多的点需要注意，很多人都一眼略过了，这里我个人认为在DeepFM模型中有三点需要注意：</p>
<ul>
<li><strong>Deep模型部分</strong></li>
<li><strong>FM模型部分</strong></li>
<li><strong>Sparse Feature中黄色和灰色节点代表什么意思</strong></li>
</ul>
<h6 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h6><p>详细内容参考FM模型部分的内容，下图是FM的一个结构图，从图中大致可以看出FM Layer是由一阶特征和二阶特征Concatenate到一起在经过一个Sigmoid得到logits（结合FM的公式一起看），所以在实现的时候需要单独考虑linear部分和FM交叉特征部分。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222141214.png" alt="img"></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222141391.png" alt="img"></p>
<h6 id="Deep"><a href="#Deep" class="headerlink" title="Deep"></a>Deep</h6><p>Deep架构图</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222142236.png" alt="img"></p>
<p>Deep Module是为了学习高阶的特征组合，在上图中使用用全连接的方式将Dense Embedding输入到Hidden Layer，这里面Dense Embeddings就是为了解决DNN中的参数爆炸问题，这也是推荐模型中常用的处理方法。</p>
<p>Embedding层的输出是将所有id类特征对应的embedding向量concat到到一起输入到DNN中。其中表示第i个field的embedding，m是field的数量。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222143624.png" alt="img"></p>
<p>上一层的输出作为下一层的输入，我们得到：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222143038.png" alt="img"></p>
<p>其中表示激活函数，分别表示该层的输入、权重和偏置。</p>
<p>最后进入DNN部分输出使用sigmod激活函数进行激活：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222143674.png" alt="img"></p>
<h4 id="xDeepFM"><a href="#xDeepFM" class="headerlink" title="xDeepFM"></a>xDeepFM</h4><h5 id="xDeepFM的架构剖析"><a href="#xDeepFM的架构剖析" class="headerlink" title="xDeepFM的架构剖析"></a>xDeepFM的架构剖析</h5><p>首先，我们先看下xDeepFM的架构</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222202895.png" alt="img"></p>
<p>这个网络结构名副其实，依然是采用了W&amp;D架构，DNN负责Deep端，学习特征之间的隐性高阶交互， 而CIN网络负责wide端，学习特征之间的显性高阶交互，这样显隐性高阶交互就在这个模型里面体现的淋漓尽致了。</p>
<p>最终的计算公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222204455.png" alt="img"></p>
<p>这里的表示原始的特征，表示的是DNN的输出， 表示的是CIN的输出。最终的损失依然是交叉熵损失，这里也是做一个点击率预测的问题：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222205209.png" alt="img"></p>
<p>最终的目标函数加了正则化:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222206641.png" alt="img"></p>
<h5 id="CIN网络的细节"><a href="#CIN网络的细节" class="headerlink" title="CIN网络的细节"></a>CIN网络的细节</h5><p>这里尝试剖析下本篇论文的主角CIN网络，全称Compressed Interaction Network。这个东西说白了其实也是一个网络，并不是什么高大上的东西，和Cross Network一样，也是一层一层，每一层都是基于一个固定的公式进行的计算，那个公式长这样:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222209233.png" alt="img"></p>
<p> 这个公式第一眼看过来，肯定更是懵逼，这是写的个啥玩意？如果我再把CIN的三个核心图放上来:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222209772.png" alt="img"></p>
<p> 上面其实就是CIN网络的精髓了，也是它具体的运算过程，只不过直接上图的话，会有些抽象，难以理解，也不符合我整理论文的习惯。下面，我们就一一进行剖析， 先从上面这个公式开始。但在这之前，需要先约定一些符号。要不然不知道代表啥意思。</p>
<ol>
<li>: 这个就是我们的输入，也就是embedding层的输出，可以理解为各个embedding的堆叠而成的矩阵，假设有个特征，embedding的维度是维，那么这样就得到了这样的矩阵， 行列。， 这个表示的是第个特征的embedding向量。所以上标在这里表示的是网络的层数，输入可以看做第0层，而下标表示的第几行的embedding向量，这个清楚了。</li>
<li>: 这个表示的是CIN网络第层的输出，和上面这个一样，也是一个矩阵，每一行是一个embedding向量，每一列代表一个embedding维度。这里的表示的是第层特征的数量，也可以理解为神经元个数。那么显然，这个就是个为向量堆叠而成的矩阵，维度也显然了。代表的就是第层第个特征向量了。</li>
</ol>
<p>所以上面的那个公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222210887.png" alt="img"></p>
<p>其实就是计算第层第个特征向量， 这里的是第个特征向量的参数矩阵。 表示的哈达玛积，也就是向量之间对应维度元素相乘(不相加了)。。通过这个公式也能看到是通过和计算得来的，也就是说特征的显性交互阶数会虽然网络层数的加深而增加。</p>
<p>那么这个公式到底表示的啥意思呢？ 是具体怎么计算的呢？我们往前计算一层就知道了，这里令，也就是尝试计算第一层里面的第个向量， 那么上面公式就变成了:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222210151.png" alt="img"></p>
<p>这里的。这个能看懂吗？ 首先这个矩阵是行列， 而前面那两个累加正好也是行列的参数。代表的是输入特征的个数， 代表的是第0层(层)的神经元的个数， 这个也是。这个应该好理解，输入层就是第0层。所以这其实就是一个的矩阵。那么后面这个运算到底是怎么算的呢？   首先对于第个特征向量， 要依次和其他的个特征向量做哈达玛积操作，当然也乘以对应位置的权重，求和。对于每个特征向量，都重复这样的操作，最终求和得到一个维的向量，这个就是。好吧，这么说。我觉得应该也没有啥感觉，画一下就了然了，现在可以先不用管论文里面是怎么说的，先跟着这个思路走，只要理解了这个公式是怎么计算的，论文里面的那三个图就会非常清晰了。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222211775.png" alt="img"></p>
<p>这就是上面那个公式的具体过程了，图实在是太难看了， 但应该能说明这个详细的过程了。这样只要给定一个之后，就能算出一个相应的来，这样第一层的个神经元按照这样的步骤就能够都计算出来了。 后面的计算过程其实是同理，无非就是输入是前一层的输出以及罢了，而这时候，第一个矩阵特征数就不一定是了，而是一个行列的矩阵了。这里的就是上面写的行列了。</p>
<p>这个过程明白了之后，再看论文后面的内容就相对容易了，首先</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222211538.png" alt="img"></p>
<p>CIN里面能看到RNN的身影，也就是当前层的隐藏单元的计算要依赖于上一层以及当前的输入层，只不过这里的当前输入每个时间步都是。 同时这里也能看到，CIN的计算是vector-wise级别的，也就是向量之间的哈达玛积的操作，并没有涉及到具体向量里面的位交叉。</p>
<p>下面我们再从CNN的角度去看这个计算过程。其实还是和上面一样的计算过程，只不过是换了个角度看而已，所以上面那个只要能理解，下面CNN也容易理解了。首先，这里引入了一个tensor张量表示的是和的外积，那么这个东西是啥呢？ 上面加权求和前的那个矩阵，是一个三维的张量。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222211833.png" alt="img"></p>
<p>这个可以看成是一个三维的图片，高，宽，个通道。而的大小是的， 这个就相当于一个过滤器，用这个过滤器对输入的图片如果<strong>逐通道进行卷积</strong>，就会最终得到一个维的向量，而这个其实就是，也就是一张特征图(每个通道过滤器是共享的)。 第层其实有个这样的过滤器，所以最后得到的是一个的矩阵。这样，在第个隐藏层，就把了的三维张量通过逐通道卷积的方式，压缩成了一个的矩阵(张特征图)， 这就是第层的输出。 而这也就是“compressed”的由来。这时候再看这两个图就非常舒服了：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222212318.png" alt="img"></p>
<p>通过这样的一个CIN网络，就很容易的实现了特征的显性高阶交互，并且是vector-wise级别的，那么最终的输出层是啥呢？   通过上面的分析，首先我们了解了对于第层输出的某个特征向量，其实是综合了输入里面各个embedding向量显性高阶交互的信息(第层其实学习的输入embedding阶交互信息)，这个看第一层那个输出就能看出来。第层的每个特征向量其实都能学习到这样的信息，那么如果把这些向量在从维度上进行加和，也就是，这是个的，我们沿着D这个维度加和，又会得到一个的向量，公式如下:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222212723.png" alt="img"></p>
<p> 每一层，都会得到一个这样的向量，那么把所有的向量拼接到一块，其实就是CIN网络的输出了。之所以，这里要把中间结果都与输出层相连，就是因为CIN与Cross不同的一点是，在第层，CIN只包含阶的组合特征，而Cross是能包含从1阶-阶的组合特征的，所以为了让模型学习到从1阶到所有阶的组合特征，CIN这里需要把中间层的结果与输出层建立连接。</p>
<p>这也就是第三个图表示的含义:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222213526.png" alt="img"></p>
<p>这样， 就得到了最终CIN的输出了: </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222213378.png" alt="img"></p>
<p>后面那个维度的意思，就是说每一层是的向量维度是维， 最后是所有时间步的维度之和。 </p>
<h3 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h3><p>pass</p>
<h3 id="多任务模型"><a href="#多任务模型" class="headerlink" title="多任务模型"></a>多任务模型</h3><p>pass</p>
]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习Tricks</title>
    <url>/2022/10/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Tricks/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>总结一些自己在机器学习应用过程中遇到的一些问题，包括理论、代码实践等方面。</p>
<a id="more"></a>
<h1 id="One-Hot编码"><a href="#One-Hot编码" class="headerlink" title="One-Hot编码"></a>One-Hot编码</h1><p><code>One-Hot</code>编码也叫独热编码，又称一位有效编码。方法就是用 $N$ 位对 $N$ 个状态进行表示，但是其中只有一位为 $1$，剩下 $N-1$ 位全为 $0$。例如，特征为性别，就需要变成 $10$ 和 $01$。</p>
<p>在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的。而常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。使用独热编码（One-Hot Encoding），将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。将离散型特征使用独热编码（One-Hot Encoding），会让特征之间的距离计算更加合理。</p>
<p>举个例子，如果我们现在一个特征有五个取值，如果不采用One-Hot编码，则分别表示为演员=0，厨师=1，公务员=2，教师=3，律师=4，那么教师和厨师的距离为2，律师与厨师的距离为3，这显然是不合理的。比较合理的做法是将两个工作之间的距离表示为sqrt(2)，即两个工作之间的距离是一样的。</p>
<p>总结一下，如果特征的大小表示如果有意义的话，比如我们用1-9表示年龄，这种特征的大小表示就是有意义的，所以这种情况下就不需要进行One-Hot编码；如果特征的大小没有意义，仅仅表示状态时则使用One-Hot编码。</p>
<p>pandas实现：首先对f3这个特征做One-Hot编码，接着将生成的df和原来的df进行拼接，最后删除原来的f3特征</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 1: using get_dummies to encode feature</span></span><br><span class="line">dummy_df = pd.get_dummies(df[<span class="string">&quot;gender&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 2: concat dummy_df with original df</span></span><br><span class="line">df = pd.concat((df, dummy_df), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 3: remove original feature</span></span><br><span class="line">df = df.drop(<span class="string">&quot;gender&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># simplified form</span></span><br><span class="line"><span class="comment"># df = pd.concat((df, pd.get_dummies(df[&quot;gender&quot;])), axis=1)</span></span><br><span class="line"><span class="comment"># df = df.drop(&quot;gender&quot;, axis=1)</span></span><br></pre></td></tr></table></figure>
<p>存在问题：</p>
<ol>
<li><p>采用这种方法实现会存在问题，比如将性别划分成gender_male和gender_female时，这两种特征其实是冗余的，这个问题在数学中叫做多重共线性(Multicollinearity)，在pandas处理时也有人称之为虚拟变量陷阱(Dummy Varialble Trap)。解决办法就是加入参数drop_first=True，作用是除去第一个虚拟变量，然转化后的虚拟变量从k和变成k-1个。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 1: using get_dummies to encode feature</span></span><br><span class="line">dummy_df = pd.get_dummies(df[<span class="string">&quot;gender&quot;</span>], drop_first=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 2: concat dummy_df with original df</span></span><br><span class="line">df = pd.concat((df, dummy_df), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 3: remove original feature</span></span><br><span class="line">df = df.drop(<span class="string">&quot;gender&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># simplified form</span></span><br><span class="line"><span class="comment"># df = pd.concat((df, pd.get_dummies(df[&quot;gender&quot;], drop_first=True)), axis=1)</span></span><br><span class="line"><span class="comment"># df = df.drop(&quot;gender&quot;, axis=1)</span></span><br></pre></td></tr></table></figure></li>
<li><p>测试集中可能出现训练集中没出现过的变量。解决办法：①将训练集和测试集一起get_dummies，然后再切分；②检测不一致的列，然后在缺少这些列的数据集中加入取值全为0的同名列。③使用sklearn的OneHotEncoder</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>],</span><br><span class="line">        [<span class="number">1003</span>, <span class="string">&quot;unknown&quot;</span>, <span class="number">88</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train = pd.concat((train, pd.get_dummies(train[<span class="string">&quot;gender&quot;</span>], drop_first=<span class="literal">True</span>)), axis=<span class="number">1</span>)</span><br><span class="line">train.drop(<span class="string">&quot;gender&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line">test = pd.concat((test, pd.get_dummies(test[<span class="string">&quot;gender&quot;</span>], drop_first=<span class="literal">True</span>)), axis=<span class="number">1</span>)</span><br><span class="line">test.drop(<span class="string">&quot;gender&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">list</span>(test.columns.difference(train.columns)):<span class="comment">#train没有的列</span></span><br><span class="line">    df_obj = pd.DataFrame(&#123;col:np.squeeze(np.zeros((<span class="number">1</span>,train.shape[<span class="number">0</span>])))&#125;)</span><br><span class="line">    train = pd.concat([train,df_obj], axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">list</span>(train.columns.difference(test.columns)):<span class="comment">#test没有的列</span></span><br><span class="line">    df_obj = pd.DataFrame(&#123;col:np.squeeze(np.zeros((<span class="number">1</span>,test.shape[<span class="number">0</span>])))&#125;)</span><br><span class="line">    test = pd.concat([test,df_obj], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>sklearn实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line">train = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test = pd.DataFrame(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">1000</span>, <span class="string">&quot;male&quot;</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">1001</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">1002</span>, <span class="string">&quot;male&quot;</span>, <span class="number">69</span>],</span><br><span class="line">        [<span class="number">1003</span>, <span class="string">&quot;unknown&quot;</span>, <span class="number">88</span>]</span><br><span class="line">    ],</span><br><span class="line">    columns=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># drop:k-1 to represent k; handle_unknown:for missing value</span></span><br><span class="line">encoder = OneHotEncoder(sparse=<span class="literal">False</span>, handle_unknown=<span class="string">&#x27;ignore&#x27;</span>, drop=<span class="string">&quot;first&quot;</span>)</span><br><span class="line"><span class="comment"># fit</span></span><br><span class="line">enc = encoder.fit(train[[<span class="string">&quot;gender&quot;</span>]])</span><br><span class="line"><span class="comment"># 获取新列名</span></span><br><span class="line">columns = enc.get_feature_names_out([<span class="string">&quot;gender&quot;</span>])</span><br><span class="line"><span class="comment"># 转换测试数据</span></span><br><span class="line">enc_arr = enc.transform(test[[<span class="string">&quot;gender&quot;</span>]])</span><br><span class="line"><span class="comment"># 生成dataframe</span></span><br><span class="line">enc_df = pd.DataFrame(enc_arr, columns=columns)</span><br><span class="line">new_data = pd.concat([test, enc_df], axis=<span class="number">1</span>)</span><br><span class="line">new_data.drop([<span class="string">&quot;gender&quot;</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">new_data</span><br></pre></td></tr></table></figure>
<h1 id="编码转换"><a href="#编码转换" class="headerlink" title="编码转换"></a>编码转换</h1><p>对于某一个特征，比如频率，原始数据可能时low、mid、high这种字符类型，模型是没办法利用这些信息的，所以应当把这种字符类型的变量转变成数值类型的变量。</p>
<p>pandas实现：</p>
<p>最常用的是pd.factorize()，返回值为一个元组，分别表示转换之后的数字和原来的index。我们应该取元组的第一个元素作为我们的结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;../dataset/dataTrain.csv&#x27;</span>)</span><br><span class="line">data[<span class="string">&quot;f3&quot;</span>] = pd.factorize(data[<span class="string">&quot;f3&quot;</span>])[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>但是这种方法有个缺点，先出现的编码小，后出现的编码大。比如频率越高，编码的值应该越大，但是pd.factorize()就捕捉不到这个特征，此时我们可以使用map映射。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;../dataset/dataTrain.csv&#x27;</span>)</span><br><span class="line">col_mapping = &#123;</span><br><span class="line">    <span class="string">&quot;low&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">&quot;mid&quot;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;high&quot;</span>: <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line">data.f3 = data.f3.<span class="built_in">map</span>(col_mapping)</span><br></pre></td></tr></table></figure>
<p>sklearn实现：和One-Hot编码相似，先fit，然后再transform</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;../dataset/dataTrain.csv&#x27;</span>)</span><br><span class="line">cat_columns = [<span class="string">&#x27;f3&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cat_columns:</span><br><span class="line">    lb = LabelEncoder()</span><br><span class="line">    lb.fit(data[col])</span><br><span class="line">    data[col] = lb.transform(data[col])</span><br></pre></td></tr></table></figure>
<h1 id="PyTorch代码实践"><a href="#PyTorch代码实践" class="headerlink" title="PyTorch代码实践"></a>PyTorch代码实践</h1><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><p><strong>Tensor的常见形式有哪些</strong></p>
<ul>
<li>0：scalar</li>
<li>1：vector</li>
<li>2：matrix</li>
<li>3：n-dimensional tensor</li>
</ul>
<h2 id="基础操作"><a href="#基础操作" class="headerlink" title="基础操作"></a>基础操作</h2><h3 id="torch-empty"><a href="#torch-empty" class="headerlink" title="torch.empty()"></a>torch.empty()</h3><p>新建矩阵</p>
<h3 id="torch-rand"><a href="#torch-rand" class="headerlink" title="torch.rand()"></a>torch.rand()</h3><p>生成随机矩阵</p>
<h3 id="torch-zeros"><a href="#torch-zeros" class="headerlink" title="torch.zeros()"></a>torch.zeros()</h3><p>生成全0的矩阵</p>
<h3 id="xxx-size"><a href="#xxx-size" class="headerlink" title="xxx.size()"></a>xxx.size()</h3><p>展示矩阵大小</p>
<h3 id="xxx-view"><a href="#xxx-view" class="headerlink" title="xxx.view()"></a>xxx.view()</h3><p>改变矩阵维度</p>
<h3 id="xxx-numpy"><a href="#xxx-numpy" class="headerlink" title="xxx.numpy()"></a>xxx.numpy()</h3><p>将tensor转换为array</p>
<h3 id="torch-from-numpy"><a href="#torch-from-numpy" class="headerlink" title="torch.from_numpy()"></a>torch.from_numpy()</h3><p>将array转换为tensor</p>
<h3 id="xxx-requires-grad-True"><a href="#xxx-requires-grad-True" class="headerlink" title="xxx.requires_grad=True"></a>xxx.requires_grad=True</h3><p>定义自动求导</p>
<h2 id="高阶操作"><a href="#高阶操作" class="headerlink" title="高阶操作"></a>高阶操作</h2><h3 id="nn-Conv2d"><a href="#nn-Conv2d" class="headerlink" title="nn.Conv2d()"></a>nn.Conv2d()</h3><ol>
<li><code>in_channels</code>：输入的四维张量<code>[N, C, H, W]</code>中的<code>C</code>，即输入张量的<code>channels</code>数。这个形参是确定权重等可学习参数的<code>shape</code>所必需的。</li>
<li><code>out_channels</code>：期望的四维输出张量的<code>channels</code>数。</li>
<li><code>kernel_size</code>：卷积核的大小，一般我们会使用<code>5x5</code>、<code>3x3</code>这种左右两个数相同的卷积核，因此这种情况只需要写 <code>kernel_size=5</code> 这样的就行了。如果左右两个数不同，比如<code>3x5</code>的卷积核，那么写作 <code>kernel_size=(3,5)</code>，注意需要写一个<code>tuple</code>，而不能写一个<code>list</code>。</li>
<li><code>stride=1</code>：卷积核在图像窗口上每次平移的间隔，即所谓的步长。</li>
<li><code>padding=0</code>：<code>padding</code>即所谓的图像填充，后面的int型常数代表填充的多少（行数、列数），默认为<code>0</code>。需要注意的是这里的填充包括图像的上下左右，以<code>padding=1</code>为例，若原始图像大小为<code>32x32</code>，那么<code>padding</code>后的图像大小就变成了<code>34x34</code>，而不是<code>33x33</code>。</li>
<li><code>dilation=1</code>：这个参数决定了是否采用空洞卷积，默认为<code>1</code>，即不采用。</li>
<li><code>groups=1</code>：决定了是否采用分组卷积。</li>
<li><code>bias=True</code>：即是否要添加偏置参数作为可学习参数的一个，默认为<code>True</code>。</li>
<li><code>padding_mode=&#39;zeros&#39;</code>：<code>padding</code>的模式，默认采用零填充。</li>
</ol>
<h3 id="xxx-tranpose"><a href="#xxx-tranpose" class="headerlink" title="xxx.tranpose()"></a>xxx.tranpose()</h3><p>将维度1和维度2调换位置，该函数只能转换两个维度，若想要转换多个维度则需要使用permute</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">1</span>, <span class="number">22</span>, <span class="number">56</span>, <span class="number">114</span>)</span><br><span class="line">print(a.transpose(<span class="number">2</span>, <span class="number">3</span>).shape)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># torch.Size([1, 22, 114, 59])</span></span><br></pre></td></tr></table></figure>
<h3 id="xxx-permute"><a href="#xxx-permute" class="headerlink" title="xxx.permute()"></a>xxx.permute()</h3><p>转换向量维度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/1/7 13:27</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置一个三维数组</span></span><br><span class="line">x = torch.linspace(<span class="number">1</span>, <span class="number">24</span>, steps=<span class="number">24</span>).view(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不改变维度 2*3*4-&gt;2*3*4</span></span><br><span class="line">a = x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># tensor([[[ 1.,  2.,  3.,  4.],</span></span><br><span class="line"><span class="comment">#          [ 5.,  6.,  7.,  8.],</span></span><br><span class="line"><span class="comment">#          [ 9., 10., 11., 12.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[13., 14., 15., 16.],</span></span><br><span class="line"><span class="comment">#          [17., 18., 19., 20.],</span></span><br><span class="line"><span class="comment">#          [21., 22., 23., 24.]]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每一块的行与列进行交换，即每一块做转置 2*3*4-&gt;2*4*3</span></span><br><span class="line">b = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">print(b)</span><br><span class="line"><span class="comment"># tensor([[[ 1.,  5.,  9.],</span></span><br><span class="line"><span class="comment">#          [ 2.,  6., 10.],</span></span><br><span class="line"><span class="comment">#          [ 3.,  7., 11.],</span></span><br><span class="line"><span class="comment">#          [ 4.,  8., 12.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[13., 17., 21.],</span></span><br><span class="line"><span class="comment">#          [14., 18., 22.],</span></span><br><span class="line"><span class="comment">#          [15., 19., 23.],</span></span><br><span class="line"><span class="comment">#          [16., 20., 24.]]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 交换块和行 2*3*4-&gt;3*2*4</span></span><br><span class="line">c = x.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">print(c)</span><br><span class="line"><span class="comment"># tensor([[[ 1.,  2.,  3.,  4.],</span></span><br><span class="line"><span class="comment">#          [13., 14., 15., 16.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 5.,  6.,  7.,  8.],</span></span><br><span class="line"><span class="comment">#          [17., 18., 19., 20.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 9., 10., 11., 12.],</span></span><br><span class="line"><span class="comment">#          [21., 22., 23., 24.]]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 交换块和列 2*3*4-&gt;4*3*2</span></span><br><span class="line">d = x.permute(<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">print(d)</span><br><span class="line"><span class="comment"># tensor([[[ 1., 13.],</span></span><br><span class="line"><span class="comment">#          [ 5., 17.],</span></span><br><span class="line"><span class="comment">#          [ 9., 21.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 2., 14.],</span></span><br><span class="line"><span class="comment">#          [ 6., 18.],</span></span><br><span class="line"><span class="comment">#          [10., 22.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 3., 15.],</span></span><br><span class="line"><span class="comment">#          [ 7., 19.],</span></span><br><span class="line"><span class="comment">#          [11., 23.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 4., 16.],</span></span><br><span class="line"><span class="comment">#          [ 8., 20.],</span></span><br><span class="line"><span class="comment">#          [12., 24.]]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 交换块和行和列 2*3*4-&gt;4*2*3</span></span><br><span class="line">e = x.permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">print(e)</span><br><span class="line"><span class="comment"># tensor([[[ 1.,  5.,  9.],</span></span><br><span class="line"><span class="comment">#          [13., 17., 21.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 2.,  6., 10.],</span></span><br><span class="line"><span class="comment">#          [14., 18., 22.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 3.,  7., 11.],</span></span><br><span class="line"><span class="comment">#          [15., 19., 23.]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 4.,  8., 12.],</span></span><br><span class="line"><span class="comment">#          [16., 20., 24.]]])</span></span><br></pre></td></tr></table></figure>
<h3 id="nn-Linear"><a href="#nn-Linear" class="headerlink" title="nn.Linear()"></a>nn.Linear()</h3><p>改变最后一维，也就是数据的特征维度，通过调整output_size的尺寸来扩张或者是收缩特征</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/1/7 13:27</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二维数组(2,4)</span></span><br><span class="line">x_2d = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">45</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="comment"># 三维数组（2,3,4）</span></span><br><span class="line">x_3d = np.array([[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>]], [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">5</span>], [<span class="number">3</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>]]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转成tensor的形式，因为Linear要求输入是float类型，因此还需要转成float32</span></span><br><span class="line">tensor_x_2d = torch.from_numpy(x_2d.astype(np.float32))</span><br><span class="line">tensor_x_3d = torch.from_numpy(x_3d.astype(np.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用来改变最后数组最后一维的维度</span></span><br><span class="line"><span class="comment"># 用来缩小或者扩展特征维度</span></span><br><span class="line">embedding = nn.Linear(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">tensor_y_2d = embedding(tensor_x_2d)</span><br><span class="line">tensor_y_3d = embedding(tensor_x_3d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">print(tensor_y_2d)</span><br><span class="line"><span class="comment"># tensor([[  4.1090,  -2.4804,  -0.3711],</span></span><br><span class="line"><span class="comment">#         [ 23.7516, -20.5857,   0.4712]], grad_fn=&lt;AddmmBackward0&gt;)</span></span><br><span class="line"></span><br><span class="line">print(tensor_y_3d)</span><br><span class="line"><span class="comment"># tensor([[[ 4.1090, -2.4804, -0.3711],</span></span><br><span class="line"><span class="comment">#          [ 5.7849, -3.5626, -0.5762],</span></span><br><span class="line"><span class="comment">#          [ 6.0937, -3.4730, -1.0961]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 5.7498, -4.5819, -0.0172],</span></span><br><span class="line"><span class="comment">#          [ 5.4060, -4.7207,  0.3439],</span></span><br><span class="line"><span class="comment">#          [ 6.8580, -4.7442, -0.7933]]], grad_fn=&lt;AddBackward0&gt;)</span></span><br></pre></td></tr></table></figure>
<h3 id="xxx-chunk"><a href="#xxx-chunk" class="headerlink" title="xxx.chunk()"></a>xxx.chunk()</h3><p>将tensor按维度方向进行分割</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]).reshape(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">print(tensor)</span><br><span class="line"><span class="comment"># tensor([[1, 2, 3],</span></span><br><span class="line"><span class="comment">#         [4, 5, 6],</span></span><br><span class="line"><span class="comment">#         [7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line">list_of_tensors = torch.chunk(tensor, <span class="number">3</span>, dim=<span class="number">0</span>)</span><br><span class="line">print(list_of_tensors)</span><br><span class="line"><span class="comment"># (tensor([[1, 2, 3]]), tensor([[4, 5, 6]]), tensor([[7, 8, 9]]))</span></span><br></pre></td></tr></table></figure>
<h3 id="xxx-flatten"><a href="#xxx-flatten" class="headerlink" title="xxx.flatten()"></a>xxx.flatten()</h3><p>将维度展开为一维的函数，其中dim参数表示从第dim个维度开始展开，将后面的维度转化成一维。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">print(a.shape)</span><br><span class="line"><span class="comment"># torch.Size([2, 3, 4])</span></span><br><span class="line"></span><br><span class="line">d = a.flatten(<span class="number">1</span>)</span><br><span class="line">print(d.shape)</span><br><span class="line"><span class="comment"># torch.Size([2, 12])</span></span><br></pre></td></tr></table></figure>
<h3 id="rearrange"><a href="#rearrange" class="headerlink" title="rearrange()"></a>rearrange()</h3><p>rearrange是einops中的一个函数调用方法。可以一次将多个维度转换，类似于permute</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange</span><br><span class="line">input_tensor = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">output_tensor = rearrange(input_tensor, <span class="string">&#x27;h w c -&gt; c h w&#x27;</span>)</span><br><span class="line">print(output_tensor.shape)</span><br><span class="line"><span class="comment"># torch.Size([4, 2, 3])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拆分维度</span></span><br><span class="line">input_tensor = torch.randn(<span class="number">2</span>, <span class="number">9</span>, <span class="number">4</span>)</span><br><span class="line">output_tensor = rearrange(input_tensor, <span class="string">&#x27;h (w c) d -&gt; h w c d&#x27;</span>, c=<span class="number">3</span>)</span><br><span class="line">print(output_tensor.shape)</span><br><span class="line"><span class="comment"># torch.Size([2, 3, 3, 4])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并维度</span></span><br><span class="line">input_tensor = torch.randn(<span class="number">2</span>,<span class="number">9</span>,<span class="number">4</span>)</span><br><span class="line">output_tensor = rearrange(input_tensor, <span class="string">&#x27;h w d -&gt; h (w d)&#x27;</span>)</span><br><span class="line">print(output_tensor.shape)</span><br><span class="line"><span class="comment"># torch.Size([2, 36])</span></span><br></pre></td></tr></table></figure>
<h3 id="gather"><a href="#gather" class="headerlink" title="gather()"></a>gather()</h3><p><code>gather</code>函数的作用是在指定<code>dim</code>上，从原<code>tensor</code>中获取指定<code>index</code>的数据。</p>
<p>假设我们有<code>1-9</code>这几个数字，我们将其<code>reshape</code>成一个<code>3</code>行<code>3</code>列的矩阵，我们在<code>dim=0</code>的情况下举个例子，<code>dim=1</code>的情况同理。对于这个<code>9</code>个数来说，他们的索引分别是<code>(0,0),(0,1),(0,2),(1,0),(1,1),(1,2),(2,0),(2,1),(2,2)</code>。假设我们目前想要取的索引为<code>index = torch.tensor([[2, 0, 1]])</code>，意思就是把<code>dim=0</code>的索引给替换成我们想要的索引并取值，即取索引<code>(2,0),(0,1),(1,2)</code>对应的值。需要注意的是，<code>index</code>的长度是任意的，即我们可以任意多次索引取值，但是剩下的维度的维度必须保持一致，也就是说对于<code>3</code>行<code>3</code>列的矩阵来说必须是<code>3</code>，对$3$行<code>4</code>列的矩阵来说必须是<code>4</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/11/24 15:01</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">tensor_a = torch.arange(<span class="number">1</span>, <span class="number">10</span>).reshape(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">print(tensor_a)</span><br><span class="line"><span class="comment"># tensor([[1, 2, 3],</span></span><br><span class="line"><span class="comment">#         [4, 5, 6],</span></span><br><span class="line"><span class="comment">#         [7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dim=0时，取对应的值</span></span><br><span class="line">index_1 = torch.tensor([[<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line">tensor_1 = tensor_a.gather(<span class="number">0</span>, index_1)</span><br><span class="line">print(tensor_1)</span><br><span class="line"><span class="comment"># tensor([[7, 2, 6]])</span></span><br><span class="line"></span><br><span class="line">index_1 = torch.tensor([[<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>]])</span><br><span class="line">tensor_1 = tensor_a.gather(<span class="number">0</span>, index_1)</span><br><span class="line">print(tensor_1)</span><br><span class="line"><span class="comment"># tensor([[7, 2, 6],</span></span><br><span class="line"><span class="comment">#         [4, 8, 3]])</span></span><br><span class="line"></span><br><span class="line">index_1 = torch.tensor([[<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>]])</span><br><span class="line">tensor_1 = tensor_a.gather(<span class="number">0</span>, index_1)</span><br><span class="line">print(tensor_1)</span><br><span class="line"><span class="comment"># tensor([[7, 2, 6],</span></span><br><span class="line"><span class="comment">#         [4, 8, 3],</span></span><br><span class="line"><span class="comment">#         [4, 2, 9]])</span></span><br><span class="line"></span><br><span class="line">index_1 = torch.tensor([[<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>]])</span><br><span class="line">tensor_1 = tensor_a.gather(<span class="number">0</span>, index_1)</span><br><span class="line">print(tensor_1)</span><br><span class="line"><span class="comment"># tensor([[7, 2, 6],</span></span><br><span class="line"><span class="comment">#         [4, 8, 3],</span></span><br><span class="line"><span class="comment">#         [4, 2, 9],</span></span><br><span class="line"><span class="comment">#         [4, 5, 9]])</span></span><br></pre></td></tr></table></figure>
<h2 id="自定义Dataset、Dataloader、Sampler"><a href="#自定义Dataset、Dataloader、Sampler" class="headerlink" title="自定义Dataset、Dataloader、Sampler"></a>自定义Dataset、Dataloader、Sampler</h2><p>假设我有 $10000$ 条训练数据，这些训练数据是有时间先后顺序， $0-1000$ 是 $t=0$ 时刻的数据， $1000-2000$ 是 $t=1$ 时刻的数据，依次类推。模型的输入需要保留这种时间的先后顺序，我想每 $1000$ 条数据当中取 $100$ 条，构成一个<code>batch</code>的训练数据，因此我的<code>batch_size</code>就应该是 $1000$，一共有 $10$ 个<code>batch</code>。想要实现这个目标就需要自定义数据的采样方式。</p>
<p>具体做法是自己实现一个<code>MySampler</code>，继承自<code>Sampler</code>，需要实现<code>__init__</code>、<code>__len__</code>和<code>__iter__</code>方法，在<code>__iter__</code>方法当中需要自定义<code>index</code>的选取方式，比如我这里就是一共要采样 $10$ 次，每次分别在时间间隔中取想要的样本条数，然后返回一个<code>index</code>的可迭代的对象即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySampler</span>(<span class="params">Sampler</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_source, skip_interval</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(data_source)</span><br><span class="line">        self.data_source = data_source</span><br><span class="line">        self.skip_interval = skip_interval</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data_source)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        n = (<span class="built_in">len</span>(self.data_source) - <span class="number">1</span>) // self.skip_interval + <span class="number">1</span></span><br><span class="line">        indices = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(Args.NX // Args.SUB_NX * Args.NY // Args.SUB_NY):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                indices += random.sample(<span class="built_in">range</span>(i * self.skip_interval, (i + <span class="number">1</span>) * self.skip_interval),</span><br><span class="line">                                         Args.SUB_NX * Args.SUB_NY)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(indices)</span><br></pre></td></tr></table></figure>
<h3 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h3><p>首先了解一下<code>Dataloader</code>类的参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dataset: Dataset[T_co], batch_size: Optional[<span class="built_in">int</span>] = <span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             shuffle: Optional[<span class="built_in">bool</span>] = <span class="literal">None</span>, sampler: Union[Sampler, Iterable, <span class="literal">None</span>] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             batch_sampler: Union[Sampler[Sequence], Iterable[Sequence], <span class="literal">None</span>] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             num_workers: <span class="built_in">int</span> = <span class="number">0</span>, collate_fn: Optional[_collate_fn_t] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             pin_memory: <span class="built_in">bool</span> = <span class="literal">False</span>, drop_last: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             timeout: <span class="built_in">float</span> = <span class="number">0</span>, worker_init_fn: Optional[_worker_init_fn_t] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             multiprocessing_context=<span class="literal">None</span>, generator=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             *, prefetch_factor: <span class="built_in">int</span> = <span class="number">2</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             persistent_workers: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             pin_memory_device: <span class="built_in">str</span> = <span class="string">&quot;&quot;</span></span>):</span></span><br></pre></td></tr></table></figure>
<p><code>dataset</code>就是我们的数据集，<code>batch_size</code>就是每个<code>batch</code>的大小，<code>shuffle</code>代表是否打乱，这些是我们比较常用的参数，有一些其他参数也需要了解。首先<code>sampler</code>是一个采样器，可以默认也可以自定义，分布式训练的时候可能需要设置为<code>DistributedSampler</code>；<code>batch_sampler</code>用于指定从<code>sampler</code>返回的<code>index</code>当中选<code>batch_size</code>个打包成一个批次的数据，<code>num_workers</code>用于设置用于数据加载的子进程数量；<code>collate_fn</code>用于对数据集的处理，将<code>NumPy arrays</code>转换为<code>PyTorch tensors</code>。</p>
<p><code>dataset</code>：<code>PyTorch</code>支持两种类型的数据集<code>Map-style Dataset</code>和<code>Iterable-style Dataset</code>，前者本质上构建了<code>index</code>到<code>data</code>的映射，<code>dataset[idx]</code> 返回数据集中第<code>idx</code>个<code>item</code>；后者本质上是一个可迭代对象，通过 <code>next(dataset)</code> 调用 <code>__iter__(self)</code> 方法返回数据集的下一个<code>item</code>。</p>
<ul>
<li><p>如果 <code>dataset</code> 使用<code>IterableDataset</code>，则不能指定 <code>sampler</code>, <code>batch_sampler</code></p>
</li>
<li><ul>
<li><code>sampler</code> 将使用 <code>_InfiniteConstantSampler()</code>，这是一个<code>dummy sampler</code>，调用 <code>__iter__(self)</code> 方法永远返回<code>None</code></li>
<li><code>batch_sampler</code> 将使用内置的<code>BatchSampler</code></li>
<li>可以指定 <code>batch_size</code>, <code>drop_last</code></li>
</ul>
</li>
</ul>
<p><code>batch_size</code>：默认是 $1$，定义我们一个批次的训练数据的条数。<code>batch_size</code>参数和<code>batch_sampler</code>参数是相辅相成的。如果我们设置了<code>batch_size</code>参数且未设置<code>batch_sampler</code>参数，<code>PyTorch</code>会给我们生成一个<code>BatchSampler</code>对象<code>BatchSampler(sampler, batch_size, drop_last)</code>，用于从<code>sampler</code>的<code>index</code>当中迭代，到达<code>batch_size</code>个就返回。如果设置了<code>batch_sampler</code>参数，那么<code>batch_size</code>、<code>shuffle</code>、<code>sampler</code>、<code>drop_last</code>就不能再指定了（报错<code>mutually exclusive</code>），因为自己指定的<code>batch_sampler</code>当中就已经暗含了这些信息。</p>
<p><code>shuffle</code>：每个<code>epoch</code>开始，对数据集进行重新排序。<code>shuffle</code>参数和<code>sampler</code>参数是相辅相成的。如果我们设置了<code>shuffle</code>参数为<code>True</code>并且未设置<code>sampler</code>参数，那么<code>PyTorch</code>就会给我们生成一个<code>RandomSampler</code>对象，通过这个对象我们可以完成随机采样这个操作；如果设置了<code>shuffle</code>为<code>False</code>且未设置<code>sampler</code>参数，那么<code>PyTorch</code>会给我们生成一个<code>SequentialSampler</code>对象，用于顺序取训练样本。如果我们既设置了<code>sampler</code>参数又设置了<code>shuffle</code>参数，<code>PyTorch</code>则会报错（<code>mutually exclusive</code>）。</p>
<p><code>sampler</code>：默认为<code>None</code>。（其他介绍见<code>shuffle</code>参数）</p>
<p><code>batch_sampler</code>：默认为<code>None</code>。（其他介绍见<code>batch_size</code>参数）</p>
<p><code>nun_workers</code>：默认值为 $0$，表示不创建额外的子进程。如果需要启用多进程加载数据，可以通过设置<code>num_workers</code>参数的值为大于 $0$ 的整数来指定创建的子进程数量。通常，根据<code>CPU</code>的核心数量和任务负载情况来选择合适的<code>num_workers</code>值。</p>
<p><code>collate_fn</code>：该函数会将输入的数据进行拼接，并返回一个批次大小为<code>batch_size</code>的张量。可以根据自己的需求定制。默认值为<code>default_collate</code>函数，<code>collate_fn</code>的输入是来自<code>dataloader</code>取到的数据。具体来说，<code>dataloader</code>会按照<code>batch_sampler</code>指定的方式从数据集中抽取样本，并将每个样本传递给<code>collate_fn</code>函数进行整理。因此，<code>collate_fn</code>的输入是<code>dataloader</code>取到的数据。</p>
<p>具体内部运行流程（仅考虑最简单的情况）：</p>
<ol>
<li>我们调用<code>__iter__</code>方法来返回一个迭代器对象；</li>
<li><code>__iter__</code>方法会调用<code>self._get_iterator()</code>方法生成一个<code>_BaseDataLoaderIter</code>类型的迭代器对象；</li>
<li><code>_get_iterator()</code>方法会根据实际情况返回一个<code>_SingleProcessDataLoaderIter</code>类型或<code>_MultiProcessingDataLoaderIter</code>类型的变量（都是<code>_BaseDataLoaderIter</code>的子类）；</li>
<li>每次获取数据的时候，默认调用的是父类<code>_BaseDataLoaderIter</code>的<code>__next__</code>方法；</li>
<li><code>__next__</code>方法则会根据当前的子类调用子类<strong>重写过</strong>的<code>_next_data()</code>方法</li>
<li>子类<code>_SingleProcessDataLoaderIter</code>的<code>_next_data</code>方法调用了<code>_next_index()</code>方法获取<code>index</code>，这个<code>index</code>是从<code>_sampler_iter</code>中获取的，而<code>_sampler_iter</code>是<code>_index_sampler</code>的迭代器对象，根据<code>dataloader</code>的<code>batch_sampler</code>是否为空返回<code>batch_sampler</code>或<code>sampler</code>；</li>
<li>通过<code>_dataset_fetcher.fetch(index)</code>就可以获取到数据，<code>_dataset_fetcher</code>就是根据<code>dataset</code>的数据类型（<code>Map</code>和<code>Iterable</code>）封装的一个数据获取的类，根据输入的<code>index</code>获取数据；</li>
<li><code>fetch</code>方法很简单，就是根据<code>index</code>获取数据，最后返回<code>self.collate_fn(data)</code>，即处理过后的最终数据。</li>
</ol>
<p><code>pin_memory</code>：否将加载的数据（即张量）存储在<code>pinned</code>内存中，默认为<code>False</code>。在<code>PyTorch</code>中，一些操作需要使用<code>pinned</code>内存，例如将数据从<code>GPU</code>传输到<code>CPU</code>或将数据从<code>CPU</code>传输到<code>GPU</code>。如果数据存储在普通内存中，传输操作可能会导致额外的内存复制和数据移动，从而降低效率。</p>
<p><code>drop_last</code>：用于设置是否丢弃最后一个批次的数据，默认为<code>False</code>，作为<code>BatchSampler</code>的参数。</p>
<h2 id="LSTM代码实现"><a href="#LSTM代码实现" class="headerlink" title="LSTM代码实现"></a>LSTM代码实现</h2><h3 id="LSTM架构"><a href="#LSTM架构" class="headerlink" title="LSTM架构"></a>LSTM架构</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308281450042.png" alt=""></p>
<h3 id="LSTM源码"><a href="#LSTM源码" class="headerlink" title="LSTM源码"></a>LSTM源码</h3><p><code>nn.LSTM</code>继承自<code>nn.RNNBase</code>，其初始化函数定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, mode: <span class="built_in">str</span>, input_size: <span class="built_in">int</span>, hidden_size: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             num_layers: <span class="built_in">int</span> = <span class="number">1</span>, bias: <span class="built_in">bool</span> = <span class="literal">True</span>, batch_first: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             dropout: <span class="built_in">float</span> = <span class="number">0.</span>, bidirectional: <span class="built_in">bool</span> = <span class="literal">False</span>, proj_size: <span class="built_in">int</span> = <span class="number">0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">             device=<span class="literal">None</span>, dtype=<span class="literal">None</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br></pre></td></tr></table></figure>
<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p><code>input_size</code>： 输入<code>x</code>的大小。</p>
<p><code>hidden_size</code>：隐藏状态<code>h</code>的大小。</p>
<p><code>num_layers</code>：循环神经网络的层数，就是上图中的<code>depth</code>。</p>
<p><code>bias</code>：用于指定是否使用偏置项。</p>
<p><code>batch_first</code>：用于指定输入和输出张量的布局方式。当<code>batch_first</code>为<code>True</code>时，输入和输出张量的形状为<code>(batch_size, sequence_length, features)</code>，即先指定<code>batch_size</code>，然后是<code>sequence_length</code>，最后是<code>features</code>。当<code>batch_first</code>为<code>False</code>时，输入和输出张量的形状为<code>(sequence_length, batch_size, features)</code>，即先指定<code>sequence_length</code>，然后是<code>batch_size</code>，最后是<code>features</code>。</p>
<p><code>dropout</code>：用于指定除第一层外每层输入时的<code>dropout</code>概率。</p>
<p><code>bidirectional</code>：用于指定是否使用双向<code>LSTM</code>。</p>
<p><code>proj_size</code>：当指定了<code>proj_size</code>参数时，模型的输出会被一个全连接层投影到一个较低维度的空间中。这个投影层大小由<code>proj_size</code>参数指定。<code>proj_size</code>的值默认为 $0$，表示不使用投影层。当<code>proj_size</code>大于 $0$ 时，<code>LSTM</code>模型的输出将被投影到<code>proj_size</code>大小的向量空间中。</p>
<h4 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h4><p><code>LSTM</code>输入的数据格式为：<code>input, (h_0, c_0)</code></p>
<p><code>input</code>：维度形状为<code>(batch_size, sequence_length, features)</code>。<code>batch_size</code>是当前批次数据的条数，<code>sequence_length</code>是句子长度，<code>features</code>是特征数目。</p>
<p><code>h_0</code>：维度形状为 <code>(num_layers*num_directions, batch_size, hidden_size)</code>，<code>num_directions</code>是由<code>bidirectional</code>决定的，如果是<code>False</code>就为 $1$，否则为 $2$。</p>
<p><code>c_0</code>：和<code>h_0</code>类似。</p>
<h4 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h4><p><code>LSTM</code>输出的数据格式为：<code>output, (h_n, c_n)</code></p>
<p><code>output</code>： 维度和输入数据类似，即 <code>(sequence_length, batch_size, num_directions*hidden_size)</code>。</p>
<p><code>h_n</code>：最后一个<code>timestep</code>的隐状态，维度形状为<code>(num_layers*num_directions, batch_size, hidden_size)</code>。</p>
<p><code>c_n</code> ：和<code>h_n</code>类似。</p>
<h2 id="分布式数据训练"><a href="#分布式数据训练" class="headerlink" title="分布式数据训练"></a>分布式数据训练</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>在使用<code>DistributedDataParallel</code>时有一些概念必须掌握。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">单机多卡</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">world_size</td>
<td style="text-align:center">代表机器一共有几块GPU</td>
</tr>
<tr>
<td style="text-align:center">rank</td>
<td style="text-align:center">第几块GPU</td>
</tr>
<tr>
<td style="text-align:center">local_rank</td>
<td style="text-align:center">第几块GPU，与rank相同</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">多机多卡</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">world_size</td>
<td style="text-align:center">代表有几台机器，可以理解为几台服务器</td>
</tr>
<tr>
<td style="text-align:center">rank</td>
<td style="text-align:center">全部机器中的GPU的全局编号</td>
</tr>
<tr>
<td style="text-align:center">local_rank</td>
<td style="text-align:center">某台机器中的第几块GPU</td>
</tr>
</tbody>
</table>
</div>
<h3 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h3><ol>
<li><p>配置基本参数</p>
</li>
<li><p>指定进程通讯方式</p>
</li>
<li><p>更改数据采样器</p>
</li>
<li><p>模型<code>BN</code>层替换，另外可以将<code>loss</code>集成到模型中，进一步提高多卡处理的性能</p>
</li>
<li><p><code>loss</code>及指标的同步和打印，模型的保存</p>
</li>
<li><p>启动分布式进程</p>
</li>
</ol>
<h4 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h4><p>使用多进程进行分布式训练，我们需要为每个<code>GPU</code>启动一个进程。每个进程需要知道自己运行在哪个<code>GPU</code>上，以及自身在所有进程中的序号。对于多节点，我们需要在每个节点启动脚本。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&quot;--logdir&quot;</span>, default=<span class="string">&quot;test&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;directory to save the tensorboard logs&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--world-size&quot;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;number of distributed processes&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--local_rank&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;rank of distributed processes&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--img_size&quot;</span>, default=<span class="number">384</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;input size&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--batch_size&quot;</span>, default=<span class="number">4</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;batch size&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--optim_lr&quot;</span>, default=<span class="number">1e-4</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&quot;optimization learning rate&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--optim_name&quot;</span>, default=<span class="string">&quot;adamw&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;optimization algorithm&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--norm_name&quot;</span>, default=<span class="string">&quot;instance&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;normalization name&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--reg_weight&quot;</span>, default=<span class="number">1e-5</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&quot;regularization weight&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--momentum&quot;</span>, default=<span class="number">0.99</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&quot;momentum&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--patch_size&quot;</span>, default=<span class="number">16</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;patch size&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--in_chans&quot;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;number of input channels&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--out_chans&quot;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;number of output channels&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--embed_dim&quot;</span>, default=<span class="number">256</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;embedding dimension&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--max_epochs&quot;</span>, default=<span class="number">100</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;max number of training epochs&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--distributed&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;start distributed training&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--noamp&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;do NOT use amp for training&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--workers&quot;</span>, default=<span class="number">8</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;number of workers&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--rank&quot;</span>, default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;node rank for distributed training&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--dist-url&quot;</span>, default=<span class="string">&quot;tcp://127.0.0.1:23456&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;distributed url&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--dist-backend&quot;</span>, default=<span class="string">&quot;nccl&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;distributed backend&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--lrschedule&quot;</span>, default=<span class="string">&quot;cosine_anneal&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;type of learning rate scheduler&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--val_every&quot;</span>, default=<span class="number">5</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;validation frequency&quot;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">args.amp = <span class="keyword">not</span> args.noamp</span><br><span class="line">args.logdir = <span class="string">&quot;./runs/&quot;</span> + args.logdir</span><br><span class="line"><span class="keyword">if</span> args.distributed:</span><br><span class="line">    args.ngpus_per_node = torch.cuda.device_count()</span><br><span class="line">    print(<span class="string">&quot;total gpus:&quot;</span>, args.ngpus_per_node)</span><br><span class="line">    args.world_size = args.ngpus_per_node * args.world_size</span><br><span class="line">    mp.spawn(main_worker, nprocs=args.ngpus_per_node, args=(args,))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    main_worker(gpu=<span class="number">0</span>, args=args)</span><br></pre></td></tr></table></figure>
<p>其中<code>args.distributed</code>表示是否启用分布式训练，<code>args.world-size</code>表示进程总数，而<code>args.ngpus_per_node</code>是每个节点的<code>GPU</code>总数。节点总数乘以每个节点的<code>GPU</code>数可以得到<code>args.world-size</code>，也即进程总数。命令行参数<code>--loacl_rank</code>是必须声明的，但<strong>它不是由用户填写的，而是由PyTorch为用户填写</strong>，也就是说这个值是会被自动赋值为当前进程在本机上的<code>rank</code>。</p>
<h4 id="指定进程通讯方式"><a href="#指定进程通讯方式" class="headerlink" title="指定进程通讯方式"></a>指定进程通讯方式</h4><p>所有的进程需要知道进程<code>0​</code>的<code>IP</code>地址以及端口，这样所有进程可以在开始时同步，一般情况下称进程<code>0</code>是<code>master</code>进程，比如我们会在进程<code>0</code>中打印信息或者保存模型。<code>PyTorch</code>提供了<code>mp.spawn</code>来在一个节点启动该节点所有进程，每个进程运行<code>main_worker(i, args)</code>，其中<code>i</code>从<code>0</code>到<code>args.gpus-1</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> args.distributed:</span><br><span class="line">    torch.multiprocessing.set_start_method(<span class="string">&quot;fork&quot;</span>, force=<span class="literal">True</span>)</span><br><span class="line">args.gpu = gpu</span><br><span class="line"><span class="keyword">if</span> args.distributed:</span><br><span class="line">    args.rank = args.rank * args.ngpus_per_node + gpu</span><br><span class="line">    dist.init_process_group(</span><br><span class="line">        backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank</span><br><span class="line">    )</span><br><span class="line">torch.cuda.set_device(args.gpu)</span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">print(<span class="string">&quot;rank:&quot;</span>, args.rank, <span class="string">&quot; gpu:&quot;</span>, args.gpu)</span><br><span class="line"><span class="keyword">if</span> args.rank == <span class="number">0</span>:</span><br><span class="line">    print(<span class="string">&quot;batch size:&quot;</span>, args.batch_size, <span class="string">&quot;epochs:&quot;</span>, args.max_epochs)</span><br><span class="line">model = AFNONet(img_size=(args.img_size, args.img_size), patch_size=(args.patch_size, args.patch_size),</span><br><span class="line">                in_chans=args.in_chans, out_chans=args.out_chans, depth=<span class="number">5</span>, embed_dim=args.embed_dim)</span><br></pre></td></tr></table></figure>
<h4 id="设置数据采样器"><a href="#设置数据采样器" class="headerlink" title="设置数据采样器"></a>设置数据采样器</h4><ul>
<li><strong>Dataset</strong> : 从名字可以知道，是数据集的意思。负责对原始训练数据的封装，将其封装成<code>Python</code>可识别的数据结构，<code>Dataset</code>的派生类必须提供接口一边获取单个数据。</li>
<li><strong>Sampler</strong> : 从名字可知，是采样器，负责采样方式或者说是采样策略，实现某种提取/采样策略从<code>Dataset</code>之中拿到数据索引，供<code>DataLoader</code>使用。可以认为，<code>Sampler</code>是指挥者，负责决定战斗在哪里开展。</li>
<li><strong>DataLoader</strong> : 负责依据索引来从数据集中加载数据。支持<code>Map-style</code>和<code>Iterable-style</code>两种<code>Dataset</code>，支持单进程/多进程加载。<code>Loader</code>就是具体作战的斗士，负责按照<code>Sampler</code>的命令进行战斗。</li>
</ul>
<p><code>DistributedSampler</code>的分配方法是：每段连续的<code>num_replicas</code>个数据被拆成一个一个，分给<code>num_replicas</code>个进程，而且是通过每个<code>worker</code>的<code>rank</code>来获取数据，这样就达到了不重叠不交叉的目的，但也要注意的是：这样每个进程拿到的数据是不连续的。</p>
<p>每次<code>epoch</code>都会<code>shuffle</code>数据集，<strong>但是不同进程如何保持shuffle之后数据集一致性</strong>？<code>DistributedSampler</code>使用当前的<code>epoch</code>作为随机数种子，在计算<code>index</code>之前就进行配置，从而保证不同进程都使用同样的随机数种子，这样<code>shuffle</code>出来的数据就能确保一致。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_x = torch.rand(<span class="number">2048</span>, <span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>)</span><br><span class="line">data_y = data_x**<span class="number">3</span> + <span class="number">0.001</span>*data_x</span><br><span class="line">train_dataset = TensorDataset(data_x, data_y)</span><br><span class="line">train_sampler = DistributedSampler(train_dataset) <span class="keyword">if</span> args.distributed <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    train_dataset,</span><br><span class="line">    batch_size=args.batch_size,</span><br><span class="line">    shuffle=(train_sampler <span class="keyword">is</span> <span class="literal">None</span>),</span><br><span class="line">    num_workers=args.workers,</span><br><span class="line">    sampler=train_sampler,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">data_x1 = torch.rand(<span class="number">64</span>, <span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>)</span><br><span class="line">data_y1 = data_x1**<span class="number">3</span> + <span class="number">0.001</span>*data_x1</span><br><span class="line">val_dataset = TensorDataset(data_x1, data_y1)</span><br><span class="line">val_sampler = DistributedSampler(val_dataset, shuffle=<span class="literal">False</span>) <span class="keyword">if</span> args.distributed <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">val_loader = DataLoader(</span><br><span class="line">    val_dataset,</span><br><span class="line">    batch_size=args.batch_size,</span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">    num_workers=args.workers,</span><br><span class="line">    sampler=val_sampler,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="模型加载及替换"><a href="#模型加载及替换" class="headerlink" title="模型加载及替换"></a>模型加载及替换</h4><p>分布式训练需要将<code>bn</code>换成<code>sync_batchnorm</code>进行多卡同步，同时我们必须给<code>DDP</code>提示目前是哪个<code>rank</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.cuda(args.gpu)</span><br><span class="line"><span class="keyword">if</span> args.distributed:</span><br><span class="line">    torch.cuda.set_device(args.gpu)</span><br><span class="line">    <span class="keyword">if</span> args.norm_name == <span class="string">&quot;batch&quot;</span>:</span><br><span class="line">        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)</span><br><span class="line">    model.cuda(args.gpu)</span><br><span class="line">    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu],output_device=args.gpu,</span><br><span class="line">                                                      find_unused_parameters=<span class="literal">True</span>)</span><br><span class="line">start_epoch = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h4 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h4><p>关于梯度回传和参数更新，跟单卡训练无异，这里我们不需要考虑对<code>loss</code>取平均，因为当我们回传<code>loss</code>后，<code>DDP</code>会自动对所有梯度进行平均，也就是说回传后我们更新的梯度和<code>DP</code>或者单卡同样<code>batch</code>训练都是一致的。为了进一步节省显存，可以使用混合精度进行训练<code>PyTorch1.6</code>以下需要自行编译<code>nvidia apex</code>，<code>PyTorch1.6</code>后内置了<code>apex</code>，不同训练方法修改的地方不完全相同</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> args.distributed:</span><br><span class="line">    train_loader.sampler.set_epoch(epoch)</span><br><span class="line">    torch.distributed.barrier()</span><br><span class="line">    epoch_time = time.time()</span><br><span class="line">    train_loss = train_epoch(model, train_loader, optimizer, scaler=scaler, epoch=epoch,</span><br><span class="line">                             loss_func=loss_func, args=args)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch</span>(<span class="params">model, loader, optimizer, scaler, epoch, loss_func, args</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    run_loss = AverageMeter()</span><br><span class="line">    <span class="keyword">for</span> idx, batch_data <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        data, target = batch_data</span><br><span class="line">        data, target = data.cuda(args.rank), target.cuda(args.rank)</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            param.grad = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">with</span> autocast(enabled=args.amp):</span><br><span class="line">            logits = model(data)</span><br><span class="line">            loss = loss_func(logits, target)</span><br><span class="line">        <span class="comment"># 混合精度训练</span></span><br><span class="line">        <span class="keyword">if</span> args.amp:</span><br><span class="line">            scaler.scale(loss).backward()</span><br><span class="line">            scaler.step(optimizer)</span><br><span class="line">            scaler.update()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> args.distributed:</span><br><span class="line">            loss_list = distributed_all_gather([loss], out_numpy=<span class="literal">True</span>)</span><br><span class="line">            run_loss.update(</span><br><span class="line">                np.mean(np.mean(np.stack(loss_list, axis=<span class="number">0</span>), axis=<span class="number">0</span>), axis=<span class="number">0</span>), n=args.batch_size * args.world_size</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            run_loss.update(loss.item(), n=args.batch_size)</span><br><span class="line">        <span class="keyword">if</span> args.rank == <span class="number">0</span>:</span><br><span class="line">            print(</span><br><span class="line">                <span class="string">&quot;Epoch &#123;&#125;/&#123;&#125; &#123;&#125;/&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, args.max_epochs, idx + <span class="number">1</span>, <span class="built_in">len</span>(loader)),</span><br><span class="line">                <span class="string">&quot;loss: &#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(run_loss.avg),</span><br><span class="line">                <span class="string">&quot;time &#123;:.2f&#125;s&quot;</span>.<span class="built_in">format</span>(time.time() - start_time),</span><br><span class="line">            )</span><br><span class="line">        start_time = time.time()</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">        param.grad = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> run_loss.avg</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val_epoch</span>(<span class="params">model, loader, epoch, acc_func, args</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    run_acc = AverageMeter()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> idx, batch_data <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">            data, target = batch_data</span><br><span class="line">            data, target = data.cuda(args.rank), target.cuda(args.rank)</span><br><span class="line">            logits = model(data)</span><br><span class="line">            loss = acc_func(logits, target)</span><br><span class="line">            <span class="keyword">if</span> args.distributed:</span><br><span class="line">                loss_list = distributed_all_gather([loss], out_numpy=<span class="literal">True</span>)</span><br><span class="line">                run_acc.update(</span><br><span class="line">                    np.mean(np.mean(np.stack(loss_list, axis=<span class="number">0</span>), axis=<span class="number">0</span>), axis=<span class="number">0</span>), n=args.batch_size * args.world_size</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                run_acc.update(loss.item(), n=args.batch_size)</span><br><span class="line">            <span class="keyword">if</span> args.rank == <span class="number">0</span>:</span><br><span class="line">                print(</span><br><span class="line">                    <span class="string">&quot;Epoch &#123;&#125;/&#123;&#125; &#123;&#125;/&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, args.max_epochs, idx + <span class="number">1</span>, <span class="built_in">len</span>(loader)),</span><br><span class="line">                    <span class="string">&quot;val loss: &#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(run_acc.avg),</span><br><span class="line">                    <span class="string">&quot;time &#123;:.2f&#125;s&quot;</span>.<span class="built_in">format</span>(time.time() - start_time),</span><br><span class="line">                )</span><br><span class="line">            start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> run_acc.avg</span><br></pre></td></tr></table></figure>
<h4 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h4><p>模型的保存也需要在主进程进行保存</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_checkpoint</span>(<span class="params">model, epoch, args, filename=<span class="string">&quot;model.pt&quot;</span>, best_acc=<span class="number">0</span></span>):</span></span><br><span class="line">    state_dict = model.state_dict() <span class="keyword">if</span> <span class="keyword">not</span> args.distributed <span class="keyword">else</span> model.module.state_dict()</span><br><span class="line">    save_dict = &#123;<span class="string">&quot;epoch&quot;</span>: epoch, <span class="string">&quot;best_acc&quot;</span>: best_acc, <span class="string">&quot;state_dict&quot;</span>: state_dict&#125;</span><br><span class="line">    filename = os.path.join(args.logdir, filename)</span><br><span class="line">    torch.save(save_dict, filename)</span><br><span class="line">    print(<span class="string">&quot;Saving checkpoint&quot;</span>, filename)</span><br></pre></td></tr></table></figure>
<h4 id="启动多进程训练"><a href="#启动多进程训练" class="headerlink" title="启动多进程训练"></a>启动多进程训练</h4><p>直接在命令行运行：<code>python my_main.py --distributed</code></p>
<h1 id="JAX代码实践"><a href="#JAX代码实践" class="headerlink" title="JAX代码实践"></a>JAX代码实践</h1><p>首先介绍一下<code>JAX</code>，<code>JAX</code>简单来说就是一种自动微分的<code>Numpy</code>。<code>JAX</code>并不是一个深度学习的框架，而是一个科学计算的框架，深度学习只是<code>JAX</code>功能的一个子集。<code>JAX</code>的主要功能如下：</p>
<ul>
<li>科学计算</li>
</ul>
<p>既然是<code>NumPy</code>，那就可以用<code>NumPy</code>接口做各类科学计算。除了之外还带自动微分，科学计算世界中，微分是最常用的一种计算。<code>JAX</code>的自动微分包含了前向微分、反向微分等各种接口。反正各类花式微分，几乎都可以用<code>JAX</code>实现。</p>
<ul>
<li><code>JIT</code>编译</li>
</ul>
<p>将<code>NumPy</code>接口写的计算转成高效的二进制代码，可以在<code>CPU/GPU/TPU</code>上获得极高加速比。<code>JIT</code>编译主要还是基于<code>XLA(accelerated linear algebra)</code>。<code>XLA</code>是一种编译器，可以将<code>TF/JAX</code>的代码在<code>CPU/GPU/TPU</code>上加速。说到<code>JAX</code>速度快，主要就靠<code>XLA</code>！</p>
<ul>
<li>并行化</li>
</ul>
<p>比起简单的<code>NumPy</code>，<code>JAX</code>提供了大量接口做并行。无论是<code>tf</code>还是<code>torch</code>，一个简单的并行方法是：<code>batch_size</code>。<code>JAX</code>用<code>vmap</code>做并行, 用户只用实现一条数据的处理，<code>JAX</code>将帮我们做拓展，可以拓展到<code>batch_size</code>大小。<code>vmap</code>的思想与<code>Spark</code>中的<code>map</code>一样。用户关注<code>map</code>里面的一条数据的处理方法，<code>JAX</code>帮我们做并行化。</p>
<ul>
<li>函数式编程</li>
</ul>
<p><strong>深度学习框架</strong></p>
<p><code>JAX</code>并不是一个深度学习框架。想要做深度学习，还要再在<code>JAX</code>上套一层。要想在<code>JAX</code>上实现一个全连接网络，要<code>np.dot(w, x) + b</code>，没有现成的<code>nn.Dense</code>或者<code>nn.Linear</code>。于是有了<code>DeepMind</code>的<code>haiku</code>，<code>Google</code>的<code>Flax</code>和其他各种各样的库。<code>JAX</code>是纯函数的，代码写起来和<code>tf</code>、<code>torch</code>不太一样。没有了<code>.fit()</code> 这样傻瓜式的接口，没有<code>MSELoss</code>这样的损失函数。而且要适应数据的不可变：模型参数先初始化<code>init</code>，才能使用。</p>
<h2 id="网络定义"><a href="#网络定义" class="headerlink" title="网络定义"></a>网络定义</h2><p>主要是需要在<code>__call__</code>函数完成前向计算逻辑，类似<code>PyTorch</code>中的<code>forward</code>函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    layer_sizes: Sequence[<span class="built_in">int</span>]</span><br><span class="line">    M: <span class="built_in">int</span></span><br><span class="line">    L: <span class="built_in">float</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.W1 = nn.Dense(features=layer_sizes[<span class="number">1</span>])</span><br><span class="line">        self.W2 = nn.Dense(features=layer_sizes[<span class="number">1</span>])</span><br><span class="line">        self.Wz = [nn.Dense(features=size) <span class="keyword">for</span> size <span class="keyword">in</span> layer_sizes[<span class="number">1</span>:]]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">input_encoding</span>(<span class="params">self, t, x</span>):</span></span><br><span class="line">        w = <span class="number">2.0</span> * jnp.pi / L</span><br><span class="line">        k = jnp.arange(<span class="number">1</span>, M + <span class="number">1</span>)</span><br><span class="line">        out = jnp.hstack([t, jnp.ones_like(t), jnp.cos(k * w * x), jnp.sin(k * w * x)])</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, t, x</span>):</span></span><br><span class="line">        X = self.input_encoding(t, x)</span><br><span class="line">        <span class="keyword">for</span> linear <span class="keyword">in</span> self.Wz[:-<span class="number">1</span>]:</span><br><span class="line">            X = nn.tanh(linear(X))</span><br><span class="line">        X = self.Wz[-<span class="number">1</span>](X)</span><br><span class="line">        <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>
<h2 id="网络参数初始化"><a href="#网络参数初始化" class="headerlink" title="网络参数初始化"></a>网络参数初始化</h2><p>获取一个<code>PRNGKey</code>，并将其用于参数初始化，然后调用模型的<code>init</code>函数获取整个网络的<code>params</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">M = <span class="number">10</span></span><br><span class="line">L = <span class="number">2.0</span> * jnp.pi</span><br><span class="line">layer_sizes = [<span class="number">2</span> * M + <span class="number">2</span>] + [<span class="number">128</span>] * <span class="number">8</span> + [<span class="number">1</span>]</span><br><span class="line">net = Net(layer_sizes, M, L)</span><br><span class="line"></span><br><span class="line">key = jax.random.PRNGKey(<span class="number">2023</span>)</span><br><span class="line">key, skey = jax.random.split(key)</span><br><span class="line">dummy_x = jax.random.uniform(skey, (<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">key, skey = jax.random.split(skey)</span><br><span class="line">params = net.init(skey, dummy_x, dummy_x)</span><br></pre></td></tr></table></figure>
<h2 id="optimizer定义"><a href="#optimizer定义" class="headerlink" title="optimizer定义"></a>optimizer定义</h2><p><code>optimizer</code>的定义和<code>PyTorch</code>类似。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr = <span class="number">1e-3</span></span><br><span class="line">optimizer = optax.adam(learning_rate=lr)</span><br></pre></td></tr></table></figure>
<h2 id="scheduler定义"><a href="#scheduler定义" class="headerlink" title="scheduler定义"></a>scheduler定义</h2><p><code>scheduler</code>的定义和<code>PyTorch</code>类似。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr = <span class="number">1e-3</span></span><br><span class="line">schedule = optax.exponential_decay(</span><br><span class="line">    init_value=lr,</span><br><span class="line">    transition_steps=<span class="number">5000</span>,</span><br><span class="line">    decay_rate=<span class="number">0.99</span></span><br><span class="line">)</span><br><span class="line">optimizer = optax.adam(learning_rate=schedule)</span><br></pre></td></tr></table></figure>
<h2 id="训练状态定义"><a href="#训练状态定义" class="headerlink" title="训练状态定义"></a>训练状态定义</h2><p>在<code>JAX</code>当中，比较常用的模式是创建一个单一的数据类，代表整个训练状态，包括步骤数、参数和优化器状态。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">state = train_state.TrainState.create(apply_fn=net.apply, params=params, tx=optimizer)</span><br></pre></td></tr></table></figure>
<h2 id="模型训练-1"><a href="#模型训练-1" class="headerlink" title="模型训练"></a>模型训练</h2><p>因为<code>JAX</code>是面向函数编程，首先我们需要定义一下整个<code>loss</code>的形式。接着使用<code>grad</code>函数来计算损失函数的梯度。最后使用<code>apply_gradients</code>函数更新模型的参数。使用<code>@jit</code>装饰器来跟踪整个<code>train_step</code>函数，并用<code>XLA</code>将其及时编译成融合的设备操作，在硬件加速器上运行得更快、更有效。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@jax.jit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">state, t_r, x_r, t_i, x_i, u_i</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss_fn</span>(<span class="params">params</span>):</span>        </span><br><span class="line">        u = state.apply_fn(params, t_r, x_r)</span><br><span class="line">        u0 = state.apply_fn(params, t_i, x_i)</span><br><span class="line">        u_t = diff(partial(state.apply_fn, params), <span class="number">0</span>)(t_r, x_r)</span><br><span class="line">        u_fn = <span class="keyword">lambda</span> x: state.apply_fn(params, t_r, x)</span><br><span class="line">        _, (u_x, u_xx, _, u_xxxx) = jet(u_fn, (x_r, ), [[<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]])</span><br><span class="line">        f = jnp.zeros_like(u)</span><br><span class="line">        loss_f = mse_fn(u_t + (<span class="number">100</span>/<span class="number">16</span>) * u * u_x + (<span class="number">100</span>/<span class="number">16</span>**<span class="number">2</span>) * u_xx + (<span class="number">100</span>/<span class="number">16</span>**<span class="number">4</span>) * u_xxxx, f)</span><br><span class="line">        loss_d = mse_fn(u0, u_i)</span><br><span class="line">        loss = loss_f + <span class="number">100</span> * loss_d</span><br><span class="line">        <span class="keyword">return</span> loss, (loss_f, loss_d)</span><br><span class="line"></span><br><span class="line">    grads, (loss_f, loss_d) = jax.grad(loss_fn, argnums=<span class="number">0</span>, has_aux=<span class="literal">True</span>)(state.params)</span><br><span class="line">    state = state.apply_gradients(grads=grads)</span><br><span class="line">    <span class="keyword">return</span> state, loss_f, loss_d</span><br></pre></td></tr></table></figure>
<h2 id="如何对输入变量求导"><a href="#如何对输入变量求导" class="headerlink" title="如何对输入变量求导"></a>如何对输入变量求导</h2><h3 id="低阶导数的求法"><a href="#低阶导数的求法" class="headerlink" title="低阶导数的求法"></a>低阶导数的求法</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">diff</span>(<span class="params">func, argnums</span>):</span></span><br><span class="line">    <span class="keyword">return</span> jax.grad(<span class="keyword">lambda</span> *ar, **kw: jnp.<span class="built_in">sum</span>(func(*ar, **kw)), argnums=argnums)</span><br><span class="line"></span><br><span class="line">u_fn1 = partial(state.apply_fn, params)</span><br><span class="line">u = u_fn1(t_r, x_r)</span><br><span class="line">u_t = diff(u_fn1, <span class="number">0</span>)(t_r, x_r)</span><br></pre></td></tr></table></figure>
<p>首先介绍一下上面代码段中的<code>partial</code>函数，我们调用函数时需要输入函数的变量，但是对于某些函数，我们可能每次调用的某些变量值是不变的，所以我们就可以将这些参数固定下来。上面代码段中的<code>state.apply_fn</code>函数对应的是<code>net.apply</code>函数（对于<code>net.apply</code>函数来说，如果没有特指就是模型的<code>__call__</code>函数，如果特指可能是模型中的其他函数，也可能是不属于模型的函数），这个函数的第一个参数是<code>params</code>，也就是模型的参数。<code>diff</code>函数是我们定义的对某个函数的某个变量求导的函数。</p>
<h3 id="高阶导数的求法"><a href="#高阶导数的求法" class="headerlink" title="高阶导数的求法"></a>高阶导数的求法</h3><p>我们既可以采用同低阶导数相同的求法进行嵌套求解，即先求一阶导，再对一阶导数求导就可以得到二阶导，依此类推。同时我们也可以使用<code>Taylor mode</code>求高阶导数，这里主要是<code>jet</code>函数的应用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">u_fn1 = partial(state.apply_fn, params)</span><br><span class="line">u = u_fn1(t_r, x_r)</span><br><span class="line">u_t = diff(u_fn1, <span class="number">0</span>)(t_r, x_r)</span><br><span class="line">u_x = diff(u_fn1, <span class="number">1</span>)(t_r, x_r)</span><br><span class="line">u_xx = diff(diff(u_fn1, <span class="number">1</span>), <span class="number">1</span>)(t_r, x_r)</span><br><span class="line">u_xxxx = diff(diff(diff(diff(u_fn1, <span class="number">1</span>), <span class="number">1</span>), <span class="number">1</span>), <span class="number">1</span>)(t_r, x_r)</span><br><span class="line"></span><br><span class="line"><span class="comment"># u_fn = lambda x_r: state.apply_fn(params, t_r, x_r) # For using Taylor-mode AD</span></span><br><span class="line"><span class="comment"># _, (u_x, u_xx, _, u_xxxx) = jet(u_fn, (x_r, ), [[1.0, 0.0, 0.0, 0.0]]) #  Taylor-mode AD</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习总结</title>
    <url>/2021/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>小白上路啦！</p>
<p>主要参考吴恩达的《机器学习》</p>
<a id="more"></a>
<h1 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h1><h2 id="学习方式分类"><a href="#学习方式分类" class="headerlink" title="学习方式分类"></a>学习方式分类</h2><ul>
<li>监督学习</li>
<li>无监督学习</li>
<li>半监督学习</li>
<li>强化学习</li>
</ul>
<h2 id="学习结果分类"><a href="#学习结果分类" class="headerlink" title="学习结果分类"></a>学习结果分类</h2><ul>
<li>回归</li>
<li>分类</li>
</ul>
<h1 id="模型学习"><a href="#模型学习" class="headerlink" title="模型学习"></a>模型学习</h1><h2 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h2><h3 id="线性回归模型特点"><a href="#线性回归模型特点" class="headerlink" title="线性回归模型特点"></a>线性回归模型特点</h3><ul>
<li>线性回归时一种回归算法</li>
<li>模型简单、计算量较小</li>
<li>对误差敏感</li>
<li>对数据预处理要求较高</li>
</ul>
<h3 id="线性回归模型主要思想"><a href="#线性回归模型主要思想" class="headerlink" title="线性回归模型主要思想"></a>线性回归模型主要思想</h3><p>通过运用该简单的线性函数，可模拟<code>x</code>和<code>y</code>之间的关系。关键在于该函数不仅与输入变量x成线性关系，而且与参数<code>a</code>、<code>b</code>成线性关系。当前目标是确定最符合训练数据的参数<code>a</code>和<code>b</code>的值。</p>
<p>这可通过测量每个输入x的实际目标值<code>y</code>和模型<script type="math/tex">f(x)</script>之间的失配来实现，并将失配最小化。这种失配（最小值）被称为误差函数。</p>
<p>有多种误差函数可供选择，但其中最简单的要数<code>RSS</code>，即每个数据点x对应的模型<script type="math/tex">f(x)</script>与目标值y的误差平方和。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_16.png" alt=""></p>
<p>对于<code>w</code>,<code>b​</code>作为自变量，取何值时，<code>RSS</code>最小？转化为求极值问题，极值点偏导为0。</p>
<p>避免过拟合，引入正则化技术（将参数作为项加入损失函数）</p>
<p>L1正则化（LASSO回归）：具有稀疏作用</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_17.png" alt=""></p>
<p>L2正则化（Ridge回归）：收敛更快</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_18.png" alt=""></p>
<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><ul>
<li>评估是否准确：查看在训练集上的准确率</li>
<li>评估泛化性能：查看在测试集（<code>K</code>折）上的准确率</li>
</ul>
<h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>梯度：$\mbox{grad} \ f(x,y)=\nabla f(x,y)=f_{x}(x,y)\vec{i}+f_{y}(x,y)\vec{j}$ 和法向向量（是一个单位向量）$n$ 相乘后就是沿着边界外法线方向的导数值</p>
<p>散度：用于表征空间各点矢量场发散的强弱程度，$\mbox{div} \ \mathbf{F}=\nabla\cdot\mathbf{F}=\frac{\partial F_{x}}{\partial x}+\frac{\partial F_{y}}{\partial y}+\frac{\partial F_{z}}{\partial z}$，其中$F_{x}, F_{y}, F_{z}$是三个轴的分量</p>
<p>旋度：可以表示三维向量场对某一点附近的微元造成的旋转程度，$\nabla \ \times \ v = (\frac{\partial v_{z}}{\partial y}-\frac{\partial v_{y}}{\partial z})\hat{i}+(\frac{\partial v_{x}}{\partial z}-\frac{\partial v_{z}}{\partial x})\hat{j}+(\frac{\partial v_{y}}{\partial x}-\frac{\partial v_{x}}{\partial y})\hat{k}$</p>
<p>拉普拉斯算子：定义为梯度的散度，$\Delta f=\nabla^{2}f=\nabla\cdot\nabla f$</p>
<p>矢量拉普拉斯算子：简记为矢拉等于梯散减双旋。$\nabla^{2}\overline{A}=\nabla(\nabla\cdot\overline{A})-\nabla\times\nabla\times\overline{A}$</p>
<ul>
<li>更新规则（多个$\theta$同时更新）：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_19.png" alt=""></p>
<ul>
<li><p>$\alpha$太小，$J(\theta)$收敛太慢；$\alpha$太大，$J(\theta)$也许每次迭代不会减少或者不会收敛</p>
</li>
<li><p>注意特征缩放，使得特征在相似的范围</p>
</li>
<li><p>梯度下降的方向与等高线的切线方向垂直 ⇒ 梯度下降方向与等高线的法线方向相同</p>
</li>
<li><p>对于一元函数来说：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116095053.png" alt=""></p>
</li>
<li><p>多元函数的梯度方向和法向量方向</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/微信截图_20221116162051.png" alt=""></p>
<p>梯度方向是一个函数任一点处上升最快的方向。梯度的投影就是法向量，法向量需要做等高线才能求。$z=f(x,y)$ 是一个函数，$f(x,y)=C$ 则是一个等式。</p>
</li>
</ul>
<h3 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_45.png" alt=""></p>
<p>具体步骤：对参数进行细微的修改，使其对第一个数据拟合得非常好，以此类推</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_46.png" alt=""></p>
<p>如何确定算法已经收敛：每次使用一个训练样本更新$\theta$之前计算$cost(\theta,(x^{(i)},y^{(i)}))$；每1000次迭代计算一下$cost(\theta,(x^{(i)},y^{(i)}))$的均值</p>
<h3 id="Mini-batch-梯度下降法"><a href="#Mini-batch-梯度下降法" class="headerlink" title="Mini-batch 梯度下降法"></a>Mini-batch 梯度下降法</h3><p>主要思想：每次迭代使用b个样本（向量化的时候更好）</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_47.png" alt=""></p>
<h3 id="正规方程法"><a href="#正规方程法" class="headerlink" title="正规方程法"></a>正规方程法</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_20.png" alt=""></p>
<h2 id="logistic回归模型"><a href="#logistic回归模型" class="headerlink" title="logistic回归模型"></a>logistic回归模型</h2><h3 id="logistic回归模型特点"><a href="#logistic回归模型特点" class="headerlink" title="logistic回归模型特点"></a>logistic回归模型特点</h3><ul>
<li>logistic回归是一种分类算法</li>
<li>模型简单、计算量较小</li>
<li>对异常数据点并不敏感</li>
<li>对数据预处理要求较高</li>
</ul>
<h3 id="logistic回归模型主要思想"><a href="#logistic回归模型主要思想" class="headerlink" title="logistic回归模型主要思想"></a>logistic回归模型主要思想</h3><h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><p>sigmoid函数的数学形式是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_21.png" alt=""></p>
<p>对应的函数曲线如下图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/sigmoid.png" alt="sigmod.png"></p>
<h4 id="决策函数"><a href="#决策函数" class="headerlink" title="决策函数"></a>决策函数</h4><p>一个机器学习的模型，实际上是把决策函数限定在某一组条件下，这组限定条件就决定了模型的假设空间。当然，我们还希望这组限定条件简单而合理。而逻辑回归模型所做的假设是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_22.png" alt=""></p>
<p>这里的 <script type="math/tex">g(h)</script> 是上边提到的<code>sigmoid</code>函数，相应的决策函数为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_23.png" alt=""></p>
<p>选择<code>0.5</code>作为阈值是一个一般的做法，实际应用时特定的情况可以选择不同阈值，如果对正例的判别准确性要求高，可以选择阈值大一些，对正例的召回要求高，则可以选择阈值小一些。（根据<code>sigmod</code>函数，即$\theta^{T}x&gt;0$）</p>
<h4 id="参数求解"><a href="#参数求解" class="headerlink" title="参数求解"></a>参数求解</h4><p>模型的数学形式确定后，剩下就是如何去求解模型中的参数。统计学中常用的一种方法是最大似然估计，即找到一组参数，使得在这组参数下，我们的数据的似然度（概率）越大。在逻辑回归模型中，似然度可表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_24.png" alt=""></p>
<p>取对数可以得到对数似然度：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_25.png" alt=""></p>
<h2 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h2><h3 id="决策树算法特点"><a href="#决策树算法特点" class="headerlink" title="决策树算法特点"></a>决策树算法特点</h3><ul>
<li>决策树能用来做回归，也可以用来做分类，是一类算法的总称</li>
<li>决策树是一种弱分类器</li>
<li>决策树是一类具有可解释性、泛化性能较好的模型</li>
<li>精度高、无需特征归一化，能够处理缺失值，共线性特征</li>
<li>适合于低维稠密数据，不适合高维稀疏数据</li>
<li>决策树类算法兼具特征选择能力</li>
</ul>
<h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><p>信息熵<code>S</code>表征了信息不确定性的程度，分类属性应当以最高熵减为标准进行：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_48.png" alt=""></p>
<h3 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h3><p><code>C4.5</code>算法过程跟<code>ID3</code>算法一样，只是选择特征的方法由信息增益改成信息增益比。</p>
<p>特征<code>A</code>对训练数据集<code>D</code>的信息增益比<script type="math/tex">GainRatio(D,A)</script>定义为其信息增益<script type="math/tex">Gain(D,A)</script>与训练数据集D的经验熵<script type="math/tex">H(D)</script>之比</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_49.png" alt=""></p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><h3 id="随机森林算法主要思想"><a href="#随机森林算法主要思想" class="headerlink" title="随机森林算法主要思想"></a>随机森林算法主要思想</h3><ol>
<li><code>bootstrap</code>采样</li>
<li>随机选择特征，选择最佳属性建立决策树</li>
<li>形成随机森林，通过投票得到结果</li>
</ol>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_26.png" alt=""></p>
<h3 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h3><p>输入层、输出层、隐藏层、偏置单元</p>
<p>如果第<code>i</code>层有$s_{i}$个，第<code>i+1</code>层有$s_{i+1}$个，则$\theta$规模为$s_{i+1}*(s_{i}+1)$</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_27.png" alt=""></p>
<h3 id="前向自动微分"><a href="#前向自动微分" class="headerlink" title="前向自动微分"></a>前向自动微分</h3><p>在计算 $y=f(t)$ 时并行地计算 $f’(t)$ 。例如，$f(x_{1},x_{2})=x_{1}\cdot \exp(x_{2})-x_{1}$，模拟前向微分过程。 $y_{1}=\exp(x_{2})$ ， $y_{2}=x_{1}\cdot y_{1}$ ， $y_{3}=y_{2}-x_{1}$ 。此时 $\frac{dy_{1}}{dx_{2}}=\exp(x_{2})$ ， $\frac{dy_{2}}{dx_{1}}=y_{1}=\exp(x_{2})$ ， $\frac{dy_{2}}{dx_{2}}=x_{1}\cdot\frac{dy_{1}}{dx_{2}}=x_{1}\cdot\exp(x_{2})$ ， $\frac{dy_{3}}{dx_{1}}=\frac{dy_{2}}{dx_{1}}-\frac{dx_{1}}{dx_{1}}=\exp(x_{2})-1$ ， $\frac{dy_{3}}{dx_{2}}=\frac{dy_{2}}{dx_{2}}=x_{1}\cdot\exp(x_{2})$ 。</p>
<p>另一种理解是前向自动微分依赖于 dual number，形如 $a+b\epsilon,\ \epsilon^{2}=0,\ \epsilon\neq 0$，我们计算 $h(a+\epsilon)$的时候，可以一次给出 $h(a)$ 和 $h’(a)$。对于函数 $f(x,y)=x^{2}y+y+2$ 来说：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303061706927.png" alt=""></p>
<p>缺点是每次穿过一次图，只能计算一个参数的偏导数，虽然结果精确，但是对于多个参数的时候，要穿过很多次图。</p>
<h3 id="反向自动微分"><a href="#反向自动微分" class="headerlink" title="反向自动微分"></a>反向自动微分</h3><p>思路是正向穿过图来计算每个节点的值，然后二次反向穿过图，计算所有的偏导数。反向自动微分依赖于链式求导法则：$\frac{\partial{f}}{\partial{x}}=\frac{\partial{f}}{\partial{n_{i}}}\times \frac{\partial{n_{i}}}{\partial{x}}$ 。例如，$f(x_{1},x_{2})=x_{1}\cdot \exp(x_{2})-x_{1}$，模拟反向微分过程。$y_{1}=\exp(x_{2})$ ， $y_{2}=x_{1}\cdot y_{1}$ ， $y_{3}=y_{2}-x_{1}$ 。此时 $\frac{\partial{f}}{\partial{y_{3}}}=1$ ， $\frac{\partial{f}}{\partial{y_{2}}}=\frac{\partial{f}}{\partial{y_{3}}}\frac{\partial{y_{3}}}{\partial{y_{2}}}=1 \cdot 1=1$ ， $\frac{\partial{f}}{\partial{y_{1}}}=\frac{\partial{f}}{\partial{y_{2}}}\frac{\partial{y_{2}}}{\partial{y_{1}}}=1\cdot x_{1}=x_{1}$ ， $\frac{\partial{f}}{\partial{x_{2}}}=\frac{\partial{f}}{\partial{y_{1}}}\frac{\partial{y_{1}}}{\partial{x_{2}}}=x_{1}\cdot \exp(x_{2})$ ， $\frac{\partial{f}}{\partial{x_{1}}}=\frac{\partial{f}}{\partial{y_{2}}}\frac{\partial{y_{2}}}{x_{1}}+\frac{\partial{f}}{\partial{y_{3}}}\frac{\partial{y_{3}}}{\partial{x_{1}}}=1\cdot y_{1}+1\cdot (-1)=\exp(x_{2})-1$ 。对于函数 $f(x,y)=x^{2}y+y+2$ 来说：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303061757272.png" alt=""></p>
<p>反向模式的优点：一次反向传播计算出所有的偏导数，中间的偏导数计算计算只需计算一次；减少重复的计算工作量，在多参数的时候反向自动微分的时间复杂度更低。反向模式的缺点：需要额外的数据结构记录正向过程的计算操作；带来了大量内存占用。</p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_28.png" alt=""></p>
<h4 id="检测方法"><a href="#检测方法" class="headerlink" title="检测方法"></a>检测方法</h4><p>双侧差分：$\frac{J(\theta+\varepsilon)-J(\theta-\varepsilon)}{2\varepsilon}\approx\frac{\partial}{\partial z_{j}^{l}}cost(i)$</p>
<p>训练集（60%）、验证集（20%）、测试集（20%）</p>
<p>$J_{train}(\theta)$和$J_{cv}(\theta)$都高时，欠拟合；$J_{train}(\theta)$低$J_{cv}(\theta)$高时，过拟合</p>
<p>随多项式次数增长的关系</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_29.png" alt=""></p>
<p>随$\lambda$增长的关系</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_30.png" alt=""></p>
<p>bias：偏差（underfit）；variance：方差（overfit）</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_31.png" alt=""></p>
<p>Precision：$\frac{true}{predicted}$ ；Recall：$\frac{true}{actual}$；F：$2\frac{PR}{P+R}$</p>
<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_32.png" alt=""></p>
<p>$y^{(i)}=1$时，$\theta^{T}x\geq1$，即$p^{(i)}||\theta||\geq1$；$y^{(i)}=0$时，$\theta^{T}x\leq-1$，即$p^{(i)}||\theta||\leq-1$，$\theta$垂直于边界函数</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_33.png" alt=""></p>
<h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_34.png" alt=""></p>
<p>$x\approx l^{(1)}:f_{1}\approx exp(-\frac{0^{2}}{2\sigma^{2}})\approx 1;else:f_{1}=exp(-\frac{large^{2}}{2\sigma^{2}})\approx 0$</p>
<p>给定$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),(x^{(3)},y^{(3)}),(x^{(4)},y^{(4)})$，</p>
<p>选定$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},l^{(3)}=x^{(3)},l^{(4)}=x^{(4)}$；</p>
<p>对于给定的训练集$(x^{(i)},y^{(i)})$：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_35.png" alt=""></p>
<h2 id="高斯过程回归"><a href="#高斯过程回归" class="headerlink" title="高斯过程回归"></a>高斯过程回归</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>现有如下方程：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418193805.png" alt=""></p>
<p>尝试用高斯过程回归解上述的微分方程。</p>
<h3 id="先验知识"><a href="#先验知识" class="headerlink" title="先验知识"></a>先验知识</h3><h4 id="一维高斯分布"><a href="#一维高斯分布" class="headerlink" title="一维高斯分布"></a>一维高斯分布</h4><p>高斯分布又称正态分布，若随机变量 $X$ 服从一个位置参数为 $\mu$ 、尺度参数为 $\sigma$ 的概率分布，且其概率密度为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418193914.png" alt=""></p>
<p>则这个随机变量就称为正态随机变量，正态随机变量服从的分布就称为正态分布，记作 $X \sim N(\mu,\sigma^{2})$</p>
<h4 id="多维高斯分布"><a href="#多维高斯分布" class="headerlink" title="多维高斯分布"></a>多维高斯分布</h4><p>多维高斯分布其变量为 $n$ 维变量，每个变量之间可能会存在关系，为了描述这种关系，我们引入了协方差矩阵 $\Sigma$ ，其大小为 $n{\times}n$ ，其中每一个元素为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194006.png" alt=""></p>
<p>当维度为2时，2维的高斯分布公式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194048.png" alt=""></p>
<p>当维度大于2时，$n$ 维的高斯分布公式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194122.png" alt=""></p>
<h4 id="高斯过程"><a href="#高斯过程" class="headerlink" title="高斯过程"></a>高斯过程</h4><p>首先当随机变量是1维的时候，我们称之为一维高斯分布，概率密度函数 $p(x)=N(\mu,\sigma^{2})$，当随机变量的维度上升到有限的 $p$ 维的时候，就称之为高维高斯分布 $p(x)=N(\mu,\Sigma_{p \times p})$。而高斯过程则更进一步，他是一个定义在连续域上的无限多个高斯随机变量所组成的随机过程，换句话说，高斯过程是一个无限维的高斯分布。</p>
<p>对于一个连续域 $T$ (假设是一个时间轴)，如果我们在连续域上任选个时刻：$t_{1},t_{2},t_{3},\dots,t_{n}\in T$，使得获得的一个 $n$ 维向量 ${\xi_{1},\xi_{2},\xi_{3},\dots,\xi_{n}}$ 都满足其是一个2维高斯分布，那么这个 ${\xi_{t}}$ 就是一个高斯过程。</p>
<p>举一个实际的例子，直观地建立高斯过程的印象，下面的图中，横轴 $T$ 是一个关于时间的连续域，表示人的一生，而纵轴表示的是体能值，对于同一个人种的男性而言，在任意不同的时间点体能值都服从正态分布，但是不同时间点分布的均值和方差不同。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220301160123.png" alt=""></p>
<p>图中，我们取出了 $t_{1},t_{2},t_{3},t_{4},t_{5}$ 五个时间点，分别代表同一个男性群体童年、少年、青年、中年、老年的具体时刻， $\xi_{1},\xi_{2},\xi_{3},\xi_{4},\xi_{5}$ 分别对应五个时刻的体能值，他们都服从高斯分布，只不过从图中可以看出，均值和方差都不同，那么概括起来：<br>对于任意 $t \in T$ ， $\xi_{t} \sim N(\mu_{t}, \sigma_{t}^{2})$ ，也就是对于一个确定的高斯过程而言，对于任意时刻 $t$ ，他的 $\mu_{t}$ 和 $\sigma_{t}$ 都已经确定了。而像上图中，我们对同一人种男性体能值在关键节点进行采样，然后平滑连接，也就是图中的两条虚线，就形成了这个高斯过程中的两个样本。</p>
<p>$p$ 维高斯分布两个决定性的参数是均值 $\mu_{p}$ 和 $p \times p$ 的协方差矩阵 $\Sigma_{p \times p}$ ，定义在连续域 $T$ 上的高斯过程也一样，他是无限维的高斯分布。不一样的是他是在连续域上的，维数是无限的，因此均值该定义成一个关于时刻 $t$ 的函数： $m(t)$ 。协方差矩阵也是同理，无限维的情况下就定义为一个核函数 $k(s,t)$ ，其中 $s$ 和 $t$ 表示任意两个时刻，核函数也称协方差函数，核函数是一个高斯过程的核心，他决定了高斯过程的性质。其中最常见的一个核函数是径向核函数 $RBF$，其定义如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194246.png" alt=""></p>
<p>高斯过程的两个核心要素：均值函数和核函数的定义我们就描述清楚了，按照高斯过程存在性定理，一旦这两个要素确定了，那么整个高斯过程就确定了： $\xi_{t} \sim GP(m(t), k(t,s))$</p>
<h5 id="高斯过程求解偏微分方程"><a href="#高斯过程求解偏微分方程" class="headerlink" title="高斯过程求解偏微分方程"></a>高斯过程求解偏微分方程</h5><h6 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h6><p>高斯过程 $u$ 的后验均值为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194526.png" alt=""></p>
<p>后验方差为</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194601.png" alt=""></p>
<p>其中</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194636.png" alt=""></p>
<h6 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h6><ol>
<li>在训练的内部和边界分别取 $n^{i}$ ， $n^{b}$ 个点作为训练点，计算 $f(x_{j}^{i})$ ， $g(x_{l}^b)$</li>
<li>定义核函数 $c(x,x’)$ ，目前实现的是一维，取 $d=1$</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194806.png" alt=""></p>
<ol>
<li>计算 $\mathcal{L}c(x,x’)$ ， $\mathcal{B}c(x,x’)$ ， $\mathcal{L}’c(x,x’)$ ， $\mathcal{B}’c(x,x’)$ ， $\mathcal{L}\mathcal{L}’c(X^{i},X^{i})$ ， $\mathcal{L}\mathcal{B}’c(X^{i},X^{b})$ ， $\mathcal{B}\mathcal{B}’c(X^{b},X^{b})$ </li>
<li>寻找最优化的 $\sigma,l_{1},\dots,l_{d}$ ，定义函数 $\mathcal{NLML}(\sigma,l_{1},\dots,l_{d})=\frac{1}{2}y^{T}K^{-1}y+\frac{1}{2}log|K|+\frac{n^{i}+n^{b}}{2}log(2\pi)$ ，求函数的最小值 $f(\sigma^{\star},l_{1}^{\star},\dots,l_{d}^{\star}) \leqslant \mathcal{NLML}(\sigma,l_{1},\dots,l_{d})$ </li>
<li>使用找到的 $\sigma,l_{1},\dots,l_{d}$ 预测 $u(x)$ 在 $x^{\star}$ 的近似值：</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418194906.png" alt=""></p>
<h4 id="高斯过程回归-1"><a href="#高斯过程回归-1" class="headerlink" title="高斯过程回归"></a>高斯过程回归</h4><p>高斯过程回归是一个先验+观测值，然后推出后验的过程。</p>
<p>我们先通过 $\mu (t)$ 和 $k(s,t)$ 定义一个高斯过程，但是因为此时并没有任何的观测值，所以是一个先验。获得了一组观测值之后，如何来修正这个高斯过程的均值函数和核函数，使之得到他的后验过程呢？</p>
<p>高斯分布有一个很好的特性，那就是高斯分布的联合概率、边缘概率、条件概率仍然是满足高斯分布的，假设： $n$ 维随机变量满足高斯分布： $x \sim N(\mu, \Sigma_{n \times n})$ ，把这个 $n$ 维随机变量分成两部分： $p$ 维的 $x_{a}$ 和 $q$ 维的 $x_{b}$ ，满足 $n=p+q$ ，那么按照均值向量 $\mu$ 和协方差矩阵 $\Sigma$ 的分块规则，就可以写成：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418195017.png" alt=""></p>
<p>那么根据高斯分布的性质，我们知道下列条件分布依然是一个高维的高斯分布：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418195055.png" alt=""></p>
<p>也就是说，设置了高斯过程的先验参数，一旦我们拿到一些观测值，那么就可以对高斯过程的均值函数和核函数进行修正，得到一个修正后的后验高斯过程，而更新后验参数的信息就来自于观测值。</p>
<p>将高斯过程和多维高斯分布进行类比，均值向量替换成均值函数，协方差矩阵替换成核函数，就能得到高斯过程基于观测值的后验过程的参数表达式。</p>
<p>假设有一组观测值，他们的时刻对应一个向量 $X$ ，那么对应的值是另一个同纬度的向量的 $Y$ ，假设有4组观测值，即 ${(X[1],Y[1]),(X[2],Y[2]),(X[3],Y[3]),(X[4],Y[4])}$ ，那么余下的所有非观测点，在连续域上定义为 $X^{\star}$ ，值定义为 $f(X^{\star})$ 。</p>
<p>首先，联合分布满足无限维高斯分布：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418195132.png" alt=""></p>
<p>从这个联合分布所派生出来的条件概率 $f(X^{\star})|Y$ 同样也服从高斯分布： $f(X^{\star})|Y \sim N(\mu^{\star}, k^{\star})$ ，</p>
<p>类比一下，将 $Y$ 看作 $x_{a}$ ， $f(X^{\star})$ 看作 $x_{b}$ ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220418195208.png" alt=""></p>
<h2 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_36.png" alt=""></p>
<ol>
<li>初始化k个中心</li>
<li>根据数据离中心的长短进行划分</li>
<li>重新计算k个簇的中心</li>
<li>继续迭代直到达到某个条件</li>
</ol>
<h3 id="初始化K"><a href="#初始化K" class="headerlink" title="初始化K"></a>初始化K</h3><ol>
<li>K&lt;m</li>
<li>多次随机初始化</li>
</ol>
<h3 id="K聚类数量的选取"><a href="#K聚类数量的选取" class="headerlink" title="K聚类数量的选取"></a>K聚类数量的选取</h3><ol>
<li>Elbow method：可以参考</li>
<li>人工、手动、经验</li>
</ol>
<h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><ol>
<li>预处理：数据标准化$x_{j}^{(i)}=x_{j}-\mu_{j}$</li>
<li>计算协方差矩阵$\Sigma=\frac{1}{m}\sum\limits_{i=1}^{n}(x^{(i)})(x^{(i)})^{T}$</li>
<li>计算$\Sigma$的特征矩阵</li>
<li>取前k列，计算出$(U_{reduce})^{T}x^{(i)}$，$k×n×n×1=k×1$</li>
</ol>
<h3 id="PCA维度的选取"><a href="#PCA维度的选取" class="headerlink" title="PCA维度的选取"></a>PCA维度的选取</h3><p>计算$U_{reduce},z^{(1)},z^{(2)},z^{(3)},\cdots,z^{(m),x_{approx}^{(1)},\cdots,x_{approx}^{(m)}}$，判断$\frac{\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}-x_{approx}^{(i)}||^{2}}{\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}||^{2}}\leq0.01?$</p>
<p>简便方法：使用特征值矩阵，计算$1-\frac{\sum\limits_{i=1}^{k}S_{ii}}{\sum\limits_{i=1}^{n}S_{ii}}\leq0.01?$</p>
<h3 id="PCA压缩重现"><a href="#PCA压缩重现" class="headerlink" title="PCA压缩重现"></a>PCA压缩重现</h3><p>$x_{approx}=U_{reduce}·z$</p>
<h2 id="异常检测算法"><a href="#异常检测算法" class="headerlink" title="异常检测算法"></a>异常检测算法</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_37.png" alt=""></p>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>Precision/Recall；$F_{1}$-score</p>
<h3 id="异常检测vs监督学习"><a href="#异常检测vs监督学习" class="headerlink" title="异常检测vs监督学习"></a>异常检测vs监督学习</h3><ol>
<li>很少的正例</li>
<li>大量负例</li>
<li>多种异常</li>
<li>未来可能以前没有的异常</li>
</ol>
<h3 id="如何选择特征"><a href="#如何选择特征" class="headerlink" title="如何选择特征"></a>如何选择特征</h3><p>如果数据没有呈现出高斯分布的形状，对数据进行一些处理，例如：$log(x),x^{\frac{1}{2}}$。</p>
<p>选择既不特别大也不特别小的特征。</p>
<h2 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h2><h3 id="基于内容的推荐算法"><a href="#基于内容的推荐算法" class="headerlink" title="基于内容的推荐算法"></a>基于内容的推荐算法</h3><p>特定用户：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_39.png" alt=""></p>
<p>整体用户：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_40.png" alt=""></p>
<h3 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h3><p>单部影片的特征：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_41.png" alt=""></p>
<p>所有影片的特征：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_42.png" alt=""></p>
<h4 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_43.png" alt=""></p>
<p>归一化：每一行减去均值$\mu_{i}$，预测变为$(\theta^{(i)})^{T}(x^{(i)})+\mu_{i}$</p>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_44.png" alt=""></p>
<h1 id="性能度量指标"><a href="#性能度量指标" class="headerlink" title="性能度量指标"></a>性能度量指标</h1><h2 id="线性回归决定系数-R-2-（判定系数，拟合优度）"><a href="#线性回归决定系数-R-2-（判定系数，拟合优度）" class="headerlink" title="线性回归决定系数$R^{2}$ （判定系数，拟合优度）"></a>线性回归决定系数$R^{2}$ （判定系数，拟合优度）</h2><p>相关系数 $R$ 就是决定系数的开发</p>
<p>决定系数 $R^{2}$ 是衡量回归的好坏，，也就是回归拟合的曲线的拟合优度，也就是得分。</p>
<p>决定系数是表征回归方程在多大程度上解释了因变量的变化，或者说方程对观测值的拟合程度如何。</p>
<p>计算公式为：</p>
<p>设 $y$ 为待拟合数值，其均值为 $\overline{y}$ ，拟合值为 $\widehat{y}$ ，记：</p>
<ul>
<li>总平方和（$SST$）： $\sum\limits_{i=1}\limits^{N}(y_{i}-\overline{y})^{2}$</li>
<li>回归平方和（$SSR$ ）：$\sum\limits_{i=1}\limits^{N}(\hat{y_{i}}-\overline{y})^{2}$</li>
<li>残差平方和（$SSE$）：$\sum\limits_{i=1}\limits^{N}(y_{i}-\hat{y_{i}})^{2}$</li>
</ul>
<p>则有：$SST=SSR+SSE$</p>
<p>决定系数：$R^{2}=\frac{SSR}{SST}=\frac{\sum\limits_{i=1}\limits^{N}(\hat{y_{i}}-\overline{y})^{2}}{\sum\limits_{i=1}\limits^{N}(y_{i}-\hat{y_{i}})^{2}}=1-\frac{SSE}{SST}$</p>
<p>决定系数越大表明拟合优度越好！</p>
<h2 id="分类问题中的评判标准"><a href="#分类问题中的评判标准" class="headerlink" title="分类问题中的评判标准"></a>分类问题中的评判标准</h2><p>以二分类为例，分类结果的混淆矩阵如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_50.png" alt=""></p>
<p>精确率、准确率：$accuracy=\frac{TP+TN}{TP+TN+FP+FN}$</p>
<p>精准率、查准率：$precision=\frac{TP}{TP+FP}$</p>
<p>召回率、查全率：$recall=\frac{TP}{TP+FN}$</p>
<p>调和平均数：$F_{1}=2 \cdot \frac{precision \cdot recall}{precision+reacall}$</p>
<h3 id="P-R​曲线"><a href="#P-R​曲线" class="headerlink" title="P-R​曲线"></a>P-R​曲线</h3><p>我们希望模型预测结果Precision越高越好，同时Recall也越高越好，但事实上这两者在某些情况下有矛盾的。比如极端情况下，我们只预测出了一个正样本的结果，且是准确的，那么Precision就是100%，但是Recall就很低；而如果我们把所有结果都返回，那么比如Recall是100%，但是Precision就会很低。因此在不同的场合中需要自己判断希望Precision比较高或是Recall比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_51.png" alt=""></p>
<p>P-R图直观的显示出学习器在样本总体上的查全率和查准率，在进行比较时，若一个学习器的PR曲线被另一个学习器的PR曲线完全包住，则可以断言后者的性能优于前者（如图中A优于C）。如果两个学习器发生了交叉，则难以断言孰优孰劣，只能在具体的查准率或查全率条件下进行比较（如图中A和B）。如果一定要比较A和B孰优孰劣，一个合理的比较依据是比较PR曲线下面积的大小。在一定程度上表征了学习器在查准率和查全率上取得“双高”的比例，但这个值不太容易估算。所以设计了一些综合考虑查准率和查全率的性能度量。比如“平衡点”（Break-Even Point，BEP），是“查准率=查全率”时的取值。例如学习器C的BEP是0.64,，基于BEP比较，可认为学习器A优于B。</p>
<h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p>ROC的全称是Receiver Operating Characteristic Curve，中文名字叫“受试者工作特征曲线”，顾名思义，其主要的分析方法就是画这条特征曲线。如果在模型中我们没有定好阈值，而是将模型预测结果从高到低排序，将每次概率值依次作为阈值，那么就可以得到多个混淆矩阵。对于每个混淆矩阵，我们计算两个指标TPR和FPR，以FPR为x轴，TPR为y轴画图，就得到了ROC曲线。该曲线的横坐标为假阳性率（False Positive Rate, FPR），N是真实负样本的个数，FP是N个负样本中被分类器预测为正样本的个数。纵坐标为真阳性率（True Positive Rate, TPR），P是真实正样本的个数，TP是P个正样本中被分类器预测为正样本的个数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_52.png" alt=""></p>
<h4 id="为什么选择ROC曲线"><a href="#为什么选择ROC曲线" class="headerlink" title="为什么选择ROC曲线"></a>为什么选择ROC曲线</h4><p>既然已经这么多评价标准，为什么还要使用ROC曲线呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。下图是ROC曲线和Precision-Recall曲线的对比：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505301522475.png" alt=""></p>
<p>其中第一行ab均为原数据的图，左边为ROC曲线，右边为P-R曲线。第二行cd为负样本增大10倍后俩个曲线的图。可以看出，ROC曲线基本没有变化，但P-R曲线确剧烈震荡。因此，在面对正负样本数量不均衡的场景下，ROC曲线（AUC的值）会是一个更加稳定能反映模型好坏的指标。</p>
<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p>按照定义，AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，表明分类器对于正例和负例毫无区分能力。而我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x，因此大部分的ROC曲线长成下面这个样子：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/pic_53.png" alt=""></p>
<p>最理想的情况下，即没有真实类别为1而错分为0的样本（TPRate一直为1），也没有真实类别为0而错分为1的样本（FPRate一直为0），AUC为1，这便是AUC的极大值。</p>
<h4 id="AUC曲线的物理意义"><a href="#AUC曲线的物理意义" class="headerlink" title="AUC曲线的物理意义"></a>AUC曲线的物理意义</h4><p>AUC的物理意义可以从两个角度来解释。首先，从物理学角度来看，AUC可以被认为是分类器对于正负样本的区分能力的一种物理量度。它被定义为ROC曲线下的面积，描述了分类器在所有可能的阈值下对正负样本的区分能力。</p>
<p>其次，在机器学习领域中，AUC被广泛应用于二分类问题中，用于衡量分类器对正负样本的区分能力。AUC越大，表示分类器对于正负样本的区分能力越强，即分类器能够更好地将正样本和负样本分开。而AUC越小，则表示分类器对于正负样本的区分能力越弱，即分类器不能很好地将正样本和负样本分开。</p>
<p>因此，AUC的物理意义可以被解释为一个物理系统中的能量积分，用于描述该系统的能量积分性能。在物理学中，能量积分是指对于一个物理系统中的所有可能状态，将每个状态的能量乘以该状态出现的概率，然后将所有状态的能量乘以概率的积分。这个积分值就是该物理系统的能量积分。在机器学习中，AUC也可以被解释为分类器对于正负样本的区分能力的一种物理量度。</p>
<h4 id="AUC的计算公式"><a href="#AUC的计算公式" class="headerlink" title="AUC的计算公式"></a>AUC的计算公式</h4><h5 id="定义法"><a href="#定义法" class="headerlink" title="定义法"></a>定义法</h5><p>假设数据集中一共有<code>M</code>个正样本，<code>N</code>个负样本，共<code>MN</code>样本对。统计正样本预测概率大于负样本预测概率的个数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505301603622.png" alt=""></p>
<p>其中：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505301605941.png" alt=""></p>
<p>假设有4条样本，2个正样本（D和C）+2个负样本（A和B），共4个样本对。分别为：(D+, B-), (D+, A-), (C+, B-), (C+,A-)。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505301607340.png" alt=""></p>
<p>在(D, B)样本对中，正样本D预测概率大于负样本B预测概率（即D的得分比B高）记为1。同理，对于(C, B)。正样本C预测的概率小于负样本C预测概率记为0。整理如下：</p>
<p>I(D+, B-) = 1、I(D+, A-) = 1、I(C+, B-) = 0、I(C+,A-) = 1</p>
<p>共3对样本符合正样本得分高于负样本得分，故AUC为 (1 + 1 + 1 + 0) / 4 = 0.75</p>
<p>假如出现得分一致时，例如：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505301608063.png" alt=""></p>
<p>同样本是4个样本对，对于样本对(C+, B-)，其 I 值为0.5。最后的AUC为 AUC = (1 + 1+ 1 + 0.5) / 4 = 0.875</p>
<h5 id="公式法"><a href="#公式法" class="headerlink" title="公式法"></a>公式法</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308261737231.jpg" alt=""></p>
<ul>
<li>对预测概率从高到低排序</li>
<li>对每一个概率值设一个rank值（最高的概率的rank为n，第二高的为n-1）</li>
<li>rank实际上代表了该score（预测概率）超过的样本的数目。为了求的组合中正样本的score值大于负样本，如果所有的正样本score值都是大于负样本的，那么第一位与任意的进行组合score值都要大，我们取它的rank值为n，但是n-1中有M-1是正样例和正样例的组合这种是不在统计范围内的（为计算方便我们取n组，相应的不符合的有M个），所以要减掉，那么同理排在第二位的n-1，会有M-1个是不满足的，依次类推，故得到后面的公式 $M\ast(M+1)/2$，我们可以验证在正样本score都大于负样本的假设下，AUC的值为1。<strong>如果排序的时候有概率相同的，原则就是相等得分的rank取平均值。</strong></li>
<li>除以 $M \ast N$</li>
</ul>
<p>例子：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308261747231.png" alt=""></p>
<ul>
<li>对于正样本A，其rank值为7</li>
<li>对于正样本B，其rank值为6</li>
<li>对于正样本E，其rank值为（5+4+3+2）/ 4</li>
<li>对于正样本F，其rank值为（5+4+3+2）/ 4</li>
<li>最后的结果就为：$\frac{7+6+(5+4+3+2)/4+(5+4+3+2)/4-4 \ast 5/2}{4 \ast 3}=10/12$</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>毕设知识点总结</title>
    <url>/2021/04/06/%E6%AF%95%E8%AE%BE%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>毕设的项目也算是做完了，总结一下项目过程中遇见的一些问题和解决方案，避免以后再次踩坑。</p>
<a id="more"></a>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="current-user的实现机制"><a href="#current-user的实现机制" class="headerlink" title="current_user的实现机制"></a>current_user的实现机制</h2><ol>
<li><p>首先需要创建一个<code>LoginManager</code>的对象实例并注册到<code>app</code>对象实例之中，并提供一个<code>load_user</code>回调函数来获取当前登录的对象</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 会话管理</span></span><br><span class="line">login_manager = LoginManager()</span><br><span class="line"><span class="comment"># 绑定登陆视图的路由</span></span><br><span class="line">login_manager.login_view = <span class="string">&quot;login&quot;</span></span><br><span class="line">login_manager.login_message = <span class="string">&quot;请您先登陆！&quot;</span></span><br><span class="line">login_manager.session_protection = <span class="string">&quot;strong&quot;</span></span><br><span class="line">app.config[<span class="string">&quot;SECRET_KEY&quot;</span>] = <span class="string">&quot;123456&quot;</span></span><br><span class="line">login_manager.init_app(app)</span><br><span class="line"></span><br><span class="line"><span class="meta">@login_manager.user_loader</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_user</span>(<span class="params">user_id</span>):</span></span><br><span class="line">    <span class="keyword">return</span> User.query.filter_by(user_id=user_id).first()</span><br></pre></td></tr></table></figure>
<p>注：<code>load_user</code>接受一个<code>unicode</code>编码的 <code>ID</code>并返回一个用户对象，如果用户不存在就返回<code>None</code>。</p>
</li>
</ol>
<ol>
<li><p>接着你的<code>User</code>模型要继承<code>UserMixin</code>这个类，并且实现<code>is_authenticated</code>、<code>is_active</code>、<code>is_anonymous</code>、<code>get_id</code>方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_authenticated</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_active</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_anonymous</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 后面login_user用来作为用户的id</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_id</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> self.user_id</span><br></pre></td></tr></table></figure></li>
<li><p>在登陆时调用<code>login_user</code>方法，然后就可以在上下文之中随时随地使用<code>current_user</code>了</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login_user</span>(<span class="params">user, remember=<span class="literal">False</span>, force=<span class="literal">False</span>, fresh=<span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> force <span class="keyword">and</span> <span class="keyword">not</span> user.is_active:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    user_id = <span class="built_in">getattr</span>(user, current_app.login_manager.id_attribute)()</span><br><span class="line">    session[<span class="string">&#x27;user_id&#x27;</span>] = user_id</span><br><span class="line">    session[<span class="string">&#x27;_fresh&#x27;</span>] = fresh</span><br><span class="line">    session[<span class="string">&#x27;_id&#x27;</span>] = current_app.login_manager._session_identifier_generator()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> remember:</span><br><span class="line">        session[<span class="string">&#x27;remember&#x27;</span>] = <span class="string">&#x27;set&#x27;</span></span><br><span class="line"></span><br><span class="line">    _request_ctx_stack.top.user = user</span><br><span class="line">    user_logged_in.send(current_app._get_current_object(), user=_get_user())</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>用户的<code>user_id</code>是通过<code>get_attr</code>方法访问<code>login_manager</code>的<code>id_attribute</code>属性实现的，而最终访问的<code>user_id</code>就是在上一步在模型中添加的<code>get_id</code>方法获取到的值</p>
</li>
</ol>
<h2 id="openpyxl对excel的操作"><a href="#openpyxl对excel的操作" class="headerlink" title="openpyxl对excel的操作"></a>openpyxl对excel的操作</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> openpyxl</span><br><span class="line"><span class="comment"># 创建工作簿（默认创建一个工作表）</span></span><br><span class="line">new_excel = openpyxl.Workbook()</span><br><span class="line"><span class="comment"># 选中第一个工作簿</span></span><br><span class="line">work_sheet = new_excel.active</span><br><span class="line"><span class="comment"># 设置表头</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(optional_headers)):</span><br><span class="line">    work_sheet.cell(row=<span class="number">1</span>, column=i+<span class="number">1</span>, value=optional_headers[i]).alignment = Alignment(wrapText=<span class="literal">True</span>, horizontal=<span class="string">&#x27;center&#x27;</span>, vertical=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">    <span class="comment"># 填写内容</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(data_list)):</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(data_list[<span class="number">0</span>])):</span><br><span class="line">        work_sheet.cell(row=j+<span class="number">2</span>, column=k+<span class="number">1</span>, value=data_list[j][k]).alignment = Alignment(wrapText=<span class="literal">True</span>, horizontal=<span class="string">&#x27;center&#x27;</span>, vertical=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"><span class="comment"># 用时间戳给文件命名</span></span><br><span class="line">now_time = datetime.now().strftime(<span class="string">&quot;%Y-%m-%d-%H-%M-%S&quot;</span>).replace(<span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">excel_name = current_user.user_name + <span class="string">&#x27;_&#x27;</span> + now_time + <span class="string">&#x27;_&#x27;</span></span><br><span class="line"><span class="keyword">if</span> data[<span class="string">&quot;export_type&quot;</span>] == <span class="number">0</span>:</span><br><span class="line">    excel_name = excel_name + <span class="string">&quot;专利信息.xls&quot;</span></span><br><span class="line"><span class="keyword">elif</span> data[<span class="string">&quot;export_type&quot;</span>] == <span class="number">1</span>:</span><br><span class="line">    excel_name = excel_name + <span class="string">&quot;论文信息.xls&quot;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    excel_name = excel_name + <span class="string">&quot;项目信息.xls&quot;</span></span><br><span class="line">new_excel.save(<span class="string">&quot;.\\files\\&quot;</span> + excel_name)</span><br><span class="line">new_excel.close()</span><br></pre></td></tr></table></figure>
<h2 id="后端发送文件到前端"><a href="#后端发送文件到前端" class="headerlink" title="后端发送文件到前端"></a>后端发送文件到前端</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = make_response(send_from_directory(<span class="string">&quot;.\\files&quot;</span>, excel_name))</span><br><span class="line">res.headers[<span class="string">&#x27;Content-Type&#x27;</span>] = <span class="string">&#x27;text/plain;charset=UTF-8&#x27;</span></span><br><span class="line">res.headers[<span class="string">&#x27;filename&#x27;</span>] = quote(excel_name.encode(<span class="string">&quot;utf-8&quot;</span>))</span><br></pre></td></tr></table></figure>
<h2 id="前端以POST方式请求下载文件"><a href="#前端以POST方式请求下载文件" class="headerlink" title="前端以POST方式请求下载文件"></a>前端以POST方式请求下载文件</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$.ajax(&#123;</span><br><span class="line">    type: <span class="string">&quot;POST&quot;</span>,</span><br><span class="line">    url: <span class="built_in">window</span>.location.pathname,</span><br><span class="line">    contentType: <span class="string">&quot;application/json;charset=UTF-8&quot;</span>,</span><br><span class="line">    data:<span class="built_in">JSON</span>.stringify(data),</span><br><span class="line">    xhrFields:&#123;</span><br><span class="line">        responseType: <span class="string">&#x27;blob&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="function"><span class="title">success</span>(<span class="params">res, status, xhr</span>)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (res)&#123;</span><br><span class="line">            <span class="keyword">let</span> parse_data = <span class="keyword">new</span> Blob([res]);</span><br><span class="line">            <span class="keyword">let</span> download_url = <span class="built_in">window</span>.URL.createObjectURL(parse_data);</span><br><span class="line">            <span class="keyword">let</span> filename = xhr.getResponseHeader(<span class="string">&quot;filename&quot;</span>);</span><br><span class="line">            <span class="keyword">let</span> link = <span class="built_in">document</span>.createElement(<span class="string">&#x27;a&#x27;</span>);</span><br><span class="line">            link.href = download_url;</span><br><span class="line">            link.download = filename;</span><br><span class="line">            link.click();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="邮件及缓存"><a href="#邮件及缓存" class="headerlink" title="邮件及缓存"></a>邮件及缓存</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask_mail <span class="keyword">import</span> Message, Mail</span><br><span class="line"><span class="keyword">from</span> flask_caching <span class="keyword">import</span> Cache</span><br><span class="line"></span><br><span class="line"><span class="comment"># 邮件</span></span><br><span class="line">mail = Mail(app)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 缓存</span></span><br><span class="line">cache = Cache(app)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成验证码</span></span><br><span class="line">code_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    random_num = random.randint(<span class="number">0</span>, <span class="number">9</span>)</span><br><span class="line">    code_list.append(<span class="built_in">str</span>(random_num))</span><br><span class="line">verification_code = <span class="string">&#x27;&#x27;</span>.join(code_list)</span><br><span class="line"><span class="comment"># 发送邮件</span></span><br><span class="line">message = Message(<span class="string">&#x27;科研信息管理系统验证码&#x27;</span>, recipients=[email_account], body=<span class="string">&#x27;您的验证码是：%s&#x27;</span> % verification_code)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 发送</span></span><br><span class="line">    mail.send(message)</span><br><span class="line">    <span class="comment"># 验证码放入缓存</span></span><br><span class="line">    cache.<span class="built_in">set</span>(email_account, verification_code)</span><br><span class="line">    data = <span class="string">&quot;验证码发送成功&quot;</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    data = <span class="string">&quot;验证码发送失败，请检查邮箱是否输入正确&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="推送flask上下文"><a href="#推送flask上下文" class="headerlink" title="推送flask上下文"></a>推送flask上下文</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">app.app_context().push()</span><br></pre></td></tr></table></figure>
<h2 id="前端拖动插件dragula-js"><a href="#前端拖动插件dragula-js" class="headerlink" title="前端拖动插件dragula.js"></a>前端拖动插件dragula.js</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Modal Popup--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal fade&quot;</span> <span class="attr">id</span>=<span class="string">&quot;exampleModalCenter&quot;</span> <span class="attr">tabindex</span>=<span class="string">&quot;-1&quot;</span> <span class="attr">role</span>=<span class="string">&quot;dialog&quot;</span> <span class="attr">aria-labelledby</span>=<span class="string">&quot;exampleModalCenterTitle&quot;</span> <span class="attr">aria-hidden</span>=<span class="string">&quot;true&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-dialog modal-dialog-centered&quot;</span> <span class="attr">role</span>=<span class="string">&quot;document&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-content&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-header&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">h5</span> <span class="attr">class</span>=<span class="string">&quot;modal-title&quot;</span> <span class="attr">id</span>=<span class="string">&quot;exampleModalCenterTitle&quot;</span>&gt;</span>请选择需要导出的信息项<span class="tag">&lt;/<span class="name">h5</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> <span class="attr">class</span>=<span class="string">&quot;close&quot;</span> <span class="attr">data-dismiss</span>=<span class="string">&quot;modal&quot;</span> <span class="attr">aria-label</span>=<span class="string">&quot;Close&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">aria-hidden</span>=<span class="string">&quot;true&quot;</span>&gt;</span><span class="symbol">&amp;times;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-body&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;row&quot;</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;bagger&quot;</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;col-md-6&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;left&quot;</span> <span class="attr">class</span>=<span class="string">&quot;includer&quot;</span> <span class="attr">style</span>=<span class="string">&quot;background-color: rgb(161, 211, 169);&quot;</span>&gt;</span></span><br><span class="line">                            &#123;% if patent_headers %&#125;</span><br><span class="line">                            &#123;% for item in patent_headers  %&#125;</span><br><span class="line">                            <span class="tag">&lt;<span class="name">div</span>&gt;</span>&#123;&#123; item &#125;&#125;<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                            &#123;% endfor %&#125;</span><br><span class="line">                            &#123;% endif %&#125;</span><br><span class="line">                        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;right&quot;</span> <span class="attr">class</span>=<span class="string">&quot;includer&quot;</span> <span class="attr">style</span>=<span class="string">&quot;background-color: rgb(187, 206, 235);&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;col-md-6&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;col-md-6&quot;</span> <span class="attr">style</span>=<span class="string">&quot;text-align: center;&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">strong</span>&gt;</span>可选信息项<span class="tag">&lt;/<span class="name">strong</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;col-md-6&quot;</span> <span class="attr">style</span>=<span class="string">&quot;text-align: center;&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">strong</span>&gt;</span>已选信息项<span class="tag">&lt;/<span class="name">strong</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-footer&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> <span class="attr">class</span>=<span class="string">&quot;btn btn-secondary&quot;</span> <span class="attr">data-dismiss</span>=<span class="string">&quot;modal&quot;</span>&gt;</span>关闭<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- /.col-sm-9 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- /Modal Popup--&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="前端省市区地址选择distpicker-js"><a href="#前端省市区地址选择distpicker-js" class="headerlink" title="前端省市区地址选择distpicker.js"></a>前端省市区地址选择distpicker.js</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">data-toggle</span>=<span class="string">&quot;distpicker&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-inline&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">data-province</span>=<span class="string">&quot;省&quot;</span> <span class="attr">name</span>=<span class="string">&quot;province&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">data-city</span>=<span class="string">&quot;市&quot;</span> <span class="attr">name</span>=<span class="string">&quot;city&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">data-district</span>=<span class="string">&quot;区/县&quot;</span> <span class="attr">name</span>=<span class="string">&quot;district&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">placeholder</span>=<span class="string">&quot;详细通讯地址&quot;</span> <span class="attr">name</span>=<span class="string">&quot;address&quot;</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="前端表格datatable-js"><a href="#前端表格datatable-js" class="headerlink" title="前端表格datatable.js"></a>前端表格datatable.js</h2><ol>
<li><p>生成<code>datatable</code></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$(<span class="string">&quot;#select-all&quot;</span>).prop(<span class="string">&quot;checked&quot;</span>, <span class="literal">false</span>);</span><br><span class="line">atable = $(<span class="string">&#x27;#patent_table&#x27;</span>).dataTable();</span><br><span class="line">atable.fnClearTable(); <span class="comment">//清空一下table</span></span><br><span class="line">atable.fnDestroy();<span class="comment">//还原初始化了的datatable;</span></span><br><span class="line">$(<span class="string">&quot;#patent_table&quot;</span>).css(<span class="string">&#x27;display&#x27;</span>, <span class="string">&#x27;none&#x27;</span>);</span><br><span class="line">btable = $(<span class="string">&#x27;#project_table&#x27;</span>).dataTable();</span><br><span class="line">btable.fnClearTable(); <span class="comment">//清空一下table</span></span><br><span class="line">btable.fnDestroy();<span class="comment">//还原初始化了的datatable;</span></span><br><span class="line">$(<span class="string">&quot;#project_table&quot;</span>).css(<span class="string">&#x27;display&#x27;</span>, <span class="string">&#x27;none&#x27;</span>);</span><br><span class="line">$(<span class="string">&quot;#paper_table&quot;</span>).show();</span><br><span class="line">otable = $(<span class="string">&#x27;#paper_table&#x27;</span>).dataTable();</span><br><span class="line">otable.fnClearTable(); <span class="comment">//清空一下table</span></span><br><span class="line">otable.fnDestroy();<span class="comment">//还原初始化了的datatable;</span></span><br><span class="line">$(<span class="string">&quot;#paper_table tbody&quot;</span>).empty().append(table_data[<span class="string">&quot;html&quot;</span>]);</span><br><span class="line">$(<span class="string">&#x27;#paper_table&#x27;</span>).DataTable(&#123;</span><br><span class="line">    <span class="string">&quot;order&quot;</span>: [],</span><br><span class="line">    <span class="string">&quot;columnDefs&quot;</span>: [&#123;</span><br><span class="line">        <span class="string">&quot;targets&quot;</span>: <span class="string">&#x27;no-sort&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;orderable&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">    &#125;],</span><br><span class="line">    <span class="string">&quot;lengthMenu&quot;</span>: [<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>],</span><br><span class="line">    <span class="string">&quot;bAutoWidth&quot;</span>: <span class="literal">false</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>获取<code>datatable</code>被选中的数据</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> table = $(<span class="string">&quot;#project_table&quot;</span>).dataTable();</span><br><span class="line"><span class="keyword">let</span> projects_delete = [];</span><br><span class="line"><span class="keyword">let</span> checked_collection = table.$(<span class="string">&quot;input[type=&#x27;checkbox&#x27;]:checked&quot;</span>,&#123;<span class="string">&quot;page&quot;</span>:<span class="string">&quot;all&quot;</span>&#125;);</span><br><span class="line">checked_collection.each(<span class="function"><span class="keyword">function</span> (<span class="params">index, elem</span>) </span>&#123;</span><br><span class="line">    projects_delete.push($(elem).attr(<span class="string">&quot;id&quot;</span>));</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="前端柱状图"><a href="#前端柱状图" class="headerlink" title="前端柱状图"></a>前端柱状图</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">(<span class="function"><span class="keyword">function</span>(<span class="params">$</span>) </span>&#123;</span><br><span class="line"><span class="meta">    &quot;use strict&quot;</span>; <span class="comment">// Start of use strict</span></span><br><span class="line">    <span class="comment">//line Morris</span></span><br><span class="line">    <span class="keyword">var</span> lineMorris = <span class="keyword">new</span> Morris.Line(&#123;</span><br><span class="line">        element: <span class="string">&#x27;lineMorris&#x27;</span>,</span><br><span class="line">        resize: <span class="literal">true</span>,</span><br><span class="line">        data: paper_data,</span><br><span class="line">        xkey: <span class="string">&#x27;year&#x27;</span>,</span><br><span class="line">        ykeys: [<span class="string">&#x27;amounts&#x27;</span>],</span><br><span class="line">        labels: [<span class="string">&#x27;论文数量&#x27;</span>],</span><br><span class="line">        gridLineColor: <span class="string">&#x27;#eef0f2&#x27;</span>,</span><br><span class="line">        lineColors: [<span class="string">&#x27;#E57498&#x27;</span>],</span><br><span class="line">        lineWidth: <span class="number">2</span>,</span><br><span class="line">        hideHover: <span class="string">&#x27;auto&#x27;</span></span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">//barmorris</span></span><br><span class="line">    <span class="keyword">var</span> ctx = <span class="built_in">document</span>.getElementById(<span class="string">&quot;barMorris&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (ctx === <span class="literal">null</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> chart = Morris.Bar(&#123;</span><br><span class="line">        element: <span class="string">&#x27;barMorris&#x27;</span>,</span><br><span class="line">        data: project_data,</span><br><span class="line">        xkey: <span class="string">&#x27;year&#x27;</span>,</span><br><span class="line">        ykeys: [<span class="string">&#x27;amounts&#x27;</span>],</span><br><span class="line">        labels: [<span class="string">&#x27;项目数量&#x27;</span>],</span><br><span class="line">        barColors: [<span class="string">&#x27;#FF7D00&#x27;</span>],</span><br><span class="line">        barOpacity: <span class="number">1</span>,</span><br><span class="line">        barSizeRatio: <span class="number">0.5</span>,</span><br><span class="line">        hideHover: <span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">        gridLineColor: <span class="string">&#x27;#eef0f2&#x27;</span>,</span><br><span class="line">        resize: <span class="literal">true</span></span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">// morris donut charts</span></span><br><span class="line">    <span class="keyword">if</span> ($(<span class="string">&quot;#donutMorris&quot;</span>).length == <span class="number">1</span>) &#123;</span><br><span class="line">        Morris.Donut(&#123;</span><br><span class="line">            element: <span class="string">&#x27;donutMorris&#x27;</span>,</span><br><span class="line">            data: patent_data,</span><br><span class="line">            barSize: <span class="number">0.1</span>,</span><br><span class="line">            labelColor: <span class="string">&#x27;#3e5569&#x27;</span>,</span><br><span class="line">            resize: <span class="literal">true</span>, <span class="comment">//defaulted to true</span></span><br><span class="line">            colors: [<span class="string">&#x27;#FFAA2A&#x27;</span>, <span class="string">&#x27;#E57498&#x27;</span>, <span class="string">&#x27;#22c6ab&#x27;</span>]</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)(jQuery);</span><br></pre></td></tr></table></figure>
<h2 id="截图工具"><a href="#截图工具" class="headerlink" title="截图工具"></a>截图工具</h2><ol>
<li><p><code>tkinter</code>制作简易主界面</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 让系统知道使用者看到的尺寸</span></span><br><span class="line">user32 = windll.user32</span><br><span class="line">user32.SetProcessDPIAware()</span><br><span class="line"><span class="comment"># 主窗体</span></span><br><span class="line">root = Tk()</span><br><span class="line">root.wm_attributes(<span class="string">&#x27;-topmost&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">root.title(<span class="string">&quot;文字识别&quot;</span>)</span><br><span class="line">root.geometry(<span class="string">&quot;300x100&quot;</span>)</span><br><span class="line">root.resizable(width=<span class="literal">False</span>, height=<span class="literal">False</span>)</span><br><span class="line">new_menu = Menu(root)</span><br><span class="line">new_menu.add_command(label=<span class="string">&quot;开始识别&quot;</span>, command=cut)</span><br><span class="line">new_text = Text(root, show=<span class="literal">None</span>)</span><br><span class="line">new_text.place(width=<span class="number">300</span>, height=<span class="number">100</span>)</span><br><span class="line">root[<span class="string">&quot;menu&quot;</span>] = new_menu</span><br><span class="line"><span class="comment"># 识别之后的结果</span></span><br><span class="line">text = <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>调用<code>ImageGrab.grab()</code>方法截全屏并处理选中区域</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 截图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut</span>():</span></span><br><span class="line">    <span class="keyword">global</span> img</span><br><span class="line">    screen_cut()</span><br><span class="line">    img = cv2.imread(<span class="string">&#x27;screen.jpg&#x27;</span>)</span><br><span class="line">    cv2.namedWindow(<span class="string">&#x27;image&#x27;</span>)</span><br><span class="line">    cv2.setMouseCallback(<span class="string">&#x27;image&#x27;</span>, on_mouse)</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;image&#x27;</span>, img)</span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">    os.remove(<span class="string">&#x27;screen.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 截取整个屏幕</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">screen_cut</span>():</span></span><br><span class="line">    image = ImageGrab.grab()</span><br><span class="line">    image.save(<span class="string">&quot;screen.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据鼠标事件进行裁剪</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">on_mouse</span>(<span class="params">event, x, y, flags, param</span>):</span></span><br><span class="line">    <span class="keyword">global</span> img, point1, point2</span><br><span class="line">    img2 = img.copy()</span><br><span class="line">    <span class="comment"># 左键点击</span></span><br><span class="line">    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDOWN:</span><br><span class="line">        point1 = (x, y)</span><br><span class="line">        cv2.circle(img2, point1, <span class="number">10</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">5</span>)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;image&#x27;</span>, img2)</span><br><span class="line">    <span class="comment"># 按住左键拖曳</span></span><br><span class="line">    <span class="keyword">elif</span> event == cv2.EVENT_MOUSEMOVE <span class="keyword">and</span> (flags &amp; cv2.EVENT_FLAG_LBUTTON):</span><br><span class="line">        cv2.rectangle(img2, point1, (x, y), (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">5</span>)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;image&#x27;</span>, img2)</span><br><span class="line">    <span class="comment"># 左键释放</span></span><br><span class="line">    <span class="keyword">elif</span> event == cv2.EVENT_LBUTTONUP:</span><br><span class="line">        point2 = (x, y)</span><br><span class="line">        cv2.rectangle(img2, point1, point2, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">5</span>)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;image&#x27;</span>, img2)</span><br><span class="line">        min_x = <span class="built_in">min</span>(point1[<span class="number">0</span>], point2[<span class="number">0</span>])</span><br><span class="line">        min_y = <span class="built_in">min</span>(point1[<span class="number">1</span>], point2[<span class="number">1</span>])</span><br><span class="line">        width = <span class="built_in">abs</span>(point1[<span class="number">0</span>] - point2[<span class="number">0</span>])</span><br><span class="line">        height = <span class="built_in">abs</span>(point1[<span class="number">1</span>] - point2[<span class="number">1</span>])</span><br><span class="line">        cut_img = img[min_y:min_y+height, min_x:min_x+width]</span><br><span class="line">        <span class="comment"># 不存在则新建目录</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;.\\photos&quot;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;.\\photos&#x27;</span>)</span><br><span class="line">        path = <span class="string">&#x27;.\\photos\\cut.png&#x27;</span></span><br><span class="line">        new_text.delete(<span class="number">0.0</span>, END)</span><br><span class="line">        cv2.imwrite(path, cut_img)</span><br><span class="line">        get_text_by_ocr(path)</span><br><span class="line">        new_text.insert(<span class="string">&quot;insert&quot;</span>, text)</span><br><span class="line">        cv2.waitKey(<span class="number">1000</span>)</span><br><span class="line">        cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>调用百度接口进行文字识别，<code>APP_ID</code>、<code>APP_KEY</code>、<code>SECRET_KEY</code>需要自己申请</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 图片识别成文字</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_text_by_ocr</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">global</span> text</span><br><span class="line">    client = AipOcr(APP_ID, APP_KEY, SECRET_KEY)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        image = f.read()</span><br><span class="line">        all_data = client.basicAccurate(image)</span><br><span class="line">        text = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, all_data[<span class="string">&quot;words_result_num&quot;</span>]):</span><br><span class="line">            text += all_data[<span class="string">&quot;words_result&quot;</span>][i][<span class="string">&quot;words&quot;</span>]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="爬虫"><a href="#爬虫" class="headerlink" title="爬虫"></a>爬虫</h2><p>选取了request和selenium（自动化测试常用库，但用于爬虫简单易上手）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 不显式打开浏览器以及不使用GPU加速</span></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)</span><br><span class="line">browser = webdriver.Chrome(self.executable_path, options=options)</span><br><span class="line"><span class="comment"># 使用xpath获取元素</span></span><br><span class="line">keywords = browser.find_element_by_xpath(<span class="string">&quot;//span[text()=&#x27;关键词：&#x27;]/following-sibling::p&quot;</span>).text</span><br><span class="line">keywords = browser.find_element_by_xpath(<span class="string">&quot;//span[contains(text(),&#x27;关键词：&#x27;)]&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="pyinstaller打包成exe报毒"><a href="#pyinstaller打包成exe报毒" class="headerlink" title="pyinstaller打包成exe报毒"></a>pyinstaller打包成exe报毒</h2><p>下面的方法可以完全不报毒，但是原理未知。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pyinstaller -w 你的文件名.py --onefile</span><br></pre></td></tr></table></figure>
<h2 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h2><p>前端上传：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$(<span class="string">&quot;#new_projects_submit&quot;</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    $(<span class="string">&quot;#projects_upload&quot;</span>).click();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">$(<span class="string">&quot;#projects_upload&quot;</span>).on(<span class="string">&quot;change&quot;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    $(<span class="string">&quot;#projects_confirm&quot;</span>).click();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">$(<span class="string">&quot;#projects_confirm&quot;</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> fileObj = <span class="built_in">document</span>.getElementById(<span class="string">&quot;projects_upload&quot;</span>).files[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">typeof</span>(fileObj) == <span class="string">&quot;undefined&quot;</span> || fileObj.size &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        alert(<span class="string">&quot;未选择文件,请重试！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    $(<span class="string">&quot;#projects_upload&quot;</span>).val(<span class="string">&quot;&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> formFile = <span class="keyword">new</span> FormData();</span><br><span class="line">    formFile.append(<span class="string">&quot;action&quot;</span>, <span class="string">&quot;UploadVMKImagePath&quot;</span>);</span><br><span class="line">    formFile.append(<span class="string">&quot;file&quot;</span>, fileObj); <span class="comment">//加入文件对象</span></span><br><span class="line">    $.ajax(&#123;</span><br><span class="line">        url: <span class="string">&quot;/add/projects&quot;</span>,</span><br><span class="line">        data: formFile,</span><br><span class="line">        type: <span class="string">&quot;POST&quot;</span>,</span><br><span class="line">        dataType: <span class="string">&quot;json&quot;</span>,</span><br><span class="line">        cache: <span class="literal">false</span>, <span class="comment">//上传文件无需缓存</span></span><br><span class="line">        processData: <span class="literal">false</span>, <span class="comment">//用于对data参数进行序列化处理 这里必须false</span></span><br><span class="line">        contentType: <span class="literal">false</span>, <span class="comment">//必须</span></span><br><span class="line">        success: <span class="function"><span class="keyword">function</span>(<span class="params">result</span>) </span>&#123;&#125;,</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>后端获取：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">file = request.files.get(<span class="string">&#x27;file&#x27;</span>)  <span class="comment"># 获取文件</span></span><br><span class="line"><span class="keyword">if</span> file:</span><br><span class="line">    filename = file.filename</span><br><span class="line">    <span class="keyword">if</span> filename.split(<span class="string">&#x27;.&#x27;</span>)[-<span class="number">1</span>] <span class="keyword">in</span> [<span class="string">&quot;xls&quot;</span>, <span class="string">&quot;xlsx&quot;</span>]:</span><br><span class="line">        <span class="comment"># 用时间戳给文件命名</span></span><br><span class="line">        now_time = datetime.now().strftime(<span class="string">&quot;%Y-%m-%d-%H-%M-%S&quot;</span>).replace(<span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        file_path = FILE_SAVE_PATH + <span class="string">&quot;\\&quot;</span> + now_time + <span class="string">&#x27;_&#x27;</span> + filename</span><br><span class="line">        file.save(file_path)</span><br></pre></td></tr></table></figure>
<h2 id="构造字典的方法"><a href="#构造字典的方法" class="headerlink" title="构造字典的方法"></a>构造字典的方法</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cooperate_dict[i] = cooperate_dict.get(i, &#123;&#125;)</span><br><span class="line">cooperate_dict[i][<span class="string">&quot;patents&quot;</span>] = cooperate_dict[i].get(<span class="string">&quot;patents&quot;</span>, <span class="number">0</span>)</span><br><span class="line">cooperate_dict[i][<span class="string">&quot;papers&quot;</span>] = cooperate_dict[i].get(<span class="string">&quot;papers&quot;</span>, <span class="number">0</span>)</span><br><span class="line">cooperate_dict[i][<span class="string">&quot;projects&quot;</span>] = cooperate_dict[i].get(<span class="string">&quot;projects&quot;</span>, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">cooperate_dict[i][<span class="string">&quot;total&quot;</span>] = cooperate_dict[i].get(<span class="string">&quot;total&quot;</span>, <span class="number">0</span>) + <span class="number">1</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>毕设</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>毕设</tag>
      </tags>
  </entry>
  <entry>
    <title>算法Tricks</title>
    <url>/2022/11/22/%E7%AE%97%E6%B3%95Tricks/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>总结一些自己在刷题过程中遇到的一些常用的算法，便于后续复习。</p>
<a id="more"></a>
<h1 id="最大公约数"><a href="#最大公约数" class="headerlink" title="最大公约数"></a>最大公约数</h1><h2 id="短除法"><a href="#短除法" class="headerlink" title="短除法"></a>短除法</h2><p>思路：逐步找出两个数的所有公约数，再将这些公约数累乘起来，就能得到最大公约数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gcd</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    m, n = <span class="built_in">max</span>(a, b), <span class="built_in">min</span>(a, b)</span><br><span class="line">    t = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">while</span> m % i == <span class="number">0</span> <span class="keyword">and</span> n % i == <span class="number">0</span>:</span><br><span class="line">            t *= i</span><br><span class="line">            m /= i</span><br><span class="line">            n /= i</span><br><span class="line">    <span class="keyword">return</span> t</span><br></pre></td></tr></table></figure>
<h2 id="欧几里得算法（辗转相除法）"><a href="#欧几里得算法（辗转相除法）" class="headerlink" title="欧几里得算法（辗转相除法）"></a>欧几里得算法（辗转相除法）</h2><p>思路：以除数和余数反复做除法运算，当余数为 $0$ 时，取当前算式除数为最大公约数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 非递归形式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gcd</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    m, n = <span class="built_in">max</span>(a, b), <span class="built_in">min</span>(a, b)</span><br><span class="line">    <span class="keyword">while</span> n:</span><br><span class="line">        m, n = n, m % n</span><br><span class="line">    <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line"><span class="comment"># 递归形式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gcd</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    m, n = <span class="built_in">max</span>(a, b), <span class="built_in">min</span>(a, b)</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> m</span><br><span class="line">    <span class="keyword">return</span> gcd(n, m % n)</span><br></pre></td></tr></table></figure>
<h2 id="更相减损术"><a href="#更相减损术" class="headerlink" title="更相减损术"></a>更相减损术</h2><p>思路：任意给定两个正整数；判断它们是否都是偶数。若是，则用 $2$ 约简。以较大的数减较小的数，接着把所得的差与较小的数比较，并以大数减小数。继续这个操作，直到所得的减数和差相等为止。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gcd</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    m, n = <span class="built_in">max</span>(a, b), <span class="built_in">min</span>(a, b)</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> m % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">and</span> n % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        m //= <span class="number">2</span></span><br><span class="line">        n //= <span class="number">2</span></span><br><span class="line">    r = m-n</span><br><span class="line">    <span class="keyword">while</span> r != n:</span><br><span class="line">        m = <span class="built_in">max</span>(r, n)</span><br><span class="line">        n = <span class="built_in">min</span>(r, n)</span><br><span class="line">        r = m - n</span><br><span class="line">    <span class="keyword">return</span> n * <span class="number">2</span>**count</span><br></pre></td></tr></table></figure>
<h2 id="穷举法"><a href="#穷举法" class="headerlink" title="穷举法"></a>穷举法</h2><p>思路：最大公约数肯定在 $1$ ~两者之间最小数之间，只需要从大到小穷举即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gcd</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    m, n = <span class="built_in">max</span>(a, b), <span class="built_in">min</span>(a, b)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> m % i == <span class="number">0</span> <span class="keyword">and</span> n % i == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> i</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="Stein算法"><a href="#Stein算法" class="headerlink" title="Stein算法"></a>Stein算法</h2><p>思路：欧几里德算法是计算两个数最大公约数的传统算法，无论从理论还是从实际效率上都是很好的。但当出现大素数时，欧几里德法则存在较大的缺陷。计算 $\mbox{gcd}(m,n)=\mbox{gcd}(m−n,n)$ 的时候，实际上在描述的是 $\mbox{gcd}(2b,a+b)$ 。可以注意到它的第二参数本来就是一个奇数，因此按<code>Stein</code>算法可以提前将第一个参数里面的 $2$ 除掉变成 $\mbox{gcd}(b,a+b)$ 。再考虑第二参数比第一参数大，相减一下，立即就可以得到 $\mbox{gcd}(m,n)=\mbox{gcd}(a,b)=\mbox{gcd}(\frac{m+n}{2},\frac{m−n}{2})$ 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gcd</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="keyword">if</span> a &lt; b:</span><br><span class="line">        a, b = b, a</span><br><span class="line">    <span class="keyword">if</span> <span class="number">0</span> == b:</span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line">    <span class="keyword">if</span> a % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">and</span> b % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span> * gcd(a//<span class="number">2</span>, b//<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">if</span> a % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> gcd(a//<span class="number">2</span>, b)</span><br><span class="line">    <span class="keyword">if</span> b % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> gcd(a, b//<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 传统Stein算法</span></span><br><span class="line">    <span class="keyword">return</span> gcd(a-b, b)</span><br><span class="line">    <span class="comment"># 改进Stein算法（某些情况下可以降低复杂度）</span></span><br><span class="line">    <span class="comment"># return gcd((a+b)//2, (a-b)//2)</span></span><br></pre></td></tr></table></figure>
<h1 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h1><p> 并查集是一种树型的数据结构，用于处理一些不相交集合<code>(disjoint sets)</code>的合并及查询问题。并查集最常用的操作是查找和合并。</p>
<h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>初始时，每个元素都位于一个单独的集合，表示为一棵只有根节点的树。方便起见，我们将根节点的父亲设为自己。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dsu</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, size</span>):</span></span><br><span class="line">        self.pa = <span class="built_in">list</span>(<span class="built_in">range</span>(size))</span><br></pre></td></tr></table></figure>
<h2 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h2><p>我们需要沿着树向上移动，直至找到根节点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x <span class="keyword">if</span> self.pa[x] == x <span class="keyword">else</span> self.find(self.pa[x])</span><br></pre></td></tr></table></figure>
<h3 id="路径压缩"><a href="#路径压缩" class="headerlink" title="路径压缩"></a>路径压缩</h3><p>查找过程中经过的每个元素都属于该集合，我们可以将其直接连到根节点以加快后续查询。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> self.pa[x] != x:</span><br><span class="line">        self.pa[x] = self.find(self.pa[x])</span><br><span class="line">    <span class="keyword">return</span> self.pa[x]</span><br></pre></td></tr></table></figure>
<h2 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h2><p>要合并两棵树，我们只需要将一棵树的根节点连到另一棵树的根节点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">union</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">    self.pa[self.find(x)] = self.find(y)</span><br></pre></td></tr></table></figure>
<h3 id="启发式合并"><a href="#启发式合并" class="headerlink" title="启发式合并"></a>启发式合并</h3><p>合并时，选择哪棵树的根节点作为新树的根节点会影响未来操作的复杂度。我们可以将节点较少或深度较小的树连到另一棵，以免发生退化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dsu</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, size</span>):</span></span><br><span class="line">        self.pa = <span class="built_in">list</span>(<span class="built_in">range</span>(size))</span><br><span class="line">        self.size = [<span class="number">1</span>] * size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">union</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        x, y = self.find(x), self.find(y)</span><br><span class="line">        <span class="keyword">if</span> x == y:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> self.size[x] &lt; self.size[y]:</span><br><span class="line">            x, y = y, x</span><br><span class="line">        self.pa[y] = x</span><br><span class="line">        self.size[x] += self.size[y]</span><br></pre></td></tr></table></figure>
<h1 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a>KMP算法</h1><p>字符串<code>A</code>是否为字符串<code>B</code>的子串？如果是，出现在<code>B</code>的什么位置？这个问题就是字符串匹配问题。字符串<code>A</code>称为模式串，字符串<code>B</code>称为主串。</p>
<h2 id="暴力匹配"><a href="#暴力匹配" class="headerlink" title="暴力匹配"></a>暴力匹配</h2><p>从主串的第一个字符开始与模式串的第一个字符比较，如果相同则模式串往后移动一个位置和主串的下一个位置再比较，如果不同，则主串移动到下一个字符，模式串移动到第一个字符，开始重新比较，以此类推。这种方法很简单，但效率很低，假设主串的长度为<code>m</code>，模式串的长度为<code>n</code>，最差的情况是主串移动<code>m-n+1</code>次才能匹配到，时间复杂度为<code>O(mn)</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">match</span>(<span class="params">str1, str2</span>):</span></span><br><span class="line">    m = <span class="built_in">len</span>(str1)</span><br><span class="line">    n = <span class="built_in">len</span>(str2)</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; m <span class="keyword">and</span> j &lt; n:</span><br><span class="line">        <span class="keyword">if</span> str1[i] == str2[j]:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            i = i - j + <span class="number">1</span></span><br><span class="line">            j = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> j == n:</span><br><span class="line">        <span class="keyword">return</span> i - j</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="KMP算法-1"><a href="#KMP算法-1" class="headerlink" title="KMP算法"></a>KMP算法</h2><p><code>KMP</code>的核心思想是：某个位置匹配失败时，移动到这个位置之前的字符串的最长前缀的下一个字符继续匹配。简单来说，就是再已经匹配的模式串中找出最长的前缀和后缀相等的情况，然后将模式串从这个新位置开始匹配。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221216211311.png" alt=""></p>
<p>拿上图而言，目前能够匹配到的模式串为<code>ABCAB</code>，下次应该开始匹配的地方不是从头开始匹配，而是应该从<code>ABCAB</code>中的最长前后缀开始匹配。因为<code>ABCAB</code>的前缀和后缀（不包含字符串本身）分别为{<code>A</code>,<code>AB</code>,<code>ABC</code>,<code>ABCA</code>}和{<code>B</code>,<code>AB</code>,<code>CAB</code>,<code>BCAB</code>}，最长的前缀应该是<code>AB</code>。</p>
<h3 id="next数组"><a href="#next数组" class="headerlink" title="next数组"></a>next数组</h3><p>接下来的问题就是如何计算这个最长前缀的长度。最朴素的方式就是从前往后和从后往前每次增加一个长度截取字符串，然后看前缀和后缀是否相同，但是计算量太大。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20221216215017.png" alt=""></p>
<p>先看上图左边部分，箭头所指蓝色位置之前的字符串的最长前缀是<code>AB</code>，长度是<code>2</code>，我们对比这个最长前缀的下一个字符<code>A</code>和蓝色位置<code>A</code>相同，那么整个字符串的前后缀就变成了<code>ABA</code>，长度为<code>2+1=3</code>。仔细想想看：蓝色的<code>A</code>之前是最长后缀，白色的<code>A</code>之前是最长前缀，而这个最长前后缀是相同的，都是<code>AB</code>，那么如果第三个字符也相同，这三个字符连起来不是也相同吗？长度就是<code>2+1=3</code>！也就是说，如果要计算到某个位置字符串的最长前缀长度，我们只需要将这个字符和它之前字符串的最长前缀的下一个字符对比，如果相同，则它的最长前缀长度就是前面字符串的最长前缀长度+1。</p>
<p>如果不相同呢？看上图右边部分，蓝色的<code>A</code>不等于最长前缀的下一个字符<code>C</code>，我们应该往前回溯，字符<code>C</code>前面的字符串<code>AB</code>的最长前缀长度是0（即后面代码里的<code>k=next[k]</code>），我们就用这个前缀的下一个字符，即第1个字符<code>A</code>和当前字符比较，如果相同，则整个字符串的最长前缀长度为0+1，如果不同，则继续往前回溯，直到第一个字符。也就是，不断往前回溯，用前面字符串的最长前缀的下一个字符和当前字符对比。</p>
<p>注意：next数组保存的不是最长前缀的长度，而是对应的下标，也就是长度-1，如果长度是0，则保存-1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_next</span>(<span class="params">p</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(p)</span><br><span class="line">    <span class="built_in">next</span> = [<span class="number">0</span>] * n</span><br><span class="line">    <span class="built_in">next</span>[<span class="number">0</span>] = -<span class="number">1</span></span><br><span class="line">    k = -<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        <span class="comment"># 当前字符和最长前缀下一个字符不同，则往前回溯；因为next[k]就是用来记录子串的最长公共前后缀的尾坐标</span></span><br><span class="line">        <span class="keyword">while</span> k &gt; -<span class="number">1</span> <span class="keyword">and</span> p[i] != p[k + <span class="number">1</span>]:</span><br><span class="line">            k = <span class="built_in">next</span>[k]</span><br><span class="line">        <span class="comment"># 当前字符和当前字符前面字符串的最长前缀的下一个字符相同，则 k + 1</span></span><br><span class="line">        <span class="keyword">if</span> p[i] == p[k + <span class="number">1</span>]:</span><br><span class="line">            k += <span class="number">1</span></span><br><span class="line">        <span class="built_in">next</span>[i] = k</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">next</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">match</span>(<span class="params">str1, str2</span>):</span></span><br><span class="line">    index = -<span class="number">1</span></span><br><span class="line">    m = <span class="built_in">len</span>(str1)</span><br><span class="line">    n = <span class="built_in">len</span>(str2)</span><br><span class="line">    <span class="keyword">if</span> n &lt;= m:</span><br><span class="line">        <span class="built_in">next</span> = get_next(str2)</span><br><span class="line">        k = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="keyword">while</span> k &gt; -<span class="number">1</span> <span class="keyword">and</span> str1[i] != str2[k + <span class="number">1</span>]:</span><br><span class="line">                k = <span class="built_in">next</span>[k]</span><br><span class="line">            <span class="keyword">if</span> str1[i] == str2[k + <span class="number">1</span>]:</span><br><span class="line">                k += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> k == n-<span class="number">1</span>:</span><br><span class="line">                    index = i - n + <span class="number">1</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> index</span><br></pre></td></tr></table></figure>
<h1 id="字典树（前缀树）"><a href="#字典树（前缀树）" class="headerlink" title="字典树（前缀树）"></a>字典树（前缀树）</h1><p>Trie，又称前缀树或字典树，是一棵有根树，其每个节点包含以下字段：</p>
<ul>
<li>指向子节点的数组 children 。</li>
<li>布尔字段 isEnd，表示该节点是否为字符串的结尾。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Initialize your data structure here.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.children = [<span class="literal">None</span>] * <span class="number">26</span></span><br><span class="line">        self.isEnd = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h2 id="插入字符串"><a href="#插入字符串" class="headerlink" title="插入字符串"></a>插入字符串</h2><p>我们从字典树的根开始，插入字符串。对于当前字符对应的子节点，有两种情况：</p>
<ul>
<li>子节点存在。沿着指针移动到子节点，继续处理下一个字符。</li>
<li>子节点不存在。创建一个新的子节点，记录在 children 数组的对应位置上，然后沿着指针移动到子节点，继续搜索下一个字符。</li>
</ul>
<p>重复以上步骤，直到处理字符串的最后一个字符，然后将当前节点标记为字符串的结尾。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert</span>(<span class="params">self, word: <span class="built_in">str</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Inserts a word into the trie.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    node = self</span><br><span class="line">    <span class="keyword">for</span> ch <span class="keyword">in</span> word:</span><br><span class="line">        offset = <span class="built_in">ord</span>(ch) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node.children[offset]:</span><br><span class="line">            node.children[offset] = Trie()</span><br><span class="line">        node = node.children[offset]</span><br><span class="line">    node.isEnd = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h2 id="查找前缀"><a href="#查找前缀" class="headerlink" title="查找前缀"></a>查找前缀</h2><p>我们从字典树的根开始，查找前缀。对于当前字符对应的子节点，有两种情况：</p>
<ul>
<li>子节点存在。沿着指针移动到子节点，继续搜索下一个字符。</li>
<li>子节点不存在。说明字典树中不包含该前缀，返回空指针。</li>
</ul>
<p>重复以上步骤，直到返回空指针或搜索完前缀的最后一个字符。</p>
<p>若搜索到了前缀的末尾，就说明字典树中存在该前缀。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">startsWith</span>(<span class="params">self, prefix: <span class="built_in">str</span></span>) -&gt; bool:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Returns if there is any word in the trie that starts with the given prefix.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    cur = self</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> prefix:</span><br><span class="line">        od = <span class="built_in">ord</span>(c) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> cur.<span class="built_in">next</span>[od] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        cur = cur.<span class="built_in">next</span>[od]</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h2 id="查找字符串"><a href="#查找字符串" class="headerlink" title="查找字符串"></a>查找字符串</h2><p>和查找前缀相同，多了一个判断 isEnd 的步骤，若前缀末尾对应节点的 isEnd 为真，则说明字典树中存在该字符串。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, word: <span class="built_in">str</span></span>) -&gt; bool:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Returns if the word is in the trie.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    cur = self</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> word:</span><br><span class="line">        od = <span class="built_in">ord</span>(c) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> cur.<span class="built_in">next</span>[od] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    	cur = cur.<span class="built_in">next</span>[od]</span><br><span class="line">    <span class="keyword">return</span> cur.isend == <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h1 id="线段树"><a href="#线段树" class="headerlink" title="线段树"></a>线段树</h1><p>线段树是算法竞赛中常用的用来维护<strong>区间信息</strong>的数据结构。线段树可以在<code>O(logN)</code>的时间复杂度内实现单点修改、区间修改、区间查询（区间求和，求区间最大值，求区间最小值）等操作。</p>
<p>线段树将每个长度不为 $1$ 的区间划分成左右两个区间递归求解，把整个线段划分为一个树形结构，通过合并左右两区间信息来求得该区间的信息。这种数据结构可以方便的进行大部分的区间操作。</p>
<p><strong>适合场景</strong>：</p>
<ul>
<li>满足区间加法：区间的和，区间的差。</li>
<li>满足区间乘法：区间的乘积。</li>
<li>满足区间最值：区间最大值，区间最小值</li>
</ul>
<p><strong>不适合场景</strong>：</p>
<ul>
<li>区间的众数</li>
<li>区间最长连续问题</li>
<li>最长不下降问题</li>
</ul>
<h2 id="定义节点类"><a href="#定义节点类" class="headerlink" title="定义节点类"></a>定义节点类</h2><p>首先，我们需要定义一个节点类来表示线段树中的节点。每个节点包含一个左右子节点、区间起始和结束位置以及一些其他信息（如区间和、区间最大值、最小值等）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SegmentTreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, start, end</span>):</span></span><br><span class="line">        self.start = start  <span class="comment"># 区间起始位置</span></span><br><span class="line">        self.end = end  <span class="comment"># 区间结束位置</span></span><br><span class="line">        self.left = <span class="literal">None</span>  <span class="comment"># 左子节点</span></span><br><span class="line">        self.right = <span class="literal">None</span>  <span class="comment"># 右子节点</span></span><br><span class="line">        self.<span class="built_in">sum</span> = <span class="number">0</span>  <span class="comment"># 区间和</span></span><br><span class="line">        <span class="comment"># 其他信息（例如区间最大值、最小值等）可以根据需要添加</span></span><br></pre></td></tr></table></figure>
<h2 id="构建线段树"><a href="#构建线段树" class="headerlink" title="构建线段树"></a>构建线段树</h2><p>构建线段树的过程可以使用递归的方式实现。首先，定义一个 build 函数，该函数接收一个数组以及区间起始和结束位置，返回构建好的线段树的根节点。在函数内部，首先创建一个新节点表示当前区间，然后递归构建左右子树，最后将左右子树的区间和相加作为当前节点的区间和。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">nums, start, end</span>):</span></span><br><span class="line">    <span class="keyword">if</span> start &gt; end:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    root = SegmentTreeNode(start, end)</span><br><span class="line">    <span class="keyword">if</span> start == end:</span><br><span class="line">        root.<span class="built_in">sum</span> = nums[start]</span><br><span class="line">        <span class="keyword">return</span> root</span><br><span class="line">    mid = (start + end) // <span class="number">2</span></span><br><span class="line">    root.left = build(nums, start, mid)</span><br><span class="line">    root.right = build(nums, mid + <span class="number">1</span>, end)</span><br><span class="line">    root.<span class="built_in">sum</span> = root.left.<span class="built_in">sum</span> + root.right.<span class="built_in">sum</span></span><br><span class="line">    <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>
<h2 id="区间查询"><a href="#区间查询" class="headerlink" title="区间查询"></a>区间查询</h2><p>线段树最常见的用途就是区间查询。例如，查询一个区间的和、最大值、最小值等。函数接收一个根节点、区间起始和结束位置，返回区间和。如果当前节点的区间完全被包含在查询区间内，则直接返回当前节点的区间和；否则，将查询区间分别递归到左右子树中查询，并将左右子树的查询结果相加作为最终结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">query</span>(<span class="params">root, start, end</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> start &lt;= root.start <span class="keyword">and</span> end &gt;= root.end:</span><br><span class="line">        <span class="keyword">return</span> root.<span class="built_in">sum</span></span><br><span class="line">    mid = (root.start + root.end) // <span class="number">2</span></span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> start &lt;= mid:</span><br><span class="line">        res += query(root.left, start, end)</span><br><span class="line">    <span class="keyword">if</span> end &gt; mid:</span><br><span class="line">        res += query(root.right, start, end)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h2 id="单点修改"><a href="#单点修改" class="headerlink" title="单点修改"></a>单点修改</h2><p>更新某个位置的值时，需要对所有包含这个位置的结点的值重新计算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_single</span>(<span class="params">root, k, val</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> root.start == k <span class="keyword">and</span> root.end == k:</span><br><span class="line">        root.<span class="built_in">sum</span> = val</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    mid = (root.start + root.end) // <span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> k &lt;= mid:</span><br><span class="line">        update_single(root.left, k, val)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        update_single(root.right, k, val)</span><br><span class="line">    root.<span class="built_in">sum</span> = root.left.<span class="built_in">sum</span> + root.right.<span class="built_in">sum</span></span><br></pre></td></tr></table></figure>
<h2 id="区间修改"><a href="#区间修改" class="headerlink" title="区间修改"></a>区间修改</h2><p>除了区间查询之外，线段树还可以用来实现区间修改。例如，修改一个区间中的数值，或者给一个区间加上一个定值。对于区间修改而言，我们需要引入一个<code>lazy</code>标记，<code>lazy</code>标记的作用是：将此区间标记，表示这个区间的值已经更新，但是它的子区间却没有更新，更新的信息就是标记保存的值。具体步骤如下：</p>
<ol>
<li>如果要修改的区间完全覆盖当前区间，则直接更新这个区间，打上<code>lazy</code>标记；</li>
<li>如果没有完全覆盖且当前节点不是叶子节点，如果当前区间有<code>lazy</code>标记，先下传<code>lazy</code>标记到子区间，再清除当前区间的<code>lazy</code>标记；</li>
<li>如果修改区间和左孩子有交集，就搜索左孩子；</li>
<li>如果修改区间和右孩子有交集，就搜索右孩子；</li>
<li>最后将当前区间的值更新。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_some</span>(<span class="params">root, start, end, val</span>):</span></span><br><span class="line">    <span class="keyword">if</span> start &lt;= root.start <span class="keyword">and</span> end &gt;= root.end:</span><br><span class="line">        root.<span class="built_in">sum</span> += val * (root.end - root.start + <span class="number">1</span>)</span><br><span class="line">        root.flag = val</span><br><span class="line">    <span class="keyword">if</span> root.start != root.end:</span><br><span class="line">        <span class="keyword">if</span> root.flag:</span><br><span class="line">            root.left.flag = val</span><br><span class="line">            root.right.flag = val</span><br><span class="line">            root.flag = <span class="number">0</span></span><br><span class="line">        mid = (root.start + root.end) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> start &lt;= mid &lt;= end:</span><br><span class="line">            update_some(root.left, start, end, val)</span><br><span class="line">        <span class="keyword">if</span> start &lt;= mid+<span class="number">1</span> &lt;= end:</span><br><span class="line">            update_some(root.right, start, end, val)</span><br><span class="line">        root.<span class="built_in">sum</span> = root.left.<span class="built_in">sum</span> + root.right.<span class="built_in">sum</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>项目部署总结</title>
    <url>/2021/10/09/%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下毕设项目部署上线遇见的一些问题</p>
<a id="more"></a>
<h1 id="购买服务器"><a href="#购买服务器" class="headerlink" title="购买服务器"></a>购买服务器</h1><p>阿里云轻量应用服务器，装的是<code>CentOS7.3</code></p>
<h1 id="设置服务器密码"><a href="#设置服务器密码" class="headerlink" title="设置服务器密码"></a>设置服务器密码</h1><h1 id="切换超级用户"><a href="#切换超级用户" class="headerlink" title="切换超级用户"></a>切换超级用户</h1><p>貌似需要使用<code>su -</code></p>
<h1 id="系统升级"><a href="#系统升级" class="headerlink" title="系统升级"></a>系统升级</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum update</span><br></pre></td></tr></table></figure>
<h1 id="下载python环境"><a href="#下载python环境" class="headerlink" title="下载python环境"></a>下载python环境</h1><ol>
<li>下载：<code>wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz</code></li>
<li>解压：<code>tar Jxvf  Python-3.7.0.tar.xz</code></li>
<li>创建一个文件夹存放<code>python3.7.0</code>程序：<code>mkdir /usr/lib/Python3.7.0</code></li>
<li>设置配置文件：<code>./configure --prefix=/usr/lib/python3.7.0</code></li>
<li>编译安装：<code>make &amp;&amp; make install</code></li>
<li>建立软连接，使用已安装的<code>python3.7.0</code>：<code>ln -sb /usr/lib/python3.7.0/bin/python3.7 /usr/bin/python3</code></li>
</ol>
<p>报错：<code>zipimport.ZipImportError: can’t decompress data; zlib not available make: *** [install] Error 1</code></p>
<p>解决方案：<code>yum -y install zlib*</code></p>
<p>报错：<code>ModuleNotFoundError: No module named &#39;_ctypes&#39;</code></p>
<p>解决方案：<code>yum install libffi-devel</code></p>
<h1 id="安装虚拟环境"><a href="#安装虚拟环境" class="headerlink" title="安装虚拟环境"></a>安装虚拟环境</h1><p><code>pip3 install virtualenv</code></p>
<p>建立软连接：<code>ln -s /usr/local/python3/bin/virtualenv /usr/bin/virtualenv</code></p>
<p>建立目录，管理各虚拟环境：<code>mkdir my_env</code></p>
<p>建立虚拟环境：<code>virtualenv graduation</code></p>
<p>切换到<code>bin</code>目录下激活虚拟环境：<code>source activate</code></p>
<p>取消激活：<code>deactivate</code></p>
<h1 id="安装pip"><a href="#安装pip" class="headerlink" title="安装pip"></a>安装pip</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget --no-check-certificate https://github.com/pypa/pip/archive/9.0.1.tar.gz </span><br><span class="line">tar -zvxf 9.0.1.tar.gz  # 解压文件 </span><br><span class="line">cd pip-9.0.1</span><br><span class="line">python3 setup.py install # 使用 Python3 安装</span><br></pre></td></tr></table></figure>
<p>创建链接</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ln -s /usr/local/python3/bin/pip /usr/bin/pip3</span><br></pre></td></tr></table></figure>
<p>升级<code>pip</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install --upgrade pip</span><br></pre></td></tr></table></figure>
<h1 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h1><p>下载<code>mysql</code>的<code>repo</code>源</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;repo.mysql.com&#x2F;mysql-community-release-el7-5.noarch.rpm</span><br></pre></td></tr></table></figure>
<p>安装<code>mysql-community-release-el7-5.noarch.rpm</code>包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -ivh mysql-community-release-el7-5.noarch.rpm</span><br></pre></td></tr></table></figure>
<p>安装<code>MYSQL</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install -y  mysql-server</span><br></pre></td></tr></table></figure>
<p> 更改<code>MYSQL</code>用户权限：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo chown -R root:root &#x2F;var&#x2F;lib&#x2F;mysql</span><br></pre></td></tr></table></figure>
<p>重启服务：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart mysql.service</span><br></pre></td></tr></table></figure>
<p>登录，并修改密码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root</span><br><span class="line">mysql &gt; use mysql;</span><br><span class="line">mysql &gt; update user set password=password(&#x27;123456&#x27;) where user=&#x27;root&#x27;;</span><br><span class="line">mysql &gt; flush privileges;</span><br><span class="line">mysql &gt; exit;</span><br></pre></td></tr></table></figure>
<h1 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h1><p>下载对应当前系统版本的<code>nginx</code>包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm</span><br></pre></td></tr></table></figure>
<p> 建立<code>nginx</code>的<code>yum</code>仓库（默认<code>yum</code>是没有<code>nginx</code>的）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -ivh nginx-release-centos-7-0.el7.ngx.noarch.rpm</span><br></pre></td></tr></table></figure>
<p>下载并安装<code>nginx</code></p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y nginx</span><br></pre></td></tr></table></figure>
<p><code>nginx</code>启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start nginx.service</span><br></pre></td></tr></table></figure>
<p>配置<code>nginx</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">server</span> &#123;</span><br><span class="line">    <span class="string">listen</span>       <span class="number">80</span><span class="string">;</span></span><br><span class="line">    <span class="string">server_name</span> <span class="number">120.27</span><span class="number">.209</span><span class="number">.102</span><span class="string">;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#access_log  /var/log/nginx/host.access.log  main;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">location</span> <span class="string">/</span> &#123;</span><br><span class="line">        <span class="comment">#root   /home/admin/my_projects/graduation;</span></span><br><span class="line">        <span class="comment">#index  index.html index.htm;</span></span><br><span class="line">		<span class="string">proxy_pass</span> <span class="string">http://127.0.0.1:5000;</span> <span class="comment"># 这里是指向 gunicorn host 的服务地址</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">Host</span> <span class="string">$host;</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">X-Forwarded-For</span> <span class="string">$proxy_add_x_forwarded_for;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#error_page  404              /404.html;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># redirect server error pages to the static page /50x.html</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="string">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  <span class="string">/50x.html;</span></span><br><span class="line">    <span class="string">location</span> <span class="string">=</span> <span class="string">/50x.html</span> &#123;</span><br><span class="line">        <span class="string">root</span>   <span class="string">/usr/share/nginx/html;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># proxy the PHP scripts to Apache listening on 127.0.0.1:80</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#location ~ \.php$ &#123;</span></span><br><span class="line">    <span class="comment">#    proxy_pass   http://127.0.0.1;</span></span><br><span class="line">    <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#location ~ \.php$ &#123;</span></span><br><span class="line">    <span class="comment">#    root           html;</span></span><br><span class="line">    <span class="comment">#    fastcgi_pass   127.0.0.1:9000;</span></span><br><span class="line">    <span class="comment">#    fastcgi_index  index.php;</span></span><br><span class="line">    <span class="comment">#    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;</span></span><br><span class="line">    <span class="comment">#    include        fastcgi_params;</span></span><br><span class="line">    <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># deny access to .htaccess files, if Apache&#x27;s document root</span></span><br><span class="line">    <span class="comment"># concurs with nginx&#x27;s one</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#location ~ /\.ht &#123;</span></span><br><span class="line">    <span class="comment">#    deny  all;</span></span><br><span class="line">    <span class="comment">#&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="上传本地flask项目"><a href="#上传本地flask项目" class="headerlink" title="上传本地flask项目"></a>上传本地flask项目</h1><p>我使用的是<code>Xftp 7</code>，一开始准备使用<code>git</code>直接在<code>GitHub</code>上下载，但是速度太慢</p>
<h1 id="安装需要依赖的库"><a href="#安装需要依赖的库" class="headerlink" title="安装需要依赖的库"></a>安装需要依赖的库</h1><ol>
<li><p>使用虚拟环境</p>
</li>
<li><p>切换到项目路径下</p>
</li>
<li><p>从<code>requirements.txt</code>安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install -r requirements.txt</span><br></pre></td></tr></table></figure>
<h1 id="新建项目数据库"><a href="#新建项目数据库" class="headerlink" title="新建项目数据库"></a>新建项目数据库</h1></li>
<li><p>登陆<code>mysql</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure></li>
<li><p>创建与文件名相同的数据库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash">create database graduation;</span></span><br></pre></td></tr></table></figure></li>
<li><p>使用创建好的数据库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> use graduation;</span></span><br></pre></td></tr></table></figure></li>
<li><p>导入数据库文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"><span class="built_in">source</span> ./graduation.sql;</span></span><br></pre></td></tr></table></figure>
<h1 id="安装gunicorn"><a href="#安装gunicorn" class="headerlink" title="安装gunicorn"></a>安装gunicorn</h1></li>
<li><p>安装<code>gunicorn</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install gunicorn</span><br></pre></td></tr></table></figure></li>
<li><p>启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gunicorn -w 4 -b 0.0.0.0:8080 yourpyfilename:yourappname --log-level DEBUG</span><br><span class="line">gunicorn -w 4 -b 127.0.0.1:5000 app:app --log-level DEBUG</span><br></pre></td></tr></table></figure></li>
<li><p>获取<code>gunicorn</code>进程树</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pstree -ap|grep gunicorn</span><br></pre></td></tr></table></figure></li>
<li><p>终止任务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kill -9 pid</span><br></pre></td></tr></table></figure>
<h1 id="selenium的使用"><a href="#selenium的使用" class="headerlink" title="selenium的使用"></a>selenium的使用</h1></li>
<li><p>下载<code>chrome</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm</span><br></pre></td></tr></table></figure></li>
<li><p>安装<code>chrome</code>依赖的包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install libX11 libXcursor libXdamage libXext libXcomposite libXi libXrandr gtk3 libappindicator-gtk3 xdg-utils libXScrnSaver liberation-fonts</span><br></pre></td></tr></table></figure></li>
<li><p>安装<code>chrome</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -ivh google-chrome-stable_current_x86_64.rpm</span><br></pre></td></tr></table></figure></li>
<li><p>查看<code>chrome</code>是否安装完成</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">google-chrome --version</span><br></pre></td></tr></table></figure></li>
<li><p>下载<code>chrome</code>对应的<code>chromedriver</code>，下载地址<a href="http://npm.taobao.org/mirrors/chromedriver/">http://npm.taobao.org/mirrors/chromedriver/</a></p>
</li>
<li><p>安装完成之后上传至服务器</p>
</li>
</ol>
<p>一些报错：</p>
<ol>
<li><p><code>WEBDRIVEREXCEPTION: MESSAGE: &#39;CHROMEDRIVER&#39; EXECUTABLE MAY HAVE WRONG PERMISSIONS.</code></p>
<p>我的情况是没有执行权限，其他可能性见<a href="https://www.freesion.com/article/25041327554/">这里</a></p>
<p>解决方案：</p>
<ol>
<li><p>在<code>chromedriver</code>所在的路径下查看执行权限</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -l</span><br></pre></td></tr></table></figure></li>
<li><p>赋予执行权限</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod -R 777 chromedriver</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p><code>selenium WebDriverException: Message: unknown error: DevToolsActivePort file doesn&#39;t exist</code></p>
</li>
<li><p><code>WebDriverException: Message: chrome not reachable</code></p>
</li>
</ol>
<h1 id="使用screen"><a href="#使用screen" class="headerlink" title="使用screen"></a>使用screen</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install screen</span><br><span class="line">screen -S graduation</span><br></pre></td></tr></table></figure>
<p>恢复会话</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -r graduation</span><br></pre></td></tr></table></figure>
<h1 id="绑定域名"><a href="#绑定域名" class="headerlink" title="绑定域名"></a>绑定域名</h1><ol>
<li><p>首先去阿里云购买域名</p>
</li>
<li><p>工信部实名认证</p>
</li>
<li><p>域名解析</p>
</li>
<li><p>如果觉得域名后面带端口号不太美观，可以设置一下</p>
<ol>
<li><p>选择添加新记录</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220116122249.png" alt=""></p>
</li>
<li><p>记录类型选择隐性URL，主机记录就是想要设置的名字，记录值填写<a href="http://域名:端口号">http://域名:端口号</a></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20220116122426.png" alt=""></p>
</li>
<li><p>浏览器中输入主机记录的值即可访问</p>
</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>项目部署</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>项目部署</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式</title>
    <url>/2021/11/25/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>设计模式是面向对象语言特有的内容，是面对某一类问题时的固定做法。</p>
<a id="more"></a>
<h1 id="创建型模式"><a href="#创建型模式" class="headerlink" title="创建型模式"></a>创建型模式</h1><h2 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h2><p>工厂模式（Factory Pattern）的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<p>在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2021/11/25 13:07</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Factory</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">manufacture</span>(<span class="params">self, brand</span>):</span></span><br><span class="line">        <span class="keyword">if</span> brand == <span class="string">&quot;Benz&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> Benz()</span><br><span class="line">        <span class="keyword">elif</span> brand == <span class="string">&quot;Ferrari&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> Ferrari()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Benz</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;I am Benz&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ferrari</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;I am Ferrari&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    factory = Factory()</span><br><span class="line">    factory.manufacture(<span class="string">&quot;Benz&quot;</span>)</span><br><span class="line">    factory.manufacture(<span class="string">&quot;Ferrari&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h2><p>抽象工厂模式（Abstract Factory Pattern）是围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<p>在抽象工厂模式中，接口是负责创建一个相关对象的工厂，不需要显式指定它们的类。每个生成的工厂都能按照工厂模式提供对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/1/28 22:53</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PetShop</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;A pet shop&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, animal_factory=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;pet_factory is our abstract factory.</span></span><br><span class="line"><span class="string">        We can set it at will.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        self.pet_factory = animal_factory</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_pet</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Creates and shows a pet using the</span></span><br><span class="line"><span class="string">        abstract factory&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        pet = self.pet_factory.get_pet()</span><br><span class="line">        print(<span class="string">&quot;This is a lovely&quot;</span>, <span class="built_in">str</span>(pet))</span><br><span class="line">        print(<span class="string">&quot;It says&quot;</span>, pet.speak())</span><br><span class="line">        print(<span class="string">&quot;It eats&quot;</span>, self.pet_factory.get_food())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Stuff that our factory makes</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">speak</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;woof&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Dog&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cat</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">speak</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;meow&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Cat&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Factory classes</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogFactory</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_pet</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> Dog()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_food</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;dog food&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CatFactory</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_pet</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> Cat()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_food</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;cat food&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the proper family</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_factory</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Let&#x27;s be dynamic!&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> random.choice([DogFactory, CatFactory])()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Show pets with various factories</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    shop = PetShop()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        shop.pet_factory = get_factory()</span><br><span class="line">        shop.show_pet()</span><br><span class="line">        print(<span class="string">&quot;=&quot;</span> * <span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<h2 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h2><p>单例模式（Singleton Pattern）的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<p>这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2021/11/25 14:08</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySingleton</span>:</span></span><br><span class="line">    __obj = <span class="literal">None</span></span><br><span class="line">    __init_flag = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>(<span class="params">cls, *args, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">if</span> cls.__obj <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            cls.__obj = <span class="built_in">object</span>.__new__(cls)</span><br><span class="line">        <span class="keyword">return</span> cls.__obj</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        <span class="keyword">if</span> MySingleton.__init_flag:</span><br><span class="line">            print(<span class="string">&quot;init.....&quot;</span>)</span><br><span class="line">            self.name = name</span><br><span class="line">            MySingleton.__init_flag = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    a = MySingleton(<span class="string">&quot;aa&quot;</span>)</span><br><span class="line">    b = MySingleton(<span class="string">&quot;bb&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="建造者模式"><a href="#建造者模式" class="headerlink" title="建造者模式"></a>建造者模式</h2><p>建造者模式（Builder Pattern）使用多个简单的对象一步一步构建成一个复杂的对象。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/1/29 18:20</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Director</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Director</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.builder = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">construct_building</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.builder.new_building()</span><br><span class="line">        self.builder.build_floor()</span><br><span class="line">        self.builder.build_size()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_building</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.builder.building</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Abstract Builder</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Builder</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.building = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_building</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.building = Building()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Concrete Builder</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BuilderHouse</span>(<span class="params">Builder</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_floor</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.building.floor = <span class="string">&#x27;One&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_size</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.building.size = <span class="string">&#x27;Big&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BuilderFlat</span>(<span class="params">Builder</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_floor</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.building.floor = <span class="string">&#x27;More than One&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_size</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.building.size = <span class="string">&#x27;Small&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Product</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Building</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.floor = <span class="literal">None</span></span><br><span class="line">        self.size = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Floor: %s | Size: %s&#x27;</span> % (self.floor, self.size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Client</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    director = Director()</span><br><span class="line">    director.builder = BuilderHouse()</span><br><span class="line">    director.construct_building()</span><br><span class="line">    building = director.get_building()</span><br><span class="line">    print(building)</span><br><span class="line">    director.builder = BuilderFlat()</span><br><span class="line">    director.construct_building()</span><br><span class="line">    building = director.get_building()</span><br><span class="line">    print(building)</span><br></pre></td></tr></table></figure>
<h2 id="原型模式"><a href="#原型模式" class="headerlink" title="原型模式"></a>原型模式</h2><p>原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/1/29 19:18</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Prototype</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._objects = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">register_object</span>(<span class="params">self, name, obj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Register an object&quot;&quot;&quot;</span></span><br><span class="line">        self._objects[name] = obj</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">unregister_object</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Unregister an object&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">del</span> self._objects[name]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clone</span>(<span class="params">self, name, **attr</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Clone a registered object and update inner attributes dictionary&quot;&quot;&quot;</span></span><br><span class="line">        obj = copy.deepcopy(self._objects.get(name))</span><br><span class="line">        obj.__dict__.update(attr)</span><br><span class="line">        <span class="keyword">return</span> obj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;I am A&quot;</span></span><br><span class="line"></span><br><span class="line">    a = A()</span><br><span class="line">    prototype = Prototype()</span><br><span class="line">    prototype.register_object(<span class="string">&#x27;a&#x27;</span>, a)</span><br><span class="line">    b = prototype.clone(<span class="string">&#x27;a&#x27;</span>, a=<span class="number">1</span>, b=<span class="number">2</span>, c=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    print(a)</span><br><span class="line">    print(b.a, b.b, b.c)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h1 id="结构型模式"><a href="#结构型模式" class="headerlink" title="结构型模式"></a>结构型模式</h1><h2 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h2><p>适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/1/31 21:34</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.name = <span class="string">&quot;Dog&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bark</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;woof!&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cat</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.name = <span class="string">&quot;Cat&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">meow</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;meow!&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Human</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.name = <span class="string">&quot;Human&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">speak</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&#x27;hello&#x27;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Car</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.name = <span class="string">&quot;Car&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_noise</span>(<span class="params">self, octane_level</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;vroom%s&quot;</span> % (<span class="string">&quot;!&quot;</span> * octane_level)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Adapter</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Adapts an object by replacing methods.</span></span><br><span class="line"><span class="string">    Usage:</span></span><br><span class="line"><span class="string">    dog = Dog</span></span><br><span class="line"><span class="string">    dog = Adapter(dog, dict(make_noise=dog.bark))</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, obj, adapted_methods</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;We set the adapted methods in the object&#x27;s dict&quot;&quot;&quot;</span></span><br><span class="line">        self.obj = obj</span><br><span class="line">        self.__dict__.update(adapted_methods)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span>(<span class="params">self, attr</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;All non-adapted calls are passed to the object&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">getattr</span>(self.obj, attr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    objects = []</span><br><span class="line">    dog = Dog()</span><br><span class="line">    objects.append(Adapter(dog, <span class="built_in">dict</span>(make_noise=dog.bark)))</span><br><span class="line">    cat = Cat()</span><br><span class="line">    objects.append(Adapter(cat, <span class="built_in">dict</span>(make_noise=cat.meow)))</span><br><span class="line">    human = Human()</span><br><span class="line">    objects.append(Adapter(human, <span class="built_in">dict</span>(make_noise=human.speak)))</span><br><span class="line">    car = Car()</span><br><span class="line">    car_noise = <span class="keyword">lambda</span>: car.make_noise(<span class="number">3</span>)</span><br><span class="line">    objects.append(Adapter(car, <span class="built_in">dict</span>(make_noise=car_noise)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> objects:</span><br><span class="line">        print(<span class="string">&quot;A&quot;</span>, obj.name, <span class="string">&quot;goes&quot;</span>, obj.make_noise())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="桥接模式"><a href="#桥接模式" class="headerlink" title="桥接模式"></a>桥接模式</h2><p>桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/1/31 21:40</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ConcreteImplementor 1/2</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DrawingAPI1</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">draw_circle</span>(<span class="params">self, x, y, radius</span>):</span></span><br><span class="line">        print(<span class="string">&#x27;API1.circle at &#123;&#125;:&#123;&#125; radius &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(x, y, radius))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ConcreteImplementor 2/2</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DrawingAPI2</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">draw_circle</span>(<span class="params">self, x, y, radius</span>):</span></span><br><span class="line">        print(<span class="string">&#x27;API2.circle at &#123;&#125;:&#123;&#125; radius &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(x, y, radius))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Refined Abstraction</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CircleShape</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x, y, radius, drawing_api</span>):</span></span><br><span class="line">        self._x = x</span><br><span class="line">        self._y = y</span><br><span class="line">        self._radius = radius</span><br><span class="line">        self._drawing_api = drawing_api</span><br><span class="line"></span><br><span class="line">    <span class="comment"># low-level i.e. Implementation specific</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._drawing_api.draw_circle(self._x, self._y, self._radius)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># high-level i.e. Abstraction specific</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">scale</span>(<span class="params">self, pct</span>):</span></span><br><span class="line">        self._radius *= pct</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    shapes = (</span><br><span class="line">        CircleShape(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, DrawingAPI1()),</span><br><span class="line">        CircleShape(<span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, DrawingAPI2())</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> shape <span class="keyword">in</span> shapes:</span><br><span class="line">        shape.scale(<span class="number">2.5</span>)</span><br><span class="line">        shape.draw()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h2><p>组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/1/31 21:48</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Component</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, strName</span>):</span></span><br><span class="line">        self.m_strName = strName</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Add</span>(<span class="params">self, com</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Display</span>(<span class="params">self, nDepth</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Leaf</span>(<span class="params">Component</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Add</span>(<span class="params">self, com</span>):</span></span><br><span class="line">        print(<span class="string">&quot;leaf can&#x27;t add&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Display</span>(<span class="params">self, nDepth</span>):</span></span><br><span class="line">        str_temp = <span class="string">&quot;-&quot;</span> * nDepth</span><br><span class="line">        str_temp = str_temp + self.m_strName</span><br><span class="line">        print(str_temp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Composite</span>(<span class="params">Component</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, strName</span>):</span></span><br><span class="line">        self.m_strName = strName</span><br><span class="line">        self.c = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Add</span>(<span class="params">self, com</span>):</span></span><br><span class="line">        self.c.append(com)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Display</span>(<span class="params">self, nDepth</span>):</span></span><br><span class="line">        str_temp = <span class="string">&quot;-&quot;</span> * nDepth</span><br><span class="line">        str_temp = str_temp + self.m_strName</span><br><span class="line">        print(str_temp)</span><br><span class="line">        <span class="keyword">for</span> com <span class="keyword">in</span> self.c:</span><br><span class="line">            com.Display(nDepth + <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    p = Composite(<span class="string">&quot;Wong&quot;</span>)</span><br><span class="line">    p.Add(Leaf(<span class="string">&quot;Lee&quot;</span>))</span><br><span class="line">    p.Add(Leaf(<span class="string">&quot;Zhao&quot;</span>))</span><br><span class="line">    p1 = Composite(<span class="string">&quot;Wu&quot;</span>)</span><br><span class="line">    p1.Add(Leaf(<span class="string">&quot;San&quot;</span>))</span><br><span class="line">    p.Add(p1)</span><br><span class="line">    p.Display(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h2><p>装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/1 20:51</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f1</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;original f1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f2</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;original f2&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FooDecorator</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, decorator</span>):</span></span><br><span class="line">        self._decorator = decorator</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f1</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;decorated f1&quot;</span>)</span><br><span class="line">        self._decorator.f1()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">getattr</span>(self._decorator, name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    u = Foo()</span><br><span class="line">    v = FooDecorator(u)</span><br><span class="line">    v.f1()</span><br><span class="line">    v.f2()</span><br></pre></td></tr></table></figure>
<h2 id="外观模式"><a href="#外观模式" class="headerlink" title="外观模式"></a>外观模式</h2><p>外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。这种类型的设计模式属于结构型模式，它向现有的系统添加一个接口，来隐藏系统的复杂性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/1 20:56</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">SLEEP = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Complex Parts</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TC1</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;###### In Test 1 ######&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Setting up&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Running test&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Tearing down&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Test Finished &quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TC2</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;###### In Test 2 ######&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Setting up&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Running test&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Tearing down&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Test Finished &quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TC3</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;###### In Test 3 ######&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Setting up&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Running test&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Tearing down&quot;</span>)</span><br><span class="line">        time.sleep(SLEEP)</span><br><span class="line">        print(<span class="string">&quot;Test Finished &quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Facade</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestRunner</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.tc1 = TC1()</span><br><span class="line">        self.tc2 = TC2()</span><br><span class="line">        self.tc3 = TC3()</span><br><span class="line">        self.tests = [i <span class="keyword">for</span> i <span class="keyword">in</span> (self.tc1, self.tc2, self.tc3)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">runAll</span>(<span class="params">self</span>):</span></span><br><span class="line">        [i.run() <span class="keyword">for</span> i <span class="keyword">in</span> self.tests]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Client</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    test_runner = TestRunner()</span><br><span class="line">    test_runner.runAll()</span><br></pre></td></tr></table></figure>
<h2 id="享元模式"><a href="#享元模式" class="headerlink" title="享元模式"></a>享元模式</h2><p>享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/1 21:05</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> weakref</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Card</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;The object pool. Has builtin reference counting&quot;&quot;&quot;</span></span><br><span class="line">    _CardPool = weakref.WeakValueDictionary()</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Flyweight implementation. If the object exists in the</span></span><br><span class="line"><span class="string">    pool just return it (instead of creating a new one)&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>(<span class="params">cls, value, suit</span>):</span></span><br><span class="line">        obj = Card._CardPool.get(value + suit, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> obj:</span><br><span class="line">            obj = <span class="built_in">object</span>.__new__(cls)</span><br><span class="line">            Card._CardPool[value + suit] = obj</span><br><span class="line">            obj.value, obj.suit = value, suit</span><br><span class="line">        <span class="keyword">return</span> obj</span><br><span class="line"></span><br><span class="line">    <span class="comment"># def __init__(self, value, suit):</span></span><br><span class="line">    <span class="comment">#     self.value, self.suit = value, suit     </span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&lt;Card: %s%s&gt;&quot;</span> % (self.value, self.suit)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># comment __new__ and uncomment __init__ to see the difference</span></span><br><span class="line">    c1 = Card(<span class="string">&#x27;9&#x27;</span>, <span class="string">&#x27;h&#x27;</span>)</span><br><span class="line">    c2 = Card(<span class="string">&#x27;9&#x27;</span>, <span class="string">&#x27;h&#x27;</span>)</span><br><span class="line">    print(c1, c2)</span><br><span class="line">    print(c1 == c2)</span><br><span class="line">    print(<span class="built_in">id</span>(c1), <span class="built_in">id</span>(c2))</span><br></pre></td></tr></table></figure>
<h2 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h2><p>在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/1 21:08</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SalesManager</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">work</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Sales Manager working...&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">talk</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Sales Manager ready to talk&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Proxy</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.busy = <span class="string">&#x27;No&#x27;</span></span><br><span class="line">        self.sales = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">work</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Proxy checking for Sales Manager availability&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> self.busy == <span class="string">&#x27;No&#x27;</span>:</span><br><span class="line">            self.sales = SalesManager()</span><br><span class="line">            time.sleep(<span class="number">2</span>)</span><br><span class="line">            self.sales.talk()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            time.sleep(<span class="number">2</span>)</span><br><span class="line">            print(<span class="string">&quot;Sales Manager is busy&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    p = Proxy()</span><br><span class="line">    p.work()</span><br><span class="line">    p.busy = <span class="string">&#x27;Yes&#x27;</span></span><br><span class="line">    p.work()</span><br></pre></td></tr></table></figure>
<h1 id="行为型模式"><a href="#行为型模式" class="headerlink" title="行为型模式"></a>行为型模式</h1><h2 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h2><p>在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/1 21:11</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> types</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StrategyExample</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, func=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.name = <span class="string">&#x27;Strategy Example 0&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> func <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.execute = types.MethodType(func, self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">execute</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(self.name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute_replacement1</span>(<span class="params">self</span>):</span></span><br><span class="line">    print(self.name + <span class="string">&#x27; from execute 1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute_replacement2</span>(<span class="params">self</span>):</span></span><br><span class="line">    print(self.name + <span class="string">&#x27; from execute 2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    strat0 = StrategyExample()</span><br><span class="line"></span><br><span class="line">    strat1 = StrategyExample(execute_replacement1)</span><br><span class="line">    strat1.name = <span class="string">&#x27;Strategy Example 1&#x27;</span></span><br><span class="line"></span><br><span class="line">    strat2 = StrategyExample(execute_replacement2)</span><br><span class="line">    strat2.name = <span class="string">&#x27;Strategy Example 2&#x27;</span></span><br><span class="line"></span><br><span class="line">    strat0.execute()</span><br><span class="line">    strat1.execute()</span><br><span class="line">    strat2.execute()</span><br></pre></td></tr></table></figure>
<h2 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h2><p>在模板方法模式（Template Method Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/1 21:35</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">ingredients = <span class="string">&quot;spam eggs apple&quot;</span></span><br><span class="line">line = <span class="string">&#x27;-&#x27;</span> * <span class="number">10</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Skeletons</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iter_elements</span>(<span class="params">getter, action</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Template skeleton that iterates items&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> getter():</span><br><span class="line">        action(element)</span><br><span class="line">        print(line)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rev_elements</span>(<span class="params">getter, action</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Template skeleton that iterates items in reverse order&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> getter()[::-<span class="number">1</span>]:</span><br><span class="line">        action(element)</span><br><span class="line">        print(line)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Getters</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_list</span>():</span></span><br><span class="line">    <span class="keyword">return</span> ingredients.split()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_lists</span>():</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="built_in">list</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> ingredients.split()]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Actions</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_item</span>(<span class="params">item</span>):</span></span><br><span class="line">    print(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reverse_item</span>(<span class="params">item</span>):</span></span><br><span class="line">    print(item[::-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Makes templates</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_template</span>(<span class="params">skeleton, getter, action</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Instantiate a template method with getter and action&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">template</span>():</span></span><br><span class="line">        skeleton(getter, action)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> template</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create our template functions</span></span><br><span class="line">templates = [make_template(s, g, a)</span><br><span class="line">             <span class="keyword">for</span> g <span class="keyword">in</span> (get_list, get_lists)</span><br><span class="line">             <span class="keyword">for</span> a <span class="keyword">in</span> (print_item, reverse_item)</span><br><span class="line">             <span class="keyword">for</span> s <span class="keyword">in</span> (iter_elements, rev_elements)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Execute them</span></span><br><span class="line"><span class="keyword">for</span> template <span class="keyword">in</span> templates:</span><br><span class="line">    template()</span><br></pre></td></tr></table></figure>
<h2 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h2><p>当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知依赖它的对象。观察者模式属于行为型模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/1 21:38</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Subject</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._observers = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">attach</span>(<span class="params">self, observer</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> observer <span class="keyword">in</span> self._observers:</span><br><span class="line">            self._observers.append(observer)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detach</span>(<span class="params">self, observer</span>):</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self._observers.remove(observer)</span><br><span class="line">        <span class="keyword">except</span> ValueError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">notify</span>(<span class="params">self, modifier=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">for</span> observer <span class="keyword">in</span> self._observers:</span><br><span class="line">            <span class="keyword">if</span> modifier != observer:</span><br><span class="line">                observer.update(self)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Data</span>(<span class="params">Subject</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">        Subject.__init__(self)</span><br><span class="line">        self.name = name</span><br><span class="line">        self._data = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">data</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self._data</span><br><span class="line"></span><br><span class="line"><span class="meta">    @data.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">data</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        self._data = value</span><br><span class="line">        self.notify()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HexViewer</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self, subject</span>):</span></span><br><span class="line">        print(<span class="string">&#x27;HexViewer: Subject %s has data 0x%x&#x27;</span> %</span><br><span class="line">              (subject.name, subject.data))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecimalViewer</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self, subject</span>):</span></span><br><span class="line">        print(<span class="string">&#x27;DecimalViewer: Subject %s has data %d&#x27;</span> %</span><br><span class="line">              (subject.name, subject.data))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage...</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    data1 = Data(<span class="string">&#x27;Data 1&#x27;</span>)</span><br><span class="line">    data2 = Data(<span class="string">&#x27;Data 2&#x27;</span>)</span><br><span class="line">    view1 = DecimalViewer()</span><br><span class="line">    view2 = HexViewer()</span><br><span class="line">    data1.attach(view1)</span><br><span class="line">    data1.attach(view2)</span><br><span class="line">    data2.attach(view2)</span><br><span class="line">    data2.attach(view1)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;Setting Data 1 = 10&quot;</span>)</span><br><span class="line">    data1.data = <span class="number">10</span></span><br><span class="line">    print(<span class="string">&quot;Setting Data 2 = 15&quot;</span>)</span><br><span class="line">    data2.data = <span class="number">15</span></span><br><span class="line">    print(<span class="string">&quot;Setting Data 1 = 3&quot;</span>)</span><br><span class="line">    data1.data = <span class="number">3</span></span><br><span class="line">    print(<span class="string">&quot;Setting Data 2 = 5&quot;</span>)</span><br><span class="line">    data2.data = <span class="number">5</span></span><br><span class="line">    print(<span class="string">&quot;Detach HexViewer from data1 and data2.&quot;</span>)</span><br><span class="line">    data1.detach(view2)</span><br><span class="line">    data2.detach(view2)</span><br><span class="line">    print(<span class="string">&quot;Setting Data 1 = 10&quot;</span>)</span><br><span class="line">    data1.data = <span class="number">10</span></span><br><span class="line">    print(<span class="string">&quot;Setting Data 2 = 15&quot;</span>)</span><br><span class="line">    data2.data = <span class="number">15</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h2><p>迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/1 22:14</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_to</span>(<span class="params">count</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Counts by word numbers, up to a maximum of five&quot;&quot;&quot;</span></span><br><span class="line">    numbers = [<span class="string">&quot;one&quot;</span>, <span class="string">&quot;two&quot;</span>, <span class="string">&quot;three&quot;</span>, <span class="string">&quot;four&quot;</span>, <span class="string">&quot;five&quot;</span>]</span><br><span class="line">    <span class="comment"># enumerate() returns a tuple containing a count (from start which</span></span><br><span class="line">    <span class="comment"># defaults to 0) and the values obtained from iterating over sequence</span></span><br><span class="line">    <span class="keyword">for</span> pos, number <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(count), numbers):</span><br><span class="line">        <span class="keyword">yield</span> number</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the generator</span></span><br><span class="line">count_to_two = <span class="keyword">lambda</span>: count_to(<span class="number">2</span>)</span><br><span class="line">count_to_five = <span class="keyword">lambda</span>: count_to(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Counting to two...&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> number <span class="keyword">in</span> count_to_two():</span><br><span class="line">    print(number)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Counting to five...&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> number <span class="keyword">in</span> count_to_five():</span><br><span class="line">    print(number)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot; &quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h2><p>责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/1 22:23</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Handler</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">successor</span>(<span class="params">self, successor</span>):</span></span><br><span class="line">        self.successor = successor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteHandler1</span>(<span class="params">Handler</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle</span>(<span class="params">self, request</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> &lt; request &lt;= <span class="number">10</span>:</span><br><span class="line">            print(<span class="string">&quot;in handler1&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.successor.handle(request)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteHandler2</span>(<span class="params">Handler</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle</span>(<span class="params">self, request</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">10</span> &lt; request &lt;= <span class="number">20</span>:</span><br><span class="line">            print(<span class="string">&quot;in handler2&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.successor.handle(request)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteHandler3</span>(<span class="params">Handler</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle</span>(<span class="params">self, request</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">20</span> &lt; request &lt;= <span class="number">30</span>:</span><br><span class="line">            print(<span class="string">&quot;in handler3&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">&#x27;end of chain, no handler for &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(request))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Client</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        h1 = ConcreteHandler1()</span><br><span class="line">        h2 = ConcreteHandler2()</span><br><span class="line">        h3 = ConcreteHandler3()</span><br><span class="line"></span><br><span class="line">        h1.successor(h2)</span><br><span class="line">        h2.successor(h3)</span><br><span class="line"></span><br><span class="line">        requests = [<span class="number">2</span>, <span class="number">5</span>, <span class="number">14</span>, <span class="number">22</span>, <span class="number">18</span>, <span class="number">3</span>, <span class="number">35</span>, <span class="number">27</span>, <span class="number">20</span>]</span><br><span class="line">        <span class="keyword">for</span> request <span class="keyword">in</span> requests:</span><br><span class="line">            h1.handle(request)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    client = Client()</span><br></pre></td></tr></table></figure>
<h2 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h2><p>命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/2 8:00</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MoveFileCommand</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, src, dest</span>):</span></span><br><span class="line">        self.src = src</span><br><span class="line">        self.dest = dest</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">execute</span>(<span class="params">self</span>):</span></span><br><span class="line">        self()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&#x27;renaming &#123;&#125; to &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(self.src, self.dest))</span><br><span class="line">        os.rename(self.src, self.dest)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">undo</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&#x27;renaming &#123;&#125; to &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(self.dest, self.src))</span><br><span class="line">        os.rename(self.dest, self.src)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># commands are just pushed into the command stack</span></span><br><span class="line">    command_stack = [MoveFileCommand(<span class="string">&#x27;foo.txt&#x27;</span>, <span class="string">&#x27;bar.txt&#x27;</span>), MoveFileCommand(<span class="string">&#x27;bar.txt&#x27;</span>, <span class="string">&#x27;baz.txt&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># they can be executed later on</span></span><br><span class="line">    <span class="keyword">for</span> cmd <span class="keyword">in</span> command_stack:</span><br><span class="line">        cmd.execute()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># and can also be undone at will</span></span><br><span class="line">    <span class="keyword">for</span> cmd <span class="keyword">in</span> <span class="built_in">reversed</span>(command_stack):</span><br><span class="line">        cmd.undo()</span><br></pre></td></tr></table></figure>
<h2 id="备忘录模式"><a href="#备忘录模式" class="headerlink" title="备忘录模式"></a>备忘录模式</h2><p>备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。备忘录模式属于行为型模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/2 8:07</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Memento</span>(<span class="params">obj, deep=<span class="literal">False</span></span>):</span></span><br><span class="line">    state = (copy.copy, copy.deepcopy)[<span class="built_in">bool</span>(deep)](obj.__dict__)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Restore</span>():</span></span><br><span class="line">        obj.__dict__.clear()</span><br><span class="line">        obj.__dict__.update(state)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Restore</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transaction</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;A transaction guard. This is really just</span></span><br><span class="line"><span class="string">      syntactic suggar arount a memento closure.</span></span><br><span class="line"><span class="string">      &quot;&quot;&quot;</span></span><br><span class="line">    deep = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *targets</span>):</span></span><br><span class="line">        self.targets = targets</span><br><span class="line">        self.Commit()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Commit</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.states = [Memento(target, self.deep) <span class="keyword">for</span> target <span class="keyword">in</span> self.targets]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Rollback</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> st <span class="keyword">in</span> self.states:</span><br><span class="line">            st()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">transactional</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Adds transactional semantics to methods. Methods decorated  with</span></span><br><span class="line"><span class="string">    @transactional will rollback to entry state upon exceptions.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, method</span>):</span></span><br><span class="line">        self.method = method</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span>(<span class="params">self, obj, T</span>):</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">transaction</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">            state = Memento(obj)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">return</span> self.method(obj, *args, **kwargs)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                state()</span><br><span class="line">                <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> transaction</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NumObj</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        self.value = value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&lt;%s: %r&gt;&#x27;</span> % (self.__class__.__name__, self.value)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Increment</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.value += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @transactional</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">DoStuff</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.value = <span class="string">&#x27;1111&#x27;</span>  <span class="comment"># &lt;- invalid value</span></span><br><span class="line">        self.Increment()  <span class="comment"># &lt;- will fail and rollback</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    n = NumObj(-<span class="number">1</span>)</span><br><span class="line">    print(n)</span><br><span class="line">    t = Transaction(n)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            n.Increment()</span><br><span class="line">            print(n)</span><br><span class="line">        t.Commit()</span><br><span class="line">        print(<span class="string">&#x27;-- commited&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            n.Increment()</span><br><span class="line">            print(n)</span><br><span class="line">        n.value += <span class="string">&#x27;x&#x27;</span>  <span class="comment"># will fail</span></span><br><span class="line">        print(n)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        t.Rollback()</span><br><span class="line">        print(<span class="string">&#x27;-- rolled back&#x27;</span>)</span><br><span class="line">    print(n)</span><br><span class="line">    print(<span class="string">&#x27;-- now doing stuff ...&#x27;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        n.DoStuff()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">&#x27;-&gt; doing stuff failed!&#x27;</span>)</span><br><span class="line">        <span class="keyword">import</span> traceback</span><br><span class="line"></span><br><span class="line">        traceback.print_exc(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    print(n)</span><br></pre></td></tr></table></figure>
<h2 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h2><p>在状态模式（State Pattern）中，类的行为是基于它的状态改变的。这种类型的设计模式属于行为型模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/2 8:09</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">State</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Base state. This is to share functionality&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">scan</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Scan the dial to the next station&quot;&quot;&quot;</span></span><br><span class="line">        self.pos += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.pos == <span class="built_in">len</span>(self.stations):</span><br><span class="line">            self.pos = <span class="number">0</span></span><br><span class="line">        print(<span class="string">&quot;Scanning... Station is&quot;</span>, self.stations[self.pos], self.name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AmState</span>(<span class="params">State</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, radio</span>):</span></span><br><span class="line">        self.radio = radio</span><br><span class="line">        self.stations = [<span class="string">&quot;1250&quot;</span>, <span class="string">&quot;1380&quot;</span>, <span class="string">&quot;1510&quot;</span>]</span><br><span class="line">        self.pos = <span class="number">0</span></span><br><span class="line">        self.name = <span class="string">&quot;AM&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">toggle_amfm</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Switching to FM&quot;</span>)</span><br><span class="line">        self.radio.state = self.radio.fmstate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FmState</span>(<span class="params">State</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, radio</span>):</span></span><br><span class="line">        self.radio = radio</span><br><span class="line">        self.stations = [<span class="string">&quot;81.3&quot;</span>, <span class="string">&quot;89.1&quot;</span>, <span class="string">&quot;103.9&quot;</span>]</span><br><span class="line">        self.pos = <span class="number">0</span></span><br><span class="line">        self.name = <span class="string">&quot;FM&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">toggle_amfm</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Switching to AM&quot;</span>)</span><br><span class="line">        self.radio.state = self.radio.amstate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Radio</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;A radio.     It has a scan button, and an AM/FM toggle switch.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;We have an AM state and an FM state&quot;&quot;&quot;</span></span><br><span class="line">        self.amstate = AmState(self)</span><br><span class="line">        self.fmstate = FmState(self)</span><br><span class="line">        self.state = self.amstate</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">toggle_amfm</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.state.toggle_amfm()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">scan</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.state.scan()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test our radio out</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    radio = Radio()</span><br><span class="line">    actions = [radio.scan] * <span class="number">2</span> + [radio.toggle_amfm] + [radio.scan] * <span class="number">2</span></span><br><span class="line">    actions = actions * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> action <span class="keyword">in</span> actions:</span><br><span class="line">        action()</span><br></pre></td></tr></table></figure>
<h2 id="访问者模式"><a href="#访问者模式" class="headerlink" title="访问者模式"></a>访问者模式</h2><p>在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变。这种类型的设计模式属于行为型模式。根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/2 8:16</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>(<span class="params">Node</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>(<span class="params">Node</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span>(<span class="params">A, B</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Visitor</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visit</span>(<span class="params">self, node, *args, **kwargs</span>):</span></span><br><span class="line">        meth = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> cls <span class="keyword">in</span> node.__class__.__mro__:</span><br><span class="line">            meth_name = <span class="string">&#x27;visit_&#x27;</span> + cls.__name__</span><br><span class="line">            meth = <span class="built_in">getattr</span>(self, meth_name, <span class="literal">None</span>)</span><br><span class="line">            <span class="keyword">if</span> meth:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> meth:</span><br><span class="line">            meth = self.generic_visit</span><br><span class="line">        <span class="keyword">return</span> meth(node, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generic_visit</span>(<span class="params">self, node, *args, **kwargs</span>):</span></span><br><span class="line">        print(<span class="string">&#x27;generic_visit &#x27;</span> + node.__class__.__name__)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visit_B</span>(<span class="params">self, node, *args, **kwargs</span>):</span></span><br><span class="line">        print(<span class="string">&#x27;visit_B &#x27;</span> + node.__class__.__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a = A()</span><br><span class="line">b = B()</span><br><span class="line">c = C()</span><br><span class="line">visitor = Visitor()</span><br><span class="line">visitor.visit(a)</span><br><span class="line">visitor.visit(b)</span><br><span class="line">visitor.visit(c)</span><br></pre></td></tr></table></figure>
<h2 id="中介者模式"><a href="#中介者模式" class="headerlink" title="中介者模式"></a>中介者模式</h2><p>中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/2 8:22</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TC</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._tm = tm</span><br><span class="line">        self._bProblem = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Setting up the Test&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        self._tm.prepareReporting()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">execute</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._bProblem:</span><br><span class="line">            print(<span class="string">&quot;Executing the test&quot;</span>)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">&quot;Problem in setup. Test not executed.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tearDown</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._bProblem:</span><br><span class="line">            print(<span class="string">&quot;Tearing down&quot;</span>)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            self._tm.publishReport()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">&quot;Test not executed. No tear down required.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setTM</span>(<span class="params">self, TM</span>):</span></span><br><span class="line">        self._tm = tm</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setProblem</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        self._bProblem = value</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Reporter</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._tm = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">prepare</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Reporter Class is preparing to report the results&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">report</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Reporting the results of Test&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setTM</span>(<span class="params">self, TM</span>):</span></span><br><span class="line">        self._tm = tm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DB</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._tm = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Inserting the execution begin status in the Database&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># Following code is to simulate a communication from DB to TC</span></span><br><span class="line">        <span class="keyword">import</span> random</span><br><span class="line">        <span class="keyword">if</span> random.randrange(<span class="number">1</span>, <span class="number">4</span>) == <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Updating the test results in Database&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setTM</span>(<span class="params">self, TM</span>):</span></span><br><span class="line">        self._tm = tm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestManager</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._reporter = <span class="literal">None</span></span><br><span class="line">        self._db = <span class="literal">None</span></span><br><span class="line">        self._tc = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">prepareReporting</span>(<span class="params">self</span>):</span></span><br><span class="line">        rvalue = self._db.insert()</span><br><span class="line">        <span class="keyword">if</span> rvalue == -<span class="number">1</span>:</span><br><span class="line">            self._tc.setProblem(<span class="number">1</span>)</span><br><span class="line">            self._reporter.prepare()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setReporter</span>(<span class="params">self, reporter</span>):</span></span><br><span class="line">        self._reporter = reporter</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setDB</span>(<span class="params">self, db</span>):</span></span><br><span class="line">        self._db = db</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">publishReport</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._db.update()</span><br><span class="line">        rvalue = self._reporter.report()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setTC</span>(<span class="params">self, tc</span>):</span></span><br><span class="line">        self._tc = tc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    reporter = Reporter()</span><br><span class="line">    db = DB()</span><br><span class="line">    tm = TestManager()</span><br><span class="line">    tm.setReporter(reporter)</span><br><span class="line">    tm.setDB(db)</span><br><span class="line">    reporter.setTM(tm)</span><br><span class="line">    db.setTM(tm)</span><br><span class="line">    <span class="comment"># For simplification we are looping on the same test.</span></span><br><span class="line">    <span class="comment"># Practically, it could be about various unique test classes and their</span></span><br><span class="line">    <span class="comment"># objects</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        tc = TC()</span><br><span class="line">        tc.setTM(tm)</span><br><span class="line">        tm.setTC(tc)</span><br><span class="line">        tc.setup()</span><br><span class="line">        tc.execute()</span><br><span class="line">        tc.tearDown()</span><br></pre></td></tr></table></figure>
<h2 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h2><p>解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @Author 坦克手贝塔</span></span><br><span class="line"><span class="string">    @Date 2023/2/2 8:26</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Context</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.<span class="built_in">input</span> = <span class="string">&quot;&quot;</span></span><br><span class="line">        self.output = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AbstractExpression</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Interpret</span>(<span class="params">self, context</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Expression</span>(<span class="params">AbstractExpression</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Interpret</span>(<span class="params">self, context</span>):</span></span><br><span class="line">        print(<span class="string">&quot;terminal interpret&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NonterminalExpression</span>(<span class="params">AbstractExpression</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Interpret</span>(<span class="params">self, context</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Nonterminal interpret&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    context = <span class="string">&quot;&quot;</span></span><br><span class="line">    c = []</span><br><span class="line">    c = c + [Expression()]</span><br><span class="line">    c = c + [NonterminalExpression()]</span><br><span class="line">    c = c + [Expression()]</span><br><span class="line">    c = c + [Expression()]</span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> c:</span><br><span class="line">        a.Interpret(context)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>面经</title>
    <url>/2023/03/06/%E9%9D%A2%E7%BB%8F/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一些自己整理的面经。</p>
<a id="more"></a>
<h1 id="训练过程中模型不收敛，是否说明这个模型无效，致模型不收敛的原因有哪些"><a href="#训练过程中模型不收敛，是否说明这个模型无效，致模型不收敛的原因有哪些" class="headerlink" title="训练过程中模型不收敛，是否说明这个模型无效，致模型不收敛的原因有哪些?"></a>训练过程中模型不收敛，是否说明这个模型无效，致模型不收敛的原因有哪些?</h1><p>在训练过程中，如果模型不收敛并不能说明该模型时无效的。</p>
<p>导致模型不收敛的原因包括：</p>
<ol>
<li>没有对数据做归一化处理。</li>
<li>没有使用正则化。</li>
<li><code>Batch Size</code>设的太大。</li>
<li>学习率设置的太大容易产生震荡，太小会导致不收敛。</li>
<li>没有做数据预处理。</li>
<li>没有检查过预处理结果和最终的训练测试结果。</li>
<li>网络存在坏梯度，比如当<code>ReLU</code>对负值的梯度为 $0$ ，反向传播时，梯度为 $0$ 表示不传播。</li>
<li>网络设定不合理，网络太浅或者太深。</li>
<li>最后一层的激活函数错误。</li>
<li>参数初始化错误。</li>
<li>隐藏层神经元数量错误。</li>
<li>数据集标签的设置有错误。</li>
</ol>
<h1 id="特征归一化"><a href="#特征归一化" class="headerlink" title="特征归一化"></a>特征归一化</h1><ul>
<li><p>训练数据集归一化很好理解，用于训练模型。</p>
</li>
<li><p>不能直接对测试数据集按公式进行归一化，而是要使用训练数据集的均值和方差对测试数据集归一化。</p>
<ul>
<li>原因1：真实的环境中，数据会源源不断输出进模型，无法求取均值和方差的。</li>
<li>原因2：训练数据集是模拟真实环境中的数据，不能直接使用自身的均值和方差。</li>
<li>原因3：真实环境中，无法对单个数据进行归一化。</li>
</ul>
</li>
</ul>
<h1 id="加快模型训练速度的方法"><a href="#加快模型训练速度的方法" class="headerlink" title="加快模型训练速度的方法"></a>加快模型训练速度的方法</h1><ul>
<li>合理的超参数设计</li>
<li>权值共享</li>
<li>升级相关软件包</li>
<li>多卡训练、数据并行</li>
<li>混合精度训练</li>
</ul>
<h1 id="训练集、测试集、验证集的作用"><a href="#训练集、测试集、验证集的作用" class="headerlink" title="训练集、测试集、验证集的作用"></a>训练集、测试集、验证集的作用</h1><p>训练集：训练集用来训练模型，即确定模型的权重和偏置这些参数，通常我们称这些参数为学习参数。</p>
<p>验证集：而验证集用于模型的选择，更具体地来说，验证集并不参与学习参数的确定，也就是验证集并没有参与梯度下降的过程。验证集只是为了选择超参数，比如网络层数、网络节点数、迭代次数、学习率这些都叫超参数。比如在k-NN算法中，k值就是一个超参数。所以可以使用验证集来求出误差率最小的k。</p>
<p>测试集：测试集只使用一次，即在训练完成后评价最终的模型时使用。它既不参与学习参数过程，也不参数超参数选择过程，而仅仅使用于模型的评价。值得注意的是，千万不能在训练过程中使用测试集，而后再用相同的测试集去测试模型。这样做其实是一个cheat，使得模型测试时准确率很高。</p>
<h1 id="极大似然估计和贝叶斯估计"><a href="#极大似然估计和贝叶斯估计" class="headerlink" title="极大似然估计和贝叶斯估计"></a>极大似然估计和贝叶斯估计</h1><p>极大似然估计（Maximum Likelihood Estimation，MLE）和贝叶斯估计（Bayesian Estimation）是统计推断中两种最常用的参数估计方法，二者在机器学习中的应用也十分广泛。</p>
<p>考虑这样一个问题：总体 $X$ 的概率密度函数为 $f(x\vert\theta)$，观测到一组样本 $(X_{1},X_{2},\cdots,X_{n})=(x_{1},x_{2},\cdots,x_{n})$，需要估计参数 $\theta$。下面我们将采用不同的估计方法来求解这个问题。</p>
<h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>极大似然估计是典型的频率学派观点，它的基本思想是：待估计参数 $\theta$ 是客观存在的，只是未知而已，当 $\hat{\theta}_{mle}$ 满足“ $\theta=\hat{\theta}_{mle}$ 时，该组观测样本 $(X_{1},X_{2},\cdots,X_{n})=(x_{1},x_{2},\cdots,x_{n})$ 更容易被观测到”，我们就说 $\hat{\theta}_{mle}$ 是 $\theta$ 的极大似然估计值。即估计值 $\hat{\theta}_{mle}$ 使得事件发生的可能性最大。下面给出极大似然估计的数学描述：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308231023271.png" alt=""></p>
<h2 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h2><p>贝叶斯估计是典型的贝叶斯学派观点，它的基本思想是：待估计参数 $\theta$ 也是随机的，和一般随机变量没有本质区别，因此只能根据观测样本估计参数 $\theta$ 的分布。贝叶斯估计利用了贝叶斯公式，给出贝叶斯公式的数学描述：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308231029120.png" alt=""></p>
<p>下面给出贝叶斯估计的数学描述：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308231122873.png" alt=""></p>
<p>其中， $\pi(\theta)$ 为参数 $\theta$ 的先验分布（prior distribution），表示对参数 $\theta$ 的主观认识，是非样本信息， $\pi(\theta\vert x)$ 为参数 $\theta$ 的后验分布（posterior distribution）。因此，贝叶斯估计可以看作是，在假定 $\theta$ 服从 $\pi(\theta)$ 的先验分布前提下，根据样本信息去校正先验分布，得到后验分布 $\pi(\theta\vert x)$ 。由于后验分布是一个条件分布，通常我们取后验分布的期望作为参数的估计值。因此，在观测到n个样本之后，下一个数据样本的 $x_{n+1}$ 的预测分布如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308231355906.png" alt=""></p>
<h3 id="最大后验估计"><a href="#最大后验估计" class="headerlink" title="最大后验估计"></a>最大后验估计</h3><p>在贝叶斯估计中，如果我们采用极大似然估计的思想，考虑后验分布极大化而求解 $\theta$，就变成了最大后验估计（Maximum A Posteriori estimation，MAP）：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308231127826.png" alt=""></p>
<p>由于 $m(x)$ 与 $\theta$ 无关，因此简化了计算。</p>
<p>作为贝叶斯估计的一种近似解，MAP有其存在的价值，因为贝叶斯估计中后验分布的计算往往是非常棘手的；而且，MAP并非简单地回到极大似然估计，它依然利用了来自先验的信息，这些信息无法从观测样本获得。</p>
<p>对上面的式子稍作处理：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308231137928.png" alt=""></p>
<p>如果将机器学习结构风险中的正则化项对应为上式的 $\log\pi(\theta)$ ，那么带有正则化项的最大似然学习就可以被解释为MAP。当然，这并不是总是正确的，例如，有些正则化项可能不是一个概率分布的对数，还有些正则化项依赖于数据，当然也不会是一个先验概率分布。不过，MAP提供了一个直观的方法来设计复杂但可解释的正则化项，例如，更复杂的惩罚项可以通过混合高斯分布作为先验得到，而不是一个单独的高斯分布。</p>
<h3 id="共轭先验"><a href="#共轭先验" class="headerlink" title="共轭先验"></a>共轭先验</h3><p>在贝叶斯估计中，如果选取先验分布 $\pi(\theta)$ ，使得后验分布 $\pi(\theta\vert x)$ 与 $\pi(\theta)$ 属于同一分布簇（即共轭分布），则称 $\pi(\theta)$ 为似然函数 $f(x\vert \theta)$ 的共轭先验。</p>
<p>共轭先验的选取有如下好处：</p>
<ul>
<li>符合直观，先验分布和后验分布应该是相同形式的；</li>
<li>可以给出后验分布的解析形式；</li>
<li>可以形成一个先验链，即现在的后验分布可以作为下一次计算的先验分布，如果形式相同，就可以形成一个链条。</li>
</ul>
<p>常见的共轭先验有：Beta分布（二项分布）、Dirichlet分布（多项分布）。</p>
<h1 id="Zero-Shot-One-Shot-Few-Shot"><a href="#Zero-Shot-One-Shot-Few-Shot" class="headerlink" title="Zero-Shot,One-Shot,Few-Shot"></a>Zero-Shot,One-Shot,Few-Shot</h1><p>Zero-Shot Learning（零样本学习）：利用训练集数据训练模型，使得模型能够对测试集的对象进行分类，但是训练集类别和测试集类别之间没有交集；期间需要借助类别的描述，来建立训练集和测试集之间的联系，从而使得模型有效。</p>
<p>Few-Shot Learning（小样本学习）：我们只通过看几张鸭嘴兽的照片，就能认识鸭嘴兽，这个过程就称作小样本学习。</p>
<p>One-Shot Learning（单样本学习）：Few-Shot Learning的特殊情况，即只看了一张鸭嘴兽的照片，就认识了鸭嘴兽。（人脸识别）</p>
<h1 id="PyTorch和TensorFlow的区别"><a href="#PyTorch和TensorFlow的区别" class="headerlink" title="PyTorch和TensorFlow的区别"></a>PyTorch和TensorFlow的区别</h1><h2 id="动态图与静态图"><a href="#动态图与静态图" class="headerlink" title="动态图与静态图"></a>动态图与静态图</h2><p><code>TensorFlow</code>最初选择使用静态图，这样的设计带来了较高的性能，但在构建网络时较为烦琐，用户需要专门学习<code>TensorFlow</code>的语法架构才能搭建网络，同时很难调试。<code>PyTorch</code>选择使用动态图，动态图的设计模式更加符合人类的思考过程，方便查看、修改中间变量的值，用户可以轻松地搭建网络进行训练。目前，<code>TensorFlow 2.0</code>之后的版本已经支持动态图的构建，并且提供动态图与静态图的转换功能。</p>
<ul>
<li>静态图</li>
</ul>
<p>静态图的生成与执行采用先编译后执行的方式，该模式将计算图的定义和执行进行分离。</p>
<p>静态图只建一次，然后不断复用它，容易在图上做优化，图的效率更高（比如Add操作和ReLU结合在一起优化）。</p>
<p>静态图可以在磁盘中序列化，可以保存整个网络的结构，可以重载，在部署中很实用。</p>
<p>静态图中条件和循环需要特定的语法（tf.condition和tf.while_loop）。</p>
<ul>
<li>动态图</li>
</ul>
<p>动态图采用解析式的执行方式，其核心特点是编译与执行同时发生。</p>
<p>动态图每次使用时建立，不容易优化。</p>
<p>动态图需要重复之前的代码。</p>
<p>只用Python的语法就可以实现条件和循环。</p>
<h2 id="部署和可扩展性"><a href="#部署和可扩展性" class="headerlink" title="部署和可扩展性"></a>部署和可扩展性</h2><p>如果您的项目范围很大，需要大规模部署，或者项目涉及跨平台，那么您的选择应该是<code>TensorFlow</code>，<code>TensorFlow</code>提供了<code>TensorFlow Serving</code>和<code>TensorFlow Lite</code>，可以便捷地将训练好的模型部署到集群以及移动设备上。如果它只是一个较小规模的研究项目的原型设计或类似的东西，那么<code>PyTorch</code>更好。</p>
<h2 id="资源优化和利用率"><a href="#资源优化和利用率" class="headerlink" title="资源优化和利用率"></a>资源优化和利用率</h2><p>如果您正在寻找更好的资源利用率和优化，如<code>GPU</code>，那么<code>PyTorch</code>肯定是首选。但是，当涉及到<code>TensorFlow</code>时，它使用当时可用的所有<code>GPU</code>容量，因此，功能略微缓慢。</p>
<h2 id="学术研究和开源代码"><a href="#学术研究和开源代码" class="headerlink" title="学术研究和开源代码"></a>学术研究和开源代码</h2><p>在学术界<code>PyTorch</code>有很多好评，其中四分之三的论文使用它。而且最早使用<code>TensorFlow</code>的研究人员中，很多人已经迁移到了<code>PyTorch</code>。正因如此，研究会影响教学，从而决定学生学到的是什么。所以如今，大学生对<code>PyTorch</code>了解的相对多一些。</p>
<h1 id="Pytorch底层原理"><a href="#Pytorch底层原理" class="headerlink" title="Pytorch底层原理"></a>Pytorch底层原理</h1><h2 id="自动微分的实现"><a href="#自动微分的实现" class="headerlink" title="自动微分的实现"></a>自动微分的实现</h2><ol>
<li><strong>计算图</strong>：在PyTorch中，每次操作都会被记录在一个计算图上。这个图是一个有向无环图（DAG），表示了所有操作之间的依赖关系。在这个图中，每个节点表示一个操作，每个边表示张量传输。</li>
<li><strong>梯度缓冲区</strong>：在每个操作上，PyTorch都会保留一个梯度缓冲区，用于存储该操作的梯度。在反向传播过程中，这个梯度缓冲区会被填充，然后用于计算每个变量的梯度。</li>
<li><strong>反向传播</strong>：当我们调用<code>.backward()</code>时，PyTorch会开始从最后一层开始，根据每个操作的梯度计算上游的梯度。这个过程会一直进行，直到到达第一层。在这个过程中，每个变量的梯度都会被累积到对应的<code>.grad</code>属性中。</li>
</ol>
<h1 id="Pytorch多卡训练"><a href="#Pytorch多卡训练" class="headerlink" title="Pytorch多卡训练"></a>Pytorch多卡训练</h1><p>对于pytorch而言，有两种方式进行并行：数据并行（DataParallel，DP）和分布式数据并行（DistributedDataParallel，DDP）。</p>
<p>在多卡训练的实现上，DP与DDP的思路是相似的：</p>
<ol>
<li>每张卡都复制一个有相同参数的模型副本。</li>
<li>每次迭代，每张卡分别输入不同批次数据，分别计算梯度。</li>
<li>DP与DDP的主要不同在于接下来的多卡通信：</li>
</ol>
<p>DP的多卡交互实现在一个进程之中，它将一张卡视为主卡，维护单独模型优化器。所有卡计算完梯度后，主卡汇聚其它卡的梯度进行平均并用优化器更新模型参数，再将模型参数更新至其它卡上。</p>
<p>DDP则分别为每张卡创建一个进程，每个进程相应的卡上都独立维护模型和优化器。在每次每张卡计算完梯度之后，进程之间以NCLL（NVIDIA GPU通信）为通信后端，使各卡获取其它卡的梯度。各卡对获取的梯度进行平均，然后执行后续的参数更新。由于每张卡上的模型与优化器参数在初始化时就保持一致，而每次迭代的平均梯度也保持一致，那么即使没有进行参数复制，所有卡的模型参数也是保持一致的。</p>
<h1 id="DataLoader-DataSet-Sampler之间的关系"><a href="#DataLoader-DataSet-Sampler之间的关系" class="headerlink" title="DataLoader, DataSet, Sampler之间的关系"></a>DataLoader, DataSet, Sampler之间的关系</h1><p>首先我们看一下DataLoader.next的源代码长什么样,为方便理解只选取了num_works为0的情况（num_works简单理解就是能够并行化地读取数据）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataLoader</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">	...</span><br><span class="line">	</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.num_workers == <span class="number">0</span>:  </span><br><span class="line">            indices = <span class="built_in">next</span>(self.sample_iter)  <span class="comment"># Sampler</span></span><br><span class="line">            batch = self.collate_fn([self.dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices]) <span class="comment"># Dataset</span></span><br><span class="line">            <span class="keyword">if</span> self.pin_memory:</span><br><span class="line">                batch = _utils.pin_memory.pin_memory_batch(batch)</span><br><span class="line">            <span class="keyword">return</span> batch</span><br></pre></td></tr></table></figure>
<p>假设我们的数据是一组图像，每一张图像对应一个index，那么如果我们要读取数据就只需要对应的index即可，即上面代码中的indices，而选取index的方式有多种，有按顺序的，也有乱序的，所以这个工作需要Sampler完成。</p>
<p>那么Dataset和DataLoader在什么时候产生关系呢？没错就是下面一行。我们已经拿到了indices，那么下一步我们只需要根据index对数据进行读取即可了。</p>
<p>综上可以知道DataLoader，Sampler和Dataset三者关系如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308221330259.png" alt=""></p>
<h1 id="混合精度训练"><a href="#混合精度训练" class="headerlink" title="混合精度训练"></a>混合精度训练</h1><h2 id="FP16"><a href="#FP16" class="headerlink" title="FP16"></a>FP16</h2><p><strong>半精度浮点数 (FP16)</strong> 是一种计算机使用的二进制浮点数数据类型，使用 2 字节 (16 位) 存储，表示范围为 $[-6.5e^{4},-5.9e^{-8}]\cup[5.9e^{-8},6.5e^{4}]$。而 PyTorch 默认使用<strong>单精度浮点数 (FP32)</strong> 来进行网络模型的计算和权重存储。FP32 在内存中用 4 字节 (32 位) 存储，表示范围为 $[-3e^{38},-1e^{-38}]\cup[1e^{-38},3e^{38}]$。可以看到 FP32 能够表示的范围要比 FP16 大的多得多。</p>
<h2 id="为什么要用FP16"><a href="#为什么要用FP16" class="headerlink" title="为什么要用FP16"></a>为什么要用FP16</h2><ul>
<li>减少显存占用：FP16 的显存占用只有 FP32 的一半，这使得我们可以用更大的 batch size；</li>
<li>加速训练：使用 FP16，模型的训练速度几乎可以提升 1 倍。</li>
</ul>
<h2 id="为什么只用FP16会有问题"><a href="#为什么只用FP16会有问题" class="headerlink" title="为什么只用FP16会有问题"></a>为什么只用FP16会有问题</h2><ul>
<li>上/下溢出：FP16 的表示范围不大，超过 $6.5e^{4}$ 的数字会上溢出变成 inf，小于 $5.9e^{-8}$ 的数字会下溢出变成 0。下溢出更加常见，因为在网络训练的后期，模型的梯度往往很小，甚至会小于 FP16 的下限 $5.9e^{-8}$，此时梯度值就会变成 0，模型参数无法更新。</li>
<li>舍入误差：就算梯度不会上/下溢出，如果梯度值和模型的参数值相差太远，也会发生舍入误差的问题。假设模型参数 $weight=2^{-3}$ ，学习率 $\eta=2^{-2}$ ，梯度 $gradient=2^{-12}$ ，$weight^{‘}=weight+\eta\times gradient=2^{-3}+2^{-2}\times2^{-12}=2^{-3}$ 。</li>
</ul>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><ul>
<li>损失缩放 (Loss Scaling)：为了解决下溢出的问题，论文中对计算出来的 loss 值进行缩放 (scale)，由于链式法则的存在，对 loss 的缩放会作用在每个梯度上。缩放后的梯度，就会平移到 FP16 的有效范围内。这样就可以用 FP16 存储梯度而又不会溢出了。此外，在进行更新之前，需要先将缩放后的梯度转化为 FP32，再将梯度反缩放 (unscale) 回去。 <strong>注意这里一定要先转成 FP32，不然 unscale 的时候还是会下溢出。</strong></li>
<li>FP32 权重备份：为了实现 FP16 的训练，我们需要把模型权重和输入数据都转成 FP16，反向传播的时候就会得到 FP16 的梯度。如果此时直接进行更新，因为<strong>梯度 * 学习率</strong>的值往往较小，和模型权重的差距会很大，可能会出现舍入误差的问题。 所以解决思路是：将<strong>模型权重、激活值、梯度</strong>等数据用 <strong>FP16</strong> 来存储，同时维护一份 <strong>FP32</strong> 的<strong>模型权重副本</strong>用于更新。在反向传播得到 FP16 的梯度以后，<strong>将其转化成 FP32 并 unscale</strong>，最后更新 FP32 的模型权重。因为整个更新过程是在 FP32 的环境中进行的，所以不会出现舍入误差。</li>
<li>黑名单：对于那些在 FP16 环境中运行不稳定的模块，我们会将其添加到黑名单中，强制它在 FP32 的精度下运行。比如需要计算 batch 均值的 BN 层就应该在 FP32 下运行，否则会发生舍入误差。还有一些函数对于算法精度要求很高，比如 torch.acos()，也应该在 FP32 下运行。论文中的黑名单只包含 BN 层。</li>
</ul>
<h1 id="提升模型泛化能力的方法"><a href="#提升模型泛化能力的方法" class="headerlink" title="提升模型泛化能力的方法"></a>提升模型泛化能力的方法</h1><ul>
<li>从数据角度上来说。可以通过数据增强、扩充训练集等方法提高泛化能力。</li>
<li>在训练策略上，可以增加每个<code>Batch Size</code>的大小，进而让模型每次迭代时见到更多数据，防止过拟合。</li>
<li>调整数据分布，做训练数据集的类别均衡。</li>
<li>调整网络结构。如果数据集较小，可以降低模型复杂度防止过拟合。如果数据集较大，可以尝试更加复杂的模型。</li>
<li>减少过拟合的方法也可以提升模型的泛化能力。</li>
</ul>
<h1 id="偏差和方差"><a href="#偏差和方差" class="headerlink" title="偏差和方差"></a>偏差和方差</h1><p>偏差：模型预测值的期望与真实值之间的差异，反应的是模型的拟合能力。<br>方差：反应的是训练集的变化所导致的学习性能的变化，即刻画了<strong>数据扰动</strong>所造成的影响，模型过拟合时会出现较大的方差。</p>
<h1 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>过拟合就是随着模型的训练，模型在训练集上的表现越来越好，但是在验证集上的表现却越来越差，也就是说对训练集的拟合程度过高，导致模型的泛化能力降低。<br>欠拟合就是模型在训练集上也无法达到满意的精度。</p>
<h2 id="过拟合的解决方案"><a href="#过拟合的解决方案" class="headerlink" title="过拟合的解决方案"></a>过拟合的解决方案</h2><p>过拟合通常是由于训练数据过少、模型复杂度过大等问题导致的，因此相应的解决方案也是从这两个角度考虑。</p>
<ul>
<li>使用更多的数据进行训练，并且数据集尽量均匀，做一些数据增强。</li>
<li>降低模型复杂度。并不是说模型越复杂越好，如果模型过于复杂，而训练集又较少，那么参数就很容易拟合到一个过于适配训练集的参数空间中，自然就会导致过拟合的出现。</li>
<li><code>Early Stopping</code>，简单来说就是减少迭代次数。随着训练次数的增加，模型对训练数据的拟合程度也会随之增高，所以也可以通过减少训练时间的方法避免过拟合，提高模型泛化能力。</li>
<li><code>L1</code>、<code>L2</code>正则化方法，限制模型权重。</li>
<li>在数据中增加一些噪声，从而通过影响损失函数的优化方向避免过拟合。</li>
<li><code>Dropout</code>，目的也是降低模型的复杂度。</li>
<li><code>ResNet</code>。是的，<code>ResNet</code>也可以解决过拟合问题，因为<code>ResNet</code>的跳线结构可以让部分参数权重归零，进而达到类似于<code>Dropout</code>的效果。</li>
</ul>
<h3 id="L1正则化和L2正则化"><a href="#L1正则化和L2正则化" class="headerlink" title="L1正则化和L2正则化"></a>L1正则化和L2正则化</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202309052221203.png" alt=""></p>
<h4 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h4><p>优点：</p>
<ul>
<li>L1正则化可以自动进行特征选择，这对于需要大量特征的模型非常有用。通过将某些参数优化为零，可以降低模型的复杂度，提高模型的泛化能力。</li>
<li>在L1正则化下，模型的系数向量具有稀疏性（正则化项的解和目标函数的等高线焦点容易在坐标轴上），这使得模型解释性更好。</li>
</ul>
<p>缺点：</p>
<ul>
<li>L1正则化可能会导致模型在零附近的波动较大，因为参数的绝对值可能会受到较大影响。</li>
<li>在L1正则化下，某些特征可能会被错误地忽略，因为它们可能只是与其他特征有微小的差异。</li>
</ul>
<h4 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h4><p>优点：</p>
<ul>
<li>L2正则化可以减少模型的复杂性，降低过拟合的风险。</li>
<li>L2正则化可以使得模型的系数向量的范数较小，这可以防止模型过度拟合训练数据。</li>
</ul>
<p>缺点：</p>
<ul>
<li>L2正则化不会自动进行特征选择，因此对于需要大量特征的模型可能需要手动选择特征。</li>
<li>在L2正则化下，所有特征的重要性都是相等的，这可能会导致某些特征被错误地赋予更高的权重。</li>
</ul>
<h2 id="欠拟合的解决方案"><a href="#欠拟合的解决方案" class="headerlink" title="欠拟合的解决方案"></a>欠拟合的解决方案</h2><p>欠拟合通常是由于模型表征能力不足、数据量过大导致的，刚好和过拟合相反。</p>
<ul>
<li>使用更复杂的模型。</li>
<li>增加迭代次数。</li>
<li>减少数据中的噪声。</li>
</ul>
<h1 id="梯度消失和梯度爆炸"><a href="#梯度消失和梯度爆炸" class="headerlink" title="梯度消失和梯度爆炸"></a>梯度消失和梯度爆炸</h1><h2 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h2><p>梯度消失就是指在网络反向传播过程中由于链式求导法则不断的累积，如果每一层的梯度都小于 $1$ ，由于累乘效应，出现了某些参数的梯度非常小的现象。在使用这些梯度更新梯度的时候参数值基本没有发生变化，因此就出现了网络训练停滞、模型无法继续优化的问题。</p>
<p>梯度爆炸与之刚好相反，在网络反向传播过程中由于链式求导法则的累乘效应，在每一层梯度都大于 $1$ 的时候，就可能会出现某些参数的梯度非常大。在使用这些梯度更新参数的时候就会导致参数变化过大，就会出现损失函数震荡的现象。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol>
<li>预训练和<code>fine-tuning</code>就是将一些在公开训练集上训练好的模型参数加载到自己对应的模型中，这样损失函数通常就能稳定的优化。</li>
<li>梯度裁剪：梯度裁剪是一个针对梯度爆炸的解决方案，也就是说将梯度限制在某个阈值范围内，如果梯度超过的这个阈值，那么就将其设置为这个阈值。</li>
<li>正则化：正则化也是一种限制梯度爆炸的解决方案，同时也有限制过拟合的作用。</li>
<li>使用<code>ReLU</code>、<code>Leaky ReLU</code>、<code>ELU</code>等激活函数：梯度消失通常是因为损失函数选择 <code>Sigmoid</code> 导致的，而<code>ReLU</code>激活函数在正数部分梯度是恒等于 $1$ 的，由于 $1$ 不会累积加权的特性，自然就可以避免梯度消失或梯度爆炸现象。但是<code>ReLU</code>同样有缺点，作为分段函数，<code>ReLU</code>在负数部分恒为 $0$ ，导致一些神经元无法被激活。而<code>Leaky ReLU</code>、<code>ELU</code>就可以避免这个问题。</li>
<li><code>BN(Batch Normalization)</code>：<code>BN</code>可以加速网络收敛提升训练的稳定性，它把每一层神经网络的任意神经元输入值的分布规范为正态分布，如果采用<code>Sigmoid</code>激活函数，那么就可以使得激活函数的输入落在梯度较大的区域，因此就能一定程度解决梯度消失的问题。</li>
<li>使用类似<code>ResNet</code>的跳线结构：由于离输出近的层学习效果好，而由于链式求导法则的影响可能会导致梯度消失或者梯度爆炸，因此可以模仿<code>ResNet</code>在网络的中间增加跳线结构，这样对应层求导梯度时候由于跳线的连接可以增加一个让梯度无损传播的通路，从而避免梯度消失或者梯度爆炸。</li>
<li>采用<code>LSTM</code>等结构：在<code>NLP</code>领域中，<code>LSTM</code>有时也会被用于对抗梯度现象，这是由于其具有复杂的门结构来控制梯度更新。</li>
</ol>
<h1 id="解决样本不均衡的方法"><a href="#解决样本不均衡的方法" class="headerlink" title="解决样本不均衡的方法"></a>解决样本不均衡的方法</h1><ul>
<li>以多种数据组合形式训练模型并做模型融合。顾名思义，这种方法就是将全部的小样本数据和等量的大样本数据分别组合成几批训练数据集，并以此训练出几个不同的模型并做模型融合，这种方法能够有效的解决样本不均衡问题。</li>
<li>在计算损失函数时改变数据的权重，增加小样本数据的权重，减少大样本的权重。这种方法实际上参考了<code>focal loss</code>的思想，只不过解决的不是难易样本不均衡，而是样本数据量不均衡，同样能保证模型的泛化性能。</li>
<li>过采样小样本，欠采样大样本。也就是对于训练数据，把那些样本量较小的数据多在<code>load</code>数据时重复几遍，对于那些样本量较大的数据，则尽量减少<code>load</code>它们，以此来达到样本均衡的目的。例如：SMOTE、ADASYN、bSMOTE算法通过插值生成合成样本进行过采样；使用Tomek Links、Cluster Centroids、NearMiss进行欠采样。</li>
<li>使用集成方法：如Bagging、Boosting等集成方法可以改善不平衡数据集的分类性能。</li>
<li>将分类问题看成异常检测问题。</li>
</ul>
<h1 id="LabelSmoothing"><a href="#LabelSmoothing" class="headerlink" title="LabelSmoothing"></a>LabelSmoothing</h1><p>传统做图像分类采用的损失是交叉熵损失，具体形式是： $\mathcal{L}=-\sum_{i=1}^{m}t_{i}\log(y_{i})$ 。其中， $m$ 表示类别数， $y_{i}$ 表示<code>softmax</code>之后每个类的预测概率， $t_{i}$ 表示样本的真实标签值。然而，神经网络有一个坏习惯，就是在训练过程中对预测变得”过于自信“，这可能会降低它们的泛化能力，从而在新的、看不见的未来数据上表现得同样出色。此外，大型数据集通常会包含标签错误的数据，这意味着神经网络在本质上应该对“正确答案”持怀疑态度，以减少一定程度上围绕错误答案的极端情况下的建模。</p>
<p>因此，标签平滑所做的就是通过训练网络向<code>1-adjustment</code>目标移动，然后在其余的类上除以这个<code>adjustment</code>，从而使它对自己的答案不那么自信，而不是简单的设为 $1$ 。新标签的表现形式为：$T^{\prime}=(1-\varepsilon)*T+\frac{\varepsilon}{N}$。其中， $N$ 表示类别的个数， $T$ 表示真实标签值， $T^{\prime}$ 表示平滑后的标签。</p>
<p>例如，原来的标签 $T$ 为 $[0,0,1,0,0]$ ， $\varepsilon=0.1$ ，经过<code>LabelSmoothing</code>之后的标签 $T^{\prime}$ 为 $[0.02,0.02,0.92,0.02,0.02]$ 。</p>
<h1 id="图像处理中平滑和锐化操作是什么？"><a href="#图像处理中平滑和锐化操作是什么？" class="headerlink" title="图像处理中平滑和锐化操作是什么？"></a>图像处理中平滑和锐化操作是什么？</h1><h2 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h2><p>锐化就是通过增强图像的高频信息，也就是纹理边缘来减少图像中的模糊细节，但是在增强纹理的时候也引入了图像噪声。</p>
<p>平滑处理<code>(smoothing)</code>也称模糊处理<code>(bluring)</code>，主要用于消除图像中的噪声部分，平滑处理常用的用途是用来减少图像上的噪点或失真，平滑主要使用图像滤波。在这里，我个人认为可以把图像平滑和图像滤波联系起来，因为图像平滑常用的方法就是图像滤波器。</p>
<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ul>
<li>在计算机视觉的一些任务中，涉及到图像重建的、如高精度的深度估计、医学图像分割、三维重建等任务，最终需要得到原始图像分辨率大小的输出，同时对图像的边缘清晰度也有较高的要求，这时候可以通过增强特征图中的高频分量，在计算损失函数的时候放大这些区域的损失，进而放大对应参数的梯度，使得网络往更突出边缘的方向上优化。</li>
<li>与上相反，如果是一些希望输出更加平滑的任务，则可以考虑对特征图进行平滑操作，进而减小高频区域的损失，减小对应参数的梯度，使得网络往更平滑的方向上优化，通常这种技术都会用在<code>smooth loss</code>中。</li>
</ul>
<h1 id="图像中的低频信号和高频信号"><a href="#图像中的低频信号和高频信号" class="headerlink" title="图像中的低频信号和高频信号"></a>图像中的低频信号和高频信号</h1><p>图像中的高频分量，指的是图像强度（亮度/灰度）变化剧烈的地方，也就是我们常说的边缘（轮廓）；图像中的低频分量，指的是图像强度（亮度/灰度）变换平缓的地方，也就是大片色块的地方。人眼对图像中的高频信号更为敏感。</p>
<h1 id="batchsize"><a href="#batchsize" class="headerlink" title="batchsize"></a>batchsize</h1><ul>
<li><code>batchsize</code>：批大小。在深度学习中，一般采用<code>SGD</code>训练，即每次训练在训练集中取<code>batchsize</code>个样本训练。</li>
<li><code>iteration</code>：1个<code>iteration</code>等于使用<code>batchsize</code>个样本训练一次。</li>
<li><code>epoch</code>：1个<code>epoch</code>等于使用训练集中的全部样本训练一次。</li>
</ul>
<p>如果数据集比较小，则完全可以采用全数据集的形式。这样做的好处有两点：</p>
<ol>
<li>全数据集的方向能够更好的代表样本总体，确定其极值所在。</li>
<li>由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。</li>
</ol>
<p>增大<code>batchsize</code>的好处有三点：</p>
<ol>
<li>内存的利用率提高了，大矩阵乘法的并行化效率提高。</li>
<li>跑完一次<code>epoch</code>（全数据集）所需迭代次数减少，对于相同的数据量的处理速度进一步加快。</li>
<li>一定范围内，<code>batchsize</code>越大，其确定的下降方向就越准，引起训练震荡越小。</li>
</ol>
<p>盲目增大<code>batchsize</code>的坏处有三点：</p>
<ol>
<li>当数据集太大时，内存撑不住。</li>
<li>跑完一次<code>epoch</code>（全数据集）所需迭代次数减少了，但要想达到相同的精度，时间开销太大，参数的修正更加缓慢。</li>
<li><code>batchsize</code>增大到一定的程度，其确定的下降方向已经基本不再变化。</li>
</ol>
<h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><h2 id="Huber-Loss"><a href="#Huber-Loss" class="headerlink" title="Huber Loss"></a>Huber Loss</h2><p>Huber损失函数是一种在回归问题中常用的损失函数，它对于输入数据的小偏差具有较低的敏感性，对于大偏差具有较高的敏感性。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308261842588.png" alt=""></p>
<h2 id="Smooth-L1-Loss"><a href="#Smooth-L1-Loss" class="headerlink" title="Smooth L1 Loss"></a>Smooth L1 Loss</h2><p>smooth L1 loss是Huber loss在 $\delta=1$ 条件下的特例。</p>
<ol>
<li>当预测框与<code>ground truth</code>差别过大时，梯度值不至于过大；</li>
<li>当预测框与<code>ground truth</code>差别很小时，梯度值足够小。</li>
</ol>
<p>为啥要做这两方面的限制呢？</p>
<ol>
<li>差距大时，梯度过于大，可能会导致梯度爆炸；</li>
<li>差距很小时，梯度足够小，能够接近最优点，避免大幅横跳。</li>
</ol>
<p><code>L2</code>、<code>L1</code>、<code>Smooth L1</code>损失函数分别定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303222347197.png" alt=""></p>
<p>损失函数对 $x$ 的导数分别为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303222349037.png" alt=""></p>
<p><code>L2</code>对 $x$ 的导数，与 $x$ 成<strong>正比关系</strong>。也就是当 $x$ 增大时，对 $x$ 的导数也线性增大。这就导致在训练初期，预测值与 <code>groud truth</code> 差异过于大时，损失函数对预测值的梯度十分大，<strong>训练初期不稳定</strong>。</p>
<p><code>L1</code>对 $x$ 的导数为常数，始终为 $1$ 或 $-1$ 。这就导致训练后期，预测值与<code>ground truth</code>差异很小时，损失对预测值的导数的绝对值仍然为 $1$ ，而 <code>learning rate</code>如果不变，损失函数将在稳定值附近波动，难以继续收敛以达到更高精度。</p>
<p><code>Smooth L1</code> 在 $x$ 较小时，也就是 $[-1,1]$ 区间，对 $x$ 的梯度也会变小；而在 $x$ 很大时，对 $x$ 的梯度的绝对值达到上限 $1$ ，也不会太大以至于破坏网络参数。 完美地避开了<code>L1</code> 和 <code>L2</code>损失的缺陷。</p>
<h2 id="Cross-Entropy-Loss"><a href="#Cross-Entropy-Loss" class="headerlink" title="Cross Entropy Loss"></a>Cross Entropy Loss</h2><p>既可用于多分类任务（只有一个能胜出），也可用于二分类任务。设标签为 $y$ （多分类中是one-hot编码），网络预测结果为 $\hat{y}$ ，<code>CE</code>损失函数为（这里只考虑了一个样本，c指的是多分类的类别数目）：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306211132940.png" alt=""></p>
<p><strong>分类为什么选择交叉熵而不是MAE：</strong></p>
<ol>
<li>稀疏性：交叉熵对于错误分类的样本具有稀疏性，即将一个样本错误分类为另一个类别的损失相对较小。相比之下，MAE对于每一个错误分类的样本都会产生较大的损失。因此，交叉熵在处理不平衡的数据集时表现更好。</li>
<li>对异常值的鲁棒性：交叉熵对于异常值不太敏感，而MAE对于异常值非常敏感。因此，使用交叉熵的模型对异常值的鲁棒性更强。</li>
<li>优化性能：对于深度学习模型，使用交叉熵作为损失函数通常会导致更快的优化收敛。这是由于交叉熵损失函数相对于模型参数的梯度具有较小的方差。</li>
</ol>
<h2 id="Binary-Cross-Entropy-Loss"><a href="#Binary-Cross-Entropy-Loss" class="headerlink" title="Binary Cross Entropy Loss"></a>Binary Cross Entropy Loss</h2><p>二值交叉熵损失，虽然总是用来学习0/1分布，即二分类问题，但不是0/1两个数，只要在0~1之间的数也都能学习。设标签为 $y$ ，网络预测结果为 $\hat{y}$ ，<code>BCE</code>损失函数为（这里考虑了N个样本，每个样本都是二分类）： </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306211055521.png" alt=""></p>
<p>某些情况下需要加上权重：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306211059473.png" alt=""></p>
<h2 id="Focal-loss"><a href="#Focal-loss" class="headerlink" title="Focal loss"></a>Focal loss</h2><p>Focal Loss的引入主要是为了解决one-stage目标检测中正负样本数量极不平衡问题。当易区分负样本超级多时，整个训练过程将会围绕着易区分负样本进行，进而淹没正样本，造成大损失。所以这里引入了一个调制因子 ，用来聚焦难分样本，公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306211251919.png" alt=""></p>
<p>当 $p_{t}$ 趋向于1，即说明该样本是易区分样本，此时调制因子是趋向于0，说明对损失的贡献较小，即减低了易区分样本的损失比例。当 $p_{t}$ 很小，也就是假如某个样本被分到正样本，但是该样本为前景的概率特别小，即被错分到正样本了，此时调制因子是趋向于1，对loss也没有太大的影响。</p>
<p>我们在实验中采用了如下的$\alpha$-平衡变体形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308101255449.png" alt=""></p>
<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><p><code>Sigmoid</code>是最基础的激活函数，可以将任意数值转换为概率（缩放到 $0 \thicksim 1$ 之间），在分类等场景中有广泛的应用。<code>Sigmoid</code>函数的形式是 $\sigma(z)=\frac{1}{1+e^{-z}}$ 。其对应的函数图像如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101955821.png" alt=""></p>
<h2 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h2><p>激活函数<code>tanh</code>和<code>Sigmoid</code>类似，都是<code>S</code>形曲线，输出范围是$[-1, 1]$。<code>tanh</code>函数的形式为 $g(z)=\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$ 。其对应的函数图像如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304102004442.png" alt=""></p>
<h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p><code>ReLU(Rectified Linear Unit)</code>，是一种人工神经网络中常用的激活函数。通常意义下，其指代数学中的斜坡函数，即<br> $f(x)=\max(0,x)$ 。其对应的函数图像如下所示：<br><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101950246.png" alt=""></p>
<h2 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h2><p>为了解决<code>dead ReLU</code>问题（<code>ReLU</code>在训练的时很“脆弱”。在 $x&lt;0$ 时，梯度为 $0$ ，这个神经元及之后的神经元梯度永远为 $0$ ，不再对任何数据有所响应，导致相应参数永远不会被更新）。<code>Leaky ReLU</code>用一个类似 $0.01$ 的小值来初始化神经元，从而使得<code>ReLU</code>在负数区域更偏向于激活而不是坏死，这里的斜率都是确定的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304102008358.png" alt=""></p>
<h2 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h2><p><code>ELU</code>的提出也解决了<code>ReLU</code>的问题。与<code>ReLU</code>相比，<code>ELU</code>有负值，这会使激活的平均值接近零，让模型学习得更快。当 $x&lt;0$ 时，<code>ELU</code>的函数形式为 $f(x)=\alpha(e^{x}-1)$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304102010115.png" alt=""></p>
<h2 id="GELU"><a href="#GELU" class="headerlink" title="GELU"></a>GELU</h2><p>激活函数<code>GELU</code>的灵感来源于<code>ReLU</code>和<code>Dropout</code>，在激活中引入了<strong>随机正则</strong>的思想。<code>GELU</code>通过输入自身的概率分布情况，决定抛弃还是保留当前的神经元。<code>GELU</code>函数的形式是 $GELU(x)=0.5x(1+\tanh(\sqrt\frac{2}{\pi}(x+0.044715x^{3})))$ 。其对应的函数图像如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304102019772.png" alt=""></p>
<p>可以理解为，对于输入的值，根据它的情况乘上 $1$ 或 $0$ 。更「数学」一点的描述是，对于每一个输入 $x$ ，其服从于标准正态分布 $\mathcal{N}(0, 1)$ ，它会乘上一个伯努利分布 $Bernoulli(\Phi(x))$，其中 $\Phi(x) = P(X \leq x)$ 。随着 $x$ 的降低，它被归零的概率会升高。对于<code>ReLU</code>来说，这个界限就是 $0$ ，输入少于零就会被归零。这一类激活函数，不仅保留了概率性，同时也保留了对输入的依赖性。<code>GELU</code>在最近的<code>Transformer</code>模型中（包括<code>BERT</code>，<code>RoBertA</code>和<code>GPT2</code>等）得到了广泛的应用。</p>
<h2 id="ReLU比Sigmoid效果好在哪里？"><a href="#ReLU比Sigmoid效果好在哪里？" class="headerlink" title="ReLU比Sigmoid效果好在哪里？"></a>ReLU比Sigmoid效果好在哪里？</h2><p><code>ReLU</code>的输出要么是 $0$ , 要么是输入本身。虽然方程简单，但实际上效果更好。</p>
<ol>
<li><code>ReLU</code>函数计算简单，可以减少很多计算量。反向传播求误差梯度时，涉及除法，计算量相对较大，采用<code>ReLU</code>激活函数，可以节省很多计算量。</li>
<li>避免梯度消失问题。对于深层网络，<code>Sigmoid</code>函数反向传播时，很容易就会出现梯度消失问题（在<code>Sigmoid</code>接近饱和区时，变换太缓慢，导数趋于 $0$ ，这种情况会造成信息丢失），从而无法完成深层网络的训练。例如在<code>RNN</code>当中，随着时间序列的不断深入，小数的累乘就会导致梯度越来越小直到接近于 $0$ ，这就是“梯度消失“现象。此时采用<code>ReLU</code>激活函数就避免了“梯度消失“的发生。</li>
<li>可以缓解过拟合问题的发生，<code>ReLU</code>会使一部分神经元的输出为 $0$ ，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。</li>
</ol>
<h1 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h1><p>记号： $\theta_{t}$ 表示第 $t$ 轮的参数， $\eta$ 表示学习率， $g_{t}$ 表示第 $t$ 轮的梯度即 $\triangledown\hat{\mathcal{L}}(\theta_{t})$ ， $m_{t}$ 表示第 $t$ 轮的一阶动量， $v_{t}$ 表示第 $t$ 轮的二阶动量， $\hat{m}_{t}$ 为偏差纠正后的一阶矩估计， $\hat{v}_{t}$ 为偏差纠正后的二阶矩估计。</p>
<h2 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h2><p><code>SGD(Stochastic Gradient Descent)</code>，随机梯度下降。每次选择一个<code>mini-batch</code>，而不是全部样本，使用梯度下降来更新模型参数。它解决了随机小批量样本的问题，但仍然有自适应学习率、容易卡在梯度较小点等问题。</p>
<p>$m_{t}=g_{t}, \ v_{t}=1$</p>
<p>$\theta_{t+1}=\theta_{t}-\eta \frac{m_{t}}{\sqrt{v_{t}}}=\theta_{t}-\eta g_{t} $</p>
<p><strong>缺点：</strong>下降速度慢，而且可能会在沟壑的两边持续振荡，停留在一个局部最优点</p>
<h2 id="SGDM"><a href="#SGDM" class="headerlink" title="SGDM"></a>SGDM</h2><p><code>SGDM(SGD with momentum)</code>，在<code>SGD</code>基础上增加一阶动量。  参数更新时以上一个时刻的一阶动量为主，其中 $\beta$ 通常取 $0.9$。</p>
<p>$m_{t} = \beta m_{t-1} + (1-\beta)  g_{t}, \ v_{t} = 1$</p>
<p>$\theta_{t+1} = \theta_{t} - \eta \frac{m_{t}}{\sqrt{v_{t}}} = \theta_{t} - \eta (\beta m_{t-1} + (1-\beta) g_{t}) $</p>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><p>在<code>SGD</code>基础上增加二阶动量，可以对模型中的每个参数分配自适应学习率。</p>
<p>$m_{t}=g_{t}$</p>
<p>$v_{t}=\sum_{\tau=1}^{t}g_{\tau}^{2}$</p>
<p>$\theta_{t+1}=\theta_{t}-\eta \frac{m_{t}}{\sqrt{v_{t}+\epsilon}}=\theta_{t}-\eta \frac{g_{t}}{\sqrt{\sum_{\tau=1}^{t}g_{\tau}^{2}+\epsilon}}$</p>
<p><strong>优点：Adagrad在稀疏数据场景下表现最好</strong>，因为对于频繁出现的参数，学习率衰减快；对于稀疏的参数，学习率衰减的更慢</p>
<p><strong>缺点：</strong>在实际很多情况下，<strong>二阶动量呈单调递增，累积从训练开始的梯度，学习率会很快减至0，导致参数不再更新</strong>，训练过程提前结束</p>
<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p><code>SGD(Root Mean Square Prop)</code>在<code>SGD</code>基础上增加二阶动量，由于<code>Adagrad</code>的学习率衰减太过激进，改变二阶动量的计算策略：<strong>不累计全部梯度，只关注过去某一窗口内的梯度</strong>。<strong>指数移动平均值</strong>大约是过去一段时间的平均值，反映<strong>局部的</strong>参数信息，用这个方法来计算二阶累积动量。</p>
<p>$m_{t}=g_{t}$</p>
<p>$v_{t}=\beta v_{t-1}+(1-\beta)g_{t}^{2}$</p>
<p>$\theta_{t+1}=\theta_{t}-\eta\frac{g_{t}}{\sqrt{v_{t}}}=\theta_{t}-\eta\frac{g_{t}}{\sqrt{\beta v_{t-1}+(1-\beta)g_{t}^{2}}} $</p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p><code>Adam(Adaptive Moment Estimation)</code>，自适应矩估计。是2014年提出的一种万金油式的优化器，使用起来非常方便，梯度下降速度快，但是容易在最优值附近震荡。竞赛中性能会略逊于<code>SGD</code>，毕竟最简单的才是最有效的。但是超强的易用性使得<code>Adam</code>被广泛使用。是<code>SGDM</code>和<code>RMSProp</code>的结合。</p>
<p>$m_{t}=\beta_{1}m_{t-1}+(1-\beta_{1})g_{t}$</p>
<p>$v_{t}=\beta_{2}v_{t-1}+(1-\beta_{2})g_{t}^{2}$</p>
<p>$\hat{m}_{t}=\frac{m_{t}}{1-\beta_{1}^{t}}$</p>
<p>$\hat{v}_{t}=\frac{v_{t}}{1-\beta_{2}^{t}}$</p>
<p>$\theta_{t+1}=\theta_{t}-\eta\frac{\hat{m}_t}{\sqrt{\hat{v}_{t}}+\epsilon}$</p>
<p><strong>解释：</strong></p>
<p>第一项 $m_{t}$ 为t时刻，梯度在动量形式下的一阶矩估计。</p>
<p>第二项 $v_{t}$ 为梯度在动量形式下的二阶矩估计。</p>
<p>第三项 $\hat{m}_{t}$ 为偏差纠正后的一阶矩估计。</p>
<p>第四项 $\hat{v}_{t}$ 为偏差纠正后的二阶矩估计。</p>
<p>最后一项是更新公式，可以参考<code>RMSProp</code>以及之前的算法。</p>
<p><strong>为什么需要偏差纠正？</strong></p>
<p>拿梯度在动量形式下的二阶矩估计 $v_{t}$ 为例，各个 $v_{t}$ 的公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071555276.png" alt=""></p>
<p>而我们实际上需要的是梯度的二阶矩估计，也就是 $E(g_{i}^{2})$ 。因此使用动量求出来的二阶矩估计是有偏的，需要纠正。我们对动量二阶矩估计 $v_{t}$ 求期望 $E(v_{t})$ ，可以通过等比数列公式得到 $E(v_{t})$ 与 $E(g_{i}^{2})$ 的关系：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071559636.png" alt=""></p>
<p>因此，要得到 $E(g_{i}^{2})$ ，就需要除掉前面的系数 $(1-\beta_{2}^{t})$ 是一个常数</p>
<h1 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h1><h2 id="Top-1-Accuracy和Top-5-Accuracy"><a href="#Top-1-Accuracy和Top-5-Accuracy" class="headerlink" title="Top-1 Accuracy和Top-5 Accuracy"></a>Top-1 Accuracy和Top-5 Accuracy</h2><p>Top-1：就是你预测的label取最后概率向量里面最大的那一个作为预测结果 ，如过预测结果中概率最大的那个分类正确，则预测正确，否则预测错误。<br>Top-5：就是最后概率向量最大的前五名中，只要出现了正确概率即为预测正确，否则预测错误。</p>
<h2 id="DICE"><a href="#DICE" class="headerlink" title="DICE"></a>DICE</h2><p>用来度量图像分割结果的精度，可以有效地度量预测结果<code>pred</code>和标签<code>label</code>的相似度（和评价指标<code>F1</code>是相同的）</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306191056073.png" alt=""></p>
<h2 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h2><p><code>IoU</code>全称<code>Intersection-over-Union</code>，即交并比，在目标检测和语义分割领域都有使用。</p>
<ul>
<li>在目标检测领域，定义为两个矩形框面积的交集和并集的比值，$IoU=\frac{A\cap B}{A\cup B}$。如果完全重叠，则<code>IoU</code>等于1，是最理想的情况。一般在检测任务中，<code>IoU</code>大于等于<code>0.5</code>就认为召回，如果设置更高的<code>IoU</code>阈值，则召回率下降，同时定位框也越更加精确。</li>
<li>在图像分割中也会经常使用<code>IoU</code>，此时就不必限定为两个矩形框的面积。比如对于二分类的前背景分割，那么$IoU=\frac{真实前景像素面积\cap预测前景像素面积}{真实前景像素面积\cup预测前景像素面积}$，这一个指标，通常比直接计算每一个像素的分类正确概率要低，也对错误分类更加敏感。</li>
</ul>
<h2 id="MIoU"><a href="#MIoU" class="headerlink" title="MIoU"></a>MIoU</h2><p>均交并比，语义分割的标准度量。计算两个集合的交集与并集之比，在语义分割中，这两个集合为真实值和预测值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306191111890.png" alt=""></p>
<p>上述公式和下面的公式是等价的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306191113911.png" alt=""></p>
<p>计算<code>MIoU</code>的三个步骤：</p>
<ol>
<li>计算混淆矩阵</li>
<li>计算每个类别的<code>IoU</code></li>
<li>对每个类别的<code>IoU</code>取平均</li>
</ol>
<h2 id="AP"><a href="#AP" class="headerlink" title="AP"></a>AP</h2><p>AP为某一类别的目标平均精确度，具体为该类目标在11个不同置信度阈值下计算得到的P-R曲线下方的面积值。</p>
<h2 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h2><p>mAP(mean Average Precision)：是多个类别AP的平均值。这个mean的意思是对每个类的AP再求平均，得到的就是mAP的值。mAP的大小一定在[0,1]并且越大越好。</p>
<h2 id="Box-AP"><a href="#Box-AP" class="headerlink" title="Box AP"></a>Box AP</h2><p>Box AP 即Box Average Precision，用于综合评价目标检测模型效能。要清楚的是AP的计算是先使用<strong>confidence threshold</strong>去除一些置信度过低的框；然后要使用NMS要用到 <strong>nms_boxiou threshold</strong>，去除和置信度最高的框IoU大于阈值的重叠框；接着会使用<strong>box_iou threshold</strong>，将每个框分为TP、FP，对于同一个GT，预测框根据置信度从高到低排列，只有IoU大于阈值且置信度最高的那个算是TP，其余IOU大于阈值的都算是FP；分配好TP、FP以后，所有框按照置信度从高到低排列，计算AP值。</p>
<ul>
<li>confidence threshold：置信度阈值，每个输出框都会给出置信度，只有置信度高于某个阈值的框才会被考虑。</li>
<li>nms_boxiou threshold：NMS方法的逻辑是先根据预测出的前景分数从高到低排序box，从分数最高的box开始遍历，与这个box的overlap大于某个threshold的box就会被去掉，例如我们以score=0.8的box为基准，overlap_threshold=0.2，那么与score=0.8的box的overlap大于0.2的框，都会被丢弃。如果框X与score=0.8的框的overlap小于0.2，那么我们会认为框X属于另一个物体，不用抑制。</li>
<li>box_iou threshold：例如我们以IoU为30%作为评估的阈值，如果检测结果和GT的IoU超过30%，则此次检测为TP，否则就是FP。</li>
<li>AP：AP的值就是PR曲线下方围成的面积的值。</li>
</ul>
<h2 id="Mask-AP"><a href="#Mask-AP" class="headerlink" title="Mask AP"></a>Mask AP</h2><p>Mask AP用于综合评价实例分割模型效能。Mask AP和Box AP的区别仅仅在于box_iou threshold作用的对象不相同，Box AP里面作用的是标准普通的GT和预测框的IoU值，Mask AP里面作用的是GT mask和预测mask的mask IoU，即像素点之间的mask IoU。</p>
<h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p><code>Bagging(Bootstrap aggregating)</code>，引导聚集算法，又称装袋算法，是机器学习领域的一种团体学习算法。<code>Bagging</code>算法可与其他分类、回归算法结合，提高其准确率、稳定性的同时，通过降低结果的方差，避免过拟合的发生。</p>
<p><strong>随机采样（bootstrap sample）</strong>从 $n$ 个数据点中<strong>有放回地重复随机</strong>抽取一个样本（即同一个样本可被多次抽取），共抽取 $n$ 次。创建一个与原数据大小相同得数据集，但有些数据点会缺失（大约 $1/3$ ），有些会重复。</p>
<p><code>Bagging</code>对于弱学习器没有限制，这和<code>Adaboost</code>一样。但是最常用的一般也是<strong>决策树</strong>和<strong>神经网络</strong>。</p>
<p><code>Bagging</code>的集合策略也比较简单，对于<strong>分类问题</strong>，通常使用<strong>简单投票法</strong>，得到最多票数的类别或者类别之一为最终的模型输出。对于<strong>回归问题</strong>，通常使用<strong>简单平均法</strong>，对 $T$ 个弱学习器得到的回归结果进行算术平均得到最终的模型输出。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071107979.png" alt=""></p>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>随机森林以决策树为基本单元，通过集成大量的决策树，就构成了随机森林。其构造过程如下：</p>
<ol>
<li>$T$ 中共有 $N$ 个样本，有放回的随机选择 $N$ 个样本（因为有放回，所以虽然是 $N$ 但是不可能遍历所有样本）。这选择好了的 $N$ 个样本用来训练一个决策树，作为决策树根节点处的样本。</li>
<li>当每个样本有 $M$ 个属性时，在决策树的每个节点需要分裂时，随机从这 $M$ 个属性中选取出 $m$ 个属性，满足条件 $m &lt;&lt; M$ 。然后从这 $m$ 个属性中采用某种策略来选择某个属性作为该节点的分裂属性。</li>
<li>决策树形成过程中每个节点都要按照上述步骤来分裂，一直到不能够再分裂为止。注意整个决策树形成过程中没有进行剪枝。</li>
<li>重复建立大量的决策树，这样就构成了随机森林了。</li>
</ol>
<h4 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h4><h5 id="决策树构建的终止条件"><a href="#决策树构建的终止条件" class="headerlink" title="决策树构建的终止条件"></a>决策树构建的终止条件</h5><ol>
<li><p>样本进来属于同一个类别，直接输出结果是 $C$ 类返回。</p>
</li>
<li><p>没法划分了，特征向量中所有属性都用完了；或者 $D$ 样本中的属性 $A$ 都相同，然后将此节点标记为叶子节点，将样本 $D$ 中数目最多的类当做类别返回。</p>
</li>
<li>当对数据进行划分成多个分支，如果存在分支中没有数据（分支为空），将划分前类别数目多的当做类别返回。</li>
</ol>
<h5 id="决策树剪枝"><a href="#决策树剪枝" class="headerlink" title="决策树剪枝"></a>决策树剪枝</h5><p>各种准则虽然对决策树的尺寸有较大影响，<strong>但对泛化性能的影响很有限，剪枝方法和程度对决策树泛化性能的影响更为显著；剪枝是决策树防止过拟合的手段</strong>。</p>
<p><strong>预剪枝：</strong>在决策树构造时就进行剪枝。在决策树构造过程中，对节点进行评估，如果对其划分并不能再验证集中提高准确性，那么该节点就不要继续往下划分。这时就会把当前节点作为叶节点。</p>
<p><strong>后剪枝：</strong>在生成决策树之后再剪枝。通常会从决策树的叶节点开始，逐层向上对每个节点进行评估。如果剪掉该节点，带来的验证集中准确性差别不大或有明显提升，则可以对它进行剪枝，用叶子节点来代填该节点。</p>
<p><strong>预剪枝vs后剪枝</strong></p>
<p>时间开销：</p>
<ul>
<li>预剪枝：训练时间开销降低，测试时间开销降低</li>
<li>后剪枝：训练时间开销增加，测试时间开销降低</li>
</ul>
<p>过/欠拟合风险:</p>
<ul>
<li>预剪枝：过拟合风险降低，欠拟合风险增加</li>
<li>后剪枝：过拟合风险降低，欠拟合风险基本不变</li>
</ul>
<p>泛化性能：后剪枝通常优于预剪枝</p>
<h5 id="决策树生成算法"><a href="#决策树生成算法" class="headerlink" title="决策树生成算法"></a>决策树生成算法</h5><p><strong>ID3</strong></p>
<p>使用信息熵增益作为特征选择的标准。</p>
<p>数据集 $D$ 的经验熵定义为： $Ent(D)=-\sum_{k=1}^{K}\frac{|C_{k}|}{|D|}\log_{2}\frac{|C_{k}|}{|D|}$ ，其中 $|C_{k}|$ 为第 $k$ 类样本的数目， $|D|$ 为数据集 $D$ 中样本的数目。</p>
<p>计算特征 $A$ 对数据集 $D$ 的经验条件熵： $Ent(D|A)=\sum_{i=1}^{n}\frac{|D_{i}|}{|D|}Ent(D_{i})=-\sum_{i=1}^{n}\frac{|D_{i}|}{|D|}\sum_{k=1}^{K}\frac{|D_{ik}|}{|D_{i}|}\log_{2}\frac{|D_{ik}|}{|D_{i}|}$  。意思就是对划分后的新的 $n$ 个小数据集的经验熵加权，权重为每一个小数据集中的样本数目占未划分前的大数据集的比例。</p>
<p>计算信息熵增益： $gain(D,A)=Ent(D)-Ent(D|A)$ ，选择信息熵增益最大的特征。</p>
<p><strong>C4.5</strong></p>
<p>与<code>ID3</code>算法的最大不同在于使用信息熵增益率代替信息熵增益。信息熵增益率的定义如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304211122841.png" alt=""></p>
<p>其中 $IV(A)=-\sum_{i=1}^{n}\frac{|D_{i}|}{|D|}\log_{2}\frac{|D_{i}|}{|D|}$ 称为数据集 $D$ 关于 $A$ 的取值熵。</p>
<p>这种方法对可能取值少的属性有所偏好，因此<code>C4.5</code>算法也不是直接使用增益率最大的来划分属性，而是使用了一种“启发式”的方法，先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。</p>
<p><strong>CART</strong></p>
<p><code>CART</code>决策树使用“基尼指数”来选择划分属性，选取那个使划分后基尼指数<strong>最小</strong>的属性。数据集 $D$ 的纯度可用基尼值来度量。 $Gini(D)$ 越小，则数据集的纯度越高。 $Gini(D)=\sum_{k=1}^{K}p_{k}(1-p_{k})=1-\sum_{k=1}^{K}p_{k}^{2}$ ，则属性 $A$ 的基尼指数表达式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304211122760.png" alt=""></p>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p><code>Bagging</code>在随机森林的构建过程中，各棵树之间是相互独立的，在构建第 $m$ 棵树的时候，不会考虑前面的 $m-1$ 棵树。<code>Boosting</code>在构建第 $m$ 棵子树的时候，会考虑到前 $m-1$ 棵子树的结果。</p>
<p><strong>提升学习(Boosting)</strong>是一种机器学习技术，通过从训练数据构建模型，然后创建第二个模型来尝试纠正第一个模型中的错误来完成的。添加模型直到完美预测训练集或添加最大数量的模型。提升学习的每一步产生弱预测模型（如决策树），并加权累加到总模型中；如果每一步的弱预测模型的生成都是依据损失函数的梯度方式，就称为梯度提升<code>(Gradient Boosting)</code>。</p>
<h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071138731.png" alt=""></p>
<p><code>Adaptive Boosting(AdaBoost)</code>是第一个为二进制分类开发的真正成功的提升算法。这是理解<code>Boosting</code>的最佳起点，现代提升方法建立在<code>AdaBoost</code>之上。</p>
<p><code>AdaBoost</code>流程：</p>
<ol>
<li><p>训练数据集中的每个实例都被加权。初始权重设置为： $Weight(X_{i})=\frac{1}{N_{}}$ </p>
</li>
<li><p>使用加权之后的样本作为训练数据，以弱分类器（决策树桩）进行训练。</p>
</li>
<li><p>为训练后的模型计算当前分类器的分类误差。传统的计算方式如下：</p>
<p>分类误差： $error_t = \sum_{i=1}^{N}(W_{t,i}\times terror_{i})$ 。其中 $terror_{i}=I(G_{t}(X_{i})\neq y_{i})$ 。</p>
<p>例如：如果我们有三个训练实例，权重分别为 $0.01$ 、 $0.5$ 和 $0.2$ 。预测值为 $-1$ 、 $-1$ 和 $-1$ ，实例中的真实输出变量为 $-1$ 、 $1$ 和 $-1$ ，则  $terror$ 为 $0$ 、 $1$ 和 $0$ 。误分类率将计算为：<strong>error = (0.01*0 + 0.5*1 + 0.2*0) or error = 0.5</strong>。</p>
</li>
<li><p>为经过训练的模型计算阶段权值，该值为模型做出的任何预测提供权重。训练模型的阶段值计算公式： $\alpha_{t}=\frac{1}{2}\times\ln\frac{1-error_{t}}{error_{t}}$</p>
</li>
<li><p>更新训练权重，为错误预测的实例提供更多的权重，为正确预测的实例提供更少权重。计算公式： $W_{t+1,i}=\frac{W_{t,i}}{Z_{t}}\exp(-\alpha_{t}G_{t}(X_{i})y_{i})$ ， $Z_{t}$ 是规范因子， $Z_{t}=\sum_{i=1}^{N}W_{t,i}\exp(-\alpha_{t}G_{t}(X_{i})y_{i})$</p>
</li>
<li><p>最终的分类器为： $G(X)=sign(\sum_{m=1}^{K}\alpha_{m}G_{m}(X))$</p>
</li>
</ol>
<h3 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h3><p><code>GBDT(Gradient Boosting Decision Tree)</code>在数据分析和预测中的效果很好。它是一种基于决策树的集成算法。其中<code>Gradient Boosting</code>是集成方法<code>Boosting</code>中的一种算法，通过梯度下降来对新的学习器进行迭代。将表现一般的数个模型（通常是深度固定的决策树）组合在一起来集成一个表现较好的模型。抽象地说，模型的训练过程是对一任意可导目标函数的优化过程。通过反复地选择一个指向负梯度方向的函数，该算法可被看做在函数空间里对目标函数进行优化。因此可以说<code>Gradient Boosting = Gradient Descent + Boosting</code>。</p>
<p>模型的结果是一组回归分类树组合<code>(CART Tree Ensemble)</code>： $T_{1},\cdots,T_{K}$ 。其中 $T_{j}$ 学习的是之前 $j-1$ 棵树预测结果的残差，这种思想就像准备考试前的复习，先做一遍习题册，然后把做错的题目挑出来，再做一次，然后把做错的题目挑出来再做一次，经过反复多轮训练，取得最好的成绩。而模型最后的输出，是一个样本在各个树中输出的结果的和： $\bar{y}=\sum_{k=1}^{K}f_{k}(x)$ 。</p>
<p>和<code>AdaBoost</code>一样，<code>Gradient Boosting</code>也是重复选择一个表现一般的模型并且每次基于先前模型的表现进行调整。不同的是，<code>AdaBoost</code>是通过提升错分数据点的权重来定位模型的不足而<code>Gradient Boosting</code>是通过算梯度<code>(gradient)</code>来定位模型的不足。因此相比<code>AdaBoost</code>，<code>Gradient Boosting</code>可以使用更多种类的目标函数。</p>
<h4 id="提升树算法"><a href="#提升树算法" class="headerlink" title="提升树算法"></a>提升树算法</h4><p>提升树是迭代多棵回归树来共同决策。当采用平方误差损失函数时，每一棵回归树学习的是之前所有树的结论和残差，拟合得到一个当前的残差回归树，残差的意义如公式：残差=真实值-预测值。提升树即是整个迭代过程生成的回归树的累加。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101613543.jpg" alt=""></p>
<p>具体的算法步骤：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101613198.png" alt=""></p>
<h4 id="Gradient-Boosting-Decision-Tree（梯度提升决策树）"><a href="#Gradient-Boosting-Decision-Tree（梯度提升决策树）" class="headerlink" title="Gradient Boosting Decision Tree（梯度提升决策树）"></a>Gradient Boosting Decision Tree（梯度提升决策树）</h4><p>提升树利用加法模型和前向分步算法实现学习的优化过程。当损失函数时平方损失和指数损失函数时，每一步的优化很简单，如平方损失函数学习残差回归树。但对于一般的损失函数，往往每一步优化没那么容易。针对这一问题，<code>Freidman</code>提出了梯度提升算法：利用最速下降的近似方法，<strong>即利用损失函数的负梯度在当前模型的值，作为回归问题中提升树算法的残差的近似值</strong>，拟合一个回归树。</p>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><p><strong>原始目标函数</strong></p>
<p>目标函数，可以分为两个部分，一部分是损失函数，一部分是正则（用于控制模型的复杂度）。</p>
<p>对于第 $t$ 颗树，第 $i$ 个样本的，模型的预测值是这样的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101650959.png" alt=""></p>
<p>进一步，我们可以得到我们的原始目标函数，如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101651061.png" alt=""></p>
<p><strong>损失函数化简</strong></p>
<p><code>XGBoost</code>是前向迭代，我们的重点在于第 $t$ 个树，所以涉及到前 $t-1$ 个树变量或者说参数我们是可以<strong>看做常数</strong>的。所以我们的损失函数进一步可以化为如下，其中一个变化是我们对正则项进行了拆分，变成可前 $t-1$ 项和第 $t$ 项：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101656177.png" alt=""></p>
<h4 id="泰勒公式展开"><a href="#泰勒公式展开" class="headerlink" title="泰勒公式展开"></a>泰勒公式展开</h4><p>使用泰勒公式进行近似展开的核心目标是对目标函数进行化简，将常数项抽离出来。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101658315.png" alt=""></p>
<p>这里 $\Delta x$ 对应的是第 $t$ 棵树的模型 $f_{t}(x_{i})$ ， $x$ 对应的是 $\hat{y}_{i}^{(t-1)}$ ，相应的 $f(x)$ 对应到损失函数应该是 $l(y_{i},\hat{y}_{i}^{(t-1)})+f_{t}(x_{i})$ 。</p>
<p>所以原有公式进行泰勒公式二阶展开，结果为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101704500.png" alt=""></p>
<p>进而我们可以得到目标函数展开公式为如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101704670.png" alt=""></p>
<h4 id="树的参数化"><a href="#树的参数化" class="headerlink" title="树的参数化"></a>树的参数化</h4><p><strong>树模型参数化</strong></p>
<ul>
<li>每棵树每个叶子节点的值（或者说每个叶子节点的权重） $w$ ：这是一个向量，因为每个树有很多叶子节点</li>
<li>样本到叶子节节点的映射关系 $q$ ：告诉每个样本落在当前这个树的哪一个叶子节点上</li>
<li>叶子节点样本归属集合 $I$ ：告诉每个叶子节点包含哪些样本</li>
</ul>
<p><strong>树复杂度参数化</strong></p>
<p>树的复杂度定义如下，其中 $T$ 参数表示当前这棵树叶子节点的个数； $w_{j}^{2}$ 是叶子节点值的 $L_{2}$ 范数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101716405.png" alt=""></p>
<p>进而我们可以对树进行参数化，带入到目标函数我们可以得到如下式子：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101727004.png" alt=""></p>
<p>最后一步的转化思路是从在这个树中，每个样本落在哪个节点转为了每个节点上有哪些样本。</p>
<p>叶子节点 $j$ 所包含的样本的一阶导数累加之和为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101743580.png" alt=""></p>
<p>叶子节点 $j$ 所包含的样本的二阶导数累加之和为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101744292.png" alt=""></p>
<p>进而我们可以进一步化简为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101744829.png" alt=""></p>
<p>对目标函数对 $w_{j}$ 进行求导就能得出极值点：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101746573.png" alt=""></p>
<h4 id="特征分裂"><a href="#特征分裂" class="headerlink" title="特征分裂"></a>特征分裂</h4><p>对于上述的目标函数，我们仍存在问题，即 $T$ 的取值，也就是如何做特征分裂。</p>
<p><strong>贪心算法</strong></p>
<p>本质上是做两次循环，第一个循环是针对每个特征的每个分割点做一次循环，计算收益，从而选择此特征的最佳分割点。分裂收益使用的是分裂之后的目标函数的变化差值。第二个循环是对样本所有特征的循环，从中挑选出收益最大的特征。</p>
<p>简单说就是首先找到基于每个特征找到收益最大的分割点，然后基于所有特征找到收益最大的特征。</p>
<p><strong>近似算法-分位数候选点</strong></p>
<p>对于每个特征，不去暴力搜索每个值，而是使用分位点</p>
<ul>
<li>根据样本数量选择三分位点或者四分位点等</li>
<li>根据二阶导数（也就是梯度）作为权重进行划分</li>
</ul>
<p>也就是说原来是某个特征的所有取值作为候选点，现在是某个特征的分位点作为候选点。</p>
<h3 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h3><p><code>LightGBM(Light Gradient Boosting Machine)</code>是一种梯度提升框架，它使用决策树作为基学习器。<code>LightGBM</code>为高效并行计算而生，它的<code>Light</code>体现在以下几个点上：</p>
<ul>
<li>更快的训练速度</li>
<li>更低的内存使用</li>
<li>支持单机多线程，多机并行计算，以及<code>GPU</code>训练</li>
<li>能够处理大规模数据</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102112494.png" alt=""></p>
<p>概括来说，<code>lightGBM</code>主要有以下特点：</p>
<ul>
<li>基于<code>Histogram</code>的决策树算法</li>
<li>带深度限制的<code>Leaf-wise</code>的叶子生长策略</li>
<li>直方图做差加速</li>
<li>直接支持类别特征<code>(Categorical Feature)</code></li>
<li><code>Cache</code>命中率优化</li>
<li>基于直方图的稀疏特征优化</li>
<li>多线程优化</li>
</ul>
<h4 id="直方图Histogram算法"><a href="#直方图Histogram算法" class="headerlink" title="直方图Histogram算法"></a>直方图Histogram算法</h4><p><strong>寻找最佳分类点</strong></p>
<p>将连续型特征值放入离散化的箱子<code>(bin)</code>中，然后用这些箱子构建特征直方图。然后模型基于特征直方图寻找最佳分裂点，构建直方图的时间复杂度是 $O(data \times feature)$ ，但寻找最佳分裂点的时间复杂度为 $O(bin \times feature)$ 。模型训练速度会因此而提高，而且因为不需要存储排序索引，内存压力也变小了。<code>LGBM</code>采用的就是直方图算法（现在<code>XGBoost</code>开源代码也支持直方图算法）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102149708.png" alt=""></p>
<p><strong>直方图差加速</strong></p>
<p>直方图做差是指：“一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的 $k$ 个桶。利用这个方法，<code>LightGBM</code>可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。” 示意图如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102152516.png" alt=""></p>
<h4 id="带深度限制的Leaf-wise的叶子生长策略"><a href="#带深度限制的Leaf-wise的叶子生长策略" class="headerlink" title="带深度限制的Leaf-wise的叶子生长策略"></a>带深度限制的Leaf-wise的叶子生长策略</h4><p><code>GBDT</code>与<code>XGBoost</code>模型在叶子生长策略上均采用按层<code>level-wise</code>分裂的方式，这种方式在分裂时会针对同一层的每一个节点，即每次迭代都要遍历整个数据集中的全部数据，这种方式虽然可以使每一层的叶子节点并行完成，并控制模型的复杂度，但也会产生许多不必要搜索或分裂，从而消耗更多的运行内存，增加计算成本。</p>
<p>而<code>LightGBM</code>算法对其进行了改进，使用了按叶子节点<code>leaf-wise</code>分裂的生长方式，即每次是对所有叶子中<strong>分裂增益最大的叶子节点进行分裂</strong>，其他叶子节点则不会分裂。这种分裂方式比按层分裂会带来更小的误差，并且加快算法的学习速度，但由于没有对其他叶子进行分裂，会使得分裂结果不够细化，并且在每层中只对一个叶子不断进行分裂将增大树的深度，造成模型过拟合。因此，<code>LightGBM</code>算法在按叶子节点生长过程中会限制树的深度来避免过拟合。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102156269.png" alt=""></p>
<h4 id="支持类别特征"><a href="#支持类别特征" class="headerlink" title="支持类别特征"></a>支持类别特征</h4><p>实际上大多数机器学习工具都无法直接支持类别特征，一般需要把类别特征，转化<code>one-hot</code>特征，降低了空间和时间的效率。而类别特征的使用是在实践中很常用的。基于这个考虑，<code>LightGBM</code>优化了对类别特征的支持，可以直接输入类别特征，不需要额外的 $0/1$ 展开。并在决策树算法上增加了类别特征的决策规则。决策树在学习节点分裂时，是一种<code>one-vs-rest</code>模式，每次只能根据一个类别做分类，如下图。这种模式效率比较低，而且不利于决策树学习。<code>LightGBM</code>对此进行了优化，采用<code>many-vs-many</code>模式分裂节点，如下图。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102208969.png" alt=""></p>
<h4 id="基于梯度的单边采样-GOSS"><a href="#基于梯度的单边采样-GOSS" class="headerlink" title="基于梯度的单边采样(GOSS)"></a>基于梯度的单边采样(GOSS)</h4><p>在<code>AdaBoost</code>中，样本权重指示了数据样本的重要性，而在<code>GBDT</code>上并没有样本权重这一说，可作者发现：在<code>GBDT</code>中，梯度对于每个样本是个很有用的信息，它可以用来帮助采样。为什么这么说呢？让我们打个比方，如果某样本得到的一个小的梯度值，那么说明该样本的训练误差也小，模型在该样本上表现得就很好，那这些小梯度的样本其实是不是不用参与训练了？就好像准备考试时刷题不刷简单题，这样可以吗？不可以！因为如果真的直接剔除它们，数据分布会改变，从而损害模型的准确率。为了处理这个问题，作者提出了<code>GOSS</code>，<code>GOSS</code>全称是<code>Gradient-based One-Side Sampling</code>单边梯度采样，它保留所有大梯度的样本，然后小梯度样本采用随机采样，在不改变原始数据分布的同时，减小了样本数量，提升了模型的训练速度。</p>
<h4 id="互斥特征绑定"><a href="#互斥特征绑定" class="headerlink" title="互斥特征绑定"></a>互斥特征绑定</h4><p>从特征角度来看，稀疏特征会包含很多 $0$ 元素；从样本角度来看，一个样本的多个稀疏特征经常同时为 $0$ 。<code>EFB(Exclusive Feature Bundling)</code>基于这种想法，对<strong>互斥特征</strong>进行了<strong>捆绑</strong>，整体过程有点类似于<code>One-Hot</code>逆过程。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102216271.png" alt=""></p>
<p><strong>捆哪些特征</strong></p>
<p>尝试每种组合，是<code>NP</code>难问题，现有算力做不到。所以只能采用贪心算法找。具体过程如下：</p>
<ol>
<li>遍历特征，先把第一个特征拿出来作为一个组合</li>
<li>第二个特征往这个组合里放，冲突比例小就放进去合并成一个特征，冲突比例大就单拿出来作为另一个组合</li>
<li>第三个特征继续往已有的组合里放，能放就放，不能放就单成一个新组合</li>
<li>以此类推对所有特征做同样的操作。</li>
</ol>
<p><strong>如何捆绑特征</strong></p>
<p>因为不同特征下的值有不同的量纲，比如：特征<code>A</code>的值范围为 $[0, 10)$ ，特征<code>B</code>的值范围为 $[0, 20)$ ，将特征<code>A</code>和特征<code>B</code>的直方图加起来捆绑一起后，<code>bundle</code>的值范围变为 $[0, 20)$ ，但是我们无法从中辨别哪些是特征<code>A</code>，哪些是特征<code>B</code>。这样对模型是不利的，因为模型这样就没法根据<code>bundle</code>直方图的值范围去很好区分特征，对树生成会带来误差。对于该问题的解决办法就是<strong>加偏移量</strong>，如果我们对特征<code>B</code>加偏移量 $10$ ，特征<code>B</code>的值范围变为 $[10, 30)$ ，合并后的<code>bundle</code>值范围变为 $[0, 30)$ 。</p>
<h3 id="CatBoost"><a href="#CatBoost" class="headerlink" title="CatBoost"></a>CatBoost</h3><p><code>CatBoost</code>主要是在类别特征上的处理上做了很多的改进。从用户使用角度来看，相比<code>XGBoost</code>和<code>LightGBM</code>，<code>CatBoost</code>具有如下特点。</p>
<ul>
<li><strong>模型精度：</strong><code>XGBoost</code>和<code>LightGBM</code>相当，<code>CatBoost</code>往往略好一些，无需调参即可获取很好的结果。</li>
<li><strong>训练速度：</strong><code>LightGBM</code>远快于<code>XGBoost</code>，<code>CatBoost</code>快于<code>XGBoost</code>但比<code>LightGBM</code>慢。</li>
<li><strong>预测速度：</strong><code>LightGBM</code>与<code>XGBoost</code>相当，<code>CatBoost</code>远快于<code>LightGBM</code>与<code>XGBoost</code>，是它们的几十分之一。</li>
<li><strong>内存消耗：</strong><code>LightGBM</code>远小于<code>XGBoost</code>，<code>CatBoost</code>小于<code>XGBoost</code>，但大于<code>LightGBM</code>。</li>
<li><strong>类别特征：</strong><code>XGBoost</code>不支持类别特征，需要<code>One-Hot</code>编码预处理。<code>LightGBM</code>支持类别特征，需转换成整数编码。<code>CatBoost</code>提供更强大的对类别特征的支持，直接支持字符串类型的类别特征，无需预处理。</li>
<li><strong>缺失值特征：</strong><code>XGBoost</code>和<code>LightGBM</code>都可以自动处理特征缺失值，<code>CatBoost</code>不能自动处理缺失值（或者将缺失值视为最小值/最大值）。</li>
<li><strong>GPU支持：</strong><code>LightGBM</code>与<code>CatBoost</code>支持<code>GPU</code>训练，<code>XGBoost</code>也支持<code>GPU</code>训练。</li>
<li><strong>可视化：</strong><code>CatBoost</code>还自带一套可视化工具，可以在<code>Jupyter Notebook</code>或者<code>TensorBoard</code>中实时看到指标变化。</li>
</ul>
<h4 id="基于类别特征的Ordered-Target-Statistics数值编码方法"><a href="#基于类别特征的Ordered-Target-Statistics数值编码方法" class="headerlink" title="基于类别特征的Ordered Target Statistics数值编码方法"></a>基于类别特征的Ordered Target Statistics数值编码方法</h4><p>对于类别特征，如果类别数目不多，可以使用<code>One-Hot</code>编码。但如果类别数量成百上千，使用<code>One-Hot</code>编码会导致特征数量爆炸。<strong>CatBoost设计了一种基于预测目标统计值的方法可以将类别特征转化为数值特征。</strong>先将样本随机打乱，然后每个样本只使用它排序在它前面的样本来计算其类别特征的数值编码。这样就防止了<code>label</code>的泄露，并且能够较为合理地评估这个特征的真实有效性。具体公式表达为： $i \rightarrow \frac{Current\ Count+a\star P}{Max\ Count + a}$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303111538347.png" alt=""></p>
<p>对上述例子来说，我们要计算第 $i$ 条数据的<code>label</code>，计算结果就为 $\frac{2+a \star P}{3+a}$ ，如果将第三行的<code>label</code>改为 $1$ ，那么结果就变成了 $\frac{3+a\star P}{3+a}$ 。</p>
<h4 id="基于贪心策略的特征交叉方法"><a href="#基于贪心策略的特征交叉方法" class="headerlink" title="基于贪心策略的特征交叉方法"></a>基于贪心策略的特征交叉方法</h4><p>使用<code>Ordered Target Statistics</code>方法将类别特征转化成为数值特征以后，会影响到特征交叉，因为数值特征无法有效地进行交叉。为了有效地利用特征交叉，<code>CatBoost</code>在将类别特征转换为数值编码的同时，会自动生成交叉特征。但如果让全部的类别特征之间都进行交叉，两两交叉，三三交叉，四四交叉，这个复杂度是指数级的，特征维度一定会爆炸。<code>CatBoost</code>使用一种贪心的策略来进行特征交叉。生成<code>tree</code>的第一次分裂，<code>CatBoost</code>不使用任何交叉特征。在后面的分裂中，<code>CatBoost</code>会使用生成<code>tree</code>所用到的<strong>全部原始特征和交叉特征</strong>跟数据集中的<strong>全部类别特征</strong>进行交叉。</p>
<h4 id="避免预测偏移的Ordered-Boosting方法"><a href="#避免预测偏移的Ordered-Boosting方法" class="headerlink" title="避免预测偏移的Ordered Boosting方法"></a>避免预测偏移的Ordered Boosting方法</h4><p>使用<code>XGBoost</code>或者<code>LightGBM</code>做模型时，我们可能经常会发现模型在训练集上拟合的很好，<code>train_auc</code>甚至达到了 $1.0$ ，但是在验证集上却差了很多，<code>val_auc</code>可能只有 $0.7$ 。这当然有可能是因为<code>tree</code>的数量太多了，或者是每棵<code>tree</code>的<code>leaves</code>太多了，总之模型太复杂了造成了过拟合。</p>
<p>但也有一些<code>XGBoost</code>和<code>LightGBM</code>自身算法的缺陷因素。我们知道<code>LightGBM</code>在训练下一棵<code>tree</code>的时候，需要计算前面这些<code>tree</code>构成的加法模型在所有样本上的一阶梯度和二阶梯度（<code>Loss</code>对模型预测结果的导数），然后用这些梯度来决定下一棵树的结构和叶子节点取值。</p>
<p>但是我们计算的这些一阶梯度和二阶梯度值是有问题的。前面的这些<code>tree</code>都是在这些样本上训练的，现在我们又在这些样本上估计模型预测结果的一阶和二阶梯度。我们应该换一些新的样本才更合理。但是我们从哪里找这些新的样本呢？</p>
<p><code>CatBoost</code>的作者故伎重演。先将样本随机打乱，然后每个样本只使用<strong>排序在它前面的样本</strong>来训练模型。用这样的模型来估计这个样本预测结果的一阶和二阶梯度。然后用这些梯度构建一棵<code>tree</code>的结构，最终<code>tree</code>的每个叶子节点的取值，是使用全体样本进行计算的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303111601603.png" alt=""></p>
<h4 id="使用对称二叉树作为基模型"><a href="#使用对称二叉树作为基模型" class="headerlink" title="使用对称二叉树作为基模型"></a>使用对称二叉树作为基模型</h4><p><code>XGBoost</code>和<code>LightGBM</code>采用的基模型是普通的二叉树，但是<code>CatBoost</code>采用的是对称的二叉树。这种对树结构上的约束有一定的<strong>正则作用</strong>。更为重要的是，它可以让<code>CatBoost</code>模型的推断过程极快。对于<code>CatBoost</code>的<code>tree</code>的预测过程来说，每个特征的分裂都是独立的，不分先后顺序，多个样本可以一起预测。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303111619137.jpg" alt=""></p>
<h2 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h2><p>待总结</p>
<h1 id="LR"><a href="#LR" class="headerlink" title="LR"></a>LR</h1><h2 id="逻辑回归为什么使用sigmoid函数"><a href="#逻辑回归为什么使用sigmoid函数" class="headerlink" title="逻辑回归为什么使用sigmoid函数"></a>逻辑回归为什么使用sigmoid函数</h2><ol>
<li>sigmoid函数可以将任何输入转换为概率值输出，这使得逻辑回归可以用于分类问题。通过设置一个阈值，可以决定将输入分类为哪一类。</li>
<li>sigmoid函数具有性质，当函数的自变量趋近于正无穷时，函数值将趋近于1；当函数的自变量趋近于负无穷时，函数值将趋近于0。这一性质与逻辑回归的假设相符，即当事件发生的条件概率相对于其发生概率比无限大时，事件发生的概率为1；当事件发生的条件概率相对于其发生概率比无限小时，事件发生的概率为0。</li>
<li>sigmoid函数的导数计算简单，这使得逻辑回归的模型训练更快。</li>
</ol>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><p>支持向量机<code>(support vector machines，SVM)</code>是一种二分类模型，它将实例的特征向量映射为空间中的一些点，<code>SVM</code>的目的就是想要画出一条线，以 “最好地” 区分这两类点，以至如果以后有了新的点，这条线也能做出很好的分类。<code>SVM</code>适合中小型数据样本、非线性、高维的分类问题。</p>
<p>将实例的特征向量（以二维为例）映射为空间中的一些点，如下图的实心点和空心点，它们属于不同的两类。<code>SVM</code>的目的就是想要画出一条线，以“最好地”区分这两类点，以至如果以后有了新的点，这条线也能做出很好的分类。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071255957.png" alt=""></p>
<p><strong>Q1：能够画出多少条线对样本点进行区分？</strong><br>答：线是有无数条可以画的，区别就在于效果好不好，每条线都可以叫做一个划分超平面。比如上面的绿线就不好，蓝线还凑合，红线看起来就比较好。我们所希望找到的这条效果最好的线就是具有 “最大间隔的划分超平面”。</p>
<p><strong>Q2：为什么要叫作“超平面”呢？</strong><br>答：因为样本的特征很可能是高维的，此时样本空间的划分就不是一条线了。</p>
<p><strong>Q3：画线的标准是什么？/ 什么才叫这条线的效果好？/ 哪里好？</strong><br>答：<code>SVM</code>将会寻找可以区分两个类别并且能使间隔<code>(margin)</code>最大的划分超平面。比较好的划分超平面，样本局部扰动时对它的影响最小、产生的分类结果最鲁棒、对未见示例的泛化能力最强。</p>
<p><strong>Q4：间隔margin是什么？</strong><br>答：对于任意一个超平面，其两侧数据点都距离它有一个最小距离（垂直距离），这两个最小距离的和就是间隔。比如下图中两条虚线构成的带状区域就是<code>margin</code>，虚线是由距离中央实线最近的两个点所确定出来的（也就是由支持向量决定）。但此<code>margin</code>比较小，如果用第二种方式画，<code>margin</code>明显变大也更接近我们的目标。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071300267.png" alt=""></p>
<p><strong>Q5：为什么要让margin尽量大？</strong><br>答：因为大<code>margin</code>犯错的几率比较小，也就是更鲁棒啦。</p>
<p><strong>Q6：支持向量是什么？</strong><br>答：从上图可以看出，虚线上的点到划分超平面的距离都是一样的，实际上只有这几个点共同确定了超平面的位置，因此被称作 “支持向量<code>(support vectors)</code>”，“支持向量机” 也是由此来的。</p>
<p><strong>Q7：SVM 算法特性</strong></p>
<ol>
<li>训练好的模型的算法复杂度是由支持向量的个数决定的，而不是由数据的维度决定的。所以<code>SVM</code>不太容易产生<code>overfitting</code>。</li>
<li><code>SVM</code>训练出来的模型完全依赖于支持向量，即使训练集里面所有非支持向量的点都被去除，重复训练过程，结果仍然会得到完全一样的模型。</li>
<li>一个<code>SVM</code>如果训练得出的支持向量个数比较少，那么<code>SVM</code>训练出的模型比较容易被泛化。</li>
<li><code>SVM</code>算法对大规模训练样本难以实施。</li>
<li>用<code>SVM</code>解决多分类问题存在困难。</li>
</ol>
<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><h2 id="多尺度"><a href="#多尺度" class="headerlink" title="多尺度"></a>多尺度</h2><p>多尺度，实际上就是对信号的不同粒度的采样。粒度小，说明是一个很密集的采样，能看到更多更多的细节；而粒度大，说明是一个很稀疏的采样，但是点与点之间隔得远了，就容易看到趋势了。通常在不同尺度下我们可以观察到不同的特征，从而完成不同的任务。</p>
<p>例如，我们判断一张图片中是否有前景，那么<code>12×8</code>的图像尺度就够了；如果我们要识别图中的水果种类，那么<code>64×48</code>的图像尺度勉强够用；如果我们要后期合成该图像的景深，则需要更高分辨率的图像，例如<code>640×480</code>。</p>
<h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>卷积的作用是<strong>提取特征</strong>，图像的空间联系是局部的像素联系较为紧密，而距离较远的像素相关性则较弱。因而，每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。同时卷积通过权重共享降低参数量。</p>
<p>常见的卷积核选择都是<code>3x3</code>、<code>5x5</code>、<code>7x7</code>的，为什么很少见到偶数的卷积核呢？</p>
<ul>
<li>其主要原因是为了保护位置信息，使用奇数的卷积核，保证了中心点刚好在中间，避免了位置信息发生偏移。在需要使用位置信息的任务，如目标检测、目标识别、三维重建、图像重建等任务中非常有价值。</li>
<li>另一个就是因为<code>padding</code>时候能够保证左右对称，实际上也是为了位置信息。</li>
</ul>
<h3 id="普通卷积"><a href="#普通卷积" class="headerlink" title="普通卷积"></a>普通卷积</h3><p>在卷积神经网络中我们通常需要输入<code>in_channels</code>和<code>out_channels</code>，即输入通道数和输出通道数。</p>
<p>对于最初输入图片样本的通道数<code>in_channels</code>取决于图片的类型，如果是彩色的，即<code>RGB</code>类型，这时候通道数固定为 $3$ ，如果是灰度图，通道数为 $1$ 。<br>卷积完成之后，输出的通道数<code>out_channels</code>取决于过滤器的数量。从这个方向理解，这里的<code>out_channels</code>设置的就是过滤器的数目。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230106231925.png" alt=""></p>
<p>如上图，输入的通道数为 $3$ ，所以卷积的时候每个需要对每个通道有个卷积核；输出的通道数为 $4$ ，输出的通道数就是我们设置的过滤器的数目。</p>
<h3 id="分组卷积-group-convolution"><a href="#分组卷积-group-convolution" class="headerlink" title="分组卷积(group convolution)"></a>分组卷积(group convolution)</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303212301932.png" alt=""></p>
<p><strong>我们用同等的参数量运算量生成了g个feature map！！！</strong></p>
<p>所以<code>group convolution</code>常用在轻量型高效网络中，因为它用少量的参数量和运算量就能生成大量的<code>feature map</code>，大量的<code>feature map</code>意味着能够编码更多的信息！</p>
<p>从分组卷积的角度来看，分组数 $g$ 就像一个控制旋钮，最小值是 $1$ ，此时 $g=1$ 的卷积就是普通卷积；最大值是输入<code>feature map</code>的通道数 $C$ ，此时 $g=C$ 的卷积就是<strong>depthwise sepereable convolution</strong>，即深度分离卷积，又叫逐通道卷积。</p>
<h3 id="卷积结果"><a href="#卷积结果" class="headerlink" title="卷积结果"></a>卷积结果</h3><p>假设 $W_{1}$ 、 $H_{1}$ 表示输入的宽度和长度， $W_{2}$ 、 $H_{2}$ 表示输出特征图的的宽度和长度， $F$ 表示卷积核长和宽的大小， $S$ 表示滑动窗口的步长， $P$ 表示边界填充。那么输出特征图的宽度和长度分别为： $W_{2}=\frac{W_{1}-F_{W}+2P}{S}+1$ ， $H_{2}=\frac{H_{1}-F_{H}+2P}{S}+1$ 。</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化的作用是进行<strong>特征压缩（下采样）</strong>，池化层是当前卷积神经网络中常用组件之一，它最早见于<code>LeNet</code>一文，称之为<code>Subsample</code>。自<code>AlexNet</code>之后采用<code>Pooling</code>命名。池化层是模仿人的视觉系统对数据进行降维，用更高层次的特征表示图像。</p>
<p>实施池化的目的：(1) 降低信息冗余；(2) 提升模型的尺度不变性、旋转不变性；(3) 降低特征维数，防止过拟合。</p>
<h2 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h2><p>padding的主要作用是使得图像边界的特征也能够被充分利用。</p>
<h2 id="CNN中的等变和不变"><a href="#CNN中的等变和不变" class="headerlink" title="CNN中的等变和不变"></a>CNN中的等变和不变</h2><p>简单的来说，CNN中的卷积操作中的参数共享使得它对平移操作有等变性，而一些池化操作对平移有近似不变性。先来说前者， 我们举个很简单的例子，我们都知道CNN的第一层往往可以解释为一些简单的线条处理，比如竖直/水平线条检测等等，那么如果图像平移，显然并不会影响到这一层线条检测的功能，但是其输出也会做相应平移。后者的之所以说是近似不变性，是因为池化层并非能保持完全不变，例如我们使用max池化，只要变换不影响到最大值，我们的池化结果不会收到影响，对于一个NxN的filter，只有一个值的变动会影响到输出， 其他的变换都不会造成扰动。 平均池化的近似不变性就稍弱些。这里池化的其实是一个非常强的先验，等于是忽视了这一步维数约简带来的信息损失而保证了近似不变性。</p>
<p>我们换个角度来说，CNN是既具有不变性，又具有等变性。 可以这么理解，如果我们的输出是给出图片中猫的位置，那么我们将图片中的猫从左边移到右边，这种平移也会反应在输出上，我们输出的位置也是从左边到右边，那么我们则可以说CNN有等变性；如果我们只是输出图片中是否有猫，那么我们无论把猫怎么移动，我们的输出都保持”有猫”的判定，因此体现了CNN的不变性。</p>
<h3 id="等变性"><a href="#等变性" class="headerlink" title="等变性"></a>等变性</h3><p>等变性 equivariant，对于一个函数，如果你对其输入施加的变换也会同样反应在输出上，那么这个函数就对该变换具有等变性。</p>
<h3 id="不变性"><a href="#不变性" class="headerlink" title="不变性"></a>不变性</h3><p>不变性 invraiant，对于一个函数，如果对其输入施加的某种操作丝毫不会影响到输出，那么这个函数就对该变换具有不变性。</p>
<h2 id="神经网络中权值共享的理解？"><a href="#神经网络中权值共享的理解？" class="headerlink" title="神经网络中权值共享的理解？"></a>神经网络中权值共享的理解？</h2><p>所谓权值共享就是说给定一张输入图片，用一个卷积核来卷积这张图，卷积核里的值叫做权重，这张图的每个位置是被同一个卷积核扫的，即卷积的时候所用的权重是一样的。其实权值共享这个词说全了就是整张图片在使用同一个卷积核内的参数，比如一个 $3\times 3 \times 1$ 的卷积核，这个卷积核内 $9$ 个的参数被整张图共享，而不会因为图像内位置的不同而改变卷积核内的权系数。说的再直白一些，就是用一个卷积核不改变其内权系数的情况下卷积处理整张图片（当然<code>CNN</code>中每一层不会只有一个卷积核的，这样说只是为了方便解释而已）。<br>作用：大大减少网络训练参数的同时，还可以实现并行训练。</p>
<h2 id="对微调-fine-tuning-的理解，为什么要修改最后几层神经网络权值？"><a href="#对微调-fine-tuning-的理解，为什么要修改最后几层神经网络权值？" class="headerlink" title="对微调(fine-tuning)的理解，为什么要修改最后几层神经网络权值？"></a>对微调(fine-tuning)的理解，为什么要修改最后几层神经网络权值？</h2><p>使用预训练模型的好处，在于利用训练好的<code>SOTA</code>模型权重去做特征提取，可以节省我们训练模型和调参的时间。</p>
<p>为什么只微调最后几层神经网络权重，是因为：</p>
<ol>
<li><code>CNN</code>中更靠近底部的层（定义模型时先添加到模型中的层）编码的是更加通用的可复用特征，而更靠近顶部的层（最后添加到模型中的层）编码的是更专业化的特征。微调这些更专业化的特征更加有用，它更代表了新数据集上的有用特征。</li>
<li>训练的参数越多，过拟合的风险越大。很多<code>SOTA</code>模型拥有超过千万的参数，在一个不大的数据集上训练这么多参数是有过拟合风险的，除非你的数据集像<code>ImageNet</code>那样大。</li>
</ol>
<h2 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h2><p>优点：这种网络当时提出来成为了CNN标准的“模板”——叠加卷积层和池化层，并以一个全连接层结束网络。</p>
<p>缺点：当时一段时间并未火起来，原因在于当时历史背景，这个简单的网络仅有 $6000$ 多个参数，但训练起来费时且没有<code>GPU</code>加速，相比较于传统的<code>SVM</code>等算法，效率还是差了许多，所以并没有大放异彩。</p>
<h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><ul>
<li>使用<code>ReLU</code>激活函数，不容易发生梯度消失问题。</li>
<li>对输入的数据进行了数据增强处理。（水平变换、光照增强、随机裁剪、平移变换等等）</li>
<li>首次使用<code>Dropout</code>防止过拟合。</li>
<li>采用两块<code>GPU</code>并行计算，每一层分两块进行计算，所以看着比较繁琐，这里也是由于<code>GPU</code>不是很好，所以要两块并行。</li>
</ul>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p><code>2012</code>年，<code>Hinton</code>在其论文中提出<code>Dropout</code>。当一个复杂的前馈神经网络被训练在小的数据集时，容易造成过拟合。为了防止过拟合，可以通过阻止特征检测器的共同作用来提高神经网络的性能。<br><code>Droupout</code>是一种针对深度学习广泛应用的<strong>正则化技术</strong>。在每次迭代时随机关闭一些神经单元，随着迭代的进行，由于其他神经元可能在任何时候都被关闭，因此神经元对其他特定神经元的激活变得不那么敏感。</p>
<p>经过上面屏蔽掉某些神经元，使其激活值为 $0$ 以后，我们还需要对向量 $y_{1},\cdots,y_{n}$ <strong>进行缩放</strong>，也就是乘以 $1/(1-p)$ ，此方法为<code>invert Dropout</code>；如果你在训练的时候，经过置 $0$ 后，没有对 $y_{1}\cdots y_{n}$ 进行<code>rescale</code>，那么在测试的时候，就需要对权重进行缩放，即对每个神经元的权重都乘以一个 $p$ ，这样在“总体上”使得测试数据和训练数据是大致一样的，此方法为<code>vanilla Dropout</code>。比如一个神经元的输出是 $x$ ，那么在训练的时候它有 $p$ 的概率参与训练， $(1-p)$ 的概率丢弃，那么它输出的期望是 $p\cdot x+ (1-p)\cdot 0=p\cdot x$。因此测试的时候把这个神经元 $d$ 的权重乘以 $p$ 可以得到同样的期望。</p>
<h4 id="为什么说Dropout可以解决过拟合？"><a href="#为什么说Dropout可以解决过拟合？" class="headerlink" title="为什么说Dropout可以解决过拟合？"></a>为什么说Dropout可以解决过拟合？</h4><ol>
<li>取平均的作用。<code>Dropout</code>掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个<code>Dropout</code>过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</li>
<li>减少神经元之间复杂的共适应关系：因为<code>Dropout</code>导致两个神经元不一定每次都在一个<code>Dropout</code>网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况 。迫使网络去学习更加鲁棒的特征，这些特征在其它的神经元的随机子集中也存在。换句话说假如我们的神经网络是在做出某种预测，它不应该对一些特定的线索片段太过敏感，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的特征。</li>
<li><code>Dropout</code>类似于性别在生物进化中的角色：物种为了生存往往会倾向于适应这种环境，环境突变则会导致物种难以做出及时反应，性别的出现可以繁衍出适应新环境的变种，有效的阻止过拟合，即避免环境改变时物种可能面临的灭绝。</li>
</ol>
<h4 id="Dropout缺点"><a href="#Dropout缺点" class="headerlink" title="Dropout缺点"></a>Dropout缺点</h4><p>明确定义的损失函数每一次迭代都会下降，而<code>Dropout</code>每一次都会随机删除节点，也就是说每一次训练的网络都是不同的，损失函数不再被明确地定义，在某种程度上很难计算，我们失去了调试工具。</p>
<h2 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h2><p>全部使用<code>3×3</code>卷积核的堆叠，来模拟更大的感受野，并且网络层数更深。<code>VGG</code>有五段卷积，每段卷积后接一层最大池化。卷积核数目逐渐增加。</p>
<p><strong>作者用的是多个3×3卷积叠加，而不是例如7×7、11×11的单个卷积，原因如下：</strong></p>
<ul>
<li><code>2</code>个<code>3×3</code>卷积叠加得到的理论感受野和一个<code>5×5</code>卷积的理论感受野是相同的，<code>3</code>个<code>3×3</code>卷积叠加得到的理论感受野和一个<code>7×7</code>卷积的理论感受野是相同的。</li>
<li>因为每个卷积层后面都会跟着一个<code>ReLU</code>，<code>3</code>个<code>3×3</code>卷积就会有<code>3</code>个<code>ReLU</code>，但是一个<code>7×7</code>的卷积只有一个，所以这么做可以使得模型的非线性拟合能力更强。</li>
<li>减少了参数数量。假设<code>3</code>个<code>3×3</code>卷积的输入和输出都是<code>C</code>个通道，那么参数数量为 $3 \times 3 \times 3 \times C \times C = 27C^{2}$  ，而<code>7×7</code>卷积的参数数量为 $7 \times 7 \times C \times C = 49C^{2}$ 。</li>
</ul>
<p><strong>1×1卷积的作用是什么？</strong></p>
<ul>
<li>为了在不影响卷积层感受野的前提下，增加模型的非线性。</li>
<li>可以压缩通道数，即减少特征的维度。</li>
</ul>
<h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p><code>GoogLeNet</code>专注于加深网络结构，与此同时引入了新的基本结构——<code>Inception</code>模块，从而来增加网络的宽度。每个原始<code>Inception</code>模块由<code>previous layer</code>、并行处理层及<code>filter concatenation</code>层组成。并行处理层包含 $4$ 个分支，即<code>1×1</code>卷积分支，<code>3×3</code>卷积分支，<code>5×5</code>卷积分支和<code>3×3</code>最大池化分支。一个关于原始<code>Inception</code>模块的最大问题是，<code>5×5</code>卷积分支即使采用中等规模的卷积核个数，在计算代价上也可能是无法承受的。这个问题在混合池化层之后会更为突出，很快的出现计算量的暴涨。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303222128650.png" alt=""></p>
<p>为了克服原始<code>Inception</code>模块上的困难，<code>GoogLeNet</code>推出了一个新款，即采用<code>1×1</code>的卷积层来降低输入层的维度，使网络参数减少，因此减少网络的复杂性。因此得到降维<code>Inception</code>模块，称为<code>inception V1</code>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303222129537.png" alt=""></p>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><h3 id="ResNet中的一些亮点"><a href="#ResNet中的一些亮点" class="headerlink" title="ResNet中的一些亮点"></a>ResNet中的一些亮点</h3><ol>
<li>超深的网络结构（超过 $1000$ 层）。</li>
<li>提出<code>residual</code>（残差结构）模块。</li>
<li>使用<code>Batch Normalization</code>加速训练（丢弃<code>Dropout</code>）。</li>
</ol>
<h3 id="为什么采用residual"><a href="#为什么采用residual" class="headerlink" title="为什么采用residual?"></a>为什么采用residual?</h3><p>人们认为卷积层和池化层的层数越多，获取到的图片特征信息越全，学习效果也就越好。但是在实际的试验中发现，随着卷积层和池化层的叠加，不但没有出现学习效果越来越好的情况，反而两种问题：</p>
<ol>
<li>梯度消失和梯度爆炸<br>梯度消失：若每一层的误差梯度小于 $1$ ，反向传播时，网络越深，梯度越趋近于 $0$<br>梯度爆炸：若每一层的误差梯度大于 $1$ ，反向传播时，网络越深，梯度越来越大</li>
<li>退化问题<br>随着层数的增加，预测效果反而越来越差。</li>
</ol>
<ul>
<li>为了解决梯度消失或梯度爆炸问题，<code>ResNet</code>论文提出通过数据的预处理以及在网络中使用 <code>BN(Batch Normalization)</code>层来解决。</li>
<li>为了解决深层网络中的退化问题，可以人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为残差网络<code>(ResNets)</code>。<code>ResNet</code>论文提出了<code>residual</code>结构（残差结构）来减轻退化问题，随着网络的不断加深，效果并没有变差，而是变的更好了。</li>
</ul>
<h3 id="residual结构"><a href="#residual结构" class="headerlink" title="residual结构"></a>residual结构</h3><h4 id="residual的计算方式"><a href="#residual的计算方式" class="headerlink" title="residual的计算方式"></a>residual的计算方式</h4><p><code>residual</code>结构使用了一种<code>shortcut</code>的连接方式，也可理解为捷径。让特征矩阵隔层相加，注意 $\mathcal{F}(\mathbb{x})$ 和 $\mathbb{x}$ 形状要相同，所谓相加是特征矩阵相同位置上的数字进行相加。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071317819.png" alt=""></p>
<h4 id="ResNet中两种不同的residual"><a href="#ResNet中两种不同的residual" class="headerlink" title="ResNet中两种不同的residual"></a>ResNet中两种不同的residual</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071317983.png" alt=""></p>
<ol>
<li>左侧残差结构称为<code>BasicBlock</code></li>
<li>右侧残差结构称为<code>Bottleneck</code><ul>
<li>其中第一层的 $1\times1$ 的卷积核的作用是对特征矩阵进行降维操作，将特征矩阵的深度由 $256$ 降为 $64$ ；</li>
<li>第三层的 $1\times1$ 的卷积核是对特征矩阵进行升维操作，将特征矩阵的深度由 $64$ 升成 $256$ 。<br>降低特征矩阵的深度主要是为了减少参数的个数。<br>如果采用<code>BasicBlock</code>，参数的个数应该是： $256\times256\times3\times3\times2=1179648$<br>采用<code>Bottleneck</code>，参数的个数是： $1\times1\times256\times64+3\times3\times64\times64+1\times1\times256\times64=69632$</li>
<li>先降后升为了主分支上输出的特征矩阵和捷径分支上输出的特征矩阵形状相同，以便进行加法操作。</li>
</ul>
</li>
</ol>
<h3 id="BatchNormalization"><a href="#BatchNormalization" class="headerlink" title="BatchNormalization"></a>BatchNormalization</h3><p><strong>BatchNormalization就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布。</strong></p>
<p>在神经网络中, 数据分布对训练会产生影响。比如某个神经元 $x$ 的值为 $1$ ，某个 <code>Weights</code> 的初始值为 $0.1$ ，这样后一层神经元计算结果就是 $Wx = 0.1$ ；又或者 $x = 20$ ，这样 $Wx$ 的结果就为 $2$ 。现在还不能看出什么问题,，但是，当我们加上一层激活函数，激活这个  $Wx$ 值的时候，问题就来了。如果使用像 <code>tanh</code> 的激活函数， $Wx$ 的激活值就变成了 $\approx 0.1$ 和 $\approx 1$, 接近于 $1$ 的部已经处在了激活函数的饱和阶段, 也就是 $x$ 无论再怎么扩大， <code>tanh</code> 激励函数输出值也还是接近 $1$ 。</p>
<p>我们为了避免这种情况，就会对数据进行归一化，<strong>对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0​，方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。</strong>同时了为了恢复出原始的某一层所学到的特征，我们引入了这个可学习重构参数 $\gamma$ 、$\beta$ ，让我们的网络可以学习恢复出原始网络所要学习的特征分布。</p>
<p>均值的计算，就是在一个批次内，将每个通道中的数字单独加起来，再除以 $N \times H \times W$。举个例子：该批次内有10张图片，每张图片有三个通道RBG，每张图片的高、宽是H、W，那么均值就是计算<strong>10张图片R通道的像素数值总和</strong>除以 $10 \times H \times W$，再计算B通道全部像素值总和除以 $10 \times H \times W$，最后计算G通道的像素值总和除以 $10 \times H \times W$。方差的计算类似。</p>
<h3 id="LayerNormalization"><a href="#LayerNormalization" class="headerlink" title="LayerNormalization"></a>LayerNormalization</h3><ul>
<li>BN在mini-batch较小的情况下不太适用。BN是对整个mini-batch的样本统计均值和方差，当训练样本数很少时，样本的均值和方差不能反映全局的统计分布信息，从而导致效果下降。</li>
<li>BN无法应用于RNN。<ul>
<li>RNN实际是共享的MLP，在时间维度上展开，每个step的输出是(bsz, hidden_dim)。由于不同句子的同一位置的分布大概率是不同的，所以应用BN来约束是没意义的。注：而BN应用在CNN可以的原因是同一个channel的特征图都是由同一个卷积核产生的。</li>
<li>LN原文的说法是：在训练时，对BN来说需要保存每个step的统计信息（均值和方差）。在测试时，由于变长句子的特性，测试集可能出现比训练集更长的句子，所以对于后面位置的step，是没有训练的统计量使用的。（不过实践中的话都是固定了max len，然后padding的。）</li>
<li>当然还有一种说法是，不同句子的长度不一样，对所有的样本统计均值是无意义的，因为某些样本在后面的timestep时其实是padding。</li>
<li>还有一种说法是（Normalization helps training of quantized lstm.）：应用BN层的话，每个timestep都需要去保存和计算batch统计量，耗时又耗力，后面就有人提出across timestep去shared BN的统计量，这明显不对，因为不同timestep的分布明显是不同的。</li>
<li>最后，大家发现LN的效果还很不错，比BN好，所以就变成NLP data里面的default config了。</li>
</ul>
</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151052109.png" alt=""></p>
<h3 id="ResNet为什么不用Dropout？"><a href="#ResNet为什么不用Dropout？" class="headerlink" title="ResNet为什么不用Dropout？"></a>ResNet为什么不用Dropout？</h3><p><code>Dropout</code>与<code>BN</code>不兼容。<code>BN</code>在训练过程对每个单个样本的<code>forward</code>均引入多个样本的统计信息，相当于自带一定噪音，起到正则效果，所以也就基本消除了<code>Dropout</code>的必要。</p>
<h2 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h2><p>每个层从前面的所有层获得额外的输入，并将自己的特征映射传递到后续的所有层，使用级联<code>(Concatenation)</code>方式，每一层都在接受来自前几层的“集体知识”<code>(collective knowledge)</code>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303222332494.png" alt=""></p>
<p>如图所示，第<code>i</code>层的输入不仅与<code>i-1</code>层的输出相关，还有所有之前层的输出有关，记作： $X_{l}=H_{l}([X_{0},\cdots,X_{l-1}])$ 。第<code>l</code>层产生 $k_{0}+(l-1)k$ 个<code>feature maps</code>，其中 $k$ 称为网络的增长率。</p>
<h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>循环神经网络<code>(Recurrent Neural Network, RNN)</code>是一类以序列<code>(sequence)</code>数据为输入，在序列的演进方向进行递归<code>(recursion)</code>且所有节点（循环单元）按链式连接的递归神经网络<code>(recursive neural network)</code> 。</p>
<p>对循环神经网络的研究始于二十世纪八九十年代，并在二十一世纪初发展为深度学习算法之一 ，其中双向循环神经网络<code>(Bidirectional RNN, Bi-RNN)</code>和长短期记忆网络<code>(Long Short-Term Memory networks, LSTM)</code>是常见的循环神经网络。</p>
<h2 id="为什么需要RNN？"><a href="#为什么需要RNN？" class="headerlink" title="为什么需要RNN？"></a>为什么需要RNN？</h2><p>在<code>CNN</code>网络中的训练样本的数据为<code>IID</code>数据（独立同分布数据），所解决的问题也是分类问题或者回归问题或者是特征表达问题。<strong>但更多的数据是不满足IID的</strong>，如语言翻译，自动文本生成。它们是一个序列问题，包括时间序列和空间序列。比如时间序列数据，这类数据是在不同时间点上收集到的数据，反映了某一事物、现象等随时间的变化状态或程度。一般的神经网络，在训练数据足够、算法模型优越的情况下，给定特定的 $x$ ，就能得到期望 $y$ 。其一般处理单个的输入，前一个输入和后一个输入完全无关，但实际应用中，某些任务需要能够更好的处理序列的信息，即前面的输入和后面的输入是有关系的。 这时就要用到<code>RNN</code>网络，<code>RNN</code>的结构图如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071328562.png" alt=""></p>
<h2 id="RNN的主要应用领域"><a href="#RNN的主要应用领域" class="headerlink" title="RNN的主要应用领域"></a>RNN的主要应用领域</h2><p>可以说只要考虑时间先后顺序的问题都可以使用<code>RNN</code>来解决，这里主要说一下几个常见的应用领域：</p>
<ul>
<li>自然语言处理<code>(NLP)</code>：主要有视频处理，文本生成，语言模型，图像处理。</li>
<li>机器翻译，机器写文章。</li>
<li>语音识别。</li>
<li>图像描述生成。</li>
<li>文本相似度计算。</li>
<li>推荐系统。例如：音乐推荐、网易考拉商品推荐、<code>Youtube</code>视频推荐等新的应用领域。</li>
</ul>
<h2 id="RNN的计算过程"><a href="#RNN的计算过程" class="headerlink" title="RNN的计算过程"></a>RNN的计算过程</h2><p><code>RNN</code>引入了隐状态 $h$ ， $h$ 可对序列数据提取特征，接着再转换为输出。首先我们计算 $h_{1}$ ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071332166.jpg" alt=""></p>
<p><code>RNN</code>中，每个步骤使用的参数 $U,W,b$ 相同， $h_{2},h_{3},h_{4}$ 的计算方式和 $h_{1}$ 类似，其计算结果如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071333924.jpg" alt=""></p>
<p>接下来，计算<code>RNN</code>的输出 $y_1$ ，采用<code>Softmax</code>作为激活函数，根据 $y_n=f(Wx+b)$ ，得到 $y_1$ :</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071335563.jpg" alt=""></p>
<p>使用和 $y_1$ 相同的参数 $V,c$ ，得到 $y_2,y_3,y_4$ 的输出结构：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071336003.jpg" alt=""></p>
<h2 id="RNN的建模方式"><a href="#RNN的建模方式" class="headerlink" title="RNN的建模方式"></a>RNN的建模方式</h2><h3 id="一对多-vector-to-sequence"><a href="#一对多-vector-to-sequence" class="headerlink" title="一对多(vector-to-sequence)"></a>一对多(vector-to-sequence)</h3><p>输入是一个单独的值，输出是一个序列。此时，有两种主要建模方式：</p>
<p>方式一：可只在其中的某一个序列进行计算，比如序列第一个进行输入计算，其建模方式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071339814.jpg" alt=""></p>
<p>方式二：把输入信息 $X$ 作为每个阶段的输入，其建模方式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071339457.jpg" alt=""></p>
<h3 id="多对一-sequence-to-vector"><a href="#多对一-sequence-to-vector" class="headerlink" title="多对一(sequence-to-vector)"></a>多对一(sequence-to-vector)</h3><p>输入是一个序列，输出是一个单独的值，此时通常在最后的一个序列上进行输出变换，其建模如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071340668.jpg" alt=""></p>
<h3 id="多对多-Encoder-Decoder"><a href="#多对多-Encoder-Decoder" class="headerlink" title="多对多(Encoder-Decoder)"></a>多对多(Encoder-Decoder)</h3><p><strong>步骤一</strong>：将输入数据编码成一个上下文向量 $c$ ，这部分称为<code>Encoder</code>，得到 $c$ 有多种方式，最简单的方法就是把<code>Encoder</code>的最后一个隐状态赋值给 $c$ ，还可以对最后的隐状态做一个变换得到 $c$ ，也可以对所有的隐状态做变换。其示意如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071341013.jpg" alt=""></p>
<p><strong>步骤二</strong>：用另一个<code>RNN</code>网络（我们将其称为<code>Decoder</code>）对其进行编码。</p>
<p>方法一是将步骤一中的 $c$ 作为初始状态输入到<code>Decoder</code>，示意图如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071342703.jpg" alt=""></p>
<p>方法二是将 $c$ 作为<code>Decoder</code>的每一步输入，示意图如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071343619.jpg" alt=""></p>
<h2 id="RNN中为什么会出现梯度消失？如何解决？"><a href="#RNN中为什么会出现梯度消失？如何解决？" class="headerlink" title="RNN中为什么会出现梯度消失？如何解决？"></a>RNN中为什么会出现梯度消失？如何解决？</h2><p><strong>梯度消失的原因：</strong><code>Sigmoid</code>函数的导数范围是 $(0,0.25]$，<code>tanh</code>函数的导数范围是 $(0,1]$ ，他们的导数最大都不大于 $1$ ，如果取<code>tanh</code>或<code>Sigmoid</code>函数作为激活函数嵌套到<code>RNN</code>中，那么必然是一堆小数在做乘法，结果就是越乘越小。随着时间序列的不断深入，小数的累乘就会导致梯度越来越小直到接近于 $0$ ，这就是“梯度消失“现象。实际使用中，会优先选择<code>tanh</code>函数，原因是<code>tanh</code>函数相对于<code>Sigmoid</code>函数来说梯度较大，收敛速度更快且引起梯度消失更慢。</p>
<p> <strong>解决RNN中的梯度消失方法主要有：</strong></p>
<ol>
<li>选取更好的激活函数，如<code>ReLU</code>激活函数。<code>ReLU</code>函数的左侧导数为 $0$ ，右侧导数恒为 $1$ ，这就避免了“梯度消失“的发生。但恒为 $1$ 的导数容易导致“梯度爆炸“，但设定合适的阈值可以解决这个问题。</li>
<li>加入<code>BN</code>层，其优点包括可加速收敛、控制过拟合，可以少用或不用<code>Dropout</code>和正则、降低网络对初始化权重不敏感，且能允许使用较大的学习率等。</li>
<li>改变传播结构，选择更高级的模型，例如：<code>LSTM</code>结构可以有效解决这个问题。</li>
</ol>
<h2 id="RNN的注意力机制"><a href="#RNN的注意力机制" class="headerlink" title="RNN的注意力机制"></a>RNN的注意力机制</h2><p>在上述的<code>Encoder-Decoder</code>结构中，<code>Encoder</code>把所有的输入序列都编码成一个统一的语义特征 $c$ 再解码。因此， $c$ 中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。如机器翻译问题，当要翻译的句子较长时，一个 $c$ 可能存不下那么多信息，就会造成翻译精度的下降。<code>Attention</code>机制通过在每个时间输入不同的 $c$ 来解决此问题。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071356215.png" alt=""></p>
<h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><h2 id="传统RNN存在的问题"><a href="#传统RNN存在的问题" class="headerlink" title="传统RNN存在的问题"></a>传统RNN存在的问题</h2><p><strong>长期依赖(Long Term Dependencies)</strong></p>
<p>在深度学习领域中（尤其是<code>RNN</code>），“长期依赖”问题是普遍存在的。长期依赖产生的原因是当神经网络的节点经过许多阶段的计算后，之前比较长的时间片的特征已经被覆盖，例如：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101147762.png" alt=""></p>
<p>我们想预测<code>full</code>之前系动词的单复数情况，显然<code>full</code>是取决于第二个单词<code>cat</code>的单复数情况，而非其前面的单词<code>food</code>。随着数据时间片的增加，<code>RNN</code>丧失了学习连接如此远的信息的能力。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101148082.png" alt=""></p>
<p><strong>梯度消失/爆炸</strong></p>
<p>梯度消失和梯度爆炸是困扰<code>RNN</code>模型训练的关键原因之一，产生梯度消失和梯度爆炸是由于<code>RNN</code>的权值矩阵循环相乘导致的，相同函数的多次组合会导致极端的非线性行为。梯度消失和梯度爆炸主要存在<code>RNN</code>中，因为<code>RNN</code>中每个时间片使用相同的权值矩阵。对于一个<code>DNN</code>，虽然也涉及多个矩阵的相乘，但是通过精心设计权值的比例可以避免梯度消失和梯度爆炸的问题。</p>
<p>处理梯度爆炸可以采用梯度截断的方法。所谓梯度截断是指将梯度值超过阈值 $\theta$ 的梯度手动降到 $\theta$ 。虽然梯度截断会一定程度上改变梯度的方向，但梯度截断的方向依旧是朝向损失函数减小的方向。</p>
<p>对比梯度爆炸，梯度消失不能简单的通过类似梯度截断的阈值式方法来解决，因为长期依赖的现象也会产生很小的梯度。在上面例子中，我们希望 $t_{9}$ 时刻能够读到 $t_{1}$ 时刻的特征，在这期间内我们自然不希望隐层节点状态发生很大的变化，所以 $[t_{2},t_{8}]$ 时刻的梯度要尽可能的小才能保证梯度变化小。很明显，如果我们刻意提高小梯度的值将会使模型失去捕捉长期依赖的能力。</p>
<h2 id="LSTM-1"><a href="#LSTM-1" class="headerlink" title="LSTM"></a>LSTM</h2><p><code>LSTM</code>的全称是<code>Long Short Term Memory</code>，顾名思义，它具有记忆长短期信息的能力的神经网络。<code>LSTM</code>提出的动机是为了解决上面我们提到的长期依赖问题。传统的<code>RNN</code>节点输出仅由权值，偏置以及激活函数决定。<code>RNN</code>是一个链式结构，每个时间片使用的是相同的参数。<strong>其中，细胞状态作为<code>LSTM</code>的核心信息通道，用于长期存储信息。它通过 forget 门控制遗忘哪些信息，通过输入门决定添加哪些新信息，并通过输出门选择性地将信息传递到后续步骤。隐藏状态是当前单元的输出，作为上下文信息传递给下一个时间步。隐藏状态不仅反映了细胞状态的内容，还结合了门控机制的选择结果，起到短期记忆的作用。</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101504342.png" alt=""></p>
<p>而<code>LSTM</code>之所以能够解决<code>RNN</code>的长期依赖问题，是因为<code>LSTM</code>引入了门<code>(gate)</code>机制用于控制特征的流通和损失。对于上面的例子，<code>LSTM</code>可以做到在 $t_{9}$ 时刻将 $t_{2}$ 时刻的特征传过来，这样就可以非常有效的判断 $t_{9}$ 时刻使用单数还是复数了。<code>LSTM</code>是由一系列<code>LSTM</code>单元<code>(LSTM Unit)</code>组成，其链式结构如下图。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101504156.png" alt=""></p>
<p><code>LSTM</code>的核心部分是在上图最上边类似于传送带的部分，这一部分一般叫做单元状态<code>(cell state)</code>它自始至终存在于<code>LSTM</code>的整个链式系统中。其中 $C_{t}=f_{t} \times C_{t-1} + i_{t} \times \tilde{C}_{t}$ ，其中 $f_{t}$ 叫做遗忘门，表示 $C_{t-1}$ 的哪些特征被用于计算 $C_{t}$ 。 $f_{t}$ 是一个向量，向量的每个元素均位于 $[0,1]$ 范围内。通常我们使用<code>Sigmoid</code>作为激活函数，<code>Sigmoid</code>的输出是一个介于 $[0,1]$ 区间内的值，但是当你观察一个训练好的<code>LSTM</code>时，你会发现门的值绝大多数都非常接近 $0$ 或者 $1$ ，其余的值少之又少。其中 $\otimes$ 是<code>LSTM</code>最重要的门机制，表示 $f_{t}$ 和 $C_{t-1}$ 之间的单位乘的关系。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101539655.png" alt=""></p>
<p> $\tilde{C}_{t}$ 表示单元状态更新值，由输入数据 $x_{t}$ 和隐节点 $h_{t-1}$ 经由一个神经网络层得到，单元状态更新值的激活函数通常使用<code>tanh</code>。 $i_{t}$ 叫做输入门，同 $f_{t}$ 一样也是一个元素介于 $[0,1]$ 区间内的向量，同样由 $x_{t}$ 和 $h_{t-1}$ 经由<code>Sigmoid</code>激活函数计算而成。 $i_{t}$ 用于控制 $\tilde{C}_{t}$ 的哪些特征用于更新 $C_{t}$ ，使用方式和 $f_t$ 相同。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101545859.png" alt=""></p>
<p>最后，为了计算预测值 $\hat{y}_{t}$ 和生成下个时间片完整的输入，我们需要计算隐节点的输出 $h_{t}$，这里有一个输出门，用来控制新的细胞状态 $C_{t}$ 有多少用于输出。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101553212.png" alt=""></p>
<h2 id="LSTM的激活函数选取"><a href="#LSTM的激活函数选取" class="headerlink" title="LSTM的激活函数选取"></a>LSTM的激活函数选取</h2><p>算门的时候使用sigmoid，算值的时候使用tanh（可以替换成其他的）。</p>
<ul>
<li>Sigmoid的输出在0-1之同，符合门控的物理定义，且当输入较大或较小时，其输出会非常接近1或0，从而保证该门开或关；</li>
<li>使用tanh函数，是因为其输出在-1-1之间，这与大多数场景下特征分布是0中心的吻合；</li>
<li>tanh函数在输入为0附近相比 Sigmoid函数有更大的梯度，通常使模型收敛更快。</li>
</ul>
<h1 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h1><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p><code>GRU</code>的出现是为了在传统<code>RNN</code>和<code>LSTM</code>之间取得一个平衡。传统<code>RNN</code>虽然结构简单，但在处理长序列时容易遗忘重要信息；而<code>LSTM</code>通过引入复杂的门控机制以及记忆单元，有效解决了遗忘问题，但其结构较为复杂。因此，<code>GRU</code>应运而生，其设计相较于<code>LSTM</code>更为简洁，同时在性能上与<code>LSTM</code>相当。具体而言，<code>GRU</code>仅采用两个门控机制（更新门和重置门）来控制信息的流动，同时将记忆单元和隐藏状态合并，简化了计算过程。可以将<code>GRU</code>比喻为“便利贴”：在处理序列数据的过程中，当遇到重要的信息时，更新门 类似于将该信息记录在便利贴上，以便于后续参考；如果在后续处理中发现某些信息不再重要，重置门则允许迅速丢弃这些信息。</p>
<h2 id="计算过程"><a href="#计算过程" class="headerlink" title="计算过程"></a>计算过程</h2><ul>
<li>更新门$\mathbf{z}_{t}$：控制前一时刻隐藏状态$\mathbf{h}_{t-1}$的权重，即决定当前时间步的隐藏状态需要保留多少前一个时间步的信息。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505292214632.png" alt=""></p>
<ul>
<li>重置门$\mathbf{r}_{t}$：控制前一时刻隐藏状态$\mathbf{h}_{t-1}$对生成当前时刻隐藏状态$\mathbf{\tilde{h}}_{t}$的权重，即决定了前一时间步的隐藏状态在多大程度上被忽略。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505292221481.png" alt=""></p>
<ul>
<li>当前时刻隐藏状态$\tilde{\mathbf{h}}_{t}$：这里是和<code>RNN</code>最大的不同，即用到了重置门$\mathbf{r}_{t}$。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505292222863.png" alt=""></p>
<ul>
<li>最新的隐藏状态$\mathbf{h}_t$：利用更新门控制最后的隐藏状态。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505292222076.png" alt=""></p>
<p>从上述过程可以看出，相比于传统<code>RNN</code>，为了计算得出$\mathbf{h}_t$，<code>GRU</code>主要计算了一个权重向量$\mathbf{z}_{t}$去控制当前时刻隐藏状态$\tilde{\mathbf{h}}_{t}$的重要程度（<strong>重点记录</strong>），同时在计算$\tilde{\mathbf{h}}_{t}$时，使用另一个权重向量$\mathbf{r}_{t}$进行自适应控制，以调整前一时刻隐藏状态$\mathbf{h}_{t-1}$的重要程度（<strong>允许遗忘</strong>）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202505292227775.png" alt=""></p>
<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p><code>Transformer</code>是一个利用注意力机制来提高模型训练速度的模型。<code>Transformer</code>可以说是完全基于自注意力机制的一个深度学习模型，因为它适用于并行化计算，和它本身模型的复杂程度导致它在精度和性能上都要高于之前流行的<code>RNN</code>循环神经网络。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302227637.png" alt=""></p>
<p>当我输入一个文本的时候，该文本数据会先经过一个叫<code>Encoders</code>的模块，对该文本进行编码，然后将编码后的数据再传入一个叫<code>Decoders</code>的模块进行解码，解码后就得到了翻译后的文本，对应的我们称<code>Encoders</code>为编码器，<code>Decoders</code>为解码器。一般情况下，<code>Encoders</code>里边有 $6$ 个小编码器<code>(Encoder)</code>，<code>Decoders</code>里边有 $6$ 个小解码器<code>(Decoder)</code>。我们看到，在编码部分，每一个的小编码器的输入是前一个小编码器的输出，而每一个小解码器的输入不光是它的前一个解码器的输出，还包括了整个编码部分的输出。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302042116.png" alt=""></p>
<h2 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h2><p>Encoder输入源语言序列，Decoder里面输入需要被翻译的语言文本。一个文本常有许多序列组成，常见操作为将序列进行一些预处理（如词切分等）变成列表，一个序列的列表的元素通常为词表中不可切分的最小词，整个文本就是一个大列表，元素为一个个由序列组成的列表。如一个序列经过切分后变为[“am”, “##ro”, “##zi”, “meets”, “his”, “father”]，接下来按照它们在词表中对应的索引进行转换，假设结果如[23, 94, 13, 41, 27, 96]。假如整个文本一共100个句子，那么就有100个列表为它的元素，因为每个序列的长度不一，需要设定最大长度，这里不妨设为128，那么将整个文本转换为数组之后，形状即为100 x 128，这就对应着batch_size和seq_length。</p>
<p>输入之后，紧接着进行词嵌入处理，词嵌入就是将每一个词用预先训练好的向量进行映射。词嵌入在torch里基于<code>torch.nn.Embedding</code>实现，实例化时需要设置的参数为词表的大小和被映射的向量的维度比如<code>embed = nn.Embedding(10,8)</code>。向量的维度通俗来说就是向量里面有多少个数。注意，第一个参数是词表的大小，如果你目前最多有8个词，通常填写10（多一个位置留给unk和pad），你后面万一进入与这8个词不同的词就映射到unk上，序列padding的部分就映射到pad上。</p>
<p>假如我们打算映射到8维（num_features或者embed_dim），那么整个文本的形状变为100 x 128 x 8。接下来举个小例子解释一下：假设我们词表一共有10个词（算上unk和pad），文本里有2个句子，每个句子有4个词，每个词在词表中都有一个index，然后我们通过index取embed中对应的向量，就可以把每个词映射到8维的向量。</p>
<h2 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h2><h3 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h3><p>Self-Attention属于Attention，要求QKV必须同源，依然代表X，本质上可以看作是相等的，只是对同一个词向量X乘上了参数矩阵，作了空间上的变换。</p>
<h3 id="Cross-attention"><a href="#Cross-attention" class="headerlink" title="Cross-attention"></a>Cross-attention</h3><ul>
<li>Transformer架构中混合两种不同嵌入序列的注意机制</li>
<li>两个序列<strong>必须具有相同的维度</strong></li>
<li>两个序列可以是不同的模式形态（如：文本、声音、图像）</li>
<li>一个序列作为输入的Q，定义了输出的序列长度，另一个序列提供输入的K&amp;V</li>
</ul>
<h2 id="编码器-Encoder"><a href="#编码器-Encoder" class="headerlink" title="编码器(Encoder)"></a>编码器(Encoder)</h2><p>我们放大一个<code>Encoder</code>，发现里边的结构是一个多头自注意力机制加上一个前馈神经网络。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302053360.png" alt=""></p>
<p>像大部分<code>NLP</code>应用一样，我们首先将每个输入单词通过词嵌入算法转换为词向量，每个单词都被嵌入为 $512$ 维的向量。</p>
<ul>
<li>计算自注意力的第一步就是从每个编码器的输入向量（每个单词的词向量）中生成三个向量。也就是说对于每个单词，我们创造一个查询向量、一个键向量和一个值向量。这三个向量是通过词嵌入与三个权重矩阵后相乘创建的。可以发现这些新向量在维度上比词嵌入向量更低。他们的维度是 $64$ ，而词嵌入和编码器的输入/输出向量的维度是 $512$ 。但实际上不强求维度更小，这只是一种基于架构上的选择，它可以使多头注意力<code>(Multi-Head Attention)</code>的大部分计算保持不变。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302112845.png" alt=""></p>
<ul>
<li>计算自注意力的第二步是计算得分。这个得分是通过计算<code>Q</code>与各个单词的<code>K</code>向量的点积得到的。我们以<code>X1</code>为例，分别将<code>Q1</code>和<code>K1</code>、<code>K2</code>进行点积运算，假设分别得到得分 $112$ 和 $96$ 。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302133753.png" alt=""></p>
<ul>
<li>将得分分别除以一个特定数值 $8$ （<code>K</code>向量的维度的平方根，通常<code>K</code>向量的维度是 $64$ ）这能让梯度更加稳定，则得到结果如下：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302134012.png" alt=""></p>
<ul>
<li>将上述结果进行<code>softmax</code>运算得到，<code>softmax</code>主要将分数标准化，使他们都是正数并且加起来等于 $1$ 。这个<code>softmax</code>分数决定了每个单词对编码当下位置的贡献。显然，已经在这个位置上的单词将获得最高的<code>softmax</code>分数，但有时关注另一个与当前单词相关的单词也会有帮助。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302137784.png" alt=""></p>
<ul>
<li>将<code>V</code>向量乘上<code>softmax</code>的结果，这个思想主要是为了保持我们想要关注的单词的值不变，而掩盖掉那些不相关的单词（例如将他们乘上很小的数字）。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302138098.png" alt=""></p>
<ul>
<li>将带权重的各个<code>V</code>向量加起来，至此，产生在这个位置上（第一个单词）的<code>self-attention</code>层的输出，其余位置的<code>self-attention</code>输出也是同样的计算方式。（注：自注意力的另一种解释就是在编码某个单词时，就是将所有单词的表示（值向量<code>V</code>）进行加权求和，而权重是通过该词的表示（键向量<code>K</code>）与被编码词表示（查询向量<code>Q</code>）的点积并通过<code>softmax</code>得到。）</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302139598.png" alt=""></p>
<p>论文为了进一步细化自注意力机制层，增加了<strong>多头注意力机制</strong>的概念，这从两个方面提高了自注意力层的性能。</p>
<ol>
<li>扩展了模型关注不同位置的能力，比如<code>Apple</code>可能和<code>Banana</code>比较相关，但是如果使用单个自注意力机制可能这种关系就被<code>Apple</code>自己支配了（体现在<code>softmax</code>之后的权重最大），而采用多头自注意力机制则可以缓解这种现象。</li>
<li>他给了自注意力层多个表示子空间。对于多头自注意力机制，我们不止有一组权重矩阵，而是有多组（论文中使用 $8$ 组），所以每个编码器/解码器使用 $8$ 个头（可以理解为 $8$ 个互不干扰自的注意力机制运算），每一组的<code>Q/K/V</code>都不相同。然后，得到 $8$ 个不同的权重矩阵 <code>Z</code>，每个权重矩阵被用来将输入向量投射到不同的表示子空间。论文中说到这样的好处是可以允许模型在不同的表示子空间里学习到相关的信息。输出矩阵的维度是（序列长度×单词向量长度）</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303302156146.png" alt=""></p>
<p>为了解决梯度消失的问题，在<code>Encoder</code>和<code>Decoder</code>中都是用了<strong>残差神经网络</strong>的结构，即每一个前馈神经网络的输入不光包含上述<code>self-attention</code>的输出，还包含最原始的输入。</p>
<h3 id="为什么选择除以-sqrt-d"><a href="#为什么选择除以-sqrt-d" class="headerlink" title="为什么选择除以$\sqrt{d}$"></a>为什么选择除以$\sqrt{d}$</h3><ol>
<li><p>防止softmax输入值过大，当embedding的维度越大，矩阵乘法的数值越大，所以防止softmax输入值过大，偏导数趋于0，有益于训练稳定；</p>
</li>
<li><p>$\frac{qk}{\sqrt{d}}$服从均值为0，方差为1的分布，作归一化；</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202306151023478.png" alt=""></p>
</li>
<li><p>类似softmax加温度系数，温度系数根号d越大，softmax输出越平滑（而非尖锐），如果不除以$\sqrt{d}$，相当于softmax输出更尖锐，进而导致梯度稀疏。</p>
</li>
</ol>
<h2 id="解码器-Decoder"><a href="#解码器-Decoder" class="headerlink" title="解码器(Decoder)"></a>解码器(Decoder)</h2><p>同样的，在<code>Decoder</code>中使用的也是类似的结构。不同的地方在于，<code>Decoder</code>不是并行的，而是像<code>RNN</code>一样是一个一个产生的，有时序概念，在这个前提之下，<code>Encoder</code>的第一个模块是一个<code>Masked Multi-Head Attention</code>（就是生产第一步只有一个词，自己做<code>self-attention</code>，第二步生成两个词的时候，就做两个词的<code>self-attetion</code>，那么每一步在该层有一个输出，假设为<code>Q</code>，那么送入到中间的<code>Multi-Head Attention</code>层，和<code>Encoder</code>部分的<code>K</code>，<code>V</code>做<code>attention</code>）。进行过自注意力机制后，将<code>self-attention</code>的输出再与<code>Encoder</code>模块的输出计算一遍注意力机制得分之后，再进入前馈神经网络模块。</p>
<h2 id="Transformer中Encoder和Decoder的区别"><a href="#Transformer中Encoder和Decoder的区别" class="headerlink" title="Transformer中Encoder和Decoder的区别"></a>Transformer中Encoder和Decoder的区别</h2><ul>
<li><p>Decoder包含两个 Multi-Head Attention 层。</p>
</li>
<li><p>Decoder第一个 Multi-Head Attention 层采用了 Masked 操作，也就是一句话中左边的word看不到右边的word信息，这是因为在真实翻译的场景中也是word by word依次翻译出来的，在翻译当前词的时候肯定是不知道下一个翻译词是什么，所以在模型训练的时候就mask掉右边的信息让模型去学习，称之为<strong>Sequence mask</strong>。（假设target序列有m个token，那么可以构建m*m的矩阵，以主对角线为界，上三角的元素设置为-INF，这样在后续的softmax中其attention值趋于0，做到了mask的效果，并且mask操作是在计算出Q，K点积之后，softmax之前。）</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202308231436850.jpg" alt=""></p>
</li>
<li><p>Decoder第二个 Multi-Head Attention 层的<strong>K, V</strong>矩阵使用 Encoder 的<strong>编码信息矩阵C</strong>进行计算，而<strong>Q</strong>使用上一个 Decoder block 的输出计算。</p>
</li>
<li><p>Decoder最后有一个 Softmax 层计算下一个翻译单词的概率。</p>
</li>
</ul>
<h2 id="BERT和GPT的区别"><a href="#BERT和GPT的区别" class="headerlink" title="BERT和GPT的区别"></a>BERT和GPT的区别</h2><p>BERT和GPT是两种不同的预训练语言模型，它们在原理和应用方面存在一些显著的区别。</p>
<h3 id="目标任务"><a href="#目标任务" class="headerlink" title="目标任务"></a>目标任务</h3><p>BERT：BERT是一种基于Transformer的预训练模型，它的目标是通过双向语言模型预训练来学习上下文相关的词表示。在预训练过程中，BERT通过掩码语言模型（Masked Language Model，MLM）和下一句预测（Next Sentence Prediction，NSP）任务进行训练。</p>
<ul>
<li><p>掩码语言模型（Masked Language Model，MLM）：在输入序列中，BERT随机掩盖一些词语，然后要求模型预测这些被掩盖的词语。通过这个任务，BERT可以学习到在给定上下文的情况下，预测缺失词语的能力。这使得BERT能够理解词语的语义和上下文信息。具体来说，对于每个输入序列，BERT会随机选择一些词语进行掩码。通常，选择的词语占总词语数量的15%左右。对于被选择的词语，有以下三种方式来处理：</p>
<ul>
<li>80%的情况下，将被选择的词语替换为特殊的掩码标记 [MASK]。例如，将句子 “I love apples” 中的 “apples” 替换为 “[MASK] love [MASK]”。“this movie is great”变为“this movie is [MASK]”；</li>
<li>10%的情况下，将被选择的词语随机替换为其他词语。这样模型不仅需要理解上下文，还需要具备词语替换和词义推断的能力。例如，“this movie is great”变为“this movie is drink”；</li>
<li>10%的情况下，保持被选择的词语不变。这样做是为了让模型学习到如何处理未被掩码的词语。“this movie is great”变为“this movie is great”。</li>
<li>接下来，BERT将处理过的输入序列输入到模型中，然后使用Transformer的编码器结构进行编码。在编码过程中，模型会同时考虑到被掩码的词语和其它上下文中的信息。最终，模型会生成一组对应被掩码的词语的预测结果。</li>
</ul>
</li>
<li><p>下一句预测（Next Sentence Prediction，NSP）：在一些自然语言处理任务中，理解句子之间的关系是很重要的。为了让模型学习句子级别的关系，BERT使用了NSP任务。该任务要求模型判断两个句子是否是连续的，即一个句子是否是另一个句子的下一句。通过这个任务，BERT能够学习到句子级别的语义关系和推理能力。显式地建模文本对之间的逻辑关系。具体以下方式来处理：</p>
<ul>
<li>对于每个训练样本，BERT会随机选择两个句子A和B。其中，50%的情况下，句子B是句子A的下一句，而另外50%的情况下，句子B是从语料库中随机选择的其他句子。</li>
<li>为了进行NSP任务，BERT引入了一种特殊的输入编码方式。对于每个输入序列，BERT会将句子A和句子B之间插入一个特殊的分隔标记 [SEP]，并在输入的开始处添加一个特殊的句子标记 [CLS]。</li>
<li>接下来，BERT将这个编码后的序列输入到模型中，并使用Transformer的编码器结构对其进行编码。编码器会根据上下文信息对句子A和句子B的表示进行学习。</li>
<li>在编码过程中，模型会将整个序列作为输入，并在特殊的 [CLS] 标记上进行预测。这个预测任务可以是一个分类任务，用于判断句子A和句子B是否是连续的。通常，模型会使用一个全连接层将 [CLS] 的隐藏状态映射到一个二分类问题上，例如使用sigmoid激活函数来预测两个句子的连续性。</li>
</ul>
</li>
</ul>
<p>GPT：GPT是一种基于Transformer的生成式预训练模型，其目标是通过自回归语言模型预训练来学习生成连贯文本的能力。GPT采用了自回归语言模型的预训练方式。在预训练过程中，GPT使用大规模的文本数据，并通过自回归的方式逐步生成下一个词语。模型根据已生成的上文预测下一个词语，通过最大似然估计来优化模型参数。这使得GPT能够学习到生成连贯、有逻辑性的文本的能力。GPT实现过程大致如下：</p>
<ul>
<li>GPT将文本数据分割成词语或子词的过程通常是通过分词（tokenization）来实现的。在分词过程中，常用的方法有两种：<ul>
<li>基于词语的分词（Word-based Tokenization）：这种方法将文本划分为独立的词语单元。例如，对于句子”I love natural language processing”，基于词语的分词将它划分为[“I”, “love”, “natural”, “language”, “processing”]。</li>
<li>基于子词的分词（Subword-based Tokenization）：这种方法将文本划分为更小的子词单元。它可以处理词语的内部结构和复杂性，更适用于处理未登录词（out-of-vocabulary）和稀有词（rare words）。例如，对于句子”I love natural language processing”，基于子词的分词可以将它划分为[“I”, “love”, “nat”, “ural”, “language”, “pro”, “cess”, “ing”]。</li>
</ul>
</li>
<li>Embedding词嵌入：将token编码为向量。即每个词语或子词都会被转换为对应的嵌入向量表示嵌入向量是一种连续的实数向量，用于表示词语或子词在语义空间中的位置。常见的方法是使用预训练的词向量模型，如Word2Vec、GloVe或FastText，将词语或子词映射到固定维度的实数向量。</li>
<li>Transformer架构：GPT采用了Transformer作为其基础架构。Transformer是一种强大的深度学习模型，其核心机制是自注意力机制。它能够在处理序列数据时捕捉全局依赖关系，同时具有并行计算的能力。</li>
<li>自回归语言模型：在预训练过程中，GPT使用自回归语言模型进行训练。具体而言，模型逐步生成下一个词语，以此生成连贯的文本。在生成第i个词语时，模型使用已生成的前i-1个词语作为上文来预测下一个词语。</li>
<li>学习预训练参数：在自回归语言模型中，GPT的目标是最大化生成真实训练样本的概率。通过最大似然估计，模型的参数被优化以最大化真实训练样本的生成概率。通过大规模的预训练数据和迭代的优化过程，GPT能够学习到语言的统计规律和结构，从而能够生成连贯、有逻辑性的文本。</li>
<li>生成文本：在预训练完成后，GPT可以生成文本。给定一个初始文本或种子句子，模型会逐步生成下一个词语，将其添加到已生成的文本中，然后再用生成的文本作为上文来预测下一个词语。通过重复这个过程，模型可以生成连贯、有逻辑性的文本。</li>
</ul>
<h3 id="训练方式"><a href="#训练方式" class="headerlink" title="训练方式"></a>训练方式</h3><p>BERT：BERT使用了双向语言模型的训练策略。在输入序列中，BERT随机掩盖一些词语，并让模型预测这些被掩盖的词语。这种方式使BERT能够从上下文中学习词语的语义和语境信息。<br>GPT：GPT使用了自回归语言模型的训练方式。它通过让模型预测当前位置的词语来学习生成文本的能力。在预训练过程中，GPT逐步生成下一个词语，并优化参数以最大化下一个词语的概率。</p>
<h2 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h2><p>解码器输出本来是一个浮点型的向量，怎么转化成这两个词呢？解决办法是在最后的线性层接上一个<code>softmax</code>，其中线性层是一个简单的全连接神经网络，它将解码器产生的向量投影到一个更高维度的向量<code>(logits)</code>上，假设我们模型的词汇表是 $10000$ 个词，那么<code>logits</code>就有 $10000$ 个维度，每个维度对应一个唯一的词的得分。之后的<code>softmax</code>层将这些分数转换为概率。选择概率最大的维度，并对应地生成与之关联的单词作为此时间步的输出就是最终的输出。</p>
<h2 id="位置编码-Positional-Encoding"><a href="#位置编码-Positional-Encoding" class="headerlink" title="位置编码(Positional Encoding)"></a>位置编码(Positional Encoding)</h2><p><code>Transformer</code>中没有考虑顺序信息，那怎么办呢，我们可以在输入中做手脚，把输入变得有位置信息。我们可以给每个词向量加上一个有顺序特征的向量，发现<code>sin</code>函数和<code>cos</code>函数能够很好的表达这种特征，所以通常位置向量用以下公式来表示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303310947858.png" alt=""></p>
<p>也即第 $t$ 个位置的位置编码为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303310948367.png" alt=""></p>
<p>对编码的可视化：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303310952548.png" alt=""></p>
<h3 id="Vanilla-Transformer的位置编码的特点"><a href="#Vanilla-Transformer的位置编码的特点" class="headerlink" title="Vanilla Transformer的位置编码的特点"></a>Vanilla Transformer的位置编码的特点</h3><ol>
<li>只要位置小于 $10000$ ，每一个位置的编码都是不同的。</li>
<li>奇数维度之间或者偶数维度之间周期不同。</li>
<li>也可以很好的表示相对位置信息。给定k,存在一个固定的与 $k$ 相关的线性变换矩阵，从而由 <code>pos</code> 的位置编码线性变换而得到 <code>pos+k</code> 的位置编码。这个相对位置信息可能可以被模型发现而利用。因为绝对位置信息只保证了各个位置不一样，但是并不是像 $0,1,2$ 这样的有明确前后关系的编码。</li>
</ol>
<p>我们拿出位置编码的两个维度出来做个例子，其他维度也是一样的，可以拼接起来变成完整的位置编码：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303311001584.png" alt=""></p>
<p>其中 $M$ 为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303311002558.png" alt=""></p>
<p>上面的操作也只可以看到线性关系，怎么可以更直白地知道每个<code>token</code>的距离关系？我们将两个位置编码对应相乘，可以发现发现相乘后的结果为一个余弦的加和。这里影响值的因素就是 $k$ 。如果两个<code>token</code>的距离越大，也就是 $k$ 越大，根据余弦函数的性质可以知道，两个位置编码相乘结果越小。这样的关系可以得到，如果两个<code>token</code>距离越远则乘积的结果越小。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303311016054.png" alt=""></p>
<h3 id="其他编码方式"><a href="#其他编码方式" class="headerlink" title="其他编码方式"></a>其他编码方式</h3><p><strong>用[0,1]范围标记位置</strong></p>
<p>产生的问题是，当序列长度不同时，<code>token</code>间的相对距离是不一样的。例如在序列长度为 $3$ 时，<code>token</code>间的相对距离为 $0.5$ ；在序列长度为 $4$ 时，<code>token</code>间的相对距离就变为 $0.33$ 。</p>
<p><strong>用整型值标记位置</strong></p>
<p>存在的问题是：模型可能遇见比训练时所用的序列更长的序列，不利于模型的泛化；模型的位置表示是无界的，随着序列长度的增加，位置值会越来越大。</p>
<p><strong>用二进制向量标记位置</strong></p>
<p>这种编码方式也存在问题是编码出来的位置向量，处在一个离散的空间中，不同位置间的变化是不连续的。</p>
<h3 id="Vanilla-Transformer位置编码的缺点以及改进"><a href="#Vanilla-Transformer位置编码的缺点以及改进" class="headerlink" title="Vanilla Transformer位置编码的缺点以及改进"></a>Vanilla Transformer位置编码的缺点以及改进</h3><p>看一个序列中，第 $i$ 个单词和第 $j$ 个单词的<code>attention score</code>的计算：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303311035374.png" alt=""></p>
<p>其中 $W_{q}$ ， $W_{k}$ 分别是<code>Multi-Head Attention</code>给每个头加的<code>Query</code>和<code>Key</code>参数， $E_{x_{i}}$ 和 $E_{x_{j}}$ 是 $x_{i}$ 和 $x_{j}$ 的词嵌入， $U_{i}$ 和 $U_{j}$ 是第 $i$ 个位置和第 $j$ 个位置的位置向量。因式分解得到下式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303311039224.png" alt=""></p>
<p>实际上，按照<code>Vanilla Transformer</code>的位置编码方法，如果没有 $W_{q}$ 和 $W_{k}$ 那么它是包含相对位置信息的，证明见上上小节。但是中间加入一个“不可知”的线性变换以后，就没有相对位置信息了，这个可以使用实验证明，具体如下图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303311047793.png" alt=""></p>
<p><strong>Transformer中加入相对位置信息的改进方法</strong></p>
<ul>
<li><p>既然相对位置信息是在<code>self-attention</code>计算时候丢失的，那么最直接的想法就是在计算<code>self-attention</code>的时候再加回来。该工作出自<code>Transformer</code>的原班人马，具体做法是在计算<code>attention score</code>和<code>weighted value</code>时各加入一个可训练的表示相对位置的参数，并且<code>multi-head</code>之间可以共享。</p>
</li>
<li><p>改写<code>self-attention</code>的计算公式</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303311102674.png" alt=""></p>
</li>
<li><p>前面两个方法都是基于”词向量+位置向量”的模式，说白了是在“亡羊补牢”，而没有一开始就修建一个牢固的羊圈。而一种新的角度是推导出一个<strong>复数域</strong>的词向量方法，理论十分优美。</p>
</li>
</ul>
<h2 id="训练推理过程"><a href="#训练推理过程" class="headerlink" title="训练推理过程"></a>训练推理过程</h2><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>在训练模式下，模型通常采用真正的目标序列（即真实的标签）作为解码器输入，以便学习目标的条件分布。这种方法称为“教师强制”（Teacher Forcing）。教师强制的好处是，它加速了训练收敛，并避免了错误传播。</p>
<p>具体步骤如下：</p>
<ul>
<li>解码器输入： 解码器在每个时间步使用目标序列的前一个token作为当前时间步的输入。</li>
<li>掩码机制： 使用遮罩机制（masking）来确保每个时间步只能看到之前的token，而不能看到未来的token。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502141514259.png" alt=""></p>
<h3 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h3><p>在推理模式下，即在实际生成文本时，解码器不再能使用真实的目标序列。相反，它必须基于已生成的token来逐步生成下一个token。解码器在每一步生成下一个token，然后将生成的token反馈到解码器的下一个时间步。这一过程通常称为自回归生成。</p>
<p>具体步骤如下：</p>
<ul>
<li>初始输入： 解码器首先输入一个起始token（例如“sos”）。</li>
<li>逐步生成： 在每个时间步生成一个token，并将这个token作为输入反馈到解码器的下一个时间步，一直到生成结束标志（例如“eos”）或达到最大长度。</li>
</ul>
<h1 id="Vision-Transformer"><a href="#Vision-Transformer" class="headerlink" title="Vision Transformer"></a>Vision Transformer</h1><h2 id="模型组成"><a href="#模型组成" class="headerlink" title="模型组成"></a>模型组成</h2><p>模型由三个模块组成：</p>
<ul>
<li><code>Linear Projection of Flattened Patches</code>（<code>Embedding</code>层）</li>
<li><code>Transformer Encoder</code></li>
<li><code>MLP Head</code>（最终用于分类的层结构）</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101646509.png" alt=""></p>
<h2 id="Embedding层结构详解"><a href="#Embedding层结构详解" class="headerlink" title="Embedding层结构详解"></a>Embedding层结构详解</h2><p>对于标准的<code>Transformer</code>模块，要求输入的是<code>token</code>（向量）序列，即二维矩阵<code>[num_token, token_dim]</code>，<code>0-9</code>对应的<code>token</code>都是向量，以<code>ViT-B/16</code>为例，每个<code>token</code>向量长度为 $768$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101836412.png" alt=""></p>
<p>对于图像数据而言，其数据格式为<code>[H, W, C]</code>是三维矩阵明显不是<code>Transformer</code>想要的。所以需要先通过一个<code>Embedding</code>层来对数据做个变换。如上图所示，首先将一张图片按给定大小分成一堆<code>Patches</code>。以<code>ViT-B/16</code>为例，将输入图片<code>(224x224)</code>按照<code>16x16</code>大小的<code>Patch</code>进行划分，划分后会得到 $( 224 / 16 )^{2} = 196$ 个<code>Patches</code>。接着通过线性映射将每个<code>Patch</code>映射到一维向量中，以<code>ViT-B/16</code>为例，每个<code>Patch</code>数据<code>shape</code>为 $[16, 16, 3]$ 通过映射得到一个长度为 $768$ 的向量（后面都直接称为<code>token</code>）。</p>
<p><strong>在输入Transformer Encoder之前注意需要加上[class]token以及Position Embedding。</strong> 在原论文中，作者说参考<code>BERT</code>，在刚刚得到的一堆<code>tokens</code>中插入一个专门用于分类的<code>[class]token</code>，这个<code>[class]token</code>是一个可训练的参数，数据格式和其他<code>token</code>一样都是一个向量，以<code>ViT-B/16</code>为例，就是一个长度为<code>768</code>的向量，与之前从图片中生成的<code>tokens</code>拼接在一起， $([1, 768], [196, 768]) \rightarrow [197, 768]$ 。然后关于<code>Position Embedding</code>就是之前<code>Transformer</code>中讲到的<code>Positional Encoding</code>，这里的<code>Position Embedding</code>采用的是一个可训练的参数，是直接叠加在<code>tokens</code>上的<code>(add)</code>，所以<code>shape</code>要一样。以<code>ViT-B/16</code>为例，刚刚拼接<code>[class]token</code>后<code>shape</code>是 $[197, 768]$ ，那么这里的<code>Position Embedding</code>的<code>shape</code>也是 $[197, 768]$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101836048.png" alt=""></p>
<h2 id="Transformer-Encoder详解"><a href="#Transformer-Encoder详解" class="headerlink" title="Transformer Encoder详解"></a>Transformer Encoder详解</h2><p><code>Transformer Encoder</code>其实就是重复堆叠<code>Encoder Block</code> $L$ 次，主要由以下几部分组成：</p>
<ul>
<li><code>Layer Norm</code>，这种<code>Normalization</code>方法主要是针对<code>NLP</code>领域提出的，这里是对每个<code>token</code>进行<code>Norm</code>处理。</li>
<li><code>Multi-Head Attention</code>，也就是<code>Transformer</code>中的多头注意力。</li>
<li><code>Dropout/DropPath</code>，在原论文的代码中是直接使用的<code>Dropout</code>层，但<code>rwightman</code>实现的代码中使用的是<code>DropPath(stochastic depth)</code>，可能后者会更好一点。</li>
<li><code>MLP Block</code>，就是全连接+<code>GELU</code>激活函数+<code>Dropout</code>组成也非常简单，需要注意的是第一个全连接层会把输入节点个数翻 $4$ 倍 $[197, 768] \rightarrow [197, 3072]$ ，第二个全连接层会还原回原节点个数 $[197, 3072] \rightarrow [197, 768]$ 。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101738369.png" alt=""></p>
<h2 id="MLP-Head详解"><a href="#MLP-Head详解" class="headerlink" title="MLP Head详解"></a>MLP Head详解</h2><p>上面通过<code>Transformer Encoder</code>后输出的<code>shape</code>和输入的<code>shape</code>是保持不变的，以<code>ViT-B/16</code>为例，输入的是 $[197, 768]$ 输出的还是 $[197, 768]$。注意，在<code>Transformer Encoder</code>后其实还有一个<code>Layer Norm</code>没有画出来。这里我们只是需要分类的信息，所以我们只需要提取出<code>[class]token</code>生成的对应结果就行，即 $[197, 768]$ 中抽取出 $[class]token$ 对应的 $[1, 768]$ 。接着我们通过<code>MLP Head</code>得到我们最终的分类结果。<code>MLP Head</code>原论文中说在训练<code>ImageNet21K</code>时是由<code>Linear</code>+<code>tanh</code>激活函数+<code>Linear</code>组成。但是迁移到<code>ImageNet1K</code>上或者自己的数据上时，只用一个<code>Linear</code>即可。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304101841213.png" alt=""></p>
<h1 id="Swin-Transformer"><a href="#Swin-Transformer" class="headerlink" title="Swin Transformer"></a>Swin Transformer</h1><h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p>每个窗口固定有 $7\ast7$ 个patch，所以会有 $8\ast8$个window。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202307131454285.png" alt=""></p>
<h2 id="Patch-merging"><a href="#Patch-merging" class="headerlink" title="Patch merging"></a>Patch merging</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202307131152042.png" alt=""></p>
<h2 id="W-MSA"><a href="#W-MSA" class="headerlink" title="W-MSA"></a>W-MSA</h2><p>MSA全称为Windows Multi-head Self-Attention也就是窗口化的Self-Attention机制，此处以在一个 $4\ast4$ 的特征图上做为例子，在Vision Transformer中的MSA模块， $4\ast4$ 中的每个像素都要去和其他像素进行关联度的计算，那么在W-MSA中，其将原 $4\ast4$ 的特征图首先分割成了 $4$ 个 $2\ast2$ 的Window窗口，然后再在每个窗口内部进行单独的Self-Attention的计算。也就是说，每个像素只需要和自己所属Window内部的像素进行关联度的计算即可。这样一来，确实大大减少了计算量，但是你会发现窗口之间的像素也无法进行通信了，导致我们的感受野变小，对于最终的结果产生影响。优劣势还是非常的明确的。</p>
<h2 id="SW-MSA"><a href="#SW-MSA" class="headerlink" title="SW-MSA"></a>SW-MSA</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202307131153000.png" alt=""></p>
<h1 id="Mamba"><a href="#Mamba" class="headerlink" title="Mamba"></a>Mamba</h1><p>Mamba的提出起源于RNN和Transformer本身存在的问题。</p>
<p>RNN的训练过程中当前时间步依赖于前一时间步的计算，因此不能并行计算，效率非常低，而结构并不复杂，所以推理速度还可以（线性计算）；Transformer训练过程是矩阵运算，其训练是可以并行计算的，效率比较高，但是推理过程是一个词一个词去进行矩阵运算（即已经生成了一些token，当生成下一个token时，仍然需要重新计算整个序列的注意力），效率比较低。</p>
<p>那么，能不能提出一个训练和推理过程效率都很高的模型呢？这就有了Mamba。Mamba是SSM（Structured State Space for Sequence Modeling，序列的结构化状态空间，因为有4个S，所以也称为S4）的改进，所以首先要介绍一下到底什么是SSM？</p>
<h2 id="状态空间模型（SSM）"><a href="#状态空间模型（SSM）" class="headerlink" title="状态空间模型（SSM）"></a>状态空间模型（SSM）</h2><p>状态空间模型（State Space Model, SSM）是一种用于描述动态系统的数学模型，特别适用于时间序列分析和控制系统设计。它将系统的状态表示为一个状态向量，并通过状态方程和观测方程描述系统的动态行为和观测过程。因此，SSM是可以用于描述这些状态表示并根据某些输入预测其下一个状态可能是什么的模型，这就符合了作为深度学习模型基础架构的条件。</p>
<p>用一个更简单的例子来理解这个概念。想象我们正在走过一个迷宫。这里的“状态空间”就像是迷宫中所有可能位置的集合，即一张地图。地图上的每个点都代表迷宫中的一个特定位置，并包含了该位置的详细信息，比如离出口有多远。而“状态空间表示”则是对这张地图的抽象描述。它告诉我们当前所处的位置（当前状态）、我们可以移动到哪些位置（未来可能的状态），以及如何从当前位置转移到下一个状态（比如向左转或向右转）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181357256.png" alt=""></p>
<p>状态空间模型（SSM）是用来描述这些状态表示，并根据给定的输入预测下一个可能状态的模型。</p>
<p>在传统意义上，SSM在时间 $t$ 的工作方式如下：</p>
<ul>
<li>将输入序列 $x(t)$ （例如，迷宫中的左移和下移，可以理解为之前时刻的移动轨迹）</li>
<li>映射到潜在的状态表示 $h(t)$ （例如，距离出口的远近以及X/Y坐标）</li>
<li>然后从这个状态表示中推导出预测的输出序列 $y(t)$ （例如，为了更快到达出口而再次左移，即下一个时刻的动作）</li>
</ul>
<p>不过，与传统模型不同的是，SSM不仅处理离散的序列（比如一次向左移动），它还能够处理连续的序列作为输入，并预测输出序列。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181349276.png" alt=""></p>
<p>状态空间模型（SSM）假定动态系统（比如在三维空间中移动的物体）的状态可以通过两个数学方程来预测，这两个方程描述了系统在时间 $t$  时的状态如何随时间演变。【注：这里就是导数，是SSM一阶微分方程中的导数，这里还是连续型，不是离散型，毕竟只有在离散系统中才是 $t$ 和 $t-1$ 】</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181423338.png" alt=""></p>
<p>通过解这两个方程，我们假设能够发掘出统计规律，从而根据观察到的数据（包括输入序列和先前的状态）来预测系统的状态。其目标是确定状态表示 $h(t)$ ，以便我们能够从输入序列映射到输出序列。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181424017.png" alt=""></p>
<p>这两个方程构成了状态空间模型的核心。为了帮助更快地理解和引用它们，使用颜色编码来突出显示。状态方程展示了输入如何影响状态（通过矩阵B），以及状态如何随时间变化（通过矩阵A）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181427875.png" alt=""></p>
<p>正如我们之前看到的， $h(t)$ 指的是任何给定时间t的潜在状态表示，而 $x(t)$ 指的是某个输入。输出方程描述了状态如何转换为输出（通过矩阵C） 以及输入如何影响输出（通过矩阵D）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181429134.png" alt=""></p>
<p>可视化这两个方程为我们提供了以下架构：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181449184.png" alt=""></p>
<ol>
<li><p>设想我们有一个输入信号 $x(t)$ ，这个信号首先与矩阵B相乘，而矩阵B刻画了输入对系统的影响程度。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181450522.png" alt=""></p>
</li>
<li><p>我们将这个状态与矩阵A相乘，矩阵A揭示了所有内部状态是如何相互连接的，因为它们代表了系统的基本动态。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181451498.png" alt=""></p>
</li>
<li><p>接着，我们利用矩阵C来定义状态如何转换为输出。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181451529.png" alt=""></p>
</li>
<li><p>最后，我们可以利用矩阵D提供从输入到输出的直接信号。这通常也称为跳跃连接，类似于残差连接。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181453482.png" alt=""></p>
</li>
</ol>
<h3 id="从连续信号到离散信号"><a href="#从连续信号到离散信号" class="headerlink" title="从连续信号到离散信号"></a>从连续信号到离散信号</h3><p>对于连续信号，直接找到状态表示 $h(t)$ 在分析上可能颇具挑战。此外，由于我们通常处理的都是离散输入（比如文本序列），我们希望将模型转换为离散形式。</p>
<p>为了实现这一点，我们采用了零阶保持（Zero-Order Hold, ZOH）技术。其工作原理如下：每当接收到一个离散信号时，我们就保持该信号值不变，直到下一个离散信号的到来。这个过程实际上创建了一个SSM可以处理的连续信号。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181456781.png" alt=""></p>
<p>我们保持信号值的时间由一个新的可学习参数表示，这个参数称为步长 $\Delta$。它代表了输入信号的分辨率。现在，由于我们有了连续的输入信号，我们能够生成连续的输出信号，并且只需根据输入信号的时间步长来对输出值进行采样。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181501751.png" alt=""></p>
<p>这些采样值构成了我们的离散输出，且可以针对A、B按如下方式做零阶保持(做了零阶保持的在对应变量上面加了个横杠)。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181518353.png" alt=""></p>
<p>最终使我们能够从连续 SSM 转变为离散SSM，使得不再是函数到函数 $x(t) \rightarrow y(t)$，而是序列到序列 $x_{k} \rightarrow y_{k}$。所以矩阵 $\overline{\mathbf{A}}$ 和 $\overline{\mathbf{B}}$ 现在表示模型的离散参数，且这里使用 $k$，而不是 $t$ 来表示离散的时间步长。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181521304.png" alt=""></p>
<h3 id="循环结构表示"><a href="#循环结构表示" class="headerlink" title="循环结构表示"></a>循环结构表示</h3><p>在每个时间步，都会涉及到隐藏状态的更新(比如 $h_k$ 取决于 $\overline{\mathbf{B}} \mathbf{x}_{\mathrm{k}}$和 $\overline{\mathbf{A}} \mathbf{h}_{\mathrm{k}-1}$ 的共同作用结果，然后通过 $Ch_k$ 预测输出$y_k$)</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181528191.png" alt=""></p>
<p>例如，$y_{2}$的展开式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181544353.png" alt=""></p>
<p>如此，便可以RNN的结构来处理：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181536720.png" alt=""></p>
<p>然后可以这样展开(可以看到，$h_k$始终是 $\overline{\mathbf{B}} \mathbf{x}_{\mathrm{k}}$ 和 $\overline{\mathbf{A}} \mathbf{h}_{\mathrm{k}-1}$ 的共同作用之下更新的)</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181539007.png" alt=""></p>
<h3 id="卷积结构表示"><a href="#卷积结构表示" class="headerlink" title="卷积结构表示"></a>卷积结构表示</h3><p>在经典的图像识别任务中，我们用过滤器(即卷积核kernels)来导出聚合特征，而SSM也可以表示成卷积的形式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181540805.png" alt=""></p>
<p>由于我们处理的是文本而不是图像，因此我们需要一维视角</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181540864.png" alt=""></p>
<p>而用来表示这个“过滤器”的内核源自 SSM 公式</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181543339.png" alt=""></p>
<p>这个公式的解释可以按照如下例子理解：</p>
<ol>
<li><p>与卷积一样，我们可以使用 SSM 内核来检查每组token并计算输出</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181548500.png" alt=""></p>
</li>
<li><p>内核将移动一次以执行下一步的计算</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181549958.png" alt=""></p>
</li>
<li><p>最后一步，我们可以看到内核的完整效果</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181549712.png" alt=""></p>
</li>
</ol>
<p>以此内推，可得 $y_{3}=\mathbf{C} \overline{\mathbf{A}} \overline{\mathbf{A}} \overline{\mathbf{A}} \overline{\mathbf{B}} x_{0}+\mathbf{C} \overline{\mathbf{A}} \overline{\mathbf{A}} \overline{\mathbf{B}} x_{1}+\mathbf{C} \overline{\mathbf{A}} \overline{\mathbf{B}} x_{2}+\mathbf{C} \overline{\mathbf{B}} x_{3}$ ；推而广之，可得 $y_{k}=C \bar{A}^{k} \bar{B} x_{0}+C \bar{A}^{k-1} \bar{B} x_{1}+\cdots+C \bar{A} \bar{B} x_{k-1}+C \bar{B} x_{k}$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181549143.png" alt=""></p>
<p>此外，换个形式看，意味着 $y_3$ 实际上可以计算为点积，其中右侧向量是我们的输入 $x$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181551186.png" alt=""></p>
<p>由于其中三个离散参数A、B、C都是常数，因此我们可以预先计算左侧向量并将其保存为卷积核，这为我们提供了一种使用卷积超高速计算y的简单方法，如以下两个方程所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181552224.png" alt=""></p>
<p>至此，总结一下，将 SSM 表示为卷积的一个主要好处是它可以像卷积神经网络CNN一样进行并行训练。然而，由于内核大小固定，它们的推理不如 RNN 那样快速：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181552985.png" alt=""></p>
<p>那有没两全其美的办法呢？最终是有的：</p>
<ol>
<li><p>作为从输入信号到输出信号的参数化映射，SSMs可以当做是RNN与CNN的结合「These models can be interpreted as acombination of recurrent neural networks (RNNs) and convolutional neural networks (CNNs)」，即推理用RNN结构，训练用CNN结构</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181554613.png" alt=""></p>
</li>
<li><p>总之，这类模型可以非常高效地计算为递归或卷积，在序列长度上具有线性或近线性缩放(This class of models can be computed very efficiently as either arecurrence or convolution, with linear or near-linear scaling in sequence length)</p>
</li>
</ol>
<h3 id="长距离依赖问题的解决之道"><a href="#长距离依赖问题的解决之道" class="headerlink" title="长距离依赖问题的解决之道"></a>长距离依赖问题的解决之道</h3><p>如我们之前在循环表示中看到的那样，矩阵A捕获先前previous状态的信息来构建新状态($h_k = \overline{A} h_{k-1} + \overline{B} x_k$，当$k = 5$时，则有$h_5 = \overline{A} h_{4} + \overline{B} x_5$)</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181556310.png" alt=""></p>
<p>其实，某种意义上，算是矩阵 $A$ 产生了隐藏状态(matrix A produces the hidden state)</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181557447.png" alt=""></p>
<p>由于矩阵 $A$ 只记住之前的几个token和捕获迄今为止看到的每个token之间的区别，特别是在循环表示的上下文中，因为它只回顾以前的状态。那么我们怎样才能以保留比较长的memory的方式创建矩阵A呢？</p>
<ol>
<li>答案是可以使用HiPPO「HiPPO的全称是High-order Polynomial Projection Operator，HiPPO 矩阵通常用于将连续时间信号投影到正交多项式基下，以代表过去的状态/信息，解决如何在有限的存储空间中有效地解决序列建模的长距离依赖问题</li>
<li>HiPPO尝试将当前看到的所有输入信号压缩为一个系数向量(HiPPO attempts to compress all input signals it has seen thus far into a vector of coefficients)</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181600853.png" alt=""></p>
<p>它使用矩阵构建一个“可以很好地捕获最近的token并衰减旧的token”状态表示(to build a state representation that captures recent tokens well and decays older tokens)，说白了， 通过函数逼近产生状态矩阵 $A$ 的最优解，其公式可以表示如下(此处没有负号，可以理解为HiPPO的变体，毕竟HiPPO的某些变体可能会忽略负号或调整矩阵元素以适应特定应用需求或简化计算)</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181605122.png" alt=""></p>
<h3 id="S4：综合SSM-离散化-可循环表示或卷积表示-HiPPO"><a href="#S4：综合SSM-离散化-可循环表示或卷积表示-HiPPO" class="headerlink" title="S4：综合SSM + 离散化(可循环表示或卷积表示) + HiPPO"></a>S4：综合SSM + 离散化(可循环表示或卷积表示) + HiPPO</h3><p>如此，综合以上所述，S4的定义就出来了：序列的结构化状态空间——Structured State Space for Sequences，一类可以有效处理长序列的 SSM</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181606141.png" alt=""></p>
<h3 id="S4D：将参数矩阵标准化为对角结构-相当于S4的对角版本"><a href="#S4D：将参数矩阵标准化为对角结构-相当于S4的对角版本" class="headerlink" title="S4D：将参数矩阵标准化为对角结构(相当于S4的对角版本)"></a>S4D：将参数矩阵标准化为对角结构(相当于S4的对角版本)</h3><p>如下图所示，S4D本质上就是一种对角线SSM，继承了S4的优点，但同时更加简单</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181607692.png" alt=""></p>
<p>如上图左侧所示，当基于HiPPO的A矩阵变换为对角线结构之后，便使得其可以被视为一组一维SSM；如上图右侧所示，作为卷积模型，S4D具有简单且可解释的卷积核，可以用两行代码实现。其中颜色表示独立的一维SSM；紫色表示可训练参数。</p>
<h2 id="试图解决的问题"><a href="#试图解决的问题" class="headerlink" title="试图解决的问题"></a>试图解决的问题</h2><p>Mamba的两个主要创新：</p>
<ul>
<li>选择性扫描算法(selective scan algorithm)：这个算法允许模型筛选（ignore/reject）与任务不相关的信息。</li>
<li>一种硬件感知算法(hardware-aware algorithm)：这种算法通过并行扫描、内核融合和有效存储（中间）结果的重新计算，提高了计算效率。</li>
</ul>
<h3 id="选择性复制任务"><a href="#选择性复制任务" class="headerlink" title="选择性复制任务"></a>选择性复制任务</h3><p>在选择性复制任务中，SSM的目标是复制输入的一部分并按顺序输出：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181628902.png" alt=""></p>
<p>然而，(循环/卷积)SSM在执行此任务时表现不佳，因为它是线性时不变(Linear Time Invariance)的。正如我们之前所观察到的，对于SSM生成的每个token，矩阵A、B和C都是固定不变的。</p>
<p>因此，SSM无法执行内容感知推理，因为它将每个token视为固定A、B和C矩阵的结果。这是一个问题，因为我们希望SSM能够对输入（提示）进行推理。</p>
<h3 id="归纳任务"><a href="#归纳任务" class="headerlink" title="归纳任务"></a>归纳任务</h3><p>SSM在另一个任务上表现不佳，那就是归纳头，其目标是重现输入中发现的模式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181629607.png" alt=""></p>
<p>在上面的示例中，我们实际上是在执行一个一次性提示，试图“教会”模型在“Q：”之后提供“A：”响应。然而，由于SSM是时间不变的，它无法从其历史记录中选择要调用的先前token。</p>
<h2 id="有选择地保留信息-Selectively-Retain-Information"><a href="#有选择地保留信息-Selectively-Retain-Information" class="headerlink" title="有选择地保留信息(Selectively Retain Information)"></a>有选择地保留信息(Selectively Retain Information)</h2><p>SSM的循环表示创建了一个非常高效的小状态，因为它压缩了整个历史记录。然而，与不压缩历史记录（通过注意力矩阵）的Transformer模型相比，它的功能要弱得多。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181630832.png" alt=""></p>
<p>正如上文所述，Mamba通过有选择地将数据压缩到状态中来实现这一目标。当输入一个句子时，通常会包含一些没有多大意义的信息，例如停用词。为了有选择地压缩信息，我们需要参数依赖于输入。为此，我们首先探讨训练期间SSM中输入和输出的维度。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181631836.png" alt=""></p>
<p>在结构化状态空间模型 (S4) 中，矩阵A、B和C独立于输入，因为它们的维度N和D是静态的并且不会改变。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181631970.png" alt=""></p>
<p>相反，Mamba通过合并输入的序列长度和批量大小，使得矩阵B和C以及步长 $\Delta$ 都取决于输入。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181632140.png" alt=""></p>
<p>这意味着对于每个输入标记，我们现在有不同的B和C矩阵，可以解决内容感知问题！</p>
<p>注意：矩阵A保持不变，因为我们希望状态本身保持静态，但它受到影响的方式（通过B和C）是动态的。</p>
<p>他们一起有选择地决定哪些内容应该保留在隐藏状态，以及哪些内容应该被忽略，因为它们现在依赖于输入。</p>
<ul>
<li>较小的步长 $\Delta$ 会导致忽略特定单词，而更多地利用先前的上下文。</li>
<li>较大的步长 $\Delta$ 则会更多地关注输入单词而不是上下文。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181633110.png" alt=""></p>
<h2 id="扫描操作-The-Scan-Operation"><a href="#扫描操作-The-Scan-Operation" class="headerlink" title="扫描操作(The Scan Operation)"></a>扫描操作(The Scan Operation)</h2><p>由于这些矩阵现在是动态的，无法使用卷积表示来计算它们，因为卷积假设固定内核。我们只能使用循环表示，这导致失去了卷积提供的并行性。为了实现并行化，让我们探讨如何使用循环计算输出。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181635567.png" alt=""></p>
<p>每个状态都是前一个状态（乘以 $\bar{A}$ ）加上当前输入（乘以 $\bar{B}$ ）的总和，这称为扫描操作，可以使用 for 循环轻松计算。然而，并行化似乎是不可能的，因为只有在我们拥有前一个状态的情况下才能计算每个状态。然而，Mamba 通过并行扫描算法使这成为可能！它假设我们执行操作的顺序与关联属性无关。因此，我们可以分段计算序列并迭代地组合它们，即动态矩阵B和C以及并行扫描算法一起创建选择性扫描算法来表示使用循环表示的动态和快速本质。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181645944.png" alt=""></p>
<p>这里时间复杂度中的 $t$ 通常代表 用于执行任务的处理器或计算单元的数量。所以才有，如果一个任务在单核上运行需要 $O(n)$ 时间，则在 $t$ 核上并行运行时，理想情况下可以将时间复杂度降低到 $O(n/t)$ 。</p>
<h2 id="硬件感知算法-Hardware-aware-Algorithm"><a href="#硬件感知算法-Hardware-aware-Algorithm" class="headerlink" title="硬件感知算法(Hardware-aware Algorithm)"></a>硬件感知算法(Hardware-aware Algorithm)</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181654742.png" alt=""></p>
<p>最新 GPU 的一个缺点是其小型但高效的 SRAM 与大型但效率稍低的 DRAM 之间的传输 (IO) 速度有限。在 SRAM 和 DRAM 之间频繁复制信息成为瓶颈。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181703182.png" alt=""></p>
<p>Mamba 与 Flash Attention 一样，试图限制我们需要从 DRAM 到 SRAM 的次数，反之亦然。它通过内核融合来实现，这允许模型防止写入中间结果并连续执行计算直到完成。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181703941.png" alt=""></p>
<p>我们可以通过可视化 Mamba 的基础架构来查看 DRAM 和 SRAM 分配的具体实例：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181704826.png" alt=""></p>
<h2 id="The-Mamba-Block"><a href="#The-Mamba-Block" class="headerlink" title="The Mamba Block"></a>The Mamba Block</h2><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181705539.png" alt=""></p>
<p>与解码器一样，我们可以堆叠多个 Mamba 块并将它们的输出用作下一个 Mamba 块的输入：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202502181705522.png" alt=""></p>
<p>它从线性投影开始，以扩展输入嵌入。然后，在选择性SSM之前应用卷积以防止独立的token计算。</p>
<p>选择性SSM具有以下属性：</p>
<ul>
<li>通过离散化创建循环 SSM</li>
<li>HiPPO对矩阵A进行初始化以捕获长距离依赖性</li>
<li>选择性扫描算法选择性压缩信息</li>
<li>加速计算的硬件感知算法</li>
</ul>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>面试</tag>
      </tags>
  </entry>
</search>
