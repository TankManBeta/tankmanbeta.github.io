<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//unpkg.com/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//unpkg.com/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","version":"8.2.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="前言记录一些推荐系统相关的知识。">
<meta property="og:type" content="article">
<meta property="og:title" content="推荐系统">
<meta property="og:url" content="http://example.com/2023/08/23/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/index.html">
<meta property="og:site_name" content="木霈玖的博客">
<meta property="og:description" content="前言记录一些推荐系统相关的知识。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192001842.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192101633.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192102103.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192115000.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202215784.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202218223.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192140478.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210945142.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210948508.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202254827.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210936324.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210950233.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210958573.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202054636.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202055336.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202037061.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202037832.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202048519.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202104133.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202135669.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192157333.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192205012.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192210225.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192217890.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231131422.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231137649.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231146383.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231152053.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231153530.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231154583.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231206104.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231212913.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231213243.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231220341.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231221419.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231225576.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202004566.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202035154.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202054590.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202054939.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202058666.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202059177.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202100516.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202104262.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202111969.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202113543.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202113829.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202119928.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202146491.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202158449.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202201783.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211446441.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211448528.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211452527.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211453721.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211454010.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211454382.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211518409.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211523344.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211528560.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211603934.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211605627.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211606515.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211606561.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211612604.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211612034.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211613957.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211616699.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211617066.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211617038.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211617296.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211618509.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211618888.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211633299.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211638065.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211639379.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211640294.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211640558.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211642022.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211645673.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211646357.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211646534.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211711238.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211716358.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211728762.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211730740.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211731896.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211735181.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212023626.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212029715.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212030357.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212035441.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212035613.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212037262.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212044848.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212048618.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212049445.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212049720.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212050370.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212050471.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212051995.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212051641.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212051116.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212052434.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212052546.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212053113.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212053253.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212054677.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212054847.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212054640.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212059483.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212101984.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212101121.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212101061.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212103361.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212104750.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212104358.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212104590.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212105264.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212105990.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212105910.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212106394.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212106342.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211740339.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211741089.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211743079.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211744832.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211745271.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221652189.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221654279.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221655094.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221737318.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304191959346.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192002037.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192107149.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192121730.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192201890.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192209525.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192210293.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201650996.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201703206.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201704698.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201707323.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221912175.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221914930.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221916770.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221917878.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221919755.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221925847.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221951440.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221951074.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221952139.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221952937.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221952743.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221953919.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221953829.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221954360.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221954996.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222002416.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222003410.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222003825.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222005263.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222006335.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222009493.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222013355.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222014011.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222014360.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222018983.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222018848.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222019899.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222021880.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222024864.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222023574.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222025480.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222025399.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222028818.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222029092.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222030271.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222030314.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222031199.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222031359.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222032295.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222035784.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222038251.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222040735.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222041255.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222042251.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222043024.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222048779.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222048554.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222049946.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222050330.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222050837.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222051074.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222051287.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222052753.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222052222.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222053977.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222057071.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222059178.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222100079.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222100694.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222103700.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222104051.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222106689.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222106134.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222107108.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222109689.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222110388.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222111207.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222115177.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222115513.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222116327.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222116575.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222116226.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222117210.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222117026.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222117989.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222118339.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222118174.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222119465.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222138309.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222138450.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222139876.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222139053.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222140078.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222140551.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222141214.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222141391.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222142236.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222143624.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222143038.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222143674.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222202895.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222204455.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222205209.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222206641.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222209233.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222209772.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222210887.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222210151.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222211775.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222211538.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222211833.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222212318.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222212723.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222213526.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222213378.png">
<meta property="article:published_time" content="2023-08-23T06:00:02.000Z">
<meta property="article:modified_time" content="2024-11-17T08:49:47.070Z">
<meta property="article:author" content="木霈玖">
<meta property="article:tag" content="总结">
<meta property="article:tag" content="推荐系统">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192001842.png">


<link rel="canonical" href="http://example.com/2023/08/23/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>
<title>推荐系统 | 木霈玖的博客</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">木霈玖的博客</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="nav-number">2.</span> <span class="nav-text">推荐系统</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">2.1.</span> <span class="nav-text">基本概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84"><span class="nav-number">2.2.</span> <span class="nav-text">推荐系统架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84"><span class="nav-number">2.2.1.</span> <span class="nav-text">系统架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E6%9E%B6%E6%9E%84"><span class="nav-number">2.2.2.</span> <span class="nav-text">算法架构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.3.</span> <span class="nav-text">经典召回模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="nav-number">2.3.1.</span> <span class="nav-text">评估指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.3.2.</span> <span class="nav-text">基于协同过滤的召回</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95"><span class="nav-number">2.3.2.1.</span> <span class="nav-text">基于物品的协同过滤算法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4"><span class="nav-number">2.3.2.1.1.</span> <span class="nav-text">算法步骤</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97"><span class="nav-number">2.3.2.1.2.</span> <span class="nav-text">相似度计算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BB%93%E6%9E%9C%E9%A2%84%E6%B5%8B"><span class="nav-number">2.3.2.1.3.</span> <span class="nav-text">结果预测</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95"><span class="nav-number">2.3.2.2.</span> <span class="nav-text">基于用户的协同过滤算法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4-1"><span class="nav-number">2.3.2.2.1.</span> <span class="nav-text">算法步骤</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97-1"><span class="nav-number">2.3.2.2.2.</span> <span class="nav-text">相似度计算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BB%93%E6%9E%9C%E9%A2%84%E6%B5%8B-1"><span class="nav-number">2.3.2.2.3.</span> <span class="nav-text">结果预测</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Swing-Graph-based"><span class="nav-number">2.3.2.3.</span> <span class="nav-text">Swing(Graph-based)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%89%8D%E8%BF%B0%E6%96%B9%E6%B3%95%E5%B1%80%E9%99%90%E6%80%A7"><span class="nav-number">2.3.2.3.1.</span> <span class="nav-text">前述方法局限性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Swing%E7%AE%97%E6%B3%95"><span class="nav-number">2.3.2.3.2.</span> <span class="nav-text">Swing算法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Surprise%E7%AE%97%E6%B3%95"><span class="nav-number">2.3.2.3.3.</span> <span class="nav-text">Surprise算法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95"><span class="nav-number">2.3.2.4.</span> <span class="nav-text">基于模型的协同过滤算法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3"><span class="nav-number">2.3.2.4.1.</span> <span class="nav-text">矩阵分解</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="nav-number">2.3.2.4.1.1.</span> <span class="nav-text">算法原理</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95"><span class="nav-number">2.3.2.4.1.2.</span> <span class="nav-text">求解方法</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E7%9A%84%E6%8B%93%E5%B1%95%E4%B8%8E%E4%BC%98%E5%8C%96"><span class="nav-number">2.3.2.4.1.3.</span> <span class="nav-text">矩阵分解推荐算法的拓展与优化</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%90%91%E9%87%8F%E7%9A%84%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.3.3.</span> <span class="nav-text">基于向量的召回</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#FM%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.3.3.1.</span> <span class="nav-text">FM召回</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#item2vec%E5%8F%AC%E5%9B%9E%E7%B3%BB%E5%88%97"><span class="nav-number">2.3.3.2.</span> <span class="nav-text">item2vec召回系列</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Word2vec%E5%9F%BA%E7%A1%80"><span class="nav-number">2.3.3.2.1.</span> <span class="nav-text">Word2vec基础</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Word2vec%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">2.3.3.2.2.</span> <span class="nav-text">Word2vec模型结构</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#item2Vec%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.3.3.2.3.</span> <span class="nav-text">item2Vec模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Airbnb%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.3.3.2.4.</span> <span class="nav-text">Airbnb召回</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#YouTubeDNN%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.3.3.3.</span> <span class="nav-text">YouTubeDNN召回</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%8C%E5%A1%94%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.3.3.4.</span> <span class="nav-text">双塔召回</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E5%8F%8C%E5%A1%94"><span class="nav-number">2.3.3.4.1.</span> <span class="nav-text">经典双塔</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.3.3.4.1.1.</span> <span class="nav-text">经典双塔模型</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#SENet%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.3.3.4.1.2.</span> <span class="nav-text">SENet双塔模型</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%A4%9A%E7%9B%AE%E6%A0%87%E7%9A%84%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.3.3.4.1.3.</span> <span class="nav-text">多目标的双塔模型</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-number">2.3.3.4.1.4.</span> <span class="nav-text">模型的应用</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Youtube%E5%8F%8C%E5%A1%94"><span class="nav-number">2.3.3.4.2.</span> <span class="nav-text">Youtube双塔</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%B5%81%E7%A8%8B"><span class="nav-number">2.3.3.4.2.1.</span> <span class="nav-text">模型流程</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.3.4.</span> <span class="nav-text">基于图的召回</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#EGES"><span class="nav-number">2.3.4.1.</span> <span class="nav-text">EGES</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9E%84%E5%BB%BA%E7%89%A9%E5%93%81%E5%9B%BE"><span class="nav-number">2.3.4.1.1.</span> <span class="nav-text">构建物品图</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9B%BE%E5%B5%8C%E5%85%A5-BGE"><span class="nav-number">2.3.4.1.2.</span> <span class="nav-text">图嵌入(BGE)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8Eside-information%E7%9A%84%E5%9B%BE%E5%B5%8C%E5%85%A5%EF%BC%88GES%EF%BC%89"><span class="nav-number">2.3.4.1.3.</span> <span class="nav-text">基于side information的图嵌入（GES）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A2%9E%E5%BC%BA%E5%9E%8BEGS%EF%BC%88EGES%EF%BC%89"><span class="nav-number">2.3.4.1.4.</span> <span class="nav-text">增强型EGS（EGES）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PinSAGE"><span class="nav-number">2.3.4.2.</span> <span class="nav-text">PinSAGE</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#GraphSAGE%E5%8E%9F%E7%90%86"><span class="nav-number">2.3.4.2.1.</span> <span class="nav-text">GraphSAGE原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#GraphSAGE%E7%9A%84%E9%87%87%E6%A0%B7%E5%92%8C%E8%81%9A%E5%90%88"><span class="nav-number">2.3.4.2.2.</span> <span class="nav-text">GraphSAGE的采样和聚合</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#PinSAGE-1"><span class="nav-number">2.3.4.2.3.</span> <span class="nav-text">PinSAGE</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%BA%8F%E5%88%97%E7%9A%84%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.3.5.</span> <span class="nav-text">基于序列的召回</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MIND"><span class="nav-number">2.3.5.1.</span> <span class="nav-text">MIND</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%83%8C%E6%99%AF%E4%B8%8E%E5%8A%A8%E6%9C%BA"><span class="nav-number">2.3.5.1.1.</span> <span class="nav-text">背景与动机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%83%B6%E5%9B%8A%E7%BD%91%E7%BB%9C%E4%B8%8E%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%E6%9C%BA%E5%88%B6"><span class="nav-number">2.3.5.1.2.</span> <span class="nav-text">胶囊网络与动态路由机制</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%83%B6%E5%9B%8A%E7%BD%91%E7%BB%9C%E5%88%9D%E8%AF%86"><span class="nav-number">2.3.5.1.2.1.</span> <span class="nav-text">胶囊网络初识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86"><span class="nav-number">2.3.5.1.2.2.</span> <span class="nav-text">动态路由机制原理</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MIND%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E4%B8%8E%E7%BB%86%E8%8A%82%E5%89%96%E6%9E%90"><span class="nav-number">2.3.5.1.3.</span> <span class="nav-text">MIND模型的网络结构与细节剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84"><span class="nav-number">2.3.5.1.3.1.</span> <span class="nav-text">网络整体结构</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A1%E7%9B%AE%E6%A0%87"><span class="nav-number">2.3.5.1.3.2.</span> <span class="nav-text">任务目标</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Embedding-amp-Pooling%E5%B1%82"><span class="nav-number">2.3.5.1.3.3.</span> <span class="nav-text">Embedding &amp; Pooling层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Multi-Interest-Extractor-Layer-%E6%A0%B8%E5%BF%83"><span class="nav-number">2.3.5.1.3.4.</span> <span class="nav-text">Multi-Interest Extractor Layer(核心)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Label-aware-Attention-Layer"><span class="nav-number">2.3.5.1.3.5.</span> <span class="nav-text">Label-aware Attention Layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%9C%8D%E5%8A%A1"><span class="nav-number">2.3.5.1.3.6.</span> <span class="nav-text">训练与服务</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SDM"><span class="nav-number">2.3.5.2.</span> <span class="nav-text">SDM</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%83%8C%E6%99%AF%E4%B8%8E%E5%8A%A8%E6%9C%BA-1"><span class="nav-number">2.3.5.2.1.</span> <span class="nav-text">背景与动机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SDM%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E4%B8%8E%E7%BB%86%E8%8A%82%E5%89%96%E6%9E%90"><span class="nav-number">2.3.5.2.2.</span> <span class="nav-text">SDM的网络结构与细节剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E5%AE%9A%E4%B9%89"><span class="nav-number">2.3.5.2.2.1.</span> <span class="nav-text">问题定义</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Input-Embedding-with-side-Information"><span class="nav-number">2.3.5.2.2.2.</span> <span class="nav-text">Input Embedding with side Information</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%9F%AD%E6%9C%9F%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BB%BA%E6%A8%A1"><span class="nav-number">2.3.5.2.2.3.</span> <span class="nav-text">短期用户行为建模</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%94%A8%E6%88%B7%E9%95%BF%E6%9C%9F%E8%A1%8C%E4%B8%BA%E5%BB%BA%E6%A8%A1"><span class="nav-number">2.3.5.2.2.4.</span> <span class="nav-text">用户长期行为建模</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%9F%AD%E9%95%BF%E6%9C%9F%E5%85%B4%E8%B6%A3%E8%9E%8D%E5%90%88"><span class="nav-number">2.3.5.2.2.5.</span> <span class="nav-text">短长期兴趣融合</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.3.6.</span> <span class="nav-text">基于树模型的召回</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#TDM"><span class="nav-number">2.3.6.1.</span> <span class="nav-text">TDM</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">2.3.6.1.1.</span> <span class="nav-text">模型结构</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="nav-number">2.3.6.1.2.</span> <span class="nav-text">算法详解</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.</span> <span class="nav-text">经典排序模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GBDT-LR"><span class="nav-number">2.4.1.</span> <span class="nav-text">GBDT+LR</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.1.1.</span> <span class="nav-text">逻辑回归模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#GBDT"><span class="nav-number">2.4.1.2.</span> <span class="nav-text">GBDT</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#GBDT-LR%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.1.3.</span> <span class="nav-text">GBDT+LR模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89"><span class="nav-number">2.4.2.</span> <span class="nav-text">特征交叉</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#FM%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.2.1.</span> <span class="nav-text">FM模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81FM%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.2.1.1.</span> <span class="nav-text">为什么需要FM模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#FM%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">2.4.2.1.2.</span> <span class="nav-text">FM模型的应用场景</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#FM%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B7%E4%BD%93%E5%BD%A2%E5%BC%8F"><span class="nav-number">2.4.2.1.3.</span> <span class="nav-text">FM模型的具体形式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#FM%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="nav-number">2.4.2.1.4.</span> <span class="nav-text">FM模型的解决方法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#FM%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83"><span class="nav-number">2.4.2.1.5.</span> <span class="nav-text">FM模型的训练</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#FM%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%AB%98%E7%BB%B4%E6%89%A9%E5%B1%95"><span class="nav-number">2.4.2.1.6.</span> <span class="nav-text">FM模型的高维扩展</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FFM%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.2.2.</span> <span class="nav-text">FFM模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#FFM%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88%E6%96%B9%E5%BC%8F"><span class="nav-number">2.4.2.2.1.</span> <span class="nav-text">FFM模型的特征组合方式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#FFM%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">2.4.2.2.2.</span> <span class="nav-text">FFM模型的应用场景</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PNN"><span class="nav-number">2.4.2.3.</span> <span class="nav-text">PNN</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86"><span class="nav-number">2.4.2.3.1.</span> <span class="nav-text">模型结构及原理</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DCN"><span class="nav-number">2.4.2.4.</span> <span class="nav-text">DCN</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86-1"><span class="nav-number">2.4.2.4.1.</span> <span class="nav-text">模型结构及原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Embedding%E5%92%8CStacking-%E5%B1%82"><span class="nav-number">2.4.2.4.2.</span> <span class="nav-text">Embedding和Stacking 层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Cross-Network"><span class="nav-number">2.4.2.4.3.</span> <span class="nav-text">Cross Network</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Deep-Network"><span class="nav-number">2.4.2.4.4.</span> <span class="nav-text">Deep Network</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BB%84%E5%90%88%E8%BE%93%E5%87%BA%E5%B1%82"><span class="nav-number">2.4.2.4.5.</span> <span class="nav-text">组合输出层</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AutoInt"><span class="nav-number">2.4.2.5.</span> <span class="nav-text">AutoInt</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8A%A8%E6%9C%BA%E5%92%8C%E5%8E%9F%E7%90%86"><span class="nav-number">2.4.2.5.1.</span> <span class="nav-text">动机和原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AutoInt%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E5%90%91%E8%BF%87%E7%A8%8B%E6%A2%B3%E7%90%86"><span class="nav-number">2.4.2.5.2.</span> <span class="nav-text">AutoInt模型的前向过程梳理</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Input-Layer"><span class="nav-number">2.4.2.5.2.1.</span> <span class="nav-text">Input Layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Embedding-Layer"><span class="nav-number">2.4.2.5.2.2.</span> <span class="nav-text">Embedding Layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Interacting-Layer"><span class="nav-number">2.4.2.5.2.3.</span> <span class="nav-text">Interacting Layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Output-Layer"><span class="nav-number">2.4.2.5.2.4.</span> <span class="nav-text">Output Layer</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AutoInt%E7%9A%84%E5%88%86%E6%9E%90"><span class="nav-number">2.4.2.5.3.</span> <span class="nav-text">AutoInt的分析</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FiBiNet"><span class="nav-number">2.4.2.6.</span> <span class="nav-text">FiBiNet</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%8F%8A%E7%BB%86%E8%8A%82"><span class="nav-number">2.4.2.6.1.</span> <span class="nav-text">模型原理及细节</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Embedding-Layer-1"><span class="nav-number">2.4.2.6.1.1.</span> <span class="nav-text">Embedding Layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#SENET-Layer"><span class="nav-number">2.4.2.6.1.2.</span> <span class="nav-text">SENET Layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Bilinear-Interaction-Layer"><span class="nav-number">2.4.2.6.1.3.</span> <span class="nav-text">Bilinear-Interaction Layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Combination-Layer"><span class="nav-number">2.4.2.6.1.4.</span> <span class="nav-text">Combination Layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#DNN%E5%92%8C%E8%BE%93%E5%87%BA%E5%B1%82"><span class="nav-number">2.4.2.6.1.5.</span> <span class="nav-text">DNN和输出层</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Wide-amp-Deep%E7%B3%BB%E5%88%97"><span class="nav-number">2.4.3.</span> <span class="nav-text">Wide&amp;Deep系列</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Wide-amp-Deep"><span class="nav-number">2.4.3.1.</span> <span class="nav-text">Wide&amp;Deep</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8A%A8%E6%9C%BA"><span class="nav-number">2.4.3.1.1.</span> <span class="nav-text">动机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86-2"><span class="nav-number">2.4.3.1.2.</span> <span class="nav-text">模型结构及原理</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NFM"><span class="nav-number">2.4.3.2.</span> <span class="nav-text">NFM</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8A%A8%E6%9C%BA-1"><span class="nav-number">2.4.3.2.1.</span> <span class="nav-text">动机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E5%8E%9F%E7%90%86"><span class="nav-number">2.4.3.2.2.</span> <span class="nav-text">模型结构与原理</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Input-%E5%92%8CEmbedding%E5%B1%82"><span class="nav-number">2.4.3.2.2.1.</span> <span class="nav-text">Input 和Embedding层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Bi-Interaction-Pooling-layer"><span class="nav-number">2.4.3.2.2.2.</span> <span class="nav-text">Bi-Interaction Pooling layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%9A%90%E8%97%8F%E5%B1%82"><span class="nav-number">2.4.3.2.2.3.</span> <span class="nav-text">隐藏层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E5%B1%82"><span class="nav-number">2.4.3.2.2.4.</span> <span class="nav-text">预测层</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AFM"><span class="nav-number">2.4.3.3.</span> <span class="nav-text">AFM</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#AFM%E6%8F%90%E5%87%BA%E7%9A%84%E5%8A%A8%E6%9C%BA"><span class="nav-number">2.4.3.3.1.</span> <span class="nav-text">AFM提出的动机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AFM%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86"><span class="nav-number">2.4.3.3.2.</span> <span class="nav-text">AFM模型原理</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Pair-wise-Interaction-Layer"><span class="nav-number">2.4.3.3.2.1.</span> <span class="nav-text">Pair-wise Interaction Layer</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Attention-based-Pooling"><span class="nav-number">2.4.3.3.2.2.</span> <span class="nav-text">Attention-based Pooling</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#AFM%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="nav-number">2.4.3.3.2.3.</span> <span class="nav-text">AFM模型训练</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DeepFM"><span class="nav-number">2.4.3.4.</span> <span class="nav-text">DeepFM</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8A%A8%E6%9C%BA-2"><span class="nav-number">2.4.3.4.1.</span> <span class="nav-text">动机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E5%8E%9F%E7%90%86"><span class="nav-number">2.4.3.4.2.</span> <span class="nav-text">模型的结构与原理</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#FM"><span class="nav-number">2.4.3.4.2.1.</span> <span class="nav-text">FM</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Deep"><span class="nav-number">2.4.3.4.2.2.</span> <span class="nav-text">Deep</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#xDeepFM"><span class="nav-number">2.4.3.5.</span> <span class="nav-text">xDeepFM</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#xDeepFM%E7%9A%84%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90"><span class="nav-number">2.4.3.5.1.</span> <span class="nav-text">xDeepFM的架构剖析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#CIN%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%86%E8%8A%82"><span class="nav-number">2.4.3.5.2.</span> <span class="nav-text">CIN网络的细节</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.4.</span> <span class="nav-text">序列模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.5.</span> <span class="nav-text">多任务模型</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">木霈玖</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">23</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/08/23/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="木霈玖">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="木霈玖的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          推荐系统
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-08-23 14:00:02" itemprop="dateCreated datePublished" datetime="2023-08-23T14:00:02+08:00">2023-08-23</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2024-11-17 16:49:47" itemprop="dateModified" datetime="2024-11-17T16:49:47+08:00">2024-11-17</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">推荐系统</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>68k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1:02</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一些推荐系统相关的知识。</p>
<a id="more"></a>
<h1 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p><strong>CTR(Click-Through-Rate)</strong>：即点击通过率，是互联网广告常用的术语，指网络广告的点击到达率，即该广告的实际点击次数（严格的来说，可以是到达目标页面的数量）除以广告的展现量。</p>
<p>点击量过小时，是由两种原因造成的，展现量过小，或点击数偏低。</p>
<ol>
<li>展现量低，进而点击数也小。展现量过低说明潜在受众搜索需求发生的较少，也即推广结果展现在潜在受众前的机会较少，推广商户可以通过拓展关键词来提高展现量，即提高推广信息展现的机会。</li>
<li>展现量高，但是点击数偏低，造成点击率偏低。这种情况可能的原因是：<ul>
<li>关键词与文案的相关性不高，所以无法满足潜在受众的需求，进而点击数小。可以通过改善文案写作，提高关键词与文案的相关性来提高点击率。</li>
<li>推广结果的平均排名较低，不具有竞争力。可以通过调高平均点击价格来提高排名。</li>
<li>关键词匹配模式的问题。例如，推广商户购买了“葡萄”等相关关键词，用户在搜索“葡萄牙”时商户的推广结果也可能会出现，这时推广结果就是无效展现，即为推广结果信息没有展现在潜在受众前。此种情况就需通过“否定匹配”模式来解决，将“葡萄牙”设置为否定匹配，即为用户在搜索“葡萄牙”时，推广商户的推广结果不会展现，降低了无效展现的风险。</li>
</ul>
</li>
</ol>
<h2 id="推荐系统架构"><a href="#推荐系统架构" class="headerlink" title="推荐系统架构"></a>推荐系统架构</h2><p>从<strong>系统架构</strong>和<strong>算法架构</strong>两个角度出发解析推荐系统通用架构。系统架构设计思想是大数据背景下如何有效利用海量和实时数据，将推荐系统按照对数据利用情况和系统响应要求出发，将整个架构分为<strong>离线层、近线层、在线层</strong>三个模块。而算法架构是从我们比较熟悉的<strong>召回、粗排、排序、重排</strong>等算法环节角度出发的，重要的是要去理解每个环节需要完成的任务，每个环节的评价体系，以及为什么要那么设计。</p>
<h3 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h3><p>推荐系统架构，首先从数据驱动角度，对于数据，最简单的方法是存下来，留作后续离线处理，<strong>离线层</strong>就是我们用来管理离线作业的部分架构。<strong>在线层</strong>能更快地响应最近的事件和用户交互，但必须实时完成。这会限制使用算法的复杂性和处理的数据量。离线计算对于数据数量和算法复杂度限制更少，因为它以批量方式完成，没有很强的时间要求。不过，由于没有及时加入最新的数据，所以很容易过时。个性化架构的关键问题，就是如何以无缝方式结合、管理在线和离线计算过程。<strong>近线层</strong>介于两种方法之间，可以执行类似于在线计算的方法，但又不必以实时方式完成。</p>
<h3 id="算法架构"><a href="#算法架构" class="headerlink" title="算法架构"></a>算法架构</h3><p>一个通用的算法架构，设计思想就是对数据层层建模，层层筛选，帮助用户从海量数据中找出其真正感兴趣的部分。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192001842.png" alt="img"></p>
<p><strong>召回</strong></p>
<p>召回层的主要目标时从推荐池中选取几千上万的item，送给后续的排序模块。由于召回面对的候选集十分大，且一般需要在线输出，故召回模块必须轻量快速低延迟。由于后续还有排序模块作为保障，召回不需要十分准确，但<strong>不可遗漏</strong>（特别是搜索系统中的召回模块）。</p>
<p>召回主要考虑的内容有：</p>
<ol>
<li><strong>考虑用户层面</strong>：用户兴趣的多元化，用户需求与场景的多元化：例如：新闻需求，重大要闻，相关内容沉浸阅读等等</li>
<li><strong>考虑系统层面</strong>：增强系统的鲁棒性；部分召回失效，其余召回队列兜底不会导致整个召回层失效；排序层失效，召回队列兜底不会导致整个推荐系统失效</li>
<li><strong>系统多样性内容分发</strong>：图文、视频、小视频；精准、试探、时效一定比例；召回目标的多元化，例如：相关性，沉浸时长，时效性，特色内容等等</li>
<li><strong>可解释性推荐一部分召回是有明确推荐理由的</strong>：很好的解决产品性数据的引入</li>
</ol>
<p><strong>粗排</strong></p>
<p>粗排的原因是有时候召回的结果还是太多，精排层速度还是跟不上，所以加入粗排。粗排可以理解为精排前的一轮过滤机制，减轻精排模块的压力。粗排介于召回和精排之间，要同时兼顾精准性和低延迟。目前粗排一般也都模型化了，其训练样本类似于精排，选取曝光点击为正样本，曝光未点击为负样本。但由于粗排一般面向上万的候选集，而精排只有几百上千，其解空间大很多。</p>
<p><strong>精排</strong></p>
<p>精排层，也是我们学习推荐入门最常常接触的层，我们所熟悉的算法很大一部分都来自精排层。这一层的任务是获取粗排模块的结果，对候选集进行打分和排序。精排需要在最大时延允许的情况下，保证打分的精准性，是整个系统中至关重要的一个模块，也是最复杂，研究最多的一个模块。</p>
<p>精排是推荐系统各层级中最纯粹的一层，他的目标比较单一且集中，一门心思的实现目标的调优即可。最开始的时候精排模型的常见目标是CTR,后续逐渐发展了CVR等多类目标。精排和粗排层的基本目标是一致的，都是对商品集合进行排序，但是和粗排不同的是，精排只需要对少量的商品(即粗排输出的商品集合的Top-N)进行排序即可。因此，精排中可以使用比粗排更多的特征，更复杂的模型和更精细的策略（用户的特征和行为在该层的大量使用和参与也是基于这个原因）。</p>
<p><strong>重排</strong></p>
<p>常见的有三种优化目标：Point Wise、Pair Wise 和 List Wise。重排序阶段对精排生成的Top-N个物品的序列进行重新排序，生成一个Top-K个物品的序列，作为排序系统最后的结果，直接展现给用户。重排序的原因是因为多个物品之间往往是相互影响的，而精排序是根据Point Wise得分，容易造成推荐结果同质化严重，有很多冗余信息。而重排序面对的挑战就是海量状态空间如何求解的问题，一般在精排层我们使用AUC作为指标，但是在重排序更多关注NDCG等指标。</p>
<p><strong>混排</strong></p>
<p>多个业务线都想在Feeds流中获取曝光，则需要对它们的结果进行混排。比如推荐流中插入广告、视频流中插入图文和banner等。可以基于规则策略（如广告定坑）和强化学习来实现。</p>
<h2 id="经典召回模型"><a href="#经典召回模型" class="headerlink" title="经典召回模型"></a>经典召回模型</h2><h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h3><ul>
<li>召回率：在模型召回预测的物品中，预测准确的物品占用户实际喜欢的物品的比例。对用户  推荐  个物品记为  , 令用户  在测试集上喜欢的物品集合为  ， 那么召回率定义为：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192101633.png" alt="img"></p>
<ul>
<li>准确率：推荐的物品中，对用户准确推荐的物品占总物品的比例。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192102103.png" alt="img"></p>
<ul>
<li>覆盖率：覆盖率反映了推荐算法发掘长尾的能力， 覆盖率越高， 说明推荐算法越能将长尾中的物品推荐给用户。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192115000.png" alt="img"></p>
<ul>
<li>新颖度：用推荐列表中物品的平均流行度度量推荐结果的新颖度。 如果推荐出的物品都很热门， 说明推荐的新颖度较低。 由于物品的流行度分布呈长尾分布， 所以为了流行度的平均值更加稳定， 在计算平均流行度时对每个物品的流行度取对数。</li>
</ul>
<h3 id="基于协同过滤的召回"><a href="#基于协同过滤的召回" class="headerlink" title="基于协同过滤的召回"></a>基于协同过滤的召回</h3><p>协同过滤算法<code>(Collaborative Filtering)</code>是比较经典常用的推荐算法，它是一种完全依赖用户和物品之间行为关系的推荐算法。我们从它的名字“协同过滤”中，也可以窥探到它背后的原理，就是 “协同大家的反馈、评价和意见，一起对海量的信息进行过滤，从中筛选出用户可能感兴趣的信息”。协同过滤算法的主要分类：</p>
<ul>
<li>基于物品的协同过滤算法：给用户推荐与他之前喜欢的物品相似的物品。</li>
<li>基于用户的协同过滤算法：给用户推荐与他兴趣相似的用户喜欢的物品。</li>
</ul>
<h4 id="基于物品的协同过滤算法"><a href="#基于物品的协同过滤算法" class="headerlink" title="基于物品的协同过滤算法"></a>基于物品的协同过滤算法</h4><p><strong>基于物品的协同过滤(ItemCF)</strong>的基本思想是预先根据所有用户的历史偏好数据计算物品之间的相似性，然后把与用户喜欢的物品相类似的物品推荐给用户。比如物品<code>a</code>和<code>c</code>非常相似，因为喜欢<code>a</code>的用户同时也喜欢<code>c</code>，而用户<code>A</code>喜欢<code>a</code>，所以把<code>c</code>推荐给用户<code>A</code>。<code>ItemCF</code>算法并不利用物品的内容属性计算物品之间的相似度， 主要通过分析用户的行为记录计算物品之间的相似度， 该算法认为， 物品<code>a</code>和物品<code>c</code>具有很大的相似度是因为喜欢物品<code>a</code>的用户大都喜欢物品<code>c</code>。</p>
<h5 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h5><p>基于物品的协同过滤算法主要分为两步：</p>
<ul>
<li>计算物品之间的相似度；</li>
<li>根据物品的相似度和用户的历史行为给用户生成推荐列表（购买了该商品的用户也经常购买的其他商品）。</li>
</ul>
<h5 id="相似度计算"><a href="#相似度计算" class="headerlink" title="相似度计算"></a>相似度计算</h5><p><strong>购买了该商品的用户也经常购买的其他商品</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202215784.png" alt="img"></p>
<p>分母   是喜欢物品  的用户数，而分子  是同时喜欢物品  和物品  的用户数。因此，上述公式可以理解为喜欢物品  的用户中有多少比例的用户也喜欢物品  。 上述公式虽然看起来很有道理，但是却存在一个问题。如果物品  很热门，很多人都喜欢，那么  就会很大，接近  。因此，该公式会造成任何物品都会和热门的物品有很大的相似度，这对于致力于挖掘长尾信息的推荐系统来说显然不是一个好的特性。为了避免推荐出热门的物品，可以用下面的公式，这个公式惩罚了物品  的权重，因此减轻了热门物品会和很多物品相似的可能性。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202218223.png" alt="img"></p>
<p>除了在计算物品之间相似度时可以对热门物品进行惩罚外，可以在此基础上，进一步引入参数  ，这样可以通过控制参数  来决定对热门物品的惩罚力度。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192140478.png" alt="img"></p>
<p><strong>相似度算法改进</strong></p>
<p>在协同过滤中两个物品产生相似度是因为它们共同出现在很多用户的兴趣列表中。也就是说，每个用户的兴趣列表都对物品的相似度产生贡献。那么是不是每个用户的贡献都相同呢?</p>
<p>假设有这么一个用户，他是开书店的，并且买了当当网上<code>80%</code>的书准备用来自己卖。那么他的购物车里包含当当网<code>80%</code>的书。假设当当网有<code>100</code>万本书，也就是说他买了<code>80</code>万本。从前面对<code>ItemCF</code>的讨论可以看到，这意味着因为存在这么一个用户，有<code>80</code>万本书两两之间就产生了相似度，也就是说，内存里即将诞生一个<code>80</code>万乘<code>80</code>万的稠密矩阵。</p>
<p><code>John S. Breese</code>中提出了一个称为<code>IUF(Inverse User Frequence)</code>，即<strong>用户活跃度</strong>对数的倒数的参数，他也认为活跃用户对物品相似度的贡献应该小于不活跃的用户，他提出应该增加<code>IUF</code>参数来修正物品相似度的计算公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210945142.png" alt="img"></p>
<p>上述公式对活跃用户做了一种软性的惩罚，但是对于很多过于活跃的用户，比如上面那位买了当当网<code>80%</code>图书的用户，为了避免相似度矩阵过于稠密，我们在实际计算中一般直接忽略他的兴趣列表，而不将其纳入到相似度计算的数据集中。</p>
<p><strong>相似度矩阵归一化处理</strong></p>
<p><code>Karypis</code>在研究中发现如果将<code>ItemCF</code>的相似度矩阵按最大值归一化，可以提高推荐的准确率。其研究表明，如果已经得到了物品相似度矩阵  ，那么可以用如下公式得到归一化之后的相似度矩阵  ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210948508.png" alt="img"></p>
<p>归一化的好处不仅仅在于增加推荐的准确度，它还可以提高推荐的覆盖率和多样性。</p>
<p><strong>实例讲解</strong></p>
<p>下表是一个简易的原始数据集，也称之为<code>User-Item</code>表，即用户-物品列表，记录了每个用户喜爱的物品，数据表格如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>用户</th>
<th>喜爱的物品</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>{a,b,d}</td>
</tr>
<tr>
<td>B</td>
<td>{b,c,e}</td>
</tr>
<tr>
<td>C</td>
<td>{c,d}</td>
</tr>
<tr>
<td>D</td>
<td>{b,c,d}</td>
</tr>
<tr>
<td>E</td>
<td>{a,d}</td>
</tr>
</tbody>
</table>
</div>
<p>接着，我们分别建立用户<code>A</code>-<code>E</code>的共现矩阵，并将他们累加起来。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202254827.png" alt="img"></p>
<p>接下来我们计算最终的物品相似度矩阵，以物品<code>a</code>和物品<code>b</code>的相似度计算为例，通过上面计算的计算可知  ，即同时喜欢物品<code>a</code>和物品<code>b</code>的用户有一位。根据<code>User-Item</code>表可以统计出  ，  ，那么物品<code>a</code>和物品<code>b</code>的相似度  计算如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210936324.png" alt="img"></p>
<h5 id="结果预测"><a href="#结果预测" class="headerlink" title="结果预测"></a>结果预测</h5><p>在得到物品之间的相似度后，<code>ItemCF</code>通过如下公式计算用户  对一个物品  的兴趣：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210950233.png" alt="img"></p>
<p>这里  是用户喜欢的物品的集合，  是和物品  最相似的 个物品的集合，  是物品  和  的相似度，  是用户  对物品  的兴趣。（对于隐反馈数据集，如果用户  对物品  有过行为，即可令  。）该公式的含义是，和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。</p>
<p><strong>实例讲解</strong></p>
<p>下图是一个基于物品推荐的简单例子。该例子中，用户喜欢《C++ Primer中文版》和《编程之美》两本书。然后<code>ItemCF</code>会为这两本书分别找出和它们最相似的  本书，然后根据公式的定义计算用户对每本书的感兴趣程度。比如，<code>ItemCF</code>给用户推荐《算法导论》，是因为这本书和《C++Primer中文版》相似，相似度为  ，而且这本书也和《编程之美》相似，相似度是  。考虑到用户对《C++ Primer中文版》的兴趣度是  ，对《编程之美》的兴趣度是  ，那么用户对《算法导论》的兴趣度就是  。 <img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304210958573.png" alt="img"></p>
<h4 id="基于用户的协同过滤算法"><a href="#基于用户的协同过滤算法" class="headerlink" title="基于用户的协同过滤算法"></a>基于用户的协同过滤算法</h4><p><strong>基于用户的协同过滤(UserCF)</strong>，思想其实比较简单，当一个用户<code>A</code>需要个性化推荐的时候， 我们可以先找到和他有相似兴趣的其他用户， 然后把那些用户喜欢的， 而用户<code>A</code>没有听说过的物品推荐给<code>A</code>。</p>
<h5 id="算法步骤-1"><a href="#算法步骤-1" class="headerlink" title="算法步骤"></a>算法步骤</h5><p>基于用户的协同过滤算法分为两步骤：</p>
<ul>
<li>找到与当前用户<code>A</code>相似的用户<code>B</code>；</li>
<li>将相似用户<code>B</code>喜欢的物品而用户<code>A</code>没有见过的物品推荐给用户<code>A</code>。</li>
</ul>
<h5 id="相似度计算-1"><a href="#相似度计算-1" class="headerlink" title="相似度计算"></a>相似度计算</h5><p><strong>欧式距离</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202054636.png" alt="img"></p>
<p><strong>曼哈顿距离</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202055336.png" alt="img"></p>
<p><strong>杰卡德(Jaccard)相似系数</strong></p>
<p>两个集合<code>A</code>和<code>B</code>交集元素的个数在<code>A</code>、<code>B</code>并集中所占的比例，称为这两个集合的杰卡德系数，用符号<code>J(A,B)</code>表示。杰卡德相似系数是衡量两个集合相似度的一种指标（余弦距离也可以用来衡量两个集合的相似度），<code>Jaccard</code>值越大说明相似度越高。由于杰卡德相似系数一般无法反映具体用户的评分喜好信息，所以常用来<strong>评估用户是否会对某物品进行打分， 而不是预估用户会对某物品打多少分</strong>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202037061.png" alt="img"></p>
<p><strong>余弦相似度</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202037832.png" alt="img"></p>
<p><strong>皮尔逊相关系数</strong></p>
<p>相比余弦相似度，皮尔逊相关系数通过<strong>使用用户平均分对各独立评分进行修正，减小了用户评分偏置的影响</strong>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202048519.png" alt="img"></p>
<p>其中  表示用户  对物品  的评分，  表示用户  对所有物品评分的平均值，  代表所有物品的集合。</p>
<h5 id="结果预测-1"><a href="#结果预测-1" class="headerlink" title="结果预测"></a>结果预测</h5><p>根据上面的几种方法， 我们可以计算出向量之间的相似程度， 也就是可以计算出<code>Alice</code>和其他用户的相近程度， 这时候我们就可以选出与<code>Alice</code>最相近的前  个用户， 基于他们对某一物品的评价猜测出<code>Alice</code>的打分值。</p>
<p>这里最常用的方式是利用用户相似度和相似用户的评价的加权平均获得目标用户的评价预测。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202104133.png" alt="img"></p>
<p>其中  是用户  与用户  的相似度，  是用户  对物品  的评分，  是所有用户的集合。</p>
<p>还有一种方式打分方式， 这种方式考虑的更加全面， 依然是用户相似度作为权值， 但后面不单纯的是其他用户对物品的评分， 而是该物品的评分与此用户的所有评分的差值进行加权平均， 这时候考虑到了有的用户内心的评分标准不一的情况， 即有的用户喜欢打高分， 有的用户喜欢打低分的情况。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304202135669.png" alt="img"></p>
<p>其中，  是用户  与用户  的相似度，  是用户  对物品  的评分，  是用户  对所有物品打分的平均值，  是用户  对所有物品打分的平均值，其实就是对真实值与平均值的误差进行重要性加权。</p>
<h4 id="Swing-Graph-based"><a href="#Swing-Graph-based" class="headerlink" title="Swing(Graph-based)"></a>Swing(Graph-based)</h4><h5 id="前述方法局限性"><a href="#前述方法局限性" class="headerlink" title="前述方法局限性"></a>前述方法局限性</h5><ul>
<li>基于 Cosine, Jaccard, 皮尔逊相关性等相似度计算的协同过滤算法，在计算邻居关联强度的时候只关注于 Item-based (常用，因为item相比于用户变化的慢，且新Item特征比较容易获得)，Item-based CF 只关注于 Item-User-Item 的路径，把所有的User-Item交互都平等得看待，从而忽视了 User-Item 交互中的大量噪声，推荐精度存在局限性。</li>
<li>对互补性产品的建模不足，可能会导致用户购买过手机之后还继续推荐手机，但用户短时间内不会再继续购买手机，因此产生无效曝光。</li>
</ul>
<h5 id="Swing算法"><a href="#Swing算法" class="headerlink" title="Swing算法"></a>Swing算法</h5><p>Swing 通过利用 User-Item-User 路径中所包含的信息，考虑 User-Item 二部图中的鲁棒内部子结构计算相似性。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192157333.png" alt="img"></p>
<ul>
<li>什么是内部子结构？ 以经典的啤酒尿布故事为例，张三同时购买了啤酒和尿布，这可能是一种巧合。但两个甚至多个顾客都同时购买了啤酒尿布，这就证明啤酒和尿布具有相关关系。这样共同购买啤酒和尿布的用户越多，啤酒和尿布的相关度就会越高。</li>
<li>通俗解释：若用户  和用户  之间除了购买过  外，还购买过商品  ，则认为两件商品是具有某种程度上的相似的。也就是说，商品与商品之间的相似关系，是通过用户关系来传递的。为了衡量物品  和  的相似性，比较同时购买了物品  和  的用户  和用户  ， 如果这两个用户共同购买的物品越少，即这两个用户原始兴趣不相似，但仍同时购买了两个相同的物品  和  ， 则物品  和  的相似性越高。</li>
<li>计算公式如下，其中  是点击过商品  的用户集合， 是用户  点击过的商品集合，  是平滑系数。  ，  是用户权重参数，来降低活跃用户的影响。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192205012.png" alt="img"></p>
<h5 id="Surprise算法"><a href="#Surprise算法" class="headerlink" title="Surprise算法"></a>Surprise算法</h5><p>Surprise 算法利用商品分类信息和用户共同购买图上的聚类技术来建模产品之间的组合关系。</p>
<p>首先在行为相关性中引入连续时间衰减因子，然后引入基于交互数据的聚类方法解决数据稀疏的问题，旨在帮助用户找到互补商品。互补相关性主要从三个层面考虑，类别层面，商品层面和聚类层面。</p>
<ul>
<li>类别层面 首先通过商品和类别的映射关系，我们可以得到 user-category 矩阵。随后使用简单的相关性度量可以计算出类别  ，  的相关性。  为在购买过  之后购买  类的数量，  为购买  类的数量。（）</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192210225.png" alt="img"></p>
<ul>
<li><p>商品层面 商品层面的相关性挖掘主要有两个关键设计：</p>
<ul>
<li>商品的购买顺序是需要被考虑的，例如在用户购买手机后推荐充电宝是合理的，但在用户购买充电宝后推荐手机是不合理的。</li>
<li>两个商品购买的时间间隔也是需要被考虑的，时间间隔越短越能证明两个商品的互补关系。</li>
</ul>
<p>最终商品层面的互补相关性被定义为如下，其中  属于  的相关类，且  的购买时间晚于  。</p>
</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305192217890.png" alt="img"></p>
<ul>
<li>聚类层面<ul>
<li>如何聚类？传统的聚类算法（基于密度和k-means）在数十亿产品规模下的淘宝场景中不可行，所以作者采用了标签传播算法。</li>
<li>在哪里标签传播？Item-item 图，其中把Swing计算的排名靠前item为邻居，边的权重就是Swing分数。</li>
<li>表现如何？快速而有效，15分钟即可对数十亿个项目进行聚类。最终聚类层面的相关度计算同上面商品层面的计算公式。</li>
</ul>
</li>
<li>线性组合：  ，其中是  作者设置的权重超参数。Surprise算法通过利用类别信息和标签传播技术解决了用户共同购买图上的稀疏性问题。</li>
</ul>
<h4 id="基于模型的协同过滤算法"><a href="#基于模型的协同过滤算法" class="headerlink" title="基于模型的协同过滤算法"></a>基于模型的协同过滤算法</h4><p>基于模型的协同过滤作为目前最主流的协同过滤类型，我们的问题是这样的：  个物品，  个用户的数据，只有部分用户和部分数据之间是有评分数据的，其它部分评分是空白。此时我们要用已有的部分稀疏数据来预测那些空白的物品和数据之间的评分关系，找到最高评分的物品推荐给用户。</p>
<p>对于这个问题，用机器学习的思想来建模解决，主流的方法可以分为：用关联算法，聚类算法，分类算法，回归算法，矩阵分解，神经网络，图模型以及隐语义模型来解决。</p>
<p><strong>用关联算法做协同过滤</strong></p>
<p>一般我们可以找出用户购买的所有物品数据里频繁出现的项集活序列，来做频繁集挖掘，找到满足支持度值的关联物品的频繁  项集或者序列。如果用户购买了频繁  项集或者序列里的部分物品，那么我们可以将频繁项集或序列里的其他物品按一定的评分准则推荐给用户，这个评分准则可以包括支持度，置信度和提升度等。</p>
<p><strong>用聚类算法做协同过滤</strong></p>
<p>用聚类算法做协同过滤就和前面的基于用户或者项目的协同过滤有些类似了。我们可以按照用户或者按照物品基于一定的距离度量来进行聚类。如果基于用户聚类，则可以将用户按照一定距离度量方式分成不同的目标人群，将同样目标人群评分高的物品推荐给目标用户。基于物品聚类的话，则是将用户评分高物品的相似同类物品推荐给用户。</p>
<p><strong>用分类算法做协同过滤</strong></p>
<p>如果我们根据用户评分的高低，将分数分成几段的话，则这个问题变成分类问题。比如最直接的，设置一份评分阈值，评分高于阈值的就是推荐，评分低于阈值就是不推荐，我们将问题变成了一个二分类问题。虽然分类问题的算法多如牛毛，但是目前使用最广泛的是逻辑回归。为啥是逻辑回归而不是看起来更加高大上的比如支持向量机呢？因为逻辑回归的解释性比较强，每个物品是否推荐我们都有一个明确的概率放在这，同时可以对数据的特征做工程化，得到调优的目的。</p>
<p><strong>用回归算法做协同过滤</strong></p>
<p>用回归算法做协同过滤比分类算法看起来更加的自然。我们的评分可以是一个连续的值而不是离散的值，通过回归模型我们可以得到目标用户对某商品的预测打分。</p>
<p><strong>用神经网络做协同过滤</strong></p>
<p>用神经网络乃至深度学习做协同过滤应该是以后的一个趋势。目前比较主流的用两层神经网络来做推荐算法的是限制玻尔兹曼机<code>(RBM)</code>。在目前的<code>Netflix</code>算法比赛中，<code>RBM</code>算法的表现很牛。当然如果用深层的神经网络来做协同过滤应该会更好，大厂商用深度学习的方法来做协同过滤应该是将来的一个趋势。</p>
<p><strong>用图模型做协同过滤</strong></p>
<p>用图模型做协同过滤，则将用户之间的相似度放到了一个图模型里面去考虑，常用的算法是<code>SimRank</code>系列算法和马尔科夫模型算法。对于<code>SimRank</code>系列算法，它的基本思想是被相似对象引用的两个对象也具有相似性。算法思想有点类似于大名鼎鼎的<code>PageRank</code>。而马尔科夫模型算法当然是基于马尔科夫链了，它的基本思想是基于传导性来找出普通距离度量算法难以找出的相似性。</p>
<p><strong>用隐语义模型做协同过滤</strong></p>
<p>隐语义模型主要是基于<code>NLP</code>的，涉及到对用户行为的语义分析来做评分推荐，主要方法有隐性语义分析<code>LSA</code>和隐含狄利克雷分布<code>LDA</code>。</p>
<p><strong>用矩阵分解做协同过滤</strong></p>
<p>用矩阵分解做协同过滤是目前使用也很广泛的一种方法。由于传统的奇异值分解<code>SVD</code>要求矩阵不能有缺失数据，必须是稠密的，而我们的用户物品评分矩阵是一个很典型的稀疏矩阵，直接使用传统的<code>SVD</code>到协同过滤是比较复杂的。目前主流的矩阵分解推荐算法主要是<code>SVD</code>的一些变种，比如<code>FunkSVD</code>，<code>BiasSVD</code>和<code>SVD++</code>。</p>
<h5 id="矩阵分解"><a href="#矩阵分解" class="headerlink" title="矩阵分解"></a>矩阵分解</h5><p>  矩阵分解是指将一个矩阵分解成两个或者多个矩阵的乘积，实际推荐计算时不再使用大矩阵，而是用分解得到的两个小矩阵：一个是由代表用户偏好的用户隐因子向量组成，另一个是由代表物品语义主题的隐因子向量组成。</p>
<p>对于下图的<code>User-Item</code>矩阵（评分矩阵），记为  。可以将其分解成两个或者多个矩阵的乘积，假设分解成两个矩阵  和  ，我们要使得矩阵  和  的乘积能够还原原始的矩阵  ，即  。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231131422.png" alt="img"></p>
<p>在我们得到用户对每个标的物的评分后，从该评分中过滤掉用户已经操作过的标的物，针对剩下的标的物得分做降序排列取<code>topN</code>推荐给用户。矩阵分解算法的核心思想是将用户行为矩阵分解为两个低秩矩阵的乘积，通过分解，我们分别将用户和标的物嵌入到了同一个  维的向量空间（  一般很小，几十到上百），用户向量和标的物向量的内积代表了用户对标的物的偏好度。所以，矩阵分解算法本质上也是一种<strong>嵌入方法</strong>。上面提到的k维向量空间的每一个维度是<strong>隐因子(latent factor)</strong>，之所以叫隐因子，是因为每个维度不具备与现实场景对应的具体的可解释的含义，所以矩阵分解算法也是一类隐因子算法。这  个维度代表的是某种行为特性，但是这个行为特性又是无法用具体的特征解释的，从这点也可以看出，矩阵分解算法的可解释性不强，我们比较难以解释矩阵分解算法为什么这么推荐。</p>
<h6 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h6><p>通过矩阵分解将用户  和标的物  嵌入如下的  维隐式特征空间向量：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231137649.png" alt="img"></p>
<p>那么用户  对标的物  的预测评分为  ，真实值与预测值之间的误差为  。如果预测得越准，那么  越小，针对所有用户评分过的  对，如果我们可以保证这些误差之和尽量小，那么有理由认为我们的预测是精准的。有了上面的分析，我们就可以将矩阵分解转化为一个机器学习问题，这也就是<strong>Funk-SVD(Basic SVD/LFM)</strong>的思想。在Funk-SVD的基础之上加上正则化项，也就成了<strong>RSVD</strong>。具体地说，我们可以将矩阵分解转化为如下等价的求最小值的最优化问题。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231146383.png" alt="img"></p>
<p>其中  是超参数，  是正则化项。</p>
<h6 id="求解方法"><a href="#求解方法" class="headerlink" title="求解方法"></a>求解方法</h6><p>对于上一节讲到的最优化问题，在工程上一般有两种求解方法，<code>SGD(Stochastic Gradient Descent)</code>和<code>ALS(Alternating Least Squares)</code>。</p>
<ul>
<li>利用SGD来求解矩阵分解</li>
</ul>
<p>我们定义真实评分和预测评分的误差为：  ，我们可以将上面的优化问题改写成如下函数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231152053.png" alt="img"></p>
<p>对  和  求偏导数，我们可以得到：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231153530.png" alt="img"></p>
<p>有了偏导数，我们沿着导数(梯度)相反的方向更新：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231154583.png" alt="img"></p>
<ul>
<li>利用ALS来求解矩阵分解</li>
</ul>
<p><code>ALS</code>方法是一个高效的求解矩阵分解的算法，目前<code>Spark Mllib</code>中的协同过滤算法就是基于<code>ALS</code>求解的矩阵分解算法，它可以很好地拓展到分布式计算场景，轻松应对大规模训练数据的情况。下面对ALS算法原理及特点做一个简单介绍。<code>ALS</code>算法的原理基本就是名字表达的意思，通过交替优化求得极值。</p>
<p>一般过程是先固定  ，那么上述优化问题就变成了一个关于  的二次函数，可以作为最小二乘问题来解决，求出最优的  后，固定  ，再解关于  的最小二乘问题，交替进行直到收敛。</p>
<p><code>ALS</code>算法有如下两个优势：</p>
<ul>
<li><p><strong>可以并行处理</strong></p>
<p>当固定某一个参数时，另一个参数的迭代更新只依赖自己，不依赖于其他的标的物的特征向量，所以可以将不同的参数更新放到不同的服务器上执行。<code>Spark</code>的<code>ALS</code>算法就是采用这样的方式做到并行化的。</p>
</li>
<li><p><strong>对于隐式特征问题比较合适</strong></p>
<p>用户真正的评分是很稀少的，所以利用隐式行为是更好的选择（其实也是不得已的选择）。当利用了隐式行为，那么用户行为矩阵就不会那么稀疏了，即有非常多的  对是非空的，计算量会更大，这时采用<code>ALS</code>算法是更合适的，因为固定  或者  ，让整个计算问题更加简单，容易求目标函数的极值。</p>
</li>
</ul>
<h6 id="矩阵分解推荐算法的拓展与优化"><a href="#矩阵分解推荐算法的拓展与优化" class="headerlink" title="矩阵分解推荐算法的拓展与优化"></a>矩阵分解推荐算法的拓展与优化</h6><p>矩阵分解算法是一个非常容易理解并易于分布式实现的算法。不光如此，矩阵分解算法的框架还是一个非常容易拓展的框架，可以整合非常多的其他信息及特性到该框架之下，从而丰富模型的表达空间，提升预测的准确度。本节我们就来总结和梳理一下矩阵分解算法可以进行哪些拓展与优化。</p>
<p><strong>整合偏差(bias)项</strong></p>
<p>不同的人对标的物的评价可能是不一样的，有的人倾向于给更高的评分，而有的人倾向于给更低的评分。对于同一个标的物，也会受到外界其他信息的干扰，影响人们对它的评价（比如视频，可能由于主演的热点事件导致该视频突然变火），这两种情况是由于用户和标的物引起的偏差。我们可以在这里引入<code>Bias</code>项，将评分表中观察到的值分解为  个部分：全局均值<code>(global average)</code>，标的物偏差<code>(item bias)</code>，用户偏差<code>(user bias)</code>和用户标的物交叉项<code>(user-item interaction)</code>。这时，我们可以用如下公式来预测用户  对标的物  的评分：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231206104.png" alt="img"></p>
<p><strong>增加更多的用户信息输入</strong></p>
<p>由于用户一般只对很少的标的物评分，导致评分过少，可能无法给该用户做出较好的推荐，这时可以通过引入更多的信息来缓解评分过少的问题。具体来说，我们可以整合用户隐式反馈（收藏、点赞、分享等）和用户人口统计学信息（年龄、性别、地域、收入等）到矩阵分解模型中。</p>
<p><strong>整合时间因素</strong></p>
<p>到目前为止，我们的模型都是静态的。实际上，用户的偏好、用户对标的物的评分趋势、以及标的物的受欢迎程度都是随着时间变化的。拿电影来说，用户可能原来喜欢爱情类的电影，后面可能会转而喜欢科幻喜剧类电影，所以我们用包含时间的  来表示用户的偏好特性向量。用户开始对某个视频偏向于打高分，经过一段时间后，用户看的电影多了起来，用户的审美越来越挑剔，所以一般不会再对一个电影打很高的分数了，除非他觉得真的特别好，因此，我们可以用包含时间的  来表示用户的偏差随着时间而变化。对于标的物偏差也一样，一个电影可能开始不是很火，但是如果它的主演后面演了一部非常火的电影，也会将原来的电影热度带到一个新的高度。比如，前两年比较火的李现演的《亲爱的，热爱的》，导致李现人气高涨，他原来演的《南方有乔木》的百度搜索指数在《亲爱的，热爱的》播出期间高涨。因此，我们可以用包含时间的  来表示标的物偏差随着时间的变化而变化的趋势。标的物本身的特征  ，我们可以认为是稳定的，它代表的是标的物本身的固有属性或者品质，所以不会随着时间而变化。</p>
<p>基于上面的分析，我们最终的预测用户评分的公式整合时间因素后可以表达为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231212913.png" alt="img"></p>
<p><strong>整合用户对评分的置信度</strong></p>
<p>一般来说，用户对不同标的物的评分不是完全一样可信的，可能会受到外界其他因素的影响，比如某个视频播出后，主播发生了热点事件，肯定会影响用户对该视频的评价，节假日，特殊事件也会影响用户的评价。对于隐式反馈，一般我们用  和  来表示用户是否喜欢该标的物，多少有点绝对，更好的方式是引入一个喜欢的概率/置信度，用户对该标的物操作次数越多、时间越长、付出越大，相应的置信度也越大。因此，我们可以在用户对标的物的评分中增加一个置信度的因子  ，那么最终的优化公式就变为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231213243.png" alt="img"></p>
<p><strong>隐式反馈</strong></p>
<p>用二元变量  表示用户  对标的物的偏好，  表示用户  对标的物  有兴趣，  表示对标的物  无兴趣。  是用户  对标的物的隐式反馈，如观看视频的时长，点击次数等等。  和  的关系见下面公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231220341.png" alt="img"></p>
<p> 越大，有理由认为用户对标的物兴趣的置信度越高，比如一个文章读者看了好几篇，肯定比看一遍更能反映出读者对这篇文章的喜爱。具体可以用下面的公式来衡量用户  对标的物  的置信度，其中  是一个超参数，作者建议取  。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231221419.png" alt="img"></p>
<p>于是我们可以定义如下公式</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304231225576.png" alt="img"></p>
<p>将用户的操作  分解为置信度  和偏好  能够更好地反映隐式行为的特征，并且从实践上可以大幅提升预测的准确度。同时，通过该分解，利用代数上的一些技巧及该模型的巧妙设计，该算法的时间复杂度与用户操作行为总次数线性相关，不依赖于用户数和标的物数，因此非常容易并行化。</p>
<p>隐式反馈也有一些缺点，不像明确的用户评分，无法很好地表达负向反馈，用户购买一个物品可能是作为礼物送给别人的，他自己可能不喜欢这个物品，用户观看了某个视频，有可能是产品进入视频详情页时是自动起播的，这些行为是包含很多噪音的。</p>
<p><strong>整合用户和标的物metadata信息</strong></p>
<p>利用特征的嵌入向量之和来表示用户或者标的物向量，这就很好地将<code>metadata</code>信息整合到了用户和标的物向量中了，再利用用户向量   和标的物向量  的内积加上<code>bias</code>项，通过一个<code>logistic</code>函数来获得用户  对标的物  的偏好概率/得分，从这里的介绍可以看到，该模型很好地将矩阵分解和<code>metadata</code>信息整合到了一个框架之下。</p>
<h3 id="基于向量的召回"><a href="#基于向量的召回" class="headerlink" title="基于向量的召回"></a>基于向量的召回</h3><h4 id="FM召回"><a href="#FM召回" class="headerlink" title="FM召回"></a>FM召回</h4><p>FM用于排序详细介绍见后文经典排序模型。由于需要将 FM 模型用在召回，故将二阶特征交互项拆分为用户和物品项。有：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202004566.png" alt="img"></p>
<p>在比较用户与不同物品之间的匹配分时，只需要比较：（1）物品内部之间的特征交互得分；（2）用户和物品之间的特征交互得分。因此合并 FM 的一阶、二阶特征交互项，得到基于 FM 召回的匹配分计算公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202035154.png" alt="img"></p>
<h4 id="item2vec召回系列"><a href="#item2vec召回系列" class="headerlink" title="item2vec召回系列"></a>item2vec召回系列</h4><h5 id="Word2vec基础"><a href="#Word2vec基础" class="headerlink" title="Word2vec基础"></a>Word2vec基础</h5><p>Word2vec(Mikolov et al. 2013)是一个用来学习dense word vector的算法：</p>
<ol>
<li>我们使用<strong>大量的文本语料库</strong></li>
<li>词汇表中的每个单词都由一个<strong>词向量dense word vector</strong>表示</li>
<li>遍历文本中的每个位置 t，都有一个<strong>中心词 c（center） 和上下文词 o（“outside”）</strong>，如图1中的banking</li>
<li>在整个语料库上使用数学方法<strong>最大化单词o在单词c周围出现了这一事实</strong>，从而得到单词表中每一个单词的dense vector</li>
<li>不断调整词向量dense word vector以达到最好的效果</li>
</ol>
<p>Word2vec包含两个模型，<strong>Skip-gram与CBOW</strong>。我们希望<strong>最大化单词o在单词c周围出现了这一事实</strong>，而我们需要用数学语言表示“单词o在单词c周围出现了”这一事件，如此才能进行词向量的不断调整。很自然地，我们需要<strong>使用概率工具描述事件的发生</strong>，我们想到用条件概率  表示“给定中心词c,它的上下文词o在它周围出现了”。</p>
<p>下图展示了以“into”为中心词，窗口大小为2的情况下它的上下文词。以及相对应的 </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202054590.png" alt="img"></p>
<p>我们滑动窗口，再以banking为中心词</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202054939.png" alt="img"></p>
<p>那么，如果我们在整个语料库上不断地滑动窗口，我们可以得到所有位置的  ，我们希望在所有位置上<strong>最大化单词o在单词c周围出现了这一事实</strong>，由极大似然法可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202058666.png" alt="img"></p>
<p>此式还可以写为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202059177.png" alt="img"></p>
<p>加log，加负号，缩放大小可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202100516.png" alt="img"></p>
<p>上式即为<strong>skip-gram的损失函数</strong>，最小化损失函数，就可以得到合适的词向量</p>
<p>得到上式后，产生了两个问题：</p>
<ol>
<li>怎么表示？</li>
<li>为何最小化损失函数能够得到良好表示的词向量dense word vector？</li>
</ol>
<p>回答1：我们使用<strong>中心词c和上下文词o的相似性</strong>来计算  ，更具体地，相似性由<strong>词向量的点积</strong>表示：  。使用词向量的点积表示  的原因：（1）计算简单（1）出现在一起的词向量意义相关，则希望它们相似。又因为  是一个概率，所以我们在整个语料库上使用<strong>softmax</strong>将点积的值映射到概率：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202104262.png" alt="img"></p>
<p>注：注意到上图，中心词词向量为  ，而上下文词词向量为  。也就是说每个词会对应两个词向量，<strong>在词w做中心词时</strong>，使用  作为词向量，而在它做上下文词时，使用  作为词向量。这样做的原因是为了求导等操作时计算上的简便。当整个模型训练完成后，我们既可以使用  作为词  的词向量，也可以使用  作为词  的词向量，亦或是将二者平均。在下一部分的模型结构中，我们将更清楚地看到两个词向量究竟在模型的哪个位置。</p>
<p>回答2：由上文所述，  。所以损失函数是关于  和  的函数，我们通过梯度下降法调整  和  的值，最小化损失函数，即得到了良好表示的词向量。</p>
<h5 id="Word2vec模型结构"><a href="#Word2vec模型结构" class="headerlink" title="Word2vec模型结构"></a>Word2vec模型结构</h5><p>这是一个输入为  维的one-hot向量（V为整个词汇表的长度，这个向量只有一个1值，其余为0值表示一个词），单隐藏层（<strong>隐藏层的维度为N，这里是一个超参数，这个参数由我们定义，也就是词向量的维度</strong>），输出为  维的softmax层的模型。</p>
<p>为  的参数矩阵，为  的参数矩阵。</p>
<p>模型的输入为 形状的one-hot向量（V为整个词汇表的长度，这个向量只有一个1值，其余为0值表示一个词）。隐藏层的维度为N，这里是一个超参数，这个参数由我们定义，也就是词向量的维度。为  的参数矩阵。</p>
<p>我们这里，考虑Skip-gram算法，输入为中心词c的one-hot表示</p>
<p>由输入层到隐藏层，根据矩阵乘法规则，可知，<strong>的每一行即为词汇表中的每一个单词的词向量v</strong>， 的 inputs 乘上  的，隐藏层即为  维的  。</p>
<p>而中的每一列即为词汇表中的每一个单词的词向量u。根据乘法规则， 的隐藏层乘上  的参数矩阵，得到的  的输出层的每一个值即为 ，加上softmax变化即为 ，其中  的每一列就是周围词向量  。</p>
<p>有V个w,其中的P(o|c)即实际样本中的上下文词的概率，为我们最为关注的值。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202111969.png" alt="img"></p>
<p>如上文所述，Skip-gram为给定中心词，预测周围的词，即求  ，如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202113543.png" alt="img"></p>
<p>而CBOW为给定周围的词，预测中心词，即求  ,如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202113829.png" alt="img"></p>
<h5 id="item2Vec模型"><a href="#item2Vec模型" class="headerlink" title="item2Vec模型"></a>item2Vec模型</h5><p>Item2Vec 的原理十分简单，它是基于 Skip-Gram 模型的物品向量训练方法。但又存在一些区别，如下：</p>
<ul>
<li>词向量的训练是基于句子序列（sequence），但是物品向量的训练是基于物品集合（set）。</li>
<li>因此，物品向量的训练丢弃了空间、时间信息。</li>
</ul>
<p>Item2Vec 论文假设对于一个集合的物品，它们之间是相似的，与用户购买它们的顺序、时间无关。当然，该假设在其他场景下不一定使用，但是原论文只讨论了该场景下它们实验的有效性。由于忽略了空间信息，原文将共享同一集合的每对物品视为正样本。目标函数如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202119928.png" alt="img"></p>
<p>在 Skip-Gram 模型中，提到过每个单词  有2个特征表示。在 Item2Vec 中同样如此，论文中是将物品的中心词向量  作为物品的特征向量。作者还提到了其他两种方式来表示物品向量：</p>
<ul>
<li><strong>add</strong>：</li>
<li><strong>concat</strong>：</li>
</ul>
<h5 id="Airbnb召回"><a href="#Airbnb召回" class="headerlink" title="Airbnb召回"></a>Airbnb召回</h5><p>Airbnb 描述了两种 Embedding 的构建方法，分别为：</p>
<ul>
<li>用于描述短期实时性的个性化特征 Embedding：<strong>listing Embeddings</strong></li>
<li>用于描述长期的个性化特征 Embedding：<strong>user-type &amp; listing type Embeddings</strong></li>
</ul>
<h4 id="YouTubeDNN召回"><a href="#YouTubeDNN召回" class="headerlink" title="YouTubeDNN召回"></a>YouTubeDNN召回</h4><p>召回模型的结构如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202146491.png" alt="img"></p>
<p>它的输入主要是用户侧的特征，包括用户观看的历史video序列， 用户搜索的历史tokens， 然后就是用户的人文特征，比如地理位置， 性别，年龄这些。</p>
<ul>
<li><p>用户历史序列，历史搜索tokens这种序列性的特征: 一般长这样<code>[item_id5, item_id2, item_id3, ...]</code>， 这种id特征是高维稀疏，首先会通过一个embedding层，转成低维稠密的embedding特征，即历史序列里面的每个id都会对应一个embedding向量，这样历史序列就变成了多个embedding向量的形式， 这些向量一般会进行融合，常见的是average pooling，即每一维求平均得到一个最终向量来表示用户的历史兴趣或搜索兴趣。论文里面使用了用户最近的50次观看历史，用户最近50次搜索历史token，embedding维度是256维， 采用的average pooling。  当然，这里还可以把item的类别信息也隐射到embedding，与前面的concat起来。</p>
</li>
<li><p>用户人文特征， 这种特征处理方式就是离散型的依然是labelEncoder，然后embedding转成低维稠密， 而连续型特征，一般是先归一化操作，然后直接输入，当然有的也通过分桶，转成离散特征，这里不过多整理，特征工程做的事情了。  当然，这里还有一波操作值得注意，就是连续型特征除了用了本身，还用了  ，  这种， 可以加入更多非线性，增加模型表达能力。这些特征对新用户的推荐会比较有帮助，常见的用户的地理位置， 设备， 性别，年龄等。</p>
</li>
<li><p>这里一个比较特色的特征是example age。我们知道，视频有明显的生命周期，例如刚上传的视频比之后更受欢迎，也就是用户往往喜欢看最新的东西，而不管它是不是和用户相关，所以视频的流行度随着时间的分布是高度非稳态变化的（下面图中的绿色曲线）。但是我们模型训练的时候，是基于历史数据训练的（历史观看记录的平均），所以模型对播放某个视频预测值的期望会倾向于其在训练数据时间内的平均播放概率（平均热度），图中蓝色线。但如图中绿色线，实际上该视频在训练数据时间窗口内热度很可能不均匀， 用户本身就喜欢新上传的内容。所以，为了让模型学习到用户这种对新颖内容的bias，作者引入了”example age”这个特征来捕捉视频的生命周期。</p>
<p>“example age”定义为， 其中  是训练数据中所有样本的时间最大值，而  为当前样本的时间。<strong>线上预测时， 直接把example age全部设为0或一个小的负值，这样就不依赖于各个视频的上传时间了</strong>。 </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202158449.png" alt="img"></p>
<p><code>example age</code>这个特征到这里还没完， 原来加入这种时间bias的传统方法是使用<code>video age</code>， 即一个video上传到样本生成的这段时间跨度，对于某个视频的不同样本，其实这两种定义是等价的，因为他们的和是一个常数。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305202201783.png" alt="img"></p>
</li>
</ul>
<h4 id="双塔召回"><a href="#双塔召回" class="headerlink" title="双塔召回"></a>双塔召回</h4><h5 id="经典双塔"><a href="#经典双塔" class="headerlink" title="经典双塔"></a>经典双塔</h5><h6 id="经典双塔模型"><a href="#经典双塔模型" class="headerlink" title="经典双塔模型"></a>经典双塔模型</h6><p>在推荐系统中，最为关键的问题是如何做好用户与item的匹配问题，因此对于推荐系统中DSSM模型的则是为 user 和 item 分别构建独立的子网络塔式结构，利用user和item的曝光或点击日期进行训练，最终得到user侧的embedding和item侧的embedding。因此在推荐系统中，常见的模型结构如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211446441.png" alt="img"></p>
<p>从模型结构上来看，主要包括两个部分：user侧塔和item侧塔，对于每个塔分别是一个DNN结构。通过两侧的特征输入，通过DNN模块到user和item的embedding，然后计算两者之间的相似度(常用內积或者余弦值，下面会说这两种方式的联系和区别)，因此对于user和item两侧最终得到的embedding维度需要保持一致，即最后一层全连接层隐藏单元个数相同。</p>
<p>在召回模型中，将这种检索行为视为多类分类问题，类似于YouTubeDNN模型。将物料库中所有的item视为一个类别，因此损失函数需要计算每个类的概率值：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211448528.png" alt="img"></p>
<p>其中表示两个向量的相似度，表示预测类别的概率，表示物料库所有的item。但是在实际场景中，由于物料库中的item数量巨大，在计算上式时会十分的耗时，因此会采样一定的数量的负样本来近似计算，后面针对负样本的采样做一些简单介绍。</p>
<p>以上就是推荐系统中经典的双塔模型，之所以在实际应用中非常常见，是因为<strong>在海量的候选数据进行召回的场景下，速度很快，效果说不上极端好，但一般而言效果也够用了</strong>。之所以双塔模型在服务时速度很快，是因为模型结构简单(两侧没有特征交叉)，但这也带来了问题，双塔的结构无法考虑两侧特征之间的交互信息，<strong>在一定程度上牺牲掉模型的部分精准性</strong>。例如在精排模型中，来自user侧和item侧的特征会在第一层NLP层就可以做细粒度的特征交互，而对于双塔模型，user侧和item侧的特征只会在最后的內积计算时发生，这就导致很多有用的信息在经过DNN结构时就已经被其他特征所模糊了，因此双塔结构由于其结构问题先天就会存在这样的问题。下面针对这个问题来看看一下现有模型的解决思路。</p>
<h6 id="SENet双塔模型"><a href="#SENet双塔模型" class="headerlink" title="SENet双塔模型"></a>SENet双塔模型</h6><p>SENet由Momenta在2017年提出，当时是一种应用于图像处理的新型网络结构。后来张俊林大佬将SENet引入了精排模型<strong>FiBiNET</strong>中，其作用是为了将大量长尾的低频特征抛弃，弱化不靠谱低频特征embedding的负面影响，强化高频特征的重要作用。那SENet结构到底是怎么样的呢，为什么可以起到特征筛选的作用？</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211452527.png" alt="img"></p>
<p>从上图可以看出SENET主要分为三个步骤Squeeze, Excitation, Re-weight：</p>
<ul>
<li><p>Squeeze阶段：我们对每个特征的Embedding向量进行数据压缩与信息汇总，即在Embedding维度计算均值：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211453721.png" alt="img"></p>
<p>其中k表示Embedding的维度，Squeeze阶段是将每个特征的Squeeze转换成单一的数值。</p>
</li>
<li><p>Excitation阶段：这阶段是根据上一阶段得到的向量进行缩放，即将上阶段的得到的  的向量先压缩成  长度，然后在放回到   的维度，其中表示压缩的程度。这个过程的具体操作就是经过两层DNN。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211454010.png" alt="img"></p>
<p>该过程可以理解为：对于当前所有输入的特征，通过相互发生关联，来动态地判断哪些特征重要，哪些特征不重要，而这体现在Excitation阶段的输出结果 ，其反应每个特征对应的重要性权重。</p>
</li>
<li><p>Re-weight阶段：是将Excitation阶段得到的每个特征对应的权重  再乘回到特征对应的Embedding里，就完成了对特征重要性的加权操作。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211454382.png" alt="img"></p>
</li>
</ul>
<p>以上简单的介绍了一下SENet结构，可以发现这种结构可以通过对特征embedding先压缩，再交互，再选择，进而实现特征选择的效果。</p>
<p>此外张俊林大佬还将SENet应用于双塔模型中<strong>（SENet双塔模型）</strong>，模型结构如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211518409.png" alt="img"></p>
<p>从上图可以发现，具体地是将双塔中的user塔和Item侧塔的特征输入部分加上一个SENet模块，通过SENet网络，动态地学习这些特征的重要性，通过小权重抑制噪音或者无效低频特征，通过大权重放大重要特征影响的目的。</p>
<p>之所以SENet双塔模型是有效的呢？张俊林老师的解释是：双塔模型的问题在于User侧特征和Item侧特征交互太晚，在高层交互，会造成细节信息，也就是具体特征信息的损失，影响两侧特征交叉的效果。而SENet模块在最底层就进行了特征的过滤，使得很多无效低频特征即使被过滤掉，这样更多有用的信息被保留到了双塔的最高层，使得两侧的交叉效果很好；同时由于SENet模块选择出更加重要的信息，使得User侧和Item侧特征之间的交互表达方面增强了DNN双塔的能力。</p>
<p>因此SENet双塔模型主要是从特征选择的角度，提高了两侧特征交叉的有效性，减少了噪音对有效信息的干扰，进而提高了双塔模型的效果。此外，除了这样的方式，还可以通过增加通道的方式来增强两侧的信息交互。即对于user和item两侧不仅仅使用一个DNN结构，而是可以通过不同结构(如FM，DCN等)来建模user和item的自身特征交叉，例如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211523344.png" alt="img"></p>
<p>这样对于user和item侧会得到多个embedding，类似于多兴趣的概念。通过得到的多个user和item的embedding，然后分别计算余弦值再相加（两侧的Embedding维度需要对齐），进而增加了双塔两侧的信息交互。而这种方法在腾讯进行过尝试，他们提出的“并联”双塔就是按照这样的思路。</p>
<h6 id="多目标的双塔模型"><a href="#多目标的双塔模型" class="headerlink" title="多目标的双塔模型"></a>多目标的双塔模型</h6><p>现如今多任务学习在实际的应用场景也十分的常见，主要是因为实际场景中业务复杂，往往有很多的衡量指标，例如点击，评论，收藏，关注，转发等。在多任务学习中，往往会针对不同的任务使用一个独有的tower，然后优化不同任务损失。那么针对双塔模型应该如何构建多任务学习框架呢？</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211528560.png" alt="img"></p>
<p>如上图所示，在user侧和item侧分别通过多个通道(DNN结构)为每个任务得到一个user embedding和item embedding，然后针对不同的目标分别计算user 和 item 的相似度，并计算各个目标的损失，最后的优化目标可以是多个任务损失之和，或者使用多任务学习中的动态损失权重。</p>
<p>这种模型结构，可以针对多目标进行联合建模，通过多任务学习的结构，一方面可以利用不同任务之间的信息共享，为一些稀疏特征提供其他任务中的迁移信息，另一方面可以在召回时，直接使用一个模型得到多个目标预测，解决了多个模型维护困难的问题。也就是说，在线上通过这一个模型就可以同时得到多个指标，例如视频场景，一个模型就可以直接得到点赞，品论，转发等目标的预测值，进而通过这些值计算分数获得最终的Top-K召回结果。</p>
<h6 id="模型的应用"><a href="#模型的应用" class="headerlink" title="模型的应用"></a>模型的应用</h6><p>在实际的工业应用场景中，分为离线训练和在线服务两个环节。</p>
<ul>
<li>在离线训练阶段，同过训练数据，训练好模型参数。然后将候选库中所有的item集合离线计算得到对应的embedding，并存储进ANN检索系统，比如faiss。为什么将离线计算item集合，主要是因为item的会相对稳定，不会频繁的变动，而对于用户而言，如果将用户行为作为user侧的输入，那么user的embedding会随着用户行为的发生而不断变化，因此对于user侧的embedding需要实时的计算。</li>
<li>在线服务阶段，正是因为用户的行为变化需要被即使的反应在用户的embedding中，以更快的反应用户当前的兴趣，即可以实时地体现用户即时兴趣的变化。因此在线服务阶段需要实时的通过拼接用户特征，输入到user侧的DNN当中，进而得到user embedding，在通过user embedding去 faiss中进行ANN检索，召回最相似的K个item embedding。</li>
</ul>
<p>可以看到双塔模型结构十分的适合实际的应用场景，在快速服务的同时，还可以更快的反应用户即时兴趣的变化。</p>
<h5 id="Youtube双塔"><a href="#Youtube双塔" class="headerlink" title="Youtube双塔"></a>Youtube双塔</h5><p><strong>文章核心思想</strong></p>
<ul>
<li>在大规模的推荐系统中，利用双塔模型对user-item对的交互关系进行建模，学习 ， 向量与  向量.</li>
<li>针对大规模流数据，提出in-batch softmax损失函数与流数据频率估计方法(Streaming Frequency Estimation)，可以更好的适应item的多种数据分布。</li>
</ul>
<p><strong>文章主要贡献</strong></p>
<ul>
<li>提出了改进的流数据频率估计方法：针对流数据来估计item出现的频率，利用实验分析估计结果的偏差与方差，模拟实验证明该方法在数据动态变化时的功效</li>
<li>提出了双塔模型架构：提供了一个针对大规模的检索推荐系统，包括了 in-batch softmax 损失函数与流数据频率估计方法，减少了负采样在每个batch中可能会出现的采样偏差问题。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211603934.png" alt="img"></p>
<p>模型结构如上图所示，论文旨在对用户和物品建立两个不同的模型，将它们投影到相同维度的空间：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211605627.png" alt="img"></p>
<p>模型的输出为用户与物品向量的内积：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211606515.png" alt="img"></p>
<p>模型的目标是为了学习参数 ， 样本集被表示为如下格式 ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211606561.png" alt="img"></p>
<ul>
<li>在推荐系统中， 可以扩展来捕获用户对不同候选物品的参与度。</li>
<li>例如，在新闻推荐中  可以是用户在某篇文章上花费的时间。</li>
</ul>
<h6 id="模型流程"><a href="#模型流程" class="headerlink" title="模型流程"></a>模型流程</h6><ol>
<li><p>给定用户 ，基于 softmax 函数从物料库  中选中候选物品  的概率为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211612604.png" alt="img"></p>
<ul>
<li><p>考虑到相关奖励  ，加权对数似然函数的定义如下：  </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211612034.png" alt="img"></p>
</li>
</ul>
</li>
<li><p>原表达式  中的分母需要遍历物料库中所有的物品，计算成本太高，故对分母中的物品要进行负采样。为了提高负采样的速度，一般是直接从训练样本所在 Batch 中进行负样本选择。于是有：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211613957.png" alt="img"></p>
<ul>
<li>其中， 表示与样本  同在一个 Batch 的物品集合。</li>
<li>举例来说，对于用户1，Batch 内其他用户的正样本是用户1的负样本。</li>
</ul>
</li>
<li><p>一般而言，负采样分为 <strong>Easy Negative Sample</strong> 和 <strong>Hard Negative Sample</strong> 。</p>
<ul>
<li><p>这里的 Easy Negative Sample 一般是直接从<strong>全局物料库</strong>中随机选取的负样本，由于每个用户感兴趣的物品有限，而物料库又往往很大，故即便从物料库中随机选取负样本，也大概率是用户不感兴趣的。</p>
</li>
<li><p>在真实场景中，热门物品占据了绝大多数的购买点击。而这些热门物品往往只占据物料库物品的少部分，绝大部分物品是冷门物品。</p>
<ul>
<li>在物料库中随机选择负样本，往往被选中的是冷门物品。这就会造成马太效应，热门物品更热，冷门物品更冷。</li>
<li>一种解决方式时，在对训练样本进行负采样时，提高热门物品被选为负样本的概率，工业界的经验做法是物品被选为负样本的概率正比于物品点击次数的 0.75 次幂。</li>
</ul>
</li>
<li><p>前面提到 Batch 内进行负采样，热门物品出现在一个 Batch 的概率正比于它的点击次数。问题是，热门物品被选为负样本的概率过高了（一般正比于点击次数的 0.75 次幂），导致热门物品被过度打压。</p>
</li>
<li><p>在本文中，为了避免对热门物品进行过度惩罚，进行了纠偏。公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211616699.png" alt="img"></p>
<ul>
<li>在内积  的基础上，减去了物品  的采样概率的对数。</li>
</ul>
</li>
</ul>
</li>
<li><p>纠偏后，物品  被选中的概率为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211617066.png" alt="img"></p>
<ul>
<li>此时，batch loss function 的表示式如下：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211617038.png" alt="img"></p>
<ul>
<li>通过 SGD 和学习率，来优化模型参数  ：</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211617296.png" alt="img"></p>
</li>
<li><p>Normalization and Temperature</p>
<ul>
<li><p>最后一层，得到用户和物品的特征 Embedding 表示后，再进行进行  归一化：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211618509.png" alt="img"></p>
<ul>
<li>本质上，其实就是将用户和物品的向量内积转换为了余弦相似度。</li>
</ul>
</li>
<li><p>对于内积的结果，再除以温度参数 ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211618888.png" alt="img"></p>
<ul>
<li>论文提到，这样有利于提高预测准确度。</li>
<li>从实验结果来看，温度参数  一般小于 ，所以感觉就是放大了内积结果。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="基于图的召回"><a href="#基于图的召回" class="headerlink" title="基于图的召回"></a>基于图的召回</h3><h4 id="EGES"><a href="#EGES" class="headerlink" title="EGES"></a>EGES</h4><p><strong>Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba</strong></p>
<p>在电商领域，推荐已经是不可或缺的一部分，旨在为用户的喜好提供有趣的物品，并且成为淘宝和阿里巴巴收入的重要引擎。尽管学术界和产业界的各种推荐方法都取得了成功，如协同过滤、基于内容的方法和基于深度学习的方法，但由于用户和项目的数十亿规模，传统的方法已经不能满足于实际的需求，主要的问题体现在三个方面：</p>
<ul>
<li>可扩展性：现有的推荐方法无法扩展到在拥有十亿的用户和二十亿商品的淘宝中。</li>
<li>稀疏性：存在大量的物品与用户的交互行为稀疏。即用户的交互到多集中于以下部分商品，存在大量商品很少被用户交互。</li>
<li>冷启动：在淘宝中，每分钟会上传很多新的商品，由于这些商品没有用户行为的信息（点击、购买等），无法进行很好的预测。</li>
</ul>
<p><strong>思路</strong></p>
<p>根据上述所面临的三个问题，本文针对性的提出了三个模型予以解决：Base Graph Embedding（BGE）；Graph Embedding with Side Information（GES）；Enhanced Graph Embedding with Side Information（EGES）。</p>
<p>考虑可扩展性的问题，图嵌入的随机游走方式可以在物品图上捕获<strong>物品之间高阶相似性</strong>，即Base Graph Embedding（BGE）方法。其不同于CF方法，除了考虑物品的共现，还考虑到了行为的序列信息。</p>
<p>考虑到稀疏性和冷启物品问题，在图嵌入的基础上，考虑了节点的属性信息。希望具有相似属性的物品可以在空间上相似，即希望通过头部物品，提高属性信息的泛化能力，进而帮助尾部和冷启物品获取更加准确的embedding，即Graph Embedding with Side Information（GES）方法。</p>
<p>考虑到不同属性信息对于学习embedding的贡献不同，因此在聚合不同的属性信息时，动态的学习不同属性对于学习节点的embedding所参与的重要性权重，即Enhanced Graph Embedding with Side Information（EGES）。</p>
<h5 id="构建物品图"><a href="#构建物品图" class="headerlink" title="构建物品图"></a>构建物品图</h5><p>在介绍三个模型之前，我们首先需要构建好item-item图。由于基于CF的方法仅考虑物品之间的共现，忽略了行为的序列信息(即序列中相邻的物品之间的语义信息)，因此item-item图的构建方式如下图所示。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211633299.png" alt="img"></p>
<p>首先根据用户的session行为序列构建网络结构，即序列中相邻两个item之间在存在边，并且是有向带权图。物品图边上的权重为所有用户行为序列中两个 item 共现的次数，最终构造出来简单的有向有权图。</p>
<p>值得注意的是，本文通过行为序列中物品的共现来表示其中的<strong>语义信息</strong>，并将这种语义信息理解为<strong>物品之间的相似性</strong>，并将共现频次作为相似性的一个度量值。其次基于用户的历史行为序列数据，一般不太可能取全量的历史序列数据，一方面行为数据量过大，一方面用户的兴趣会随时间发生演变，因此在处理行为序列时会设置了一个窗口来截断历史序列数据，切分出来的序列称为session。</p>
<p>由于实际中会存在一些现实因素，数据中会有一些噪音，需要特殊处理，主要分为三个方面：</p>
<ul>
<li>从行为方面考虑，用户在点击后停留的时间少于1秒，可以认为是误点，需要移除。</li>
<li>从用户方面考虑，淘宝场景中会有一些过度活跃用户。本文对活跃用户的定义是三月内购买商品数超过1000，或者点击数超过3500，就可以认为是一个无效用户，需要去除。</li>
<li>从商品方面考虑，存在一些商品频繁的修改，即ID对应的商品频繁更新，这使得这个ID可能变成一个完全不同的商品，这就需要移除与这个ID相关的这个商品。</li>
</ul>
<h5 id="图嵌入-BGE"><a href="#图嵌入-BGE" class="headerlink" title="图嵌入(BGE)"></a>图嵌入(BGE)</h5><p>对于图嵌入模型，第一步先进行随机游走得到物品序列；第二步通过skip-gram为图上节点生成embedding。那么对于随机游走的思想：如何利用随机游走在图中生成的序列？不同于DeepWalk中的随机游走，本文的采样策略使用的是带权游走策略，不同权重的游走到的概率不同，（其本质上就是node2vec），传统的node2vec方法可以直接支持有向带权图。因此在给定图的邻接矩阵M后(表示节点之间的边权重)，随机游走中每次转移的概率为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211638065.png" alt="img"></p>
<p>其中为边上的权重，表示节点所有邻居节点集合，并且随机游走的转移概率的对每个节点所有邻接边权重的归一化结果。在随机游走之后，每个item得到一个序列。</p>
<p>然后类似于word2vec，为每个item学习embedding，于是优化目标如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211639379.png" alt="img"></p>
<p>其中，w 为窗口大小。考虑独立性假设的话，上面的式子可以进一步化简：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211640294.png" alt="img"></p>
<p>这样看起来就很直观了，在已知物品 i 时，最大化序列中(上下文)其他物品 j 的条件概率。为了近似计算，采样了Negative sampling，上面的优化目标可以化简得到如下式子：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211640558.png" alt="img"></p>
<p>其中表示负样本集合，负采样个数越多，结果越好。</p>
<h5 id="基于side-information的图嵌入（GES）"><a href="#基于side-information的图嵌入（GES）" class="headerlink" title="基于side information的图嵌入（GES）"></a>基于side information的图嵌入（GES）</h5><p>尽管BGE将行为序列关系编码进物品的embedding中，从而从用户行为中捕捉高阶相似性。但是这里有个问题，对于新加入的商品，由于未和用户产生过交互，所以不会出现在item-item图上，进而模型无法学习到其embedding，即无法解决冷启动问题。</p>
<p>为了解决冷启问题，本文通过使用side information（ 类别，店铺, 价格等）加入模型的训练过程中，使得模型最终的泛化能力体现在商品的side information上。这样通过<strong>side information学习到的embedding来表示具体的商品</strong>，使得相似side information的物品可以得到在空间上相近的表示，进而来增强 BGE。</p>
<p>那么对于每个商品如何通过side information的embedidng来表示呢？对于随机游走之后得到的商品序列，其中每个商品由其id和属性(品牌，价格等)组成。用公式表示，对于序列中的每一个物品可以得到,（n+1）个向量表示，表示物品v，剩下是side information的embedding。然后将所有的side information聚合成一个整体来表示物品，聚合方式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211642022.png" alt="img"></p>
<p>其中，是商品 v 的聚合后的 embedding 向量。</p>
<h5 id="增强型EGS（EGES）"><a href="#增强型EGS（EGES）" class="headerlink" title="增强型EGS（EGES）"></a>增强型EGS（EGES）</h5><p>尽管 GES 相比 BGE 在性能上有了提升，但是在聚合多个属性向量得到商品的embedding的过程中，不同 side information的聚合依然存在问题。在GES中采用 average-pooling 是在假设不同种类的 side information 对商品embedding的贡献是相等的，但实际中却并非如此。例如，购买 Iphone 的用户更可能倾向于 Macbook 或者 Ipad，相比于价格属性，品牌属性相对于苹果类商品具有更重要的影响。因此，根据实际现状，不同类型的 side information 对商品的表示是具有不同的贡献值的。</p>
<p>针对上述问题，作者提出了weight pooling方法来聚合不同类型的 side information。具体地，EGES 与 GES 的区别在聚合不同类型 side information计算不同的权重，根据权重聚合 side information 得到商品的embedding，如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211645673.png" alt="img"></p>
<p>其中  表示每个side information 用于计算权重的参数向量，最终通过下面的公式得到商品的embedding：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211646357.png" alt="img"></p>
<p>这里对参数  先做指数变换，目的是为了保证每个边界信息的贡献都能大于0，然后通过归一化为每个特征得到一个o-1之内的权重。最终物品的embedding通过权重进行加权聚合得到，进而优化损失函数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211646534.png" alt="img"></p>
<p> y是标签符号，等于1时表示正样本，等于0时表示负样本。表示商品 v 的最终的隐层表示，表示训练数据中的上下文节点的embedding。</p>
<h4 id="PinSAGE"><a href="#PinSAGE" class="headerlink" title="PinSAGE"></a>PinSAGE</h4><p><strong>Graph Convolutional Neural Networks for Web-Scale Recommender Systems</strong></p>
<p>该论文是斯坦福大学和Pinterest公司与2018年联合发表与KDD上的一篇关于GCN成功应用于工业级推荐系统的工作。该论文提到的PinSage模型，是在GraphSAGE的理论基础进行了更改，以适用于实际的工业场景。下面将简单介绍一下GraphSAGE的原理，以及Pinsage的核心和细节。</p>
<h5 id="GraphSAGE原理"><a href="#GraphSAGE原理" class="headerlink" title="GraphSAGE原理"></a>GraphSAGE原理</h5><p>GraphSAGE提出的前提是因为基于直推式(transductive)学习的图卷积网络无法适应工业界的大多数业务场景。我们知道的是，基于直推式学习的图卷积网络是通过拉普拉斯矩阵直接为图上的每个节点学习embedding表示，每次学习是针对于当前图上所有的节点。然而在实际的工业场景中，图中的结构和节点都不可能是固定的，会随着时间的变化而发生改变。例如在Pinterest公司的场景下，每分钟都会上传新的照片素材，同时也会有新用户不断的注册，那么图上的节点会不断的变化。在这样的场景中，直推式学习的方法就需要不断的重新训练才能够为新加入的节点学习embedding，导致在实际场景中无法投入使用。</p>
<p>在这样的背景下，斯坦福大学提出了一种归纳(inductive)学习的GCN方法——GraphSAGE，即<strong>通过聚合邻居信息的方式为给定的节点学习embedding</strong>。不同于直推式(transductive)学习，GraphSAGE是通过学习聚合节点邻居生成节点Embedding的函数的方式，为任意节点学习embedding，进而将GCN扩展成归纳学习任务。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211711238.png" alt="img"></p>
<p>上面这个公式可以非常直观的让我们理解GraphSAGE的原理。</p>
<ul>
<li>表示图上节点的初始化表示，等同于节点自身的特征。</li>
<li>表示第k层卷积后的节点表示，其来源于两个部分：<ul>
<li>第一部分来源于节点v的邻居节点集合，利用邻居节点的第k-1层卷积后的特征进行 （  ）后，在进行线性变换。这里<strong>借助图上的边将邻居节点的信息通过边关系聚合到节点表示中(简称卷积操作)</strong>。</li>
<li>第二部分来源于节点v的第k-1层卷积后的特征，进行线性变换。总的来说图卷积的思想是<strong>在对自身做多次非线性变换时，同时利用边关系聚合邻居节点信息。</strong></li>
</ul>
</li>
<li>最后一次卷积结果作为节点的最终表示，以用于下游任务(节点分类，链路预测或节点召回)。</li>
</ul>
<p>可以发现相比传统的方法(MLP，CNN，DeepWalk 或 EGES)，GCN或GraphSAGE存在一些优势：</p>
<ol>
<li>相比于传统的深度学习方法(MLP,CNN)，GCN在对自身节点进行非线性变换时，同时考虑了图中的邻接关系。从CNN的角度理解，GCN通过堆叠多层结构在图结构数据上拥有更大的<strong>感受野</strong>，利用更加广域内的信息。</li>
<li>相比于图嵌入学习方法(DeepWalk，EGES)，GCN在学习节点表示的过程中，在利用节点自身的属性信息之外，更好的利用图结构上的边信息。相比于借助随机采样的方式来使用边信息，GCN的方式能从全局的角度利用的邻居信息。此外，类似于GraphSAGE这种归纳(inductive)学习的GCN方法，通过学习聚合节点邻居生成节点Embedding的函数的方式，更适用于图结构和节点会不断变化的工业场景。</li>
</ol>
<p>在采样得到目标节点的邻居集之后，那么如何聚合邻居节点的信息来更新目标节点的嵌入表示呢？下面就来看看GraphSAGE中提及的四个聚合函数。</p>
<h5 id="GraphSAGE的采样和聚合"><a href="#GraphSAGE的采样和聚合" class="headerlink" title="GraphSAGE的采样和聚合"></a>GraphSAGE的采样和聚合</h5><p>通过上面的公式可以知道，得到节点的表示主要依赖于两部分，其中一部分其邻居节点。因此对于GraphSAGE的关键主要分为两步：Sample采样和Aggregate聚合。其中Sample的作用是从庞大的邻居节点中选出用于聚合的邻居节点集合以达到降低迭代计算复杂度，而聚合操作就是如何利用邻居节点的表示来更新节点v的表示，已达到聚合作用。具体的过程如下伪代码所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211716358.png" alt="img"></p>
<p>GraphSAGE的minibatch算法的思路是针对Batch内的所有节点，通过采样和聚合节点，为每一个节点学习一个embedding。</p>
<p><strong>邻居采样</strong></p>
<p>GraphSAGE的具体采样过程是，首先根据中心节点集合，对集合中每个中心节点通过随机采样的方式对其邻居节点采样固定数量S个(如果邻居节点数量大于S，采用无放回抽样；如果小于S，则采用有放回抽样)，形成的集合表示为；以此类推每次都是为前一个得到的集合的每个节点随机采样S个邻居，最终得到第k层的所有需要参与计算的节点集合。值得注意的有两点：<strong>为什么需要采样并且固定采样数量S？</strong> <strong>为什么第k层所采样的节点集合表示为？</strong></p>
<p>进行邻居采样并固定采样数量S主要是因为：1. 采样邻居节点避免了在全图的搜索以及使用全部邻居节点所导致计算复杂度高的问题；2. 可以通过采样使得部分节点更同质化，即两个相似的节点具有相同表达形式。3. 采样固定数量是保持每个batch的计算占用空间是固定的，方便进行批量训练。</p>
<p>第k层所采样的节点集合表示为主要是因为：采样和聚合过程是相反的，即采样时我们是从中心节点组层进行采样，而聚合的过程是从中心节点的第k阶邻居逐层聚合得到前一层的节点表示。因此可以认为聚合阶段是：将k阶邻居的信息聚合到k-1阶邻居上，k-1阶邻居的信息聚合到k-2阶邻居上，….，1阶邻居的信息聚合到中心节点上的过程。</p>
<p><strong>聚合函数</strong></p>
<p>如何对于采样到的节点集进行聚合，介绍的4种方式：Mean 聚合、Convolutional 聚合、LSTM聚合以及Pooling聚合。由于邻居节点是无序的，所以希望构造的聚合函数具有<strong>对称性(即输出的结果不因输入排序的不同而改变)</strong>，同时拥有<strong>较强的表达能力</strong>。</p>
<ul>
<li>Mean 聚合：首先会对邻居节点按照<strong>element-wise</strong>进行均值聚合，然后将当前节点k-1层得到特征与邻居节点均值聚合后的特征 <strong>分别</strong>送入全连接网络后<strong>相加</strong>得到结果。</li>
<li>Convolutional 聚合：这是一种基于GCN聚合方式的变种，首先对邻居节点特征和自身节点特征求均值，得到的聚合特征送入到全连接网络中。与Mean不同的是，这里<strong>只经过一个全连接层</strong>。</li>
<li>LSTM聚合：由于LSTM可以捕捉到序列信息，因此相比于Mean聚合，这种聚合方式的<strong>表达能力更强</strong>；但由于LSTM对于输入是有序的，因此该方法不具备<strong>对称性</strong>。作者对于无序的节点进行随机排列以调整LSTM所需的有序性。</li>
<li>Pooling聚合：对于邻居节点和中心节点进行一次非线性转化，将结果进行一次基于<strong>element-wise</strong>的<strong>最大池化</strong>操作。该种方式具有<strong>较强的表达能力</strong>的同时还具有<strong>对称性</strong>。</li>
</ul>
<p>综上，可以发现GraphSAGE之所以可以用于大规模的工业场景，主要是因为模型主要是通过学习聚合函数，通过归纳式的学习方法为节点学习特征表示。</p>
<h5 id="PinSAGE-1"><a href="#PinSAGE-1" class="headerlink" title="PinSAGE"></a>PinSAGE</h5><p>PinSAGE 模型是Pinterest 在GraphSAGE 的基础上实现的可以应用于实际工业场景的召回算法。Pinterest 公司的主要业务是采用瀑布流的形式向用户展现图片，无需用户翻页，新的图片会自动加载。因此在Pinterest网站上，有大量的图片(被称为pins)，而用户可以将喜欢的图片分类，即将pins钉在画板 boards上。可以发现基于这样的场景，pin相当于普通推荐场景中item，用户<strong>钉</strong>的行为可以认为是用于的交互行为。于是PinSAGE 模型主要应用的思路是，基于GraphSAGE 的原理学习到聚合方法，并为每个图片(pin)学习一个向量表示，然后基于pin的向量表示做<strong>item2item的召回</strong>。</p>
<p>可以知道的是，PinSAGE 是在GraphSAGE的基础上进行改进以适应实际的工业场景，因此除了改进卷积操作中的邻居采样策略以及聚合函数的同时还有一些工程技巧上的改进，使得在大数据场景下能更快更好的进行模型训练。因此在了解GraphSAGE的原理后，我们详细的了解一下本文的主要改进以及与GraphSAGE的区别。</p>
<p><strong>重要性采样</strong></p>
<p>在实际场景当中，一个item可能被数以百万，千万的用户交互过，所以不可能聚合所有邻居节点是不可行的，只可能是采样部分邻居进行信息聚合。但是如果采用GraphSAGE中随机采样的方法，由于采样的邻居有限(这里是相对于所有节点而言)，会存在一定的偏差。因此PinSAGE 在采样中考虑了更加重要的邻居节点，即卷积时只注重部分重要的邻居节点信息，已达到高效计算的同时又可以消除偏置。</p>
<p>PinSAGE使用重要性采样方法，即需要为每个邻居节点计算一个重要性权重，根据权重选取top-t的邻居作为聚合时的邻居集合。其中计算重要性的过程是，以目标节点为起点，进行random-walk，采样结束之后计算所有节点访问数的L1-normalized作为重要性权重，同时这个权重也会在聚合过程中加以使用(<strong>加权聚合</strong>)。</p>
<p>这里对于<strong>计算权重之后如何得到top-t的邻居节点，</strong>原文并没有直接的叙述。这里可以有两种做法，第一种就是直接采用重要权重，这种方法言简意赅，比较直观。第二种做法就是对游走得到的所有邻居进行随机抽样，而计算出的权重可以用于聚合阶段。个人理解第二种做法的可行性出于两点原因，其一是这样方法可以避免存在一些item由于权重系数低永远不会被选中的问题；其二可能并不是将所有重要性的邻居进行聚合更合理，毕竟重要性权重是通过随机采样而得到的，具有一定的随机性。当然以上两种方法都是可行的方案，可以通过尝试看看具体哪种方法会更有效。</p>
<p><strong>聚合函数</strong></p>
<p>PinSAGE中提到的Convolve算法（单层图卷积操作）相当于GraphSAGE算法的聚合过程，在实际执行过程中通过对每一层执行一次图卷积操作以得到不同阶邻居的信息，具体过程如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211728762.png" alt="img"></p>
<p>上述的单层图卷积过程如下三步：</p>
<ol>
<li>聚合邻居： 先将所有的邻居节点经过一次非线性转化(一层DNN)，再由聚合函数(Pooling聚合) （如元素平均，<strong>加权和</strong>等）将所有邻居信息聚合成目标节点的embedding。这里的加权聚合采用的是通过random-walk得到的重要性权重。</li>
<li>更新当前节点的embedding：将目标节点当前的向量  与步骤1中聚合得到的邻居向量  进行拼接，在通过一次非线性转化。</li>
<li>归一化操作：对目标节点向量  归一化。</li>
</ol>
<p>Convolve算法的聚合方法与GraphSAGE的Pooling聚合函数相同，主要区别在于对更新得到的向量  进行归一化操作，<strong>可以使训练更稳定，以及在近似查找最近邻的应用中更有效率。</strong></p>
<p><strong>基于mini-batch堆叠多层图卷积</strong></p>
<p>与GraphSAGE类似，采用的是基于mini-batch 的方式进行训练。之所以这么做的原因是因为什么呢？在实际的工业场景中，由于用户交互图非常庞大，无法对于所有的节点同时学习一个embedding，因此需要从原始图上寻找与 mini-batch 节点相关的子图。具体地是说，对于mini-batch内的所有节点，会通过采样的方式逐层的寻找相关邻居节点，再通过对每一层的节点做一次图卷积操作，以从k阶邻居节点聚合信息。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211730740.png" alt="img"></p>
<p>如上图所示：对于batch内的所有节点(图上最顶层的6个节点)，依次根据权重采样，得到batch内所有节点的一阶邻居(图上第二层的所有节点)；然后对于所有一阶邻居再次进行采样，得到所有二阶邻居(图上的最后一层)。节点采样阶段完成之后，与采样的顺序相反进行聚合操作。首先对二阶邻居进行单次图卷积，将二阶节点信息聚合已更新一阶节点的向量表示(其中小方块表示的是一层非线性转化)；其次对一阶节点再次进行图卷积操作，将一阶节点的信息聚合已更新batch内所有节点的向量表示。仅此对于一个batch内的所有的样本通过卷积操作学习到一个embedding，而每一个batch的学习过程中仅<strong>利用与mini-batch内相关节点的子图结构。</strong></p>
<p><strong>训练过程</strong></p>
<p>PinSage在训练时采用的是 Margin Hinge Loss 损失函数，主要的思想是最大化正例embedding之间的相关性，同时还要保证负例之间相关性相比正例之间的相关性小于某个阈值(Margin)。具体的公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211731896.png" alt="img"></p>
<p>其中是学习得到的目标节点embedding，是与目标节点相关item的embedding，是与目标节点不相关item的embedding，为margin值，具体大小需要调参。那么对于相关节点i，以及不相关节点nk，具体都是如何定义的，这对于召回模型的训练意义重大，让我们看看具体是如何定义的。</p>
<p>对于正样本而言，文中的定义是如果用户在点击的 item q之后立即点击了 item i，即认为 &lt; q, i &gt;构成正样本对。直观的我们很好理解这句话，不过在参考DGL中相关代码实现时，发现这部分的内容和原文中有一定的出入。具体地，代码中将所有的训练样本构造成用户-项目二部图，然后对batch内的每个 item q，根据item-user-item的元路径进行随机游走，得到被同一个用户交互过的 item i，因此组成<q,i>正样本对。对于负样本部分，相对来说更为重要，因此内容相对比较多，将在下面的负样本生成部分详细介绍。</p>
<p>这里还有一个比较重要的细节需要注意，由于模型是用于 item to item的召回，因此优化目标是与正样本之间的表示尽可能的相近，与负样本之间的表示尽可能的远。而图卷积操作会使得具有邻接关系的节点表示具有同质性，因此结合这两点，就需要在构建图结构的时，要将<strong>训练样本之间可能存在的边在二部图上删除</strong>，避免因为边的存在使得因卷积操作而导致的信息泄露。</p>
<p><strong>工程技巧</strong></p>
<ol>
<li><p>负样本的生成</p>
<p>召回模型最主要的任务是从候选集合中选出用户可能感兴趣的item，直观的理解就是让模型将用户喜欢的和不喜欢的进行区分。然而由于候选集合的庞大数量，许多item之间十分相似，导致模型划分出来用户喜欢的item中会存在一些难以区分的item(即与用户非常喜欢item比较相似的那一部分)。因此对于召回模型不仅能区分用户喜欢和不喜欢的 item，同时还能区分与用户喜欢的 item 十分相似的那一部分item。那么如果做到呢？这主要是交给 easy negative examples 和 hard negative examples 两种负样本给模型学习。</p>
<ul>
<li>easy 负样本：这里对于mini-batch内的所有pair(训练样本对)会共享500负样本，这500个样本从batch之外的所有节点中随机采样得到。这么做可以减少在每个mini-batch中因计算所有节点的embedding所需的时间，文中指出这和为每个item采样一定数量负样本无差异。</li>
<li>hard 负样本：这里使用hard 负样本的原因是根据实际场景的问题出发，模型需要从20亿的物品item集合中识别出最相似的1000个，即模型需要从2百万 item 中识别出最相似的那一个 item。也就是说模型的区分能力不够细致，为了解决这个问题，加入了一些hard样本。对于hard 负样本，应该是与 q 相似 以及和 i 不相似的物品，具体地的生成方式是将图上的节点计算相对节点 q 的个性化PageRank分值，根据分值的排序随机从2000~5000的位置选取节点作为负样本。</li>
</ul>
</li>
<li><p>渐进式训练(Curriculum training)</p>
<p>由于hard 负样本的加入，模型的训练时间加长（由于与q过于相似，导致loss比较小，导致梯度更新的幅度比较小，训练起来比较慢），那么渐进式训练就是为了来解决这个问题。</p>
<p>如何渐进式：先在第一轮训练使用easy 负样本，帮助模型先快速收敛(先让模型有个最基本的分辨能力)到一定范围，然后在逐步分加入hard负样本(方式是在第n轮训练时给每个物品的负样本集合增加n-1个 hard 负样本)，以调整模型细粒度的区分能力(让模型能够区分相似的item)。</p>
</li>
<li><p>节点特征(side information)</p>
<p>这里与EGES的不同，这里的边信息不是端到端训练得到，而是通过事前的预处理得到的。对于每个节点(即 pin)，都会有一个图片和一点文本信息。因此对于每个节点使用图片的向量、文字的向量以及节点的度拼接得到。这里其实也解释了为什么在图卷积操作时，会先进行一个非线性转化，其实就是将不同空间的特征进行转化(融合)。</p>
</li>
<li><p>构建 mini-batch</p>
<p>不同于常规的构建方式，PinSAGE中构建mini-batch的方式是基于生产者消费者模式。什么意思的，就是将CPU和GPU分开工作，让CPU负责取特征，重建索引，邻接列表，负采样等工作，让GPU进行矩阵运算，即CPU负责生产每个batch所需的所有数据，GPU则根据CPU生产的数据进行消费(运算)。这样由于考虑GPU的利用率，无法将所有特征矩阵放在GPU，只能存在CPU中，然而每次查找会导致非常耗时，通过上面的方式使得图卷积操作过程中就没有GPU与CPU的通信需求。</p>
</li>
<li><p>多GPU训练超大batch</p>
<p>前向传播过程中，各个GPU等分minibatch，共享一套模型参数；反向传播时，将每个GPU中的参数梯度都聚合到一起，同步执行SGD。为了保证因海量数据而使用的超大batchsize的情况下模型快速收敛以及泛化精度，采用warmup过程，即在第一个epoch中将学习率线性提升到最高，后面的epoch中再逐步指数下降。</p>
</li>
<li><p>使用MapReduce高效推断</p>
<p>在模型训练结束之后，需要为所有节点计算一个embedding，如果按照训练过程中的前向传播过程来生成，会存在大量重复的计算。因为当计算一个节点的embedding的时候，其部分邻居节点已经计算过了，同时如果该节点作为其他节点邻居时，也会被再次计算。针对这个问题，本文采用MapReduce的方法进行推断。该过程主要分为两步，具体如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211735181.png" alt="img"></p>
<ol>
<li>将item的embedding进行聚合，即利用item的图片、文字和度等信息的表示进行join(拼接)，在通过一层dense后得到item的低维向量。</li>
<li>然后根据item来匹配其一阶邻居(join)，然后根据item进行pooling(其实就是GroupBy pooling)，得到一次图卷积操作。通过堆叠多次直接得到全量的embedding。</li>
</ol>
<p>其实这块主要就是通过MapReduce的大数据处理能力，直接对全量节点进行一次运算得到其embedding，避免了分batch所导致的重复计算。</p>
</li>
</ol>
<h3 id="基于序列的召回"><a href="#基于序列的召回" class="headerlink" title="基于序列的召回"></a>基于序列的召回</h3><h4 id="MIND"><a href="#MIND" class="headerlink" title="MIND"></a>MIND</h4><p>MIND模型(Multi-Interest Network with Dynamic Routing)， 是阿里团队2019年在CIKM上发的一篇paper，该模型依然是用在召回阶段的一个模型，解决的痛点是之前在召回阶段的模型，比如双塔，YouTubeDNN召回模型等，在模拟用户兴趣的时候，总是基于用户的历史点击，最后通过pooling的方式得到一个兴趣向量，用该向量来表示用户的兴趣，但是该篇论文的作者认为，<strong>用一个向量来表示用户的广泛兴趣未免有点太过于单一</strong>，这是作者基于天猫的实际场景出发的发现，每个用户每天与数百种产品互动， 而互动的产品往往来自于很多个类别，这就说明用户的兴趣极其广泛，<strong>用一个向量是无法表示这样广泛的兴趣的</strong>，于是乎，就自然而然的引出一个问题，<strong>有没有可能用多个向量来表示用户的多种兴趣呢？</strong> </p>
<p>这篇paper的核心是胶囊网络，<strong>该网络采用了动态路由算法能非常自然的将历史商品聚成多个集合，每个集合的历史行为进一步推断对应特定兴趣的用户表示向量。这样，对于一个特定的用户，MND输出了多个表示向量，它们代表了用户的不同兴趣。当用户再有新的交互时，通过胶囊网络，还能实时的改变用户的兴趣表示向量，做到在召回阶段的实时个性化</strong>。那么，胶囊网络究竟是怎么做到的呢？ 胶囊网络又是什么原理呢？</p>
<h5 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h5><p>本章是基于天猫APP的背景来探索十亿级别的用户个性化推荐。天猫的推荐的流程主要分为召回阶段和排序阶段。召回阶段负责检索数千个与用户兴趣相关的候选物品，之后，排序阶段预测用户与这些候选物品交互的精确概率。这篇文章做的是召回阶段的工作，来对满足用户兴趣的物品的有效检索。</p>
<p>作者这次的出发点是基于场景出发，在天猫的推荐场景中，作者发现<strong>用户的兴趣存在多样性</strong>。平均上，10亿用户访问天猫，每个用户每天与数百种产品互动。交互后的物品往往属于不同的类别，说明用户兴趣的多样性。 一张图片会更加简洁直观：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212023626.png" alt="img"></p>
<p>因此如果能在<strong>召回阶段建立用户多兴趣模型来模拟用户的这种广泛兴趣</strong>，那么作者认为是非常有必要的，因为召回阶段的任务就是根据用户兴趣检索候选商品嘛。</p>
<p>那么，如何能基于用户的历史交互来学习用户的兴趣表示呢？  以往的解决方案如下：</p>
<ul>
<li>协同过滤的召回方法(itemcf和usercf)是通过历史交互过的物品或隐藏因子直接表示用户兴趣，但会遇到<strong>稀疏或计算问题</strong></li>
<li>基于深度学习的方法用低维的embedding向量表示用户，比如YoutubeDNN召回模型，双塔模型等，都是把用户的基本信息，或者用户交互过的历史商品信息等，过一个全连接层，最后编码成一个向量，用这个向量来表示用户兴趣，但作者认为，<strong>这是多兴趣表示的瓶颈</strong>，因为需要压缩所有与用户多兴趣相关的信息到一个表示向量，所有用户多兴趣的信息进行了混合，导致这种多兴趣并无法体现，所以往往召回回来的商品并不是很准确，除非向量维度很大，但是大维度又会带来高计算。</li>
<li>DIN模型在Embedding的基础上加入了Attention机制，来选择的捕捉用户兴趣的多样性，但采用Attention机制，<strong>对于每个目标物品，都需要重新计算用户表示</strong>，这在召回阶段是行不通的（海量），所以DIN一般是用于排序。</li>
</ul>
<p>所以，作者想在召回阶段去建模用户的多兴趣，但以往的方法都不好使，为了解决这个问题，就提出了动态路由的多兴趣网络MIND。为了推断出用户的多兴趣表示，提出了一个多兴趣提取层，该层使用动态路由机制自动的能将用户的历史行为聚类，然后每个类簇中产生一个表示向量，这个向量能代表用户某种特定的兴趣，而多个类簇的多个向量合起来，就能表示用户广泛的兴趣了。</p>
<p>这就是MIND的提出动机以及初步思路了，这里面的核心是Multi-interest extractor layer，而这里面重点是动态路由与胶囊网络，所以接下来先补充这方面的相关知识。</p>
<h5 id="胶囊网络与动态路由机制"><a href="#胶囊网络与动态路由机制" class="headerlink" title="胶囊网络与动态路由机制"></a>胶囊网络与动态路由机制</h5><h6 id="胶囊网络初识"><a href="#胶囊网络初识" class="headerlink" title="胶囊网络初识"></a>胶囊网络初识</h6><p>Hinton大佬在2011年的时候，就首次提出了”胶囊”的概念， “胶囊”可以看成是一组聚合起来输出整个向量的小神经元组合，这个向量的每个维度(每个小神经元)，代表着某个实体的某个特征。</p>
<p>胶囊网络其实可以和神经网络对比着看可能更好理解，我们知道神经网络的每一层的神经元输出的是单个的标量值，接收的输入，也是多个标量值，所以这是一种value to value的形式，而胶囊网络每一层的胶囊输出的是一个向量值，接收的输入也是多个向量，所以它是vector to vector形式的。来个图对比下就清楚了：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212029715.png" alt="img"></p>
<p>左边的图是普通神经元的计算示意，而右边是一个胶囊内部的计算示意图。 神经元这里不过多解释，这里主要是剖析右边的这个胶囊计算原理。从上图可以看出， 输入是两个向量，首先经过了一个线性映射，得到了两个新向量，然后呢，经过了一个向量的加权汇总，这里的,可以先理解成权重，具体计算后面会解释。 得到汇总后的向量，接下来进行了Squash操作，整体的计算公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212030357.png" alt="img"></p>
<p>这里的Squash操作可以简单看下，主要包括两部分，右边的那部分其实就是向量归一化操作，把norm弄成1，而左边那部分算是一个非线性操作，如果的norm很大，那么这个整体就接近1， 而如果这个norm很小，那么整体就会接近0， 和sigmoid很像有没有？</p>
<p>这样就完成了一个胶囊的计算，但有两点需要注意：</p>
<ol>
<li>这里的参数是可学习的，和神经网络一样， 通过BP算法更新</li>
<li>这里的参数不是BP算法学习出来的，而是采用动态路由机制现场算出来的，这个非常类似于pooling层，我们知道pooling层的参数也不是学习的，而是根据前面的输入现场取最大或者平均计算得到的。</li>
</ol>
<p>所以这里的问题，就是怎么通过动态路由机制得到，下面是动态路由机制的过程。</p>
<h6 id="动态路由机制原理"><a href="#动态路由机制原理" class="headerlink" title="动态路由机制原理"></a>动态路由机制原理</h6><p>我们先来一个胶囊结构: </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212035441.png" alt="img"></p>
<p>这个是通过动态路由机制计算得到，那么动态路由机制究竟是啥子意思？  其实就是通过迭代的方式去计算，没有啥神秘的，迭代计算的流程如下图:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212035613.png" alt="img"></p>
<p>首先我们先初始化，与每一个输入胶囊进行对应，这哥们有个名字叫做”routing logit”， 表示的是输出的这个胶囊与输入胶囊的相关性，和注意力机制里面的score值非常像。由于一开始不知道这个哪个胶囊与输出的胶囊有关系，所以默认相关性分数都一样，然后进入迭代。</p>
<p>在每一次迭代中，首先把分数转成权重，然后加权求和得到，这个很类似于注意力机制的步骤，得到之后，通过归一化操作，得到，接下来要通过和输入胶囊的相关性以及上一轮的来更新。</p>
<p>通过若干次迭代之后，得到最后的输出胶囊向量会慢慢的走到与它更相关的那些附近，而远离那些与它不相干的。所以上面的这个迭代过程有点像<strong>排除异常输入胶囊的感觉</strong>。</p>
<p>而从另一个角度来考虑，这个过程其实像是聚类的过程，因为胶囊的输出向量经过若干次迭代之后，会最终停留到与其非常相关的那些输入胶囊里面，而这些输入胶囊，其实就可以看成是某个类别了，因为既然都共同的和输出胶囊比较相关，那么彼此之间的相关性也比较大，于是乎，经过这样一个动态路由机制之后，就不自觉的，把输入胶囊实现了聚类。把和与其他输入胶囊不同的那些胶囊给排除了出去。</p>
<p>所以，这个动态路由机制的计算设计的还是比较巧妙的， 下面是上述过程的展开计算过程， 这个和RNN的计算有点类似：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212037262.png" alt="img"></p>
<p>这样就完成了一个胶囊内部的计算过程了。</p>
<p>Ok， 有了上面的这些铺垫，再来看MIND就会比较简单了。下面正式对MIND模型的网络架构剖析。</p>
<h5 id="MIND模型的网络结构与细节剖析"><a href="#MIND模型的网络结构与细节剖析" class="headerlink" title="MIND模型的网络结构与细节剖析"></a>MIND模型的网络结构与细节剖析</h5><h6 id="网络整体结构"><a href="#网络整体结构" class="headerlink" title="网络整体结构"></a>网络整体结构</h6><p>MIND网络的架构如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212044848.png" alt="img"></p>
<p>初步先分析这个网络结构的运作： 首先接收的输入有三类特征，用户base属性，历史行为属性以及商品的属性，用户的历史行为序列属性过了一个多兴趣提取层得到了多个兴趣胶囊，接下来和用户base属性拼接过DNN，得到了交互之后的用户兴趣。然后在训练阶段，用户兴趣和当前商品向量过一个label-aware attention，然后求softmax损失。 在服务阶段，得到用户的向量之后，就可以直接进行近邻检索，找候选商品了。 这就是宏观过程，但是，多兴趣提取层以及这个label-aware attention是在做什么事情呢？  如果单独看这个图，感觉得到多个兴趣胶囊之后，直接把这些兴趣胶囊以及用户的base属性拼接过全连接，那最终不就成了一个用户向量，此时label-aware attention的意义不就没了？ 所以这个图初步感觉画的有问题，和论文里面描述的不符。所以下面先以论文为主，正式开始描述具体细节。</p>
<h6 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h6><p>召回任务的目标是对于每一个用户从十亿规模的物品池检索出包含与用户兴趣相关的上千个物品集。</p>
<p><strong>模型的输入</strong></p>
<p>对于模型，每个样本的输入可以表示为一个三元组：，其中代表与用户交互过的物品集，即用户的历史行为；表示用户的属性，例如性别、年龄等；定义为目标物品的一些特征，例如物品id和种类id等。</p>
<p><strong>任务描述</strong></p>
<p>MIND的核心任务是学习一个从原生特征映射到<strong>用户表示</strong>的函数，用户表示定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212048618.png" alt="img"></p>
<p>其中，是用户的表示向量，是embedding的维度，表示向量的个数，即兴趣的数量。如果，那么MIND模型就退化成YouTubeDNN的向量表示方式了。</p>
<p>目标物品的embedding函数为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212049445.png" alt="img"></p>
<p>其中，表示一个embedding&amp;pooling层。</p>
<p><strong>最终结果</strong></p>
<p>根据评分函数检索（根据<strong>目标物品与用户表示向量的内积的最大值作为相似度依据</strong>，DIN的Attention部分也是以这种方式来衡量两者的相似度），得到top-N个候选项：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212049720.png" alt="img"></p>
<h6 id="Embedding-amp-Pooling层"><a href="#Embedding-amp-Pooling层" class="headerlink" title="Embedding &amp; Pooling层"></a>Embedding &amp; Pooling层</h6><p>Embedding层的输入由三部分组成，用户属性、用户行为和目标物品标签。每一部分都由多个id特征组成，则是一个高维的稀疏数据，因此需要Embedding技术将其映射为低维密集向量。具体来说，</p>
<ul>
<li>对于的id特征（年龄、性别等）是将其Embedding的向量进行Concat，组成用户属性Embedding；</li>
<li>目标物品通常包含其他分类特征id（品牌id、店铺id等） ，这些特征有利于物品的冷启动问题，需要将所有的分类特征的Embedding向量进行平均池化，得到一个目标物品向量；</li>
<li>对于用户行为，由物品的Embedding向量组成用户行为Embedding列表， 当然这里不仅只有物品embedding哈，也可能有类别，品牌等其他的embedding信息。</li>
</ul>
<h6 id="Multi-Interest-Extractor-Layer-核心"><a href="#Multi-Interest-Extractor-Layer-核心" class="headerlink" title="Multi-Interest Extractor Layer(核心)"></a>Multi-Interest Extractor Layer(核心)</h6><p>作者认为，单一的向量不足以表达用户的多兴趣。所以作者采用<strong>多个表示向量</strong>来分别表示用户不同的兴趣。通过这个方式，在召回阶段，用户的多兴趣可以分别考虑，对于兴趣的每一个方面，能够更精确的进行物品检索。</p>
<p>为了学习多兴趣表示，作者利用胶囊网络表示学习的动态路由将用户的历史行为分组到多个簇中。来自一个簇的物品应该密切相关，并共同代表用户兴趣的一个特定方面。</p>
<p>由于多兴趣提取器层的设计灵感来自于胶囊网络表示学习的动态路由，所以这里作者回顾了动态路由机制。当然，如果之前对胶囊网络或动态路由不了解，这里读起来就会有点艰难，但由于我上面进行了铺垫，这里就直接拿过原文并解释即可。</p>
<p><strong>动态路由</strong></p>
<p>动态路由是胶囊网络中的迭代学习算法，用于学习低水平胶囊和高水平胶囊之间的路由对数（logit），来得到高水平胶囊的表示。</p>
<p>我们假设胶囊网络有两层，即低水平胶囊和高水平胶囊，其中表示胶囊的个数， 表示胶囊的维度。 路由对数计算公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212050370.png" alt="img"></p>
<p>其中表示待学习的双线性映射矩阵【在胶囊网络的原文中称为转换矩阵】</p>
<p>通过计算路由对数，将高阶胶囊的候选向量计算为所有低阶胶囊的加权和：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212050471.png" alt="img"></p>
<p>其中定义为连接低阶胶囊和高阶胶囊的权重【称为耦合系数】，而且其通过对路由对数执行softmax来计算：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212051995.png" alt="img"></p>
<p>最后，应用一个非线性的“压缩”函数来获得一个高阶胶囊的向量【胶囊网络向量的模表示由胶囊所代表的实体存在的概率】</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212051641.png" alt="img"></p>
<p>路由过程重复进行3次达到收敛。当路由结束，高阶胶囊值固定，作为下一层的输入。</p>
<p>Ok，下面我们开始解释，其实上面说的这些就是胶囊网络的计算过程，只不过和之前所用的符号不一样了。这里拿个图： <img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212051116.png" alt="img"> 首先，论文里面也是个两层的胶囊网络，低水平层-&gt;高水平层。 低水平层有个胶囊，每个胶囊向量维度是，用表示的，高水平层有个胶囊，每个胶囊维，用表示。</p>
<p>单独拿出每个，其计算过程如上图所示。首先，先随机初始化路由对数，然后开始迭代，对于每次迭代：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212052434.png" alt="img"></p>
<p>只不过这里的符合和上图中的不太一样，这里的对应的是每个输入胶囊的权重， 这里的对应上图中的， 这里的对应的是输入胶囊的加权组合。这里的对应上图中的，这里的对应的是上图的权重，只不过这个可以换成矩阵运算。 和上图中不同的是路由对数更新那里，没有了上一层的路由对数值，但感觉这样会有问题。</p>
<p>所以，这样解释完之后就会发现，其实上面的一顿操作就是说的传统的动态路由机制。</p>
<p><strong>B2I动态路由</strong></p>
<p>作者设计的多兴趣提取层就是就是受到了上述胶囊网络的启发。</p>
<p>如果把用户的行为序列看成是行为胶囊， 把用户的多兴趣看成兴趣胶囊，那么多兴趣提取层就是利用动态路由机制学习行为胶囊<code>-&gt;</code>兴趣胶囊的映射关系。但是原始路由算法无法直接应用于处理用户行为数据。因此，提出了<strong>行为(Behavior)到兴趣(Interest)（B2I）动态路由</strong>来自适应地将用户的行为聚合到兴趣表示向量中，它与原始路由算法有三个不同之处：</p>
<ol>
<li><strong>共享双向映射矩阵</strong>。在初始动态路由中，使用固定的或者说共享的双线性映射矩阵而不是单独的双线性映射矩阵， 在原始的动态路由中，对于每个输出胶囊，都会有对应的，而这里是每个输出胶囊，都共用一个矩阵。 原因有两个：<ol>
<li>一方面，用户行为是可变长度的，从几十个到几百个不等，因此使用共享的双线性映射矩阵是有利于泛化。</li>
<li>另一方面，希望兴趣胶囊在同一个向量空间中，但不同的双线性映射矩阵将兴趣胶囊映射到不同的向量空间中。因为映射矩阵的作用就是对用户的行为胶囊进行线性映射嘛， 由于用户的行为序列都是商品，所以希望经过映射之后，到统一的商品向量空间中去。路由对数计算如下：</li>
</ol>
</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212052546.png" alt="img"></p>
<p>​        其中，是历史物品的embedding，表示兴趣胶囊的向量。是每一对行为胶囊(低价)到兴趣胶囊(高阶)之间        的共享映射矩阵。</p>
<ol>
<li><strong>随机初始化路由对数</strong>。由于利用共享双向映射矩阵，如果再初始化路由对数为0将导致相同的初始的兴趣胶囊。随后的迭代将陷入到一个不同兴趣胶囊在所有的时间保持相同的情景。因为每个输出胶囊的运算都一样了嘛(除非迭代的次数不同，但这样也会导致兴趣胶囊都很类似)，为了减轻这种现象，作者通过高斯分布进行随机采样来初始化路由对数，让初始兴趣胶囊与其他每一个不同，其实就是希望在计算每个输出胶囊的时候，通过随机化的方式，希望这几个聚类中心离得远一点，这样才能表示出广泛的用户兴趣(我们已经了解这个机制就仿佛是聚类，而计算过程就是寻找聚类中心)。</li>
<li><strong>动态的兴趣数量</strong>，兴趣数量就是聚类中心的个数，由于不同用户的历史行为序列不同，那么相应的，其兴趣胶囊有可能也不一样多，所以这里使用了一种启发式方式自适应调整聚类中心的数量，即值。</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212053113.png" alt="img"></p>
<p>这种调整兴趣胶囊数量的策略可以为兴趣较小的用户节省一些资源，包括计算和内存资源。这个公式不用多解释，与行为序列长度成正比。</p>
<p>最终的B2I动态路由算法如下： <img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212053253.png" alt="img"> 应该很好理解了吧。</p>
<h6 id="Label-aware-Attention-Layer"><a href="#Label-aware-Attention-Layer" class="headerlink" title="Label-aware Attention Layer"></a>Label-aware Attention Layer</h6><p> 通过多兴趣提取器层，从用户的行为embedding中生成多个兴趣胶囊。不同的兴趣胶囊代表用户兴趣的不同方面，相应的兴趣胶囊用于评估用户对特定类别的偏好。所以，在训练的期间，最后需要设置一个Label-aware的注意力层，对于当前的商品，根据相关性选择最相关的兴趣胶囊。这里其实就是一个普通的注意力机制，和DIN里面的那个注意力层基本上是一模一样，计算公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212054677.png" alt="img"></p>
<p>首先这里的表示当前的商品向量，表示用户的多兴趣向量组合，里面有个向量，表示用户的的兴趣。用户的各个兴趣向量与目标商品做内积，然后softmax转成权重，然后反乘到多个兴趣向量进行加权求和。 但是这里需要注意的一个小点，就是这里做内积求完相似性之后，先做了一个指数操作，<strong>这个操作其实能放大或缩小相似程度</strong>，至于放大或者缩小的程度，由控制。 比如某个兴趣向量与当前商品非常相似，那么再进行指数操作之后，如果也很大，那么显然这个兴趣向量就占了主导作用。是一个可调节的参数来调整注意力分布。当接近0，每一个兴趣胶囊都得到相同的关注。当大于1时，随着的增加，具有较大值的点积将获得越来越多的权重。考虑极限情况，当趋近于无穷大时，注意机制就变成了一种硬注意，选关注最大的值而忽略其他值。在实验中，发现使用硬注意导致更快的收敛。</p>
<h6 id="训练与服务"><a href="#训练与服务" class="headerlink" title="训练与服务"></a>训练与服务</h6><p>得到用户向量和标签物品embedding后，计算用户与标签物品交互的概率：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212054847.png" alt="img"></p>
<p>目标函数是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212054640.png" alt="img"></p>
<p>其中是训练数据包含用户物品交互的集合。因为物品的数量可伸缩到数十亿，所以不能直接算。因此。使用采样的softmax技术，并且选择Adam优化来训练MIND。</p>
<p>训练结束后，抛开label-aware注意力层，MIND网络得到一个用户表示映射函数。在服务期间，用户的历史序列与自身属性喂入到，每个用户得到多兴趣向量。然后这个表示向量通过一个近似邻近方法来检索top N物品。</p>
<p>这就是整个MIND模型的细节了。</p>
<h4 id="SDM"><a href="#SDM" class="headerlink" title="SDM"></a>SDM</h4><p>SDM模型(Sequential Deep Matching Model)，是阿里团队在2019年CIKM上的一篇paper。和MIND模型一样，是一种序列召回模型，研究的依然是如何通过用户的历史行为序列去学习到用户的丰富兴趣。 对于MIND，我们已经知道是基于胶囊网络的动态路由机制，设计了一个动态兴趣提取层，把用户的行为序列通过路由机制聚类，然后映射成了多个兴趣胶囊，以此来获取到用户的广泛兴趣。而SDM模型，是先把用户的历史序列根据交互的时间分成了短期和长期两类，然后从<strong>短期会话</strong>和<strong>长期行为</strong>中分别采取<strong>相应的措施（短期的RNN+多头注意力，长期的Att Net）</strong> 去学习到用户的短期兴趣和长期行为偏好，并<strong>巧妙的设计了一个门控网络有选择的将长短期兴趣进行融合</strong>，以此得到用户的最终兴趣向量。 这篇paper中的一些亮点，比如长期偏好的行为表示，多头注意力机制学习多兴趣，长短期兴趣的融合机制等，又给了一些看待问题的新角度，同时，给出了我们一种利用历史行为序列去捕捉用户动态偏好的新思路。 </p>
<p>这篇paper依然是从引言开始， 介绍SDM模型提出的动机以及目前方法存在的不足(why)， 接下来就是SDM的网络模型架构(what)， 这里面的关键是如何从短期会话和长期行为两个方面学习到用户的短期长期偏好(how)。</p>
<h5 id="背景与动机-1"><a href="#背景与动机-1" class="headerlink" title="背景与动机"></a>背景与动机</h5><p> 这里要介绍该模型提出的动机，即why要有这样的一个模型？</p>
<p>一个好的推荐系统应该是能精确的捕捉用户兴趣偏好以及能对他们当前需求进行快速响应的，往往工业上的推荐系统，为了能快速响应， 一般会把整个推荐流程分成召回和排序两个阶段，先通过召回，从海量商品中得到一个小的候选集，然后再给到排序模型做精确的筛选操作。 这也是目前推荐系统的一个范式了。在这个过程中，召回模块所检索到的候选对象的质量在整个系统中起着至关重要的作用。</p>
<p>淘宝目前的召回模型是一些基于协同过滤的模型， 这些模型是通过用户与商品的历史交互建模，从而得到用户的物品的表示向量，但这个过程是<strong>静态的</strong>，而用户的行为或者兴趣是时刻变化的， 对于协同过滤的模型来说，并不能很好的捕捉到用户整个行为序列的动态变化。</p>
<p>那我们知道了学习用户历史行为序列很重要， 那么假设序列很长呢？这时候直接用模型学习长序列之间的演进可能不是很好，因为很长的序列里面可能用户的兴趣发生过很大的转变，很多商品压根就没有啥关系，这样硬学，反而会导致越学越乱，就别提这个演进了。所以这里是以会话为单位，对长序列进行切分。作者这里的依据就是用户在同一个Session下，其需求往往是很明确的， 这时候，交互的商品也往往都非常类似。 但是Session与Session之间，可能需求改变，那么商品类型可能骤变。 所以以Session为单位来学习商品之间的序列信息，感觉要比整个长序列学习来的靠谱。 </p>
<p>作者首先是先把长序列分成了多个会话， 然后<strong>把最近的一次会话，和之前的会话分别视为了用户短期行为和长期行为分别进行了建模，并采用不同的措施学习用户的短期兴趣和长期兴趣，然后通过一个门控机制融合得到用户最终的表示向量</strong>。这就是SDM在做的事情，</p>
<p>长短期行为序列联合建模，其实是在给我们提供一种新的学习用户兴趣的新思路， 那么究竟是怎么做的呢？以及为啥这么做呢？</p>
<ul>
<li><p>对于短期用户行为， 首先作者使用了LSTM来学习序列关系， 而接下来是用一个Multi-head attention机制，学习用户的多兴趣。 </p>
<p>先分析分析作者为啥用多头注意力机制，作者这里依然是基于实际的场景出发，作者发现，<strong>用户的兴趣点在一个会话里面其实也是多重的</strong>。这个可能之前的很多模型也是没考虑到的，但在商品购买的场景中，这确实也是个事实， 顾客在买一个商品的时候，往往会进行多方比较， 考虑品牌，颜色，商店等各种因素。作者认为用普通的注意力机制是无法反映广泛的兴趣了，所以用多头注意力网络。 </p>
<p>多头注意力机制从某个角度去看，也有类似聚类的功效，首先它接收了用户的行为序列，然后从多个角度学习到每个商品与其他商品的相关性，然后根据与其他商品的相关性加权融合，这样，相似的item向量大概率就融合到了一块组成一个向量，所谓用户的多兴趣，可能是因为这些行为商品之间，可以从多个空间或者角度去get彼此之间的相关性，这里面有着用户多兴趣的表达信息。</p>
</li>
<li><p>用户的长期行为也会影响当前的决策，作者在这里举了一个NBA粉丝的例子，说如果一个是某个NBA球星的粉丝，那么他可能在之前会买很多有关这个球星的商品，如果现在这个时刻想买鞋的时候，大概率会考虑和球星相关的。所以作者说<strong>长期偏好和短期行为都非常关键</strong>。但是长期偏好或者行为往往是复杂广泛的，就像刚才这个例子里面，可能长期行为里面，买的与这个球星相关商品只占一小部分，而就只有这一小部分对当前决策有用。  这个也是之前的模型利用长期偏好方面存在的问题，那么如何选择出长期偏好里面对于当前决策有用的那部分呢？  作者这里设计了一个门控的方式融合短期和长期，这个想法还是很巧妙的，后面介绍这个东西的时候说下我的想法。 </p>
</li>
</ul>
<p>所以下面总结动机以及本篇论文的亮点：</p>
<ul>
<li>动机： 召回模型需要捕获用户的动态兴趣变化，这个过程中利用好用户的长期行为和短期偏好非常关键，而以往的模型有下面几点不足：<ul>
<li>协同过滤模型： 基于用户的交互进行静态建模，无法感知用户的兴趣变化过程，易召回同质性的商品</li>
<li>早期的一些序列推荐模型: 要么是对整个长序列直接建模，但这样太暴力，没法很好的学习商品之间的序列信息，有些是把长序列分成会话，但忽视了一个会话中用户的多重兴趣</li>
<li>有些方法在考虑用户的长期行为方面，只是简单的拼接或者加权求和，而实际上用户长期行为中只有很少一小部分对当前的预测有用，这样暴力融合反而会适得其反，起不到效果。另外还有一些多任务或者对抗方法， 在工业场景中不适用等。 </li>
<li>这些我只是通过我的理解简单总结，详细内容看原论文相关工作部分。</li>
</ul>
</li>
<li>亮点: <ul>
<li>SDM模型， 考虑了用户的短期行为和长期兴趣，以会话的形式进行分割，并对这两方面分别建模</li>
<li>短期会话由于对当前决策影响比较大，那么我们就学习的全面一点， 首先RNN学习序列关系，其次通过多头注意力机制捕捉多兴趣，然后通过一个Attention Net加权得到短期兴趣表示</li>
<li>长期会话通过Attention Net融合，然后过DNN，得到用户的长期表示</li>
<li>我们设计了一个门控机制，类似于LSTM的那种门控，能巧妙的融合这两种兴趣，得到用户最终的表示向量</li>
</ul>
</li>
</ul>
<p>这就是动机与背景总结啦。 那么接下来，SDM究竟是如何学习短期和长期表示，又是如何融合的？ 为什么要这么玩？</p>
<h5 id="SDM的网络结构与细节剖析"><a href="#SDM的网络结构与细节剖析" class="headerlink" title="SDM的网络结构与细节剖析"></a>SDM的网络结构与细节剖析</h5><h6 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h6><p>这里本来直接看模型结构，但感觉还是先过一下问题定义吧，毕竟这次涉及到了会话，还有几个小规则。</p>
<p>表示用户集合，表示item集合，模型考虑在时间，是否用户会对产生交互。 对于， 我们能够得到它的历史行为序列，那么先说一下如何进行会话的划分， 这里有三个规则：</p>
<ol>
<li>相同会话ID的商品(后台能获取)算是一个会话</li>
<li>相邻的商品，时间间隔小于10分钟(业务自己调整)算一个会话</li>
<li>同一个会话中的商品不能超过50个，多出来的放入下一个会话</li>
</ol>
<p>这样划分开会话之后， 对于用户的短期行为定义是离目前最近的这次会话， 用表示，是序列长度。 而长期的用户行为是过去一周内的会话，但不包括短期的这次会话， 这个用表示。网络推荐架构如下： <img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212059483.png" alt="img"> 这个感觉并不用过多解释。看过召回的应该都能懂， 接收了用户的短期行为和长期行为，然后分别通过两个盲盒得到表示向量，再通过门控融合就得到了最终的用户表示。 </p>
<p>下面要开那三个盲盒操作，即短期行为学习，长期行为学习以及门控融合机制。但在这之前，得先说一个东西，就是输入层这里， 要带物品的side infomation，比如物品的item ID, 物品的品牌ID，商铺ID， 类别ID等等， 那你说，为啥要单独说呢？ 之前的模型不也有，但是这里在利用方式上有些不一样需要注意。</p>
<h6 id="Input-Embedding-with-side-Information"><a href="#Input-Embedding-with-side-Information" class="headerlink" title="Input Embedding with side Information"></a>Input Embedding with side Information</h6><p>在淘宝的推荐场景中，作者发现， 顾客与物品产生交互行为的时候，不仅考虑特定的商品本身，还考虑产品， 商铺，价格等，这个显然。所以，这里对于一个商品来说，不仅要用到Item ID，还用了更多的side info信息，包括<code>leat category, fist level category, brand,shop</code>。 </p>
<p>所以，假设用户的短期行为是， 这里面的每个商品其实有5个属性表示了，每个属性本质是ID，但转成embedding之后，就得到了5个embedding， 所以这里就涉及到了融合问题。 这里用  来表示每个，但这里不是embedding的pooling操作，而是Concat</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212101984.png" alt="img"></p>
<p>其中，， 这个公式看着负责，其实就是每个side info的id过embedding layer得到各自的embedding。这里embedding的维度是， 等拼接起来之后，就是维了。</p>
<p>另外就是用户的base表示向量了，这个很简单， 就是用户的基础画像，得到embedding，直接也是Concat，这个常规操作不解释：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212101121.png" alt="img"></p>
<p>是特征的embedding。</p>
<p>Ok，输入这里说完了之后，就直接开盲盒， 不按照论文里面的顺序来了。想看更多细节的就去看原论文吧，感觉那里面说的有些啰嗦。不如直接上图解释来的明显：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212101061.png" alt="img"> 这里正好三个框把盒子框住了，下面剖析出每个来就行啦。</p>
<h6 id="短期用户行为建模"><a href="#短期用户行为建模" class="headerlink" title="短期用户行为建模"></a>短期用户行为建模</h6><p>这里短期用户行为是下面的那个框，接收的输入，首先是用户最近的那次会话，里面各个商品加入了side info信息之后，有了最终的embedding表示。 </p>
<p>这个东西，首先要过LSTM，学习序列信息，这个感觉不用多说，直接上公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212103361.png" alt="img"></p>
<p>这里采用的是多输入多输出， 即每个时间步都会有一个隐藏状态输出出来，那么经过LSTM之后，原始的序列就有了序列相关信息，得到了, 把这个记为。这里的表示时间的序列偏好表示。</p>
<p>接下来， 这个东西要过Multi-head self-attention层，这个东西的原理我这里就不多讲了，这个东西可以学习到系列之间的相关性，这个操作从某种角度看，也很像聚类， 因为我们这里是先用多头矩阵把系列映射到多个空间，然后从各个空间中互求相关性</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212104750.png" alt="img"></p>
<p>得到权重后，对原始的向量加权融合。 让， ，， 背后计算是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212104358.png" alt="img"></p>
<p>这是一个头的计算， 接下来每个头都这么算，假设有个头，这里会通过上面的映射矩阵系列，先把原始的向量映射到维度，然后计算也是维，这样个head进行拼接，正好是维， 接下来过一个全连接或者线性映射得到MultiHead的输出。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212104590.png" alt="img"></p>
<p>这样就相当于更相似的融合到了一块，而这个更相似又是从多个角度得到的，于是乎， 作者认为，这样就能学习到用户的多兴趣。</p>
<p>得到这个东西之后，接下来再过一个User Attention， 因为作者发现，对于相似历史行为的不同用户，其兴趣偏好也不太一样。 所以加入这个用户Attention层，想挖掘更细粒度的用户个性化信息。 当然，这个就是普通的embedding层了， 用户的base向量作为query，与的每个向量做Attention，然后加权求和得最终向量：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212105264.png" alt="img"></p>
<p>其中，这样短期行为兴趣就修成了正果。</p>
<h6 id="用户长期行为建模"><a href="#用户长期行为建模" class="headerlink" title="用户长期行为建模"></a>用户长期行为建模</h6><p>从长期的视角来看，用户在不同的维度上可能积累了广泛的兴趣，用户可能经常访问一组类似的商店，并反复购买属于同一类别的商品。 所以长期行为来自于不同的特征尺度。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212105990.png" alt="img"></p>
<p>这里面包含了各种side特征。这里就和短期行为那里不太一样了，长期行为这里，是从特征的维度进行聚合，也就是把用户的历史长序列分成了多个特征，比如用户历史点击过的商品，历史逛过的店铺，历史看过的商品的类别，品牌等，分成了多个特征子集，然后这每个特征子集里面有对应的id，比如商品有商品id, 店铺有店铺id等，对于每个子集，过user Attention layer，和用户的base向量求Attention， 相当于看看用户喜欢逛啥样的商店， 喜欢啥样的品牌，啥样的商品类别等等，得到每个子集最终的表示向量。每个子集的计算过程如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212105910.png" alt="img"></p>
<p>每个子集都会得到一个加权的向量，把这个东西拼起来，然后过DNN。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212106394.png" alt="img"></p>
<p>这里的， 这样就得到了用户的长期兴趣表示。</p>
<h6 id="短长期兴趣融合"><a href="#短长期兴趣融合" class="headerlink" title="短长期兴趣融合"></a>短长期兴趣融合</h6><p>长短期兴趣融合这里，作者发现之前模型往往喜欢直接拼接起来，或者加和，注意力加权等，但作者认为这样不能很好的将两类兴趣融合起来，因为长期序列里面，其实只有很少的一部分行为和当前有关。那么这样的话，直接无脑融合是有问题的。所以这里作者用了一种较为巧妙的方式，即门控机制：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305212106342.png" alt="img"></p>
<p>这个和LSTM的这种门控机制很像，首先门控接收的输入有用户画像，用户短期兴趣， 用户长期兴趣，经过sigmoid函数得到了，用来决定在时刻短期和长期兴趣的贡献程度。然后根据这个贡献程度对短期和长期偏好加权进行融合。</p>
<p>为啥这东西就有用了呢？  实验中证明了这个东西有用，但这里给出我的理解哈，我们知道最终得到的短期或者长期兴趣都是维的向量， 每一个维度可能代表着不同的兴趣偏好，比如第一维度代表品牌，第二个维度代表类别，第三个维度代表价格，第四个维度代表商店等等，当然假设哈，真实的向量不可解释。</p>
<p>那么如果我们是直接相加或者是加权相加，其实都意味着长短期兴趣这每个维度都有很高的保留， 但其实上，万一长期兴趣和短期兴趣维度冲突了呢？ 比如短期兴趣里面可能用户喜欢这个品牌，长期用户里面用户喜欢那个品牌，那么听谁的？ 你可能说短期兴趣这个占更大权重呗，那么普通加权可是所有向量都加的相同的权重，品牌这个维度听短期兴趣的，其他维度比如价格，商店也都听短期兴趣的？本身存在不合理性。那么反而直接相加或者加权效果会不好。</p>
<p>而门控机制的巧妙就在于，我会给每个维度都学习到一个权重，而这个权重非0即1(近似哈)， 那么接下来融合的时候，我通过这个门控机制，取长期和短期兴趣向量每个维度上的其中一个。比如在品牌方面听谁的，类别方面听谁的，价格方面听谁的，只会听短期和长期兴趣的其中一个的。这样就不会有冲突发生，而至于具体听谁的，交给网络自己学习。这样就使得用户长期兴趣和短期兴趣融合的时候，每个维度上的信息保留变得<strong>有选择</strong>。使得兴趣的融合方式更加的灵活。</p>
<p> <strong>这其实又给我们提供了一种两个向量融合的一种新思路，并不一定非得加权或者拼接或者相加了，还可以通过门控机制让网络自己学</strong></p>
<h3 id="基于树模型的召回"><a href="#基于树模型的召回" class="headerlink" title="基于树模型的召回"></a>基于树模型的召回</h3><h4 id="TDM"><a href="#TDM" class="headerlink" title="TDM"></a>TDM</h4><p>召回早前经历的第一代协同过滤技术，让模型可以在数量级巨大的item集中找到用户潜在想要看到的商品。这种方式有很明显的缺点，一个是对于用户而言，只能通过他历史行为去构建候选集，并且会基于算力的局限做截断。所以推荐结果的多样性和新颖性比较局限，导致推荐的有可能都是用户看过的或者买过的商品。之后在Facebook开源了FASSI库之后，基于内积模型的向量检索方案得到了广泛应用，也就是第二代召回技术。这种技术通过将用户和物品用向量表示，然后用内积的大小度量兴趣，借助向量索引实现大规模的全量检索。这里虽然改善了第一代的无法全局检索的缺点，然而这种模式下存在索引构建和模型优化目标不一致的问题，索引优化是基于向量的近似误差，而召回问题的目标是最大化topK召回率。且这类方法也不方便在用户和物品之间做特征组合。</p>
<p>所以阿里开发了一种可以承载各种深度模型来检索用户潜在兴趣的推荐算法解决方案。这个TDM模型是基于树结构，利用树结构对全量商品进行检索，将复杂度由O(N)下降到O(logN)。</p>
<h5 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h5><p><strong>树结构</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211740339.png" alt="img"></p>
<p>如上图，树中的每一个叶子节点对应一个商品item，非叶子结点表示的是item的集合<strong>（这里的树不限于二叉树）</strong>。这种层次化结构体现了粒度从粗到细的item架构。</p>
<p><strong>整体结构</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211741089.png" alt="img"></p>
<h5 id="算法详解"><a href="#算法详解" class="headerlink" title="算法详解"></a>算法详解</h5><ol>
<li><p>基于树的高效检索</p>
<p>算法通常采用beam-search的方法，根据用户对每层节点挑选出topK，将挑选出来的这几个topK节点的子节点作为下一层的候选集，最终会落到叶子节点上。 这么做的理论依据是当前层的最有优topK节点的父亲必然属于上次的父辈节点的最优topK：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211743079.png" alt="img"></p>
<p>其中表示用户u对j层节点n感兴趣的概率，表示归一化因子。</p>
</li>
<li><p>对兴趣进行建模</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211744832.png" alt="img"></p>
<p>如上图，用户对叶子层item6感兴趣，可以认为它的兴趣是1，同层别的候选节点的兴趣为0，顺着着绿色线路上去的节点都标记为1，路线上的同层别的候选节点都标记为0。这样的操作就可以根据1和0构建用于每一层的正负样本。</p>
<p>样本构建完成后，可以在模型结构左侧采用任意的深度学习模型来承担用户兴趣判别器的角色，输入就是当前层构造的正负样本，输出则是（用户，节点）对的兴趣度，这个将被用作检索过程中选取topK的评判指标。<strong>在整体结构图中，我们可以看到节点特征方面，使用的是node embedding</strong>，说明在进入模型前已经向量化了。</p>
</li>
<li><p>训练过程</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305211745271.png" alt="img"></p>
<p>整体联合训练的方式如下：</p>
<ol>
<li>构造随机二叉树</li>
<li>基于树模型生成样本</li>
<li>训练DNN模型直到收敛</li>
<li>基于DNN模型得到样本的Embedding，重新构造聚类二叉树</li>
<li>循环上述2～4过程</li>
</ol>
<p>具体的，在初始化树结构的时候，首先借助商品的类别信息进行排序，将相同类别的商品放到一起，然后递归的将同类别中的商品等量的分到两个子类中，直到集合中只包含一项，利用这种自顶向下的方式来初始化一棵树。基于该树采样生成深度模型训练所需的样本，然后进一步训练模型，训练结束之后可以得到每个树节点对应的Embedding向量，利用节点的Embedding向量，采用K-Means聚类方法来重新构建一颗树，最后基于这颗新生成的树，重新训练深层网络。</p>
</li>
</ol>
<h2 id="经典排序模型"><a href="#经典排序模型" class="headerlink" title="经典排序模型"></a>经典排序模型</h2><h3 id="GBDT-LR"><a href="#GBDT-LR" class="headerlink" title="GBDT+LR"></a>GBDT+LR</h3><p>前面介绍的协同过滤和矩阵分解存在的劣势就是仅利用了用户与物品相互行为信息进行推荐，忽视了用户自身特征，物品自身特征以及上下文信息等，导致生成的结果往往会比较片面。而这次介绍的这个模型是2014年由Facebook提出的GBDT+LR模型，该模型利用GBDT自动进行特征筛选和组合，进而生成新的离散特征向量，再把该特征向量当做LR模型的输入，来产生最后的预测结果，该模型能够综合利用用户、物品和上下文等多种不同的特征，生成较为全面的推荐结果，在CTR点击率预估场景下使用较为广泛。</p>
<h4 id="逻辑回归模型"><a href="#逻辑回归模型" class="headerlink" title="逻辑回归模型"></a>逻辑回归模型</h4><p>逻辑回归是在线性回归的基础上加了一个 Sigmoid 函数（非线形）映射，使得逻辑回归成为了一个优秀的分类算法，学习逻辑回归模型，首先应该记住一句话：<strong>逻辑回归假设数据服从伯努利分布,通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的。</strong>  </p>
<p>相比于协同过滤和矩阵分解利用用户的物品“相似度”进行推荐， 逻辑回归模型将问题看成了一个分类问题， 通过预测正样本的概率对物品进行排序。这里的正样本可以是用户“点击”了某个商品或者“观看”了某个视频， 均是推荐系统希望用户产生的“正反馈”行为， 因此<strong>逻辑回归模型将推荐问题转化成了一个点击率预估问题</strong>。而点击率预测就是一个典型的二分类， 正好适合逻辑回归进行处理， 那么逻辑回归是如何做推荐的呢？ 过程如下：</p>
<ol>
<li>将用户年龄、性别、物品属性、物品描述、当前时间、当前地点等特征转成数值型向量</li>
<li>确定逻辑回归的优化目标，比如把点击率预测转换成二分类问题， 这样就可以得到分类问题常用的损失作为目标， 训练模型</li>
<li>在预测的时候， 将特征向量输入模型产生预测， 得到用户“点击”物品的概率</li>
<li>利用点击概率对候选物品排序， 得到推荐列表</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221652189.png" alt="img"></p>
<p>这里的关键就是每个特征的权重参数， 我们一般是使用梯度下降的方式， 首先会先随机初始化参数， 然后将特征向量（也就是我们上面数值化出来的特征）输入到模型， 就会通过计算得到模型的预测概率， 然后通过对目标函数求导得到每个的梯度， 然后进行更新 ，这里的目标函数长下面这样：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221654279.png" alt="img"></p>
<p>求导之后的方式长这样：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221655094.png" alt="img"></p>
<p><strong>优点：</strong></p>
<ol>
<li>LR模型形式简单，可解释性好，从特征的权重可以看到不同的特征对最后结果的影响。</li>
<li>训练时便于并行化，在预测时只需要对特征进行线性加权，所以<strong>性能比较好</strong>，往往适合处理<strong>海量id类特征</strong>，用id类特征有一个很重要的好处，就是<strong>防止信息损失</strong>（相对于范化的 CTR 特征），对于头部资源会有更细致的描述</li>
<li>资源占用小,尤其是内存。在实际的工程应用中只需要存储权重比较大的特征及特征对应的权重。</li>
<li>方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类)</li>
</ol>
<p><strong>当然， 逻辑回归模型也有一定的局限性</strong></p>
<ol>
<li>表达能力不强， 无法进行特征交叉， 特征筛选等一系列“高级“操作（这些工作都得人工来干， 这样就需要一定的经验， 否则会走一些弯路）， 因此可能造成信息的损失</li>
<li>准确率并不是很高。因为这毕竟是一个线性模型加了个sigmoid， 形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布</li>
<li>处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据， 如果想处理非线性， 首先对连续特征的处理需要先进行<strong>离散化</strong>（离散化的目的是为了引入非线性），如上文所说，人工分桶的方式会引入多种问题。</li>
<li>LR 需要进行<strong>人工特征组合</strong>，这就需要开发者有非常丰富的领域经验，才能不走弯路。这样的模型迁移起来比较困难，换一个领域又需要重新进行大量的特征工程。</li>
</ol>
<p>所以如何<strong>自动发现有效的特征、特征组合，弥补人工经验不足，缩短LR特征实验周期</strong>，是亟需解决的问题， 而GBDT模型， 正好可以<strong>自动发现特征并进行有效组合</strong></p>
<h4 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h4><p>GBDT全称梯度提升决策树，在传统机器学习算法里面是对真实分布拟合的最好的几种算法之一，在前几年深度学习还没有大行其道之前，gbdt在各种竞赛是大放异彩。原因大概有几个，一是效果确实挺不错。二是即可以用于分类也可以用于回归。三是可以筛选特征， 所以这个模型依然是一个非常重要的模型。 </p>
<h4 id="GBDT-LR模型"><a href="#GBDT-LR模型" class="headerlink" title="GBDT+LR模型"></a>GBDT+LR模型</h4><p>2014年， Facebook提出了一种利用GBDT自动进行特征筛选和组合， 进而生成新的离散特征向量， 再把该特征向量当做LR模型的输入， 来产生最后的预测结果， 这就是著名的GBDT+LR模型了。GBDT+LR 使用最广泛的场景是CTR点击率预估，即预测当给用户推送的广告会不会被用户点击，模型的总体结构长下面这样：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221737318.png" alt="img"></p>
<p><strong>训练时</strong>，GBDT 建树的过程相当于自动进行的特征组合和离散化，然后从根结点到叶子节点的这条路径就可以看成是不同特征进行的特征组合，用叶子节点可以唯一的表示这条路径，并作为一个离散特征传入 LR 进行<strong>二次训练</strong>。</p>
<p>比如上图中， 有两棵树，x为一条输入样本，遍历两棵树后，x样本分别落到两颗树的叶子节点上，每个叶子节点对应LR一维特征，那么通过遍历树，就得到了该样本对应的所有LR特征。构造的新特征向量是取值0/1的。 比如左树有三个叶子节点，右树有两个叶子节点，最终的特征即为五维的向量。对于输入x，假设他落在左树第二个节点，编码[0,1,0]，落在右树第二个节点则编码[0,1]，所以整体的编码为[0,1,0,0,1]，这类编码作为特征，输入到线性分类模型（LR or FM）中进行分类。</p>
<p><strong>预测时</strong>，会先走 GBDT 的每棵树，得到某个叶子节点对应的一个离散特征(即一组特征组合)，然后把该特征以 one-hot 形式传入 LR 进行线性加权预测。</p>
<p>这个方案应该比较简单了， 下面有几个关键的点我们需要了解：</p>
<ol>
<li><strong>通过GBDT进行特征组合之后得到的离散向量是和训练数据的原特征一块作为逻辑回归的输入， 而不仅仅全是这种离散特征</strong></li>
<li>建树的时候用ensemble建树的原因就是一棵树的表达能力很弱，不足以表达多个有区分性的特征组合，多棵树的表达能力更强一些。GBDT每棵树都在学习前面棵树尚存的不足，迭代多少次就会生成多少棵树。</li>
<li>RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。</li>
<li>在CRT预估中， GBDT一般会建立两类树(非ID特征建一类， ID类特征建一类)， AD，ID类特征在CTR预估中是非常重要的特征，直接将AD，ID作为feature进行建树不可行，故考虑为每个AD，ID建GBDT树。<ol>
<li>非ID类树：不以细粒度的ID建树，此类树作为base，即便曝光少的广告、广告主，仍可以通过此类树得到有区分性的特征、特征组合</li>
<li>ID类树：以细粒度 的ID建一类树，用于发现曝光充分的ID对应有区分性的特征、特征组合</li>
</ol>
</li>
</ol>
<h3 id="特征交叉"><a href="#特征交叉" class="headerlink" title="特征交叉"></a>特征交叉</h3><h4 id="FM模型"><a href="#FM模型" class="headerlink" title="FM模型"></a>FM模型</h4><p><code>FM(Factorization Machine)</code>，即因式分解机。</p>
<h5 id="为什么需要FM模型"><a href="#为什么需要FM模型" class="headerlink" title="为什么需要FM模型"></a>为什么需要FM模型</h5><ol>
<li>特征组合是许多机器学习建模过程中遇到的问题，如果对特征直接建模，很有可能会忽略掉特征与特征之间的关联信息，因此，可以通过构建新的交叉特征这一特征组合方式提高模型的效果。</li>
<li>高维的稀疏矩阵是实际工程中常见的问题，并直接会导致计算量过大，特征权值更新缓慢。试想一个  的表，每一列都有  种元素，经过<code>One-Hot</code>独热编码之后，会产生一个  的表。因此表中每行元素只有  个值为  ，  个值为  。</li>
</ol>
<p>而<code>FM</code>的优势就在于对这两方面问题的处理。首先是特征组合，通过对两两特征组合，引入交叉项特征，提高模型得分；其次是高维灾难，通过引入隐向量（对参数矩阵进行矩阵分解），完成对特征的参数估计。</p>
<h5 id="FM模型的应用场景"><a href="#FM模型的应用场景" class="headerlink" title="FM模型的应用场景"></a>FM模型的应用场景</h5><p>我们已经知道了<code>FM</code>可以解决特征组合以及高维稀疏矩阵问题，而实际业务场景中，电商、豆瓣等推荐系统的场景是使用最广的领域，打个比方，小王只在豆瓣上浏览过  部电影，而豆瓣上面有  部电影，如果构建一个基于小王的电影矩阵，毫无疑问，里面将有  个元素全为  。而类似于这样的问题就可以通过<code>FM</code>来解决。</p>
<h5 id="FM模型的具体形式"><a href="#FM模型的具体形式" class="headerlink" title="FM模型的具体形式"></a>FM模型的具体形式</h5><p>首先我们回顾一下最常见的线性表达式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304191959346.png" alt="img"></p>
<p>其中  为初始权值，或者理解为偏置项，  为每个特征  对应的权值。可以看到，这种线性表达式只描述了每个特征与输出的关系。</p>
<p><code>FM</code>的表达式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192002037.png" alt="img"></p>
<p>可观察到，只是在线性表达式后面加入了新的交叉项特征及对应的权值。这里  和  分别表示两个不同的特征取值，对于  维的特征来说，这样的组合应该一共有  种，也就意味着我们需要同样数量的权重参数。</p>
<h5 id="FM模型的解决方法"><a href="#FM模型的解决方法" class="headerlink" title="FM模型的解决方法"></a>FM模型的解决方法</h5><p><code>FM</code>解决这个问题的方法非常简单，它不再是简单地为交叉之后的特征对设置参数，而是设置了一种计算特征参数的方法。<code>FM</code>模型引入了新的矩阵 ，矩阵  是一个  的二维矩阵。这里的  是我们设置的参数，一般不会很大，比如  、  之类。对于特征每一个维度  ，我们都可以找到一个  ，它表示一个  的向量。于是我们可以用  和  来计算得出上式中的  ，即  。也就是说我们<strong>用向量的内积来计算得到了就交叉特征的系数</strong>，相比于原先  量级的参数而言，我们将参数的量级降低到了  。</p>
<p>有了上面的方法，我们就能表示出交叉项，具体过程如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192107149.png" alt="img"></p>
<h5 id="FM模型的训练"><a href="#FM模型的训练" class="headerlink" title="FM模型的训练"></a>FM模型的训练</h5><p>经过上述步骤，我们能够得到变形之后的原式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192121730.png" alt="img"></p>
<p>首先需要明确的是我们想要优化的参数是  ，  和  ，所以我们对损失函数求导即可得到：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192201890.png" alt="img"></p>
<p>其中  和  是独立的，所以它是可以提前算好的，这样一来对于所有参数项，我们都可以在  的时间内计算出它们的梯度。</p>
<h5 id="FM模型的高维扩展"><a href="#FM模型的高维扩展" class="headerlink" title="FM模型的高维扩展"></a>FM模型的高维扩展</h5><p>我们仿照刚才的公式，可以写出<code>FM</code>模型推广到  维的方程：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192209525.png" alt="img"></p>
<p>前面两项都很好理解，我们着重来看第三项。第三项当中包含了从  维到  维交叉特征的情况，我们以  为例，那么这一项当中应该包含二维的交叉项以及三维的交叉项，应该是这样的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304192210293.png" alt="img"></p>
<p>这个式子<strong>整体上和之前的形式是一样的</strong>，我们不难分析出它的复杂度是  。当  的时候，我们通过一系列变形将它的复杂度优化到了  ，而当  的时候，没有很好的优化方法，而且三重特征的交叉往往没有意义，并且会过于稀疏，所以我们一般情况下只会使用  的情况。</p>
<h4 id="FFM模型"><a href="#FFM模型" class="headerlink" title="FFM模型"></a>FFM模型</h4><p><code>FFM(Field-aware Factorization Machine)</code>其实就是<code>FM</code>的进阶版，<code>FFM</code>将隐向量  又进一步细化（引入了<code>field</code>的概念，即将特征所在的不同的<code>field</code>这个信息也考虑进去），其公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201650996.png" alt="img"></p>
<p>其中，  是第  个特征所属的<code>field</code>。如果隐向量的长度为  ，那么<code>FFM</code>的二次参数有  个，远多于<code>FM</code>模型的  个。此外，由于隐向量与<code>field</code>相关，<code>FFM</code>二次项并不能够化简，其预测复杂度是  。</p>
<h5 id="FFM模型的特征组合方式"><a href="#FFM模型的特征组合方式" class="headerlink" title="FFM模型的特征组合方式"></a>FFM模型的特征组合方式</h5><p>举一个例子进行辅助说明：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>User</th>
<th>Movie</th>
<th>Genre</th>
<th>Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>YuChin</td>
<td>3Idiots</td>
<td>Comedy, Drama</td>
<td>$9.99</td>
</tr>
</tbody>
</table>
</div>
<p>对上面出现的信息进行分类标注，<strong>红字代表所在的field,蓝字代表特征,绿字代表特征的值。</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201703206.png" alt="img"></p>
<p><strong>FM的特征组合方式为：</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201704698.png" alt="img"></p>
<p><strong>FFM的特征组合方式为：</strong></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202304201707323.png" alt="img"></p>
<p>不难看出，<code>FM</code>中有  ，  ，  ，  ， 五个隐向量，但到了<code>FFM</code>中有  个，选  与  对应的域  对应的隐向量  进行交叉。</p>
<h5 id="FFM模型的应用场景"><a href="#FFM模型的应用场景" class="headerlink" title="FFM模型的应用场景"></a>FFM模型的应用场景</h5><p>和<code>FM</code>算法一样，<code>FFM</code>主要应用在推荐算法中的<code>CTR</code>点击率预估（排序）问题，推荐系统一般可以分成两个模块，召回和排序。比如对于电影推荐，召回模块会针对用户生成一个推荐电影列表，而排序模块则负责对这个电影列表根据用户的兴趣做排序。当把<code>FFM</code>算法应用到推荐系统中时，具体地是应用在排序模块。</p>
<h4 id="PNN"><a href="#PNN" class="headerlink" title="PNN"></a>PNN</h4><p>在特征交叉的相关模型中FM, FFM都证明了特征交叉的重要性，FNN将神经网络的高阶隐式交叉加到了FM的二阶特征交叉上，一定程度上说明了DNN做特征交叉的有效性。但是对于DNN这种“add”操作的特征交叉并不能充分挖掘类别特征的交叉效果。PNN虽然也用了DNN来对特征进行交叉组合，但是并不是直接将低阶特征放入DNN中，而是设计了Product层先对低阶特征进行充分的交叉组合之后再送入到DNN中去。</p>
<p>PNN模型其实是对IPNN和OPNN的总称，两者分别对应的是不同的Product实现方法，前者采用的是inner product，后者采用的是outer product。在PNN的算法方面，比较重要的部分就是Product Layer的简化实现方法，需要在数学和代码上都能够比较深入的理解。</p>
<h5 id="模型结构及原理"><a href="#模型结构及原理" class="headerlink" title="模型结构及原理"></a>模型结构及原理</h5><p>PNN模型的整体架构如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221912175.png" alt="img"></p>
<p>一共分为五层，其中除了Product Layer别的layer都是比较常规的处理方法，均可以从前面的章节进一步了解。模型中最重要的部分就是通过Product层对embedding特征进行交叉组合，也就是上图中红框所显示的部分。</p>
<p>Product层主要有线性部分和非线性部分组成，分别用和来表示，</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221914930.png" alt="img"></p>
<ol>
<li>线性模块，一阶特征(未经过显示特征交叉处理)，对应论文中的</li>
<li>非线性模块，高阶特征(经过显示特征交叉处理)，对应论文中的</li>
</ol>
<p><strong>线性部分</strong></p>
<p>先来解释一下是如何计算得到的，在介绍计算之前先介绍一下矩阵内积计算, 如下公式所示，用一句话来描述就是两个矩阵对应元素相称，然后将相乘之后的所有元素相加</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221916770.png" alt="img"></p>
<p>的计算就是矩阵内积，而是有个组成，所以需要个矩阵求得，但是在代码实现的时候不一定是定义个矩阵，可以将这些矩阵Flatten。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221917878.png" alt="img"></p>
<p>总之这一波操作就是将所有的embedding向量中的所有元素都乘以一个矩阵的对应元素，最后相加即可，这一部分比较简单(N表示的是特征的数量，M表示的是所有特征转化为embedding之后维度，也就是N*emb_dim)</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221919755.png" alt="img"></p>
<p><strong>非线性部分</strong></p>
<p>上面介绍了线性部分的计算，非线性部分的计算相比线性部分要复杂很多，先从整体上看的计算</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221925847.png" alt="img"></p>
<p>从上述公式中可以发现，和类似需要个矩阵计算内积得到，重点就是如何求这个，这里作者提出了两种方式，一种是使用内积计算，另一种是使用外积计算。</p>
<ul>
<li>IPNN</li>
</ul>
<p>使用内积实现特征交叉就和FM是类似的(两两向量计算内积)，下面将向量内积操作表示如下表达式</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221951440.png" alt="img"></p>
<p>将内积的表达式带入的计算表达式中有：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221951074.png" alt="img"></p>
<p>上面就提到了这里使用的内积是计算两两特征之间的内积，然而向量a和向量b的内积与向量b和向量a的内积是相同的，其实是没必要计算的，看一下下面FM的计算公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221952139.png" alt="img"></p>
<p>也就是说计算的内积矩阵是对称的，那么与其对应元素做矩阵内积的矩阵也是对称的，对于可学习的权重来说如果是对称的是不是可以只使用其中的一半就行了呢，所以基于这个思考，对Inner Product的权重定义及内积计算进行优化，首先将权重矩阵分解,此时（参数从原来的变成了）,将分解后的带入的计算公式有：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221952937.png" alt="img"></p>
<p>所以优化后的的计算公式为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221952743.png" alt="img"></p>
<p>这里为了好理解不做过多的解释，其实这里对于矩阵分解省略了一些细节，感兴趣的可以去看原文，最后模型实现的时候就是基于上面的这个公式计算的（给出的代码也是基于优化之后的实现）。</p>
<ul>
<li>OPNN</li>
</ul>
<p>使用外积实现相比于使用内积实现，唯一的区别就是使用向量的外积来计算矩阵,首先定义向量的外积计算</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221953919.png" alt="img"></p>
<p>从外积公式可以发现两个向量的外积得到的是一个矩阵，与上面介绍的内积计算不太相同，内积得到的是一个数值。内积实现的Product层是将计算得到的内积矩阵，乘以一个与其大小一样的权重矩阵，然后求和，按照这个思路的话，通过外积得到的计算相当于之前的内积值乘以权重矩阵对应位置的值求和就变成了，外积矩阵乘以权重矩阵中对应位置的子矩阵然后将整个相乘得到的大矩阵对应元素相加，用公式表示如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221953829.png" alt="img"></p>
<p>需要注意的是此时的表示的是一个矩阵，而不是一个值，此时计算的复杂度是, 其中表示的是特征的组合数量，表示的是计算外积的复杂度。这样的复杂度肯定是无法接受的，所以为了优化复杂度，PNN的作者重新定义了的计算方式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221954360.png" alt="img"></p>
<p>需要注意，这里新定义的外积计算与传统的外积计算时不等价的，这里是为了优化计算效率重新定义的计算方式，从公式中可以看出，相当于先将原来的embedding向量在特征维度上先求和，变成一个向量之后再计算外积。加入原embedding向量表示为，其中表示特征的数量，M表示的是所有特征的总维度，即, 在特征维度上进行求和就是将矩阵压缩成了, 然后两个维的向量计算外积得到最终所有特征的外积交叉结果，最终的可以表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305221954996.png" alt="img"></p>
<p>最终的计算方式和的计算方式看起来差不多，但是需要注意外积优化后的的维度是的，表示的是特征矩阵的维度，即。</p>
<h4 id="DCN"><a href="#DCN" class="headerlink" title="DCN"></a>DCN</h4><p>Wide&amp;Deep模型的提出不仅综合了“记忆能力”和“泛化能力”， 而且开启了不同网络结构融合的新思路。 所以后面就有各式各样的模型改进Wide部分或者Deep部分， 而Deep&amp;Cross模型(DCN)就是其中比较典型的一个，这是2017年斯坦福大学和谷歌的研究人员在ADKDD会议上提出的， 该模型针对W&amp;D的wide部分进行了改进， 因为Wide部分有一个不足就是需要人工进行特征的组合筛选， 过程繁琐且需要经验， 而2阶的FM模型在线性的时间复杂度中自动进行特征交互，但是这些特征交互的表现能力并不够，并且随着阶数的上升，模型复杂度会大幅度提高。于是乎，作者用一个Cross Network替换掉了Wide部分，来自动进行特征之间的交叉，并且网络的时间和空间复杂度都是线性的。 通过与Deep部分相结合，构成了深度交叉网络（Deep &amp; Cross Network），简称DCN。</p>
<h5 id="模型结构及原理-1"><a href="#模型结构及原理-1" class="headerlink" title="模型结构及原理"></a>模型结构及原理</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222002416.png" alt="img"></p>
<h5 id="Embedding和Stacking-层"><a href="#Embedding和Stacking-层" class="headerlink" title="Embedding和Stacking 层"></a>Embedding和Stacking 层</h5><p>Embedding层我们已经非常的熟悉了吧， 这里的作用依然是把稀疏离散的类别型特征变成低维密集型。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222003410.png" alt="img"></p>
<p>其中对于某一类稀疏分类特征（如id），是第个分类值（id序号）的embedding向量。是embedding矩阵， 维度， 是embedding维度， 是该类特征的唯一取值个数。属于该特征的二元稀疏向量(one-hot)编码的。 【实质上就是在训练得到的Embedding参数矩阵中找到属于当前样本对应的Embedding向量】。其实绝大多数基于深度学习的推荐模型都需要Embedding操作，参数学习是通过神经网络进行训练。</p>
<p>最后，该层需要将所有的密集型特征与通过embedding转换后的特征进行联合（Stacking）：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222003825.png" alt="img"></p>
<p>一共个类别特征， dense是数值型特征， 两者在特征维度拼在一块。 上面的这两个操作如果是看了前面的模型的话，应该非常容易理解了。</p>
<h5 id="Cross-Network"><a href="#Cross-Network" class="headerlink" title="Cross Network"></a>Cross Network</h5><p>这个就是本模型最大的亮点了【Cross网络】， 这个思路感觉非常Nice。设计该网络的目的是增加特征之间的交互力度。交叉网络由多个交叉层组成， 假设第层的输出向量， 那么对于第层的输出向量表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222005263.png" alt="img"></p>
<p>可以看到， 交叉层的二阶部分非常类似PNN提到的外积操作， 在此基础上增加了外积操作的权重向量， 以及原输入向量和偏置向量。 交叉层的可视化如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222006335.png" alt="img"></p>
<p>可以看到， 每一层增加了一个维的权重向量（n表示输入向量维度）， 并且在每一层均保留了输入向量， 因此输入和输出之间的变化不会特别明显。关于这一层， 原论文里面有个具体的证明推导Cross Network为啥有效， 不过比较复杂，这里我拿一个式子简单的解释下上面这个公式的伟大之处：</p>
<p><strong>我们根据上面这个公式， 尝试的写前面几层看看:</strong></p>
<p>我们暂且写到第3层的计算， 我们会发现什么结论呢？  给大家总结一下：</p>
<ol>
<li><p>中包含了所有的的1,2阶特征的交互， 包含了所有的的1、2、3阶特征的交互，中包含了所有的, 与的交互，的1、2、3、4阶特征交互。 因此， 交叉网络层的叉乘阶数是有限的。 <strong>第层特征对应的最高的叉乘阶数</strong></p>
</li>
<li><p>Cross网络的参数是共享的， 每一层的这个权重特征之间共享， 这个可以使得模型泛化到看不见的特征交互作用， 并且对噪声更具有鲁棒性。 例如两个稀疏的特征， 它们在数据中几乎不发生交互， 那么学习的权重对于预测没有任何的意义。</p>
</li>
<li><p>计算交叉网络的参数数量。 假设交叉层的数量是， 特征的维度是， 那么总共的参数是：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222009493.png" alt="img"></p>
<p>这个就是每一层会有和。且维度和的维度是一致的。</p>
</li>
<li><p>交叉网络的时间和空间复杂度是线性的。这是因为， 每一层都只有和， 没有激活函数的存在，相对于深度学习网络， 交叉网络的复杂性可以忽略不计。</p>
</li>
<li><p>Cross网络是FM的泛化形式，在FM模型中，特征  的权重 ，那么交叉项  的权重为。在DCN中，的权重为, 交叉项的权重是参数和的乘积，这个看上面那个例子展开感受下。因此两个模型都各自学习了独立于其他特征的一些参数，并且交叉项的权重是相应参数的某种组合。FM只局限于2阶的特征交叉(一般)，而DCN可以构建更高阶的特征交互， 阶数由网络深度决定，并且交叉网络的参数只依据输入的维度线性增长。</p>
</li>
<li><p>还有一点我们也要了解，对于每一层的计算中， 都会跟着, 这个是咱们的原始输入， 之所以会乘以一个这个，是为了保证后面不管怎么交叉，都不能偏离我们的原始输入太远，别最后交叉交叉都跑偏了。</p>
</li>
<li><p>, 这个东西其实有点跳远连接的意思，也就是和ResNet也有点相似，无形之中还能有效的缓解梯度消失现象。</p>
</li>
</ol>
<p>好了， 关于本模型的交叉网络的细节就介绍到这里了。这应该也是本模型的精华之处了，后面就简单了。</p>
<h5 id="Deep-Network"><a href="#Deep-Network" class="headerlink" title="Deep Network"></a>Deep Network</h5><p>这个就和上面的D&amp;W的全连接层原理一样。这里不再过多的赘述。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222013355.png" alt="img"></p>
<p>具体的可以参考W&amp;D模型。</p>
<h5 id="组合输出层"><a href="#组合输出层" class="headerlink" title="组合输出层"></a>组合输出层</h5><p>这个层负责将两个网络的输出进行拼接， 并且通过简单的Logistics回归完成最后的预测：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222014011.png" alt="img"></p>
<p>其中和分别表示交叉网络和深度网络的输出。 最后二分类的损失函数依然是交叉熵损失：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222014360.png" alt="img"></p>
<p>Cross&amp;Deep模型的原理就是这些了，其核心部分就是Cross Network， 这个可以进行特征的自动交叉， 避免了更多基于业务理解的人工特征组合。 该模型相比于W&amp;D，Cross部分表达能力更强， 使得模型具备了更强的非线性学习能力。</p>
<h4 id="AutoInt"><a href="#AutoInt" class="headerlink" title="AutoInt"></a>AutoInt</h4><h5 id="动机和原理"><a href="#动机和原理" class="headerlink" title="动机和原理"></a>动机和原理</h5><p>这篇文章的前言部分依然是说目前模型的不足，以引出模型的动机所在， 简单的来讲，就是两句话：</p>
<ol>
<li>浅层的模型会受到交叉阶数的限制，没法完成高阶交叉</li>
<li>深层模型的DNN在学习高阶隐性交叉的效果并不是很好， 且不具有可解释性</li>
</ol>
<p>于是乎：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222018983.png" alt="img"></p>
<p>那么是如何做到的呢？ 引入了transformer， 做成了一个特征交互层， 原理如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222018848.png" alt="img"></p>
<h5 id="AutoInt模型的前向过程梳理"><a href="#AutoInt模型的前向过程梳理" class="headerlink" title="AutoInt模型的前向过程梳理"></a>AutoInt模型的前向过程梳理</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222019899.png" alt="img"></p>
<h6 id="Input-Layer"><a href="#Input-Layer" class="headerlink" title="Input Layer"></a>Input Layer</h6><p>输入层这里， 用到的特征主要是离散型特征和连续性特征， 这里不管是哪一类特征，都会过embedding层转成低维稠密的向量，是的， <strong>连续性特征，这里并没有经过分桶离散化，而是直接走embedding</strong>。这个是怎么做到的呢？就是就是类似于预训练时候的思路，先通过item_id把连续型特征与类别特征关联起来，最简单的，就是把item_id拿过来，过完embedding层取出对应的embedding之后，再乘上连续值即可， 所以这个连续值事先一定要是归一化的。 当然，这个玩法，我也是第一次见。 学习到了， 所以模型整体的输入如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222021880.png" alt="img"></p>
<p>这里的表示特征的个数, 这是离散型特征， one-hot的形式， 而在这里是连续性特征。过embedding层的细节应该是我上面说的那样。</p>
<h6 id="Embedding-Layer"><a href="#Embedding-Layer" class="headerlink" title="Embedding Layer"></a>Embedding Layer</h6><p>embedding层的作用是把高维稀疏的特征转成低维稠密， 离散型的特征一般是取出对应的embedding向量即可， 具体计算是这样：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222024864.png" alt="img"></p>
<p>对于第个离散特征，直接第个嵌入矩阵乘one-hot向量就取出了对应位置的embedding。 当然，如果输入的时候不是个one-hot， 而是个multi-hot的形式，那么对应的embedding输出是各个embedding求平均得到的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222023574.png" alt="img"></p>
<p>比如， 推荐里面用户的历史行为item。过去点击了多个item，最终的输出就是这多个item的embedding求平均。 而对于连续特征， 我上面说的那样， 也是过一个embedding矩阵取相应的embedding， 不过，最后要乘一个连续值</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222025480.png" alt="img"></p>
<p>这样，不管是连续特征，离散特征还是变长的离散特征，经过embedding之后，都能得到等长的embedding向量。 我们把这个向量拼接到一块，就得到了交互层的输入。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222025399.png" alt="img"></p>
<h6 id="Interacting-Layer"><a href="#Interacting-Layer" class="headerlink" title="Interacting Layer"></a>Interacting Layer</h6><p>这个是本篇论文的核心了，其实这里说的就是transformer块的前向传播过程，所以这里我就直接用比较白话的语言简述过程了，不按照论文中的顺序展开了。</p>
<p>通过embedding层， 我们会得到M个向量，假设向量的维度是维， 那么这个就是一个的矩阵， 我们定一个符号。 接下来我们基于这个矩阵，做三次变换，也就是分别乘以三个矩阵， 这三个矩阵的维度是的话， 那么我们就会得到三个结果：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222028818.png" alt="img"></p>
<p>这三个矩阵都是的。这其实就完成了一个Head的操作。所谓的自注意力， 就是通过三次变换得到的结果之间，通过交互得到相关性，并通过相关性进行加权汇总，全是自发的。 那么是怎么做到的呢？首先， 先进行这样的操作：  这个结果得到的是一个的矩阵， 那么这个操作到底是做了一个什么事情呢？</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222029092.png" alt="img"></p>
<p>假设这里的是我们的6个特征， 而每一行代表每个特征的embedding向量，这样两个矩阵相乘，相当于得到了当前特征与其它特征两两之间的內积值， 而內积可以表示两个向量之间的相似程度。所以得到的结果每一行，就代表当前这个特征与其它特征的相似性程度。</p>
<p>接下来，我们对， 在最后一个维度上进行softmax，就根据相似性得到了权重信息，这其实就是把相似性分数归一化到了0-1之间 接下来， 我们再进行这样的一步操作 这样就得到了的矩阵， 这步操作，其实就是一个加权汇总的过程， 对于每个特征， 先求与其它特征的相似度，然后得到一个权重，再回乘到各自的特征向量再求和。 只不过这里的特征是经过了一次线性变化的过程，降维到了。</p>
<p>上面是我从矩阵的角度又过了一遍， 这个是直接针对所有的特征向量一部到位。 论文里面的从单个特征的角度去描述的，只说了一个矩阵向量过多头注意力的操作。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222030271.png" alt="img"></p>
<p>这里会更好懂一些， 就是相当于上面矩阵的每一行操作拆开了， 首先，整个拼接起来的embedding矩阵还是过三个参数矩阵得到， 然后是每一行单独操作的方式，对于某个特征向量，与其它的特征两两內积得到权重，然后在softmax，回乘到对应向量，然后进行求和就得到了融合其它特征信息的新向量。 具体过程如图：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222030314.png" alt="img"></p>
<p>上面的过程是用了一个头，理解的话就类似于从一个角度去看特征之间的相关关系，用论文里面的话讲，这是从一个子空间去看， 如果是想从多个角度看，这里可以用多个头，即换不同的矩阵得到不同的然后得到不同的， 每个是的。</p>
<p>然后，多个头的结果concat起来</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222031199.png" alt="img"></p>
<p>这是一个的向量， 假设有个头。 </p>
<p>接下来， 过一个残差网络层，这是为了保留原始的特征信息</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222031359.png" alt="img"></p>
<p>这里的是的向量， 是的矩阵， 最后得到的是的向量， 这是其中的一个特征，如果是个特征堆叠的话，最终就是的矩阵， 这个就是Interacting Layer的结果输出。</p>
<h6 id="Output-Layer"><a href="#Output-Layer" class="headerlink" title="Output Layer"></a>Output Layer</h6><p>输出层就非常简单了，加一层全连接映射出输出值即可：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222032295.png" alt="img"></p>
<p>这里的是的， 这样最终得到的是一个概率值了， 接下来交叉熵损失更新模型参数即可。</p>
<h5 id="AutoInt的分析"><a href="#AutoInt的分析" class="headerlink" title="AutoInt的分析"></a>AutoInt的分析</h5><p>这里论文里面分析了为啥AutoInt能建模任意的高阶交互以及时间复杂度和空间复杂度的分析。我们一一来看。</p>
<p>关于建模任意的高阶交互， 我们这里拿一个transformer块看下， 对于一个transformer块， 我们发现特征之间完成了一个2阶的交互过程，得到的输出里面我们还保留着1阶的原始特征。 </p>
<p>那么再经过一个transformer块呢？ 这里面就会有2阶和1阶的交互了， 也就是会得到3阶的交互信息。而此时的输出，会保留着第一个transformer的输出信息特征。再过一个transformer块的话，就会用4阶的信息交互信息， 其实就相当于， 第个transformer里面会建模出阶交互来， 这个与CrossNet其实有异曲同工之妙的，无法是中间交互时的方式不一样。 前者是bit-wise级别的交互，而后者是vector-wise的交互。 </p>
<p>所以， AutoInt是可以建模任意高阶特征的交互的，并且这种交互还是显性。</p>
<p>关于时间复杂度和空间复杂度，空间复杂度是级别的， 这个也很好理解，看参数量即可， 3个W矩阵， H个head，再假设L个transformer块的话，参数量就达到这了。 时间复杂度的话是的，论文说如果d和d’很小的话，其实这个模型不算复杂。</p>
<h4 id="FiBiNet"><a href="#FiBiNet" class="headerlink" title="FiBiNet"></a>FiBiNet</h4><h5 id="模型原理及细节"><a href="#模型原理及细节" class="headerlink" title="模型原理及细节"></a>模型原理及细节</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222035784.png" alt="img"></p>
<h6 id="Embedding-Layer-1"><a href="#Embedding-Layer-1" class="headerlink" title="Embedding Layer"></a>Embedding Layer</h6><p>这个不多讲， 整理这个是为了后面统一符号。</p>
<p>假设我们有个离散特征，经过embedding层之后，会得到， 其中，表示第个离散特征对应的embedding向量，维。</p>
<h6 id="SENET-Layer"><a href="#SENET-Layer" class="headerlink" title="SENET Layer"></a>SENET Layer</h6><p>这是第一个重点，首先这个网络接收的输入是上面的， 网络的输出也是个同样大小的张量<code>(None, f, k)</code>矩阵。 结构如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222038251.png" alt="img"></p>
<p>SENet由自动驾驶公司Momenta在2017年提出，在当时，是一种应用于图像处理的新型网络结构。它基于CNN结构，<strong>通过对特征通道间的相关性进行建模，对重要特征进行强化来提升模型准确率，本质上就是针对CNN中间层卷积核特征的Attention操作</strong>。SENet仍然是效果最好的图像处理网络结构之一。</p>
<p>把SENet放在Embedding层之上，通过SENet网络，动态地学习这些特征的重要性。<strong>对于每个特征学会一个特征权重，然后再把学习到的权重乘到对应特征的Embedding里，这样就可以动态学习特征权重，通过小权重抑制噪音或者无效低频特征，通过大权重放大重要特征影响的目的</strong>。在推荐系统里面， 结构长这个样子：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222040735.png" alt="img"></p>
<p>下面看下这个网络里面的具体计算过程， SENET主要分为三个步骤Squeeze, Excitation, Re-weight。</p>
<ul>
<li><p><strong>在Squeeze阶段</strong>，我们对每个特征的Embedding向量进行数据压缩与信息汇总，如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222041255.png" alt="img"></p>
<p>假设某个特征是维大小的，那么我们对里包含的维数字求均值，得到能够代表这个特征汇总信息的数值 ，也就是说，把第个特征的里的信息压缩到一个数值。原始版本的SENet，在这一步是对CNN的二维卷积核进行操作的，这里等于对某个特征Embedding元素求均值。我们试过，在推荐领域均值效果比效果好，这也很好理解，因为<strong>图像领域对卷积核元素求，等于找到最强的那个特征，而推荐领域的特征，每一位的数字都是有意义的，所以求均值能更好地保留和融合信息</strong>。通过Squeeze阶段，对于每个特征 ，都压缩成了单个数值，假设特征Embedding层有个特征，就形成Squeeze向量，向量大小。</p>
</li>
<li><p><strong>Excitation阶段</strong>，这个阶段引入了中间层比较窄的两层MLP网络，作用在Squeeze阶段的输出向量上，如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222042251.png" alt="img"></p>
<p>非线性激活函数，一般。本质上，这是在做特征的交叉，也就是说，每个特征以一个来表征，通过MLP来进行交互，通过交互，得出这么个结果：对于当前所有输入的特征，通过相互发生关联，来动态地判断哪些特征重要，哪些特征不重要。</p>
<p>其中，第一个MLP的作用是做特征交叉，第二个MLP的作用是为了保持输出的大小维度。因为假设Embedding层有个特征，那么我们需要保证输出个权重值，而第二个MLP就是起到将大小映射到个数值大小的作用。</p>
<p>这样，经过两层MLP映射，就会产生个权重数值，第个数值对应第个特征Embedding的权重 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222043024.png" alt="img"></p>
<p>下面再分析下维度， SENet的输入是，这个是<code>(None, f, k)</code>的维度， 通过Squeeze阶段，得到了<code>(None, f)</code>的矩阵，这个也就相当于Layer L1的输入(当然这里没有下面的偏置哈)，接下来过MLP1， 这里的, 这里的叫做reduction ratio， 这个就是中间层神经元的个数， 表示了压缩的程度。</p>
</li>
<li><p><strong>Re-Weight</strong>，我们把Excitation阶段得到的每个特征对应的权重，再乘回到特征对应的Embedding里，就完成了对特征重要性的加权操作。  , and 。数值大，说明SENet判断这个特征在当前输入组合里比较重要， 数值小，说明SENet判断这个特征在当前输入组合里没啥用。如果非线性函数用Relu，会发现大量特征的权重会被Relu搞成0，也就是说，其实很多特征是没啥用的。</p>
</li>
</ul>
<p>这样，就可以将SENet引入推荐系统，用来对特征重要性进行动态判断。注意，<strong>所谓动态，指的是比如对于某个特征，在某个输入组合里可能是没用的，但是换一个输入组合，很可能是重要特征。它重要不重要，不是静态的，而是要根据当前输入，动态变化的</strong>。</p>
<p>这里正确的理解，算是一种特征重要性选择的思路， SENET和AFM的Attention网络是起着同样功效的一个网络。只不过那个是在特征交互之后进行特征交互重要性的选择，而这里是从embedding这里先压缩，再交互，再选择，去掉不太重要的特征。 <strong>考虑特征重要性上的两种考虑思路，难以说孰好孰坏，具体看应用场景</strong>。 不过如果分析下这个东西为啥会有效果， 就像张俊林老师提到的那样， 在Excitation阶段， 各个特征过了一个MLP进行了特征组合， 这样就真有可能过滤掉对于当前的交互不太重要的特征。 至于是不是， 那神经网络这东西就玄学了，让网络自己去学吧。</p>
<h6 id="Bilinear-Interaction-Layer"><a href="#Bilinear-Interaction-Layer" class="headerlink" title="Bilinear-Interaction Layer"></a>Bilinear-Interaction Layer</h6><p>特征重要性选择完事， 接下来就是研究特征交互， 这里作者直接就列出了目前的两种常用交互以及双线性交互:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222048779.png" alt="img"></p>
<p>这个图其实非常了然了。以往模型用的交互， 内积的方式(FM,FFM)这种或者哈达玛积的方式(NFM,AFM)这种。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222048554.png" alt="img"></p>
<p>所谓的双线性，其实就是组合了内积和哈达玛积的操作，看上面的右图。就是在和之间先加一个矩阵， 这个矩阵的维度是, 是的向量。 先让与内积，得到的向量，这时候先仔细体会下这个<strong>新向量的每个元素，相当于是原来向量在每个维度上的线性组合了</strong>。这时候再与进行哈达玛积得到结果。</p>
<p>这里我不由自主的考虑了下双线性的功效，也就是为啥作者会说双线性是细粒度，下面是我自己的看法哈。</p>
<ul>
<li>如果我们单独先看内积操作，特征交互如果是两个向量直接内积，这时候， 结果大的，说明两个向量相似或者特征相似， 但向量内积，其实是相当于向量的各个维度先对应位置元素相乘再相加求和。 这个过程中认为的是向量的各个维度信息的重要性是一致的。类似于， 但真的一致吗？ —- <strong>内积操作没有考虑向量各个维度的重要性</strong></li>
<li>如果我们单独看哈达玛积操作， 特征交互如果是两个向量哈达玛积，这时候，是各个维度对应位置元素相乘得到一个向量， 而这个向量往往后面会进行线性或者非线性交叉的操作， 最后可能也会得到具体某个数值，但是这里经过了线性或者非线性交叉操作之后， 有没有感觉把向量各个维度信息的重要性考虑了进来？   就类似于。 如果模型认为重要性相同，那么哈达玛积还有希望退化成内积，所以哈达玛积感觉考虑的比内积就多了一些。 —- <strong>哈达玛积操作自身也没有考虑各个维度重要性，但通过后面的线性或者非线性操作，有一定的维度重要性在里面</strong></li>
<li>再看看这个双线性， 是先内积再哈达玛积。这个内积操作不是直接和内积，而是中间引入了个矩阵，参数可学习。 那么和做内积之后，虽然得到了同样大小的向量，但是这个向量是各个维度元素的线性组合，相当于变成了， 这时候再与哈达玛积的功效，就变成了， 这时候，就可以看到，如果这里的是个对角矩阵，那么这里就退化成了哈达玛积。  所以双线性感觉考虑的又比哈达玛积多了一些。如果后面再走一个非线性操作的话，就会发现这里同时考虑了两个交互向量各个维度上的重要性。—-<strong>双线性操作同时可以考虑交互的向量各自的各个维度上的重要性信息， 这应该是作者所说的细粒度，各个维度上的重要性</strong></li>
</ul>
<p><strong>当然思路是思路，双线性并不一定见得一定比哈达玛积有效， SENET也不一定就会比原始embedding要好，一定要辩证看问题</strong></p>
<p>这里还有个厉害的地方在于这里的W有三种选择方式，也就是三种类型的双线性交互方式。</p>
<ol>
<li>Field-All Type</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222049946.png" alt="img"></p>
<p>也就是所有的特征embedding共用一个矩阵，这也是Field-All的名字来源。。这种方式最简单</p>
<ol>
<li>Field-Each Type</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222050330.png" alt="img"></p>
<p>每个特征embedding共用一个矩阵， 那么如果有个特征的话，这里的需要个。所以这里的参数个数， 这里的是因为两两组合之后，比如<code>[0,1,2]</code>， 两两组合<code>[0,1], [0,2], [1,2]</code>。 这里用到的域是0和1。</p>
<ol>
<li>Field-Interaction Type</li>
</ol>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222050837.png" alt="img"></p>
<p>每组特征交互的时候，用一个矩阵， 那么这里如果有个特征的话，需要是个。参数个数个。</p>
<p>不知道看到这里，这种操作有没有种似曾相识的感觉， 有没有想起FM和FFM， 反正我是不自觉的想起了哈哈，不知道为啥。总感觉FM的风格和上面的Field-All很像， 而FFM和下面的Field-Interaction很像。</p>
<p>我们的原始embedding和SKNET-like embedding都需要过这个层，那么得到的就是一个双线性两两组合的矩阵， 维度是的矩阵。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222051074.png" alt="img"></p>
<h6 id="Combination-Layer"><a href="#Combination-Layer" class="headerlink" title="Combination Layer"></a>Combination Layer</h6><p>这个层的作用就是把目前得到的特征拼起来</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222051287.png" alt="img"></p>
<p>这里他直拼了上面得到的两个离散特征通过各种交互之后的形式，如果是还有连续特征的话，也可以在这里拼起来，然后过DNN，不过这里其实还省略了一步操作就是Flatten，先展平再拼接。</p>
<h6 id="DNN和输出层"><a href="#DNN和输出层" class="headerlink" title="DNN和输出层"></a>DNN和输出层</h6><p> DNN的话普通的全连接网络， 再捕捉一波高阶的隐性交互。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222052753.png" alt="img"></p>
<p>而输出层</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222052222.png" alt="img"></p>
<p>分类问题损失函数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222053977.png" alt="img"></p>
<h3 id="Wide-amp-Deep系列"><a href="#Wide-amp-Deep系列" class="headerlink" title="Wide&amp;Deep系列"></a>Wide&amp;Deep系列</h3><h4 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide&amp;Deep"></a>Wide&amp;Deep</h4><h5 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h5><p>在CTR预估任务中利用手工构造的交叉组合特征来使线性模型具有“记忆性”，使模型记住共现频率较高的特征组合，往往也能达到一个不错的baseline，且可解释性强。但这种方式有着较为明显的缺点：</p>
<ol>
<li>特征工程需要耗费太多精力。</li>
<li>模型是强行记住这些组合特征的，对于未曾出现过的特征组合，权重系数为0，无法进行泛化。</li>
</ol>
<p>为了加强模型的泛化能力，研究者引入了DNN结构，将高维稀疏特征编码为低维稠密的Embedding vector，这种基于Embedding的方式能够有效提高模型的泛化能力。但是，基于Embedding的方式可能因为数据长尾分布，导致长尾的一些特征值无法被充分学习，其对应的Embedding vector是不准确的，这便会造成模型泛化过度。</p>
<p>Wide&amp;Deep模型就是围绕记忆性和泛化性进行讨论的，模型能够从历史数据中学习到高频共现的特征组合的能力，称为是模型的Memorization。能够利用特征之间的传递性去探索历史数据中从未出现过的特征组合，称为是模型的Generalization。Wide&amp;Deep兼顾Memorization与Generalization并在Google Play store的场景中成功落地。</p>
<h5 id="模型结构及原理-2"><a href="#模型结构及原理-2" class="headerlink" title="模型结构及原理"></a>模型结构及原理</h5><p>其实wide&amp;deep模型本身的结构是非常简单的，对于有点机器学习基础和深度学习基础的人来说都非常的容易看懂，但是如何根据自己的场景去选择那些特征放在Wide部分，哪些特征放在Deep部分就需要理解这篇论文提出者当时对于设计该模型不同结构时的意图了，所以这也是用好这个模型的一个前提。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222057071.png" alt="img"></p>
<p><strong>如何理解Wide部分有利于增强模型的“记忆能力”，Deep部分有利于增强模型的“泛化能力”？</strong></p>
<ul>
<li><p>wide部分是一个广义的线性模型，输入的特征主要有两部分组成，一部分是原始的部分特征，另一部分是原始特征的交叉特征(cross-product transformation)，对于交互特征可以定义为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222059178.png" alt="img"></p>
<p>是一个布尔变量，当第i个特征属于第k个特征组合时，的值为1，否则为0，是第i个特征的值，大体意思就是两个特征都同时为1这个新的特征才能为1，否则就是0，说白了就是一个特征组合。</p>
<p>对于wide部分训练时候使用的优化器是带正则的FTRL算法(Follow-the-regularized-leader)，而L1 FTLR是非常注重模型稀疏性质的，也就是说W&amp;D模型采用L1 FTRL是想让Wide部分变得更加的稀疏，即Wide部分的大部分参数都为0，这就大大压缩了模型权重及特征向量的维度。<strong>Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现”直接的”，“暴力的”，“显然的”关联规则的能力。</strong>例如Google W&amp;D期望wide部分发现这样的规则：<strong>用户安装了应用A，此时曝光应用B，用户安装应用B的概率大。</strong></p>
</li>
<li><p>Deep部分是一个DNN模型，输入的特征主要分为两大类，一类是数值特征(可直接输入DNN)，一类是类别特征(需要经过Embedding之后才能输入到DNN中)，Deep部分的数学形式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222100079.png" alt="img"></p>
<p><strong>我们知道DNN模型随着层数的增加，中间的特征就越抽象，也就提高了模型的泛化能力。</strong>对于Deep部分的DNN模型作者使用了深度学习常用的优化器AdaGrad，这也是为了使得模型可以得到更精确的解。</p>
</li>
</ul>
<p><strong>Wide部分与Deep部分的结合</strong></p>
<p>W&amp;D模型是将两部分输出的结果结合起来联合训练，将deep和wide部分的输出重新使用一个逻辑回归模型做最终的预测，输出概率值。联合训练的数学形式如下：需要注意的是，因为Wide侧的数据是高维稀疏的，所以作者使用了FTRL算法优化，而Deep侧使用的是 Adagrad。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222100694.png" alt="img"></p>
<h4 id="NFM"><a href="#NFM" class="headerlink" title="NFM"></a>NFM</h4><h5 id="动机-1"><a href="#动机-1" class="headerlink" title="动机"></a>动机</h5><p>NFM(Neural Factorization Machines)是2017年由新加坡国立大学的何向南教授等人在SIGIR会议上提出的一个模型，传统的FM模型仅局限于线性表达和二阶交互， 无法胜任生活中各种具有复杂结构和规律性的真实数据， 针对FM的这点不足， 作者提出了一种将FM融合进DNN的策略，通过引进了一个特征交叉池化层的结构，使得FM与DNN进行了完美衔接，这样就组合了FM的建模低阶特征交互能力和DNN学习高阶特征交互和非线性的能力，形成了深度学习时代的神经FM模型(NFM)。</p>
<p>那么NFM具体是怎么做的呢？ 首先看一下NFM的公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222103700.png" alt="img"></p>
<p>我们对比FM， 就会发现变化的是第三项，前两项还是原来的， 因为我们说FM的一个问题，就是只能到二阶交叉， 且是线性模型， 这是他本身的一个局限性， 而如果想突破这个局限性， 就需要从他的公式本身下点功夫， 于是乎，作者在这里改进的思路就是<strong>用一个表达能力更强的函数来替代原FM中二阶隐向量内积的部分</strong>。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222104051.png" alt="img"></p>
<h5 id="模型结构与原理"><a href="#模型结构与原理" class="headerlink" title="模型结构与原理"></a>模型结构与原理</h5><h6 id="Input-和Embedding层"><a href="#Input-和Embedding层" class="headerlink" title="Input 和Embedding层"></a>Input 和Embedding层</h6><p>输入层的特征， 文章指定了稀疏离散特征居多， 这种特征我们也知道一般是先one-hot, 然后会通过embedding，处理成稠密低维的。 所以这两层还是和之前一样，假设为第个特征的embedding向量， 那么表示的下一层的输入特征。这里带上了是因为很多转成了One-hot之后，出现很多为0的， 这里的是不等于0的那些特征向量。  </p>
<h6 id="Bi-Interaction-Pooling-layer"><a href="#Bi-Interaction-Pooling-layer" class="headerlink" title="Bi-Interaction Pooling layer"></a>Bi-Interaction Pooling layer</h6><p>在Embedding层和神经网络之间加入了特征交叉池化层是本网络的核心创新了，正是因为这个结构，实现了FM与DNN的无缝连接， 组成了一个大的网络，且能够正常的反向传播。假设是所有特征embedding的集合， 那么在特征交叉池化层的操作：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222106689.png" alt="img"></p>
<p>表示两个向量的元素积操作，即两个向量对应维度相乘得到的元素积向量（可不是点乘呀），其中第维的操作：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222106134.png" alt="img"></p>
<p>这便定义了在embedding空间特征的二阶交互，这个不仔细看会和感觉FM的最后一项很像，但是不一样，一定要注意这个地方不是两个隐向量的内积，而是元素积，也就是这一个交叉完了之后k个维度不求和，最后会得到一个维向量，而FM那里内积的话最后得到一个数， 在进行两两Embedding元素积之后，对交叉特征向量取和， 得到该层的输出向量， 很显然， 输出是一个维的向量。</p>
<p>注意， 之前的FM到这里其实就完事了， 上面就是输出了，而这里很大的一点改进就是加入特征池化层之后， 把二阶交互的信息合并， 且上面接了一个DNN网络， 这样就能够增强FM的表达能力了， 因为FM只能到二阶， 而这里的DNN可以进行多阶且非线性，只要FM把二阶的学习好了， DNN这块学习来会更加容易， 作者在论文中也说明了这一点，且通过后面的实验证实了这个观点。</p>
<p>如果不加DNN， NFM就退化成了FM，所以改进的关键就在于加了一个这样的层，组合了一下二阶交叉的信息，然后又给了DNN进行高阶交叉的学习，成了一种“加强版”的FM。</p>
<p>Bi-Interaction层不需要额外的模型学习参数，更重要的是它在一个线性的时间内完成计算，和FM一致的，即时间复杂度为，为embedding向量的数量。参考FM，可以将上式转化为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222107108.png" alt="img"></p>
<h6 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h6><p>这一层就是全连接的神经网络， DNN在进行特征的高层非线性交互上有着天然的学习优势，公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222109689.png" alt="img"></p>
<p>这里的是第层的激活函数，可不要理解成sigmoid激活函数。</p>
<h6 id="预测层"><a href="#预测层" class="headerlink" title="预测层"></a>预测层</h6><p>这个就是最后一层的结果直接过一个隐藏层，但注意由于这里是回归问题，没有加sigmoid激活：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222110388.png" alt="img"></p>
<p>所以， NFM模型的前向传播过程总结如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222111207.png" alt="img"></p>
<p>这就是NFM模型的全貌， NFM相比较于其他模型的核心创新点是特征交叉池化层，基于它，实现了FM和DNN的无缝连接，使得DNN可以在底层就学习到包含更多信息的组合特征，这时候，就会减少DNN的很多负担，只需要很少的隐藏层就可以学习到高阶特征信息。NFM相比之前的DNN， 模型结构更浅，更简单，但是性能更好，训练和调参更容易。集合FM二阶交叉线性和DNN高阶交叉非线性的优势，非常适合处理稀疏数据的场景任务。在对NFM的真实训练过程中，也会用到像Dropout和BatchNormalization这样的技术来缓解过拟合和在过大的改变数据分布。</p>
<h4 id="AFM"><a href="#AFM" class="headerlink" title="AFM"></a>AFM</h4><h5 id="AFM提出的动机"><a href="#AFM提出的动机" class="headerlink" title="AFM提出的动机"></a>AFM提出的动机</h5><p>AFM的全称是Attentional Factorization Machines, 从模型的名称上来看是在FM的基础上加上了注意力机制，FM是通过特征隐向量的内积来对交叉特征进行建模，从公式中可以看出所有的交叉特征都具有相同的权重也就是1，没有考虑到不同的交叉特征的重要性程度：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222115177.png" alt="img"></p>
<p>如何让不同的交叉特征具有不同的重要性就是AFM核心的贡献，在谈论AFM交叉特征注意力之前，对于FM交叉特征部分的改进还有FFM，其是考虑到了对于不同的其他特征，某个指定特征的隐向量应该是不同的（相比于FM对于所有的特征只有一个隐向量，FFM对于一个特征有多个不同的隐向量）。</p>
<h5 id="AFM模型原理"><a href="#AFM模型原理" class="headerlink" title="AFM模型原理"></a>AFM模型原理</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222115513.png" alt="img"></p>
<p>上图表示的就是AFM交叉特征部分的模型结构(非交叉部分与FM是一样的，图中并没有给出)。AFM最核心的两个点分别是Pair-wise Interaction Layer和Attention-based Pooling。前者将输入的非零特征的隐向量两两计算element-wise product(哈达玛积，两个向量对应元素相乘，得到的还是一个向量)，假如输入的特征中的非零向量的数量为m，那么经过Pair-wise Interaction Layer之后输出的就是个向量，再将前面得到的交叉特征向量组输入到Attention-based Pooling，该pooling层会先计算出每个特征组合的自适应权重(通过Attention Net进行计算)，通过加权求和的方式将向量组压缩成一个向量，由于最终需要输出的是一个数值，所以还需要将前一步得到的向量通过另外一个向量将其映射成一个值，得到最终的基于注意力加权的二阶交叉特征的输出。(对于这部分如果不是很清楚，可以先看下面对两个核心层的介绍)</p>
<h6 id="Pair-wise-Interaction-Layer"><a href="#Pair-wise-Interaction-Layer" class="headerlink" title="Pair-wise Interaction Layer"></a>Pair-wise Interaction Layer</h6><p>FM二阶交叉项：所有非零特征对应的隐向量两两点积再求和，输出的是一个数值</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222116327.png" alt="img"></p>
<p>AFM二阶交叉项(无attention)：所有非零特征对应的隐向量两两对应元素乘积，然后再向量求和，输出的还是一个向量。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222116575.png" alt="img"></p>
<p>上述写法是为了更好的与FM进行对比，下面将公式变形方便与原论文中保持一致。首先是特征的隐向量。从上图中可以看出，作者对数值特征也对应了一个隐向量，不同的数值乘以对应的隐向量就可以得到不同的隐向量，相对于onehot编码的特征乘以1还是其本身(并没有什么变化)，其实就是为了将公式进行统一。</p>
<p>按照论文的意思，特征的embedding可以表示为：，经过Pair-wise Interaction Layer输出可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222116226.png" alt="img"></p>
<p>表示的是有效特征集合。此时的表示的是一个向量集合，所以需要先将这些向量集合聚合成一个向量，然后在转换成一个数值：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222117210.png" alt="img"></p>
<p>上式中的求和部分就是将向量集合聚合成一个维度与隐向量维度相同的向量，通过向量再将其转换成一个数值，b表示的是偏置。</p>
<p>从开始介绍Pair-wise Interaction Layer到现在解决的一个问题是，如何将使用哈达玛积得到的交叉特征转换成一个最终输出需要的数值，到目前为止交叉特征之间的注意力权重还没有出现。在没有详细介绍注意力之前先感性的认识一下如果现在已经有了每个交叉特征的注意力权重，那么交叉特征的输出可以表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222117026.png" alt="img"></p>
<p>就是在交叉特征得到的新向量前面乘以一个注意力权重, 那么这个注意力权重如何计算得到呢？</p>
<h6 id="Attention-based-Pooling"><a href="#Attention-based-Pooling" class="headerlink" title="Attention-based Pooling"></a>Attention-based Pooling</h6><p>对于神经网络注意力相关的基础知识大家可以去看一下邱锡鹏老师的《神经网络与深度学习》第8章注意力机制与外部记忆。这里简单的叙述一下使用MLP实现注意力机制的计算。假设现在有n个交叉特征(假如维度是k)，将nxk的数据输入到一个kx1的全连接网络中，输出的张量维度为nx1，使用softmax函数将nx1的向量的每个维度进行归一化，得到一个新的nx1的向量，这个向量所有维度加起来的和为1，每个维度上的值就可以表示原nxk数据每一行(即1xk的数据)的权重。用公式表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222117989.png" alt="img"></p>
<p>使用softmax归一化可得：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222118339.png" alt="img"></p>
<p>这样就得到了AFM二阶交叉部分的注意力权重，如果将AFM的一阶项写在一起，AFM模型用公式表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222118174.png" alt="img"></p>
<h6 id="AFM模型训练"><a href="#AFM模型训练" class="headerlink" title="AFM模型训练"></a>AFM模型训练</h6><p>AFM从最终的模型公式可以看出与FM的模型公式是非常相似的，所以也可以和FM一样应用于不同的任务，例如分类、回归及排序（不同的任务的损失函数是不一样的），AFM也有对防止过拟合进行处理：</p>
<ol>
<li>在Pair-wise Interaction Layer层的输出结果上使用dropout防止过拟合，因为并不是所有的特征组合对预测结果都有用，所以随机的去除一些交叉特征，让剩下的特征去自适应的学习可以更好的防止过拟合。</li>
<li>对Attention-based Pooling层中的权重矩阵使用L2正则，作者没有在这一层使用dropout的原因是发现同时在特征交叉层和注意力层加dropout会使得模型训练不稳定，并且性能还会下降。</li>
</ol>
<p>加上正则参数之后的回归任务的损失函数表示为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222119465.png" alt="img"></p>
<h4 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h4><h5 id="动机-2"><a href="#动机-2" class="headerlink" title="动机"></a>动机</h5><p>对于CTR问题，被证明的最有效的提升任务表现的策略是特征组合(Feature Interaction), 在CTR问题的探究历史上来看就是如何更好地学习特征组合，进而更加精确地描述数据的特点。可以说这是基础推荐模型到深度学习推荐模型遵循的一个主要的思想。而组合特征大牛们研究过组合二阶特征，三阶甚至更高阶，但是面临一个问题就是随着阶数的提升，复杂度就成几何倍的升高。这样即使模型的表现更好了，但是推荐系统在实时性的要求也不能满足了。所以很多模型的出现都是为了解决另外一个更加深入的问题：如何更高效的学习特征组合？</p>
<p>为了解决上述问题，出现了FM和FFM来优化LR的特征组合较差这一个问题。并且在这个时候科学家们已经发现了DNN在特征组合方面的优势，所以又出现了FNN和PNN等使用深度网络的模型。但是DNN也存在局限性。</p>
<ul>
<li><strong>DNN局限</strong> 当我们使用DNN网络解决推荐问题的时候存在网络参数过于庞大的问题，这是因为在进行特征处理的时候我们需要使用one-hot编码来处理离散特征，这会导致输入的维度猛增。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222138309.png" alt="img"></p>
<p>这样庞大的参数量也是不实际的。为了解决DNN参数量过大的局限性，可以采用非常经典的Field思想，将OneHot特征转换为Dense Vector</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222138450.png" alt="img"></p>
<p>此时通过增加全连接层就可以实现高阶的特征组合，如下图所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222139876.png" alt="img"></p>
<p>但是仍然缺少低阶的特征组合，于是增加FM来表示低阶的特征组合。</p>
<ul>
<li><strong>FNN和PNN</strong> 结合FM和DNN其实有两种方式，可以并行结合也可以串行结合。这两种方式各有几种代表模型。在DeepFM之前有FNN，虽然在影响力上可能并不如DeepFM，但是了解FNN的思想对我们理解DeepFM的特点和优点是很有帮助的。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222139053.png" alt="img"></p>
<p>FNN是使用预训练好的FM模块，得到隐向量，然后把隐向量作为DNN的输入，但是经过实验进一步发现，在Embedding layer和hidden layer1之间增加一个product层（如上图所示）可以提高模型的表现，所以提出了PNN，使用product layer替换FM预训练层。</p>
<ul>
<li><strong>Wide&amp;Deep</strong> FNN和PNN模型仍然有一个比较明显的尚未解决的缺点：对于低阶组合特征学习到的比较少，这一点主要是由于FM和DNN的串行方式导致的，也就是虽然FM学到了低阶特征组合，但是DNN的全连接结构导致低阶特征并不能在DNN的输出端较好的表现。看来我们已经找到问题了，将串行方式改进为并行方式能比较好的解决这个问题。于是Google提出了Wide&amp;Deep模型（将前几章），但是如果深入探究Wide&amp;Deep的构成方式，虽然将整个模型的结构调整为了并行结构，在实际的使用中Wide Module中的部分需要较为精巧的特征工程，换句话说人工处理对于模型的效果具有比较大的影响（这一点可以在Wide&amp;Deep模型部分得到验证）。</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222140078.png" alt="img"></p>
<p>如上图所示，该模型仍然存在问题：<strong>在output Units阶段直接将低阶和高阶特征进行组合，很容易让模型最终偏向学习到低阶或者高阶的特征，而不能做到很好的结合。</strong></p>
<p>综上所示，DeepFM模型横空出世。</p>
<h5 id="模型的结构与原理"><a href="#模型的结构与原理" class="headerlink" title="模型的结构与原理"></a>模型的结构与原理</h5><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222140551.png" alt="img"></p>
<p>前面的Field和Embedding处理是和前面的方法是相同的，如上图中的绿色部分；DeepFM将Wide部分替换为了FM layer如上图中的蓝色部分</p>
<p>这幅图其实有很多的点需要注意，很多人都一眼略过了，这里我个人认为在DeepFM模型中有三点需要注意：</p>
<ul>
<li><strong>Deep模型部分</strong></li>
<li><strong>FM模型部分</strong></li>
<li><strong>Sparse Feature中黄色和灰色节点代表什么意思</strong></li>
</ul>
<h6 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h6><p>详细内容参考FM模型部分的内容，下图是FM的一个结构图，从图中大致可以看出FM Layer是由一阶特征和二阶特征Concatenate到一起在经过一个Sigmoid得到logits（结合FM的公式一起看），所以在实现的时候需要单独考虑linear部分和FM交叉特征部分。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222141214.png" alt="img"></p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222141391.png" alt="img"></p>
<h6 id="Deep"><a href="#Deep" class="headerlink" title="Deep"></a>Deep</h6><p>Deep架构图</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222142236.png" alt="img"></p>
<p>Deep Module是为了学习高阶的特征组合，在上图中使用用全连接的方式将Dense Embedding输入到Hidden Layer，这里面Dense Embeddings就是为了解决DNN中的参数爆炸问题，这也是推荐模型中常用的处理方法。</p>
<p>Embedding层的输出是将所有id类特征对应的embedding向量concat到到一起输入到DNN中。其中表示第i个field的embedding，m是field的数量。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222143624.png" alt="img"></p>
<p>上一层的输出作为下一层的输入，我们得到：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222143038.png" alt="img"></p>
<p>其中表示激活函数，分别表示该层的输入、权重和偏置。</p>
<p>最后进入DNN部分输出使用sigmod激活函数进行激活：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222143674.png" alt="img"></p>
<h4 id="xDeepFM"><a href="#xDeepFM" class="headerlink" title="xDeepFM"></a>xDeepFM</h4><h5 id="xDeepFM的架构剖析"><a href="#xDeepFM的架构剖析" class="headerlink" title="xDeepFM的架构剖析"></a>xDeepFM的架构剖析</h5><p>首先，我们先看下xDeepFM的架构</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222202895.png" alt="img"></p>
<p>这个网络结构名副其实，依然是采用了W&amp;D架构，DNN负责Deep端，学习特征之间的隐性高阶交互， 而CIN网络负责wide端，学习特征之间的显性高阶交互，这样显隐性高阶交互就在这个模型里面体现的淋漓尽致了。</p>
<p>最终的计算公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222204455.png" alt="img"></p>
<p>这里的表示原始的特征，表示的是DNN的输出， 表示的是CIN的输出。最终的损失依然是交叉熵损失，这里也是做一个点击率预测的问题：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222205209.png" alt="img"></p>
<p>最终的目标函数加了正则化:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222206641.png" alt="img"></p>
<h5 id="CIN网络的细节"><a href="#CIN网络的细节" class="headerlink" title="CIN网络的细节"></a>CIN网络的细节</h5><p>这里尝试剖析下本篇论文的主角CIN网络，全称Compressed Interaction Network。这个东西说白了其实也是一个网络，并不是什么高大上的东西，和Cross Network一样，也是一层一层，每一层都是基于一个固定的公式进行的计算，那个公式长这样:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222209233.png" alt="img"></p>
<p> 这个公式第一眼看过来，肯定更是懵逼，这是写的个啥玩意？如果我再把CIN的三个核心图放上来:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222209772.png" alt="img"></p>
<p> 上面其实就是CIN网络的精髓了，也是它具体的运算过程，只不过直接上图的话，会有些抽象，难以理解，也不符合我整理论文的习惯。下面，我们就一一进行剖析， 先从上面这个公式开始。但在这之前，需要先约定一些符号。要不然不知道代表啥意思。</p>
<ol>
<li>: 这个就是我们的输入，也就是embedding层的输出，可以理解为各个embedding的堆叠而成的矩阵，假设有个特征，embedding的维度是维，那么这样就得到了这样的矩阵， 行列。， 这个表示的是第个特征的embedding向量。所以上标在这里表示的是网络的层数，输入可以看做第0层，而下标表示的第几行的embedding向量，这个清楚了。</li>
<li>: 这个表示的是CIN网络第层的输出，和上面这个一样，也是一个矩阵，每一行是一个embedding向量，每一列代表一个embedding维度。这里的表示的是第层特征的数量，也可以理解为神经元个数。那么显然，这个就是个为向量堆叠而成的矩阵，维度也显然了。代表的就是第层第个特征向量了。</li>
</ol>
<p>所以上面的那个公式：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222210887.png" alt="img"></p>
<p>其实就是计算第层第个特征向量， 这里的是第个特征向量的参数矩阵。 表示的哈达玛积，也就是向量之间对应维度元素相乘(不相加了)。。通过这个公式也能看到是通过和计算得来的，也就是说特征的显性交互阶数会虽然网络层数的加深而增加。</p>
<p>那么这个公式到底表示的啥意思呢？ 是具体怎么计算的呢？我们往前计算一层就知道了，这里令，也就是尝试计算第一层里面的第个向量， 那么上面公式就变成了:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222210151.png" alt="img"></p>
<p>这里的。这个能看懂吗？ 首先这个矩阵是行列， 而前面那两个累加正好也是行列的参数。代表的是输入特征的个数， 代表的是第0层(层)的神经元的个数， 这个也是。这个应该好理解，输入层就是第0层。所以这其实就是一个的矩阵。那么后面这个运算到底是怎么算的呢？   首先对于第个特征向量， 要依次和其他的个特征向量做哈达玛积操作，当然也乘以对应位置的权重，求和。对于每个特征向量，都重复这样的操作，最终求和得到一个维的向量，这个就是。好吧，这么说。我觉得应该也没有啥感觉，画一下就了然了，现在可以先不用管论文里面是怎么说的，先跟着这个思路走，只要理解了这个公式是怎么计算的，论文里面的那三个图就会非常清晰了。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222211775.png" alt="img"></p>
<p>这就是上面那个公式的具体过程了，图实在是太难看了， 但应该能说明这个详细的过程了。这样只要给定一个之后，就能算出一个相应的来，这样第一层的个神经元按照这样的步骤就能够都计算出来了。 后面的计算过程其实是同理，无非就是输入是前一层的输出以及罢了，而这时候，第一个矩阵特征数就不一定是了，而是一个行列的矩阵了。这里的就是上面写的行列了。</p>
<p>这个过程明白了之后，再看论文后面的内容就相对容易了，首先</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222211538.png" alt="img"></p>
<p>CIN里面能看到RNN的身影，也就是当前层的隐藏单元的计算要依赖于上一层以及当前的输入层，只不过这里的当前输入每个时间步都是。 同时这里也能看到，CIN的计算是vector-wise级别的，也就是向量之间的哈达玛积的操作，并没有涉及到具体向量里面的位交叉。</p>
<p>下面我们再从CNN的角度去看这个计算过程。其实还是和上面一样的计算过程，只不过是换了个角度看而已，所以上面那个只要能理解，下面CNN也容易理解了。首先，这里引入了一个tensor张量表示的是和的外积，那么这个东西是啥呢？ 上面加权求和前的那个矩阵，是一个三维的张量。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222211833.png" alt="img"></p>
<p>这个可以看成是一个三维的图片，高，宽，个通道。而的大小是的， 这个就相当于一个过滤器，用这个过滤器对输入的图片如果<strong>逐通道进行卷积</strong>，就会最终得到一个维的向量，而这个其实就是，也就是一张特征图(每个通道过滤器是共享的)。 第层其实有个这样的过滤器，所以最后得到的是一个的矩阵。这样，在第个隐藏层，就把了的三维张量通过逐通道卷积的方式，压缩成了一个的矩阵(张特征图)， 这就是第层的输出。 而这也就是“compressed”的由来。这时候再看这两个图就非常舒服了：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222212318.png" alt="img"></p>
<p>通过这样的一个CIN网络，就很容易的实现了特征的显性高阶交互，并且是vector-wise级别的，那么最终的输出层是啥呢？   通过上面的分析，首先我们了解了对于第层输出的某个特征向量，其实是综合了输入里面各个embedding向量显性高阶交互的信息(第层其实学习的输入embedding阶交互信息)，这个看第一层那个输出就能看出来。第层的每个特征向量其实都能学习到这样的信息，那么如果把这些向量在从维度上进行加和，也就是，这是个的，我们沿着D这个维度加和，又会得到一个的向量，公式如下:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222212723.png" alt="img"></p>
<p> 每一层，都会得到一个这样的向量，那么把所有的向量拼接到一块，其实就是CIN网络的输出了。之所以，这里要把中间结果都与输出层相连，就是因为CIN与Cross不同的一点是，在第层，CIN只包含阶的组合特征，而Cross是能包含从1阶-阶的组合特征的，所以为了让模型学习到从1阶到所有阶的组合特征，CIN这里需要把中间层的结果与输出层建立连接。</p>
<p>这也就是第三个图表示的含义:</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222213526.png" alt="img"></p>
<p>这样， 就得到了最终CIN的输出了: </p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202305222213378.png" alt="img"></p>
<p>后面那个维度的意思，就是说每一层是的向量维度是维， 最后是所有时间步的维度之和。 </p>
<h3 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h3><p>pass</p>
<h3 id="多任务模型"><a href="#多任务模型" class="headerlink" title="多任务模型"></a>多任务模型</h3><p>pass</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%80%BB%E7%BB%93/" rel="tag"># 总结</a>
              <a href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" rel="tag"># 推荐系统</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/06/14/Linux%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/" rel="prev" title="Linux使用总结">
                  <i class="fa fa-chevron-left"></i> Linux使用总结
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/10/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="next" title="强化学习">
                  强化学习 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">木霈玖</span>
</div>

    </div>
  </footer>

  
  <script src="//unpkg.com/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'none'
      },
      options: {
        renderActions: {
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//unpkg.com/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



</body>
</html>
