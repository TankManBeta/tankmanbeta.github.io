<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//unpkg.com/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//unpkg.com/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","version":"8.2.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="前言记录一下暑期实习面试经验。">
<meta property="og:type" content="article">
<meta property="og:title" content="面经">
<meta property="og:url" content="http://example.com/2023/03/06/%E9%9D%A2%E7%BB%8F/index.html">
<meta property="og:site_name" content="木霈玖的博客">
<meta property="og:description" content="前言记录一下暑期实习面试经验。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071555276.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071559636.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071107979.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071138731.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101613543.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101613198.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101650959.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101651061.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101656177.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101658315.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101704500.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101704670.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101716405.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101727004.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101743580.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101744292.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101744829.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101746573.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102112494.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102149708.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102152516.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102156269.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102208969.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102216271.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303111538347.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303111601603.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303111619137.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071255957.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071300267.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230106231925.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303212301932.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071317819.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071317983.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071328562.png">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071332166.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071333924.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071335563.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071336003.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071339814.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071339457.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071340668.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071341013.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071342703.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071343619.jpg">
<meta property="og:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071356215.png">
<meta property="article:published_time" content="2023-03-06T14:04:43.000Z">
<meta property="article:modified_time" content="2023-03-21T16:54:06.604Z">
<meta property="article:author" content="木霈玖">
<meta property="article:tag" content="总结">
<meta property="article:tag" content="面试">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071555276.png">


<link rel="canonical" href="http://example.com/2023/03/06/%E9%9D%A2%E7%BB%8F/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>
<title>面经 | 木霈玖的博客</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">木霈玖的博客</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E6%A8%A1%E5%9E%8B%E4%B8%8D%E6%94%B6%E6%95%9B%EF%BC%8C%E6%98%AF%E5%90%A6%E8%AF%B4%E6%98%8E%E8%BF%99%E4%B8%AA%E6%A8%A1%E5%9E%8B%E6%97%A0%E6%95%88%EF%BC%8C%E8%87%B4%E6%A8%A1%E5%9E%8B%E4%B8%8D%E6%94%B6%E6%95%9B%E7%9A%84%E5%8E%9F%E5%9B%A0%E6%9C%89%E5%93%AA%E4%BA%9B"><span class="nav-number">2.</span> <span class="nav-text">训练过程中模型不收敛，是否说明这个模型无效，致模型不收敛的原因有哪些?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE"><span class="nav-number">3.</span> <span class="nav-text">偏差和方差</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="nav-number">4.</span> <span class="nav-text">过拟合和欠拟合</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E5%BF%B5"><span class="nav-number">4.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">4.2.</span> <span class="nav-text">过拟合的解决方案</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AC%A0%E6%8B%9F%E5%90%88%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">4.3.</span> <span class="nav-text">欠拟合的解决方案</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8"><span class="nav-number">5.</span> <span class="nav-text">梯度消失和梯度爆炸</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E5%BF%B5-1"><span class="nav-number">5.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">5.2.</span> <span class="nav-text">解决方案</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Dropout"><span class="nav-number">6.</span> <span class="nav-text">Dropout</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4Dropout%E5%8F%AF%E4%BB%A5%E8%A7%A3%E5%86%B3%E8%BF%87%E6%8B%9F%E5%90%88%EF%BC%9F"><span class="nav-number">6.1.</span> <span class="nav-text">为什么说Dropout可以解决过拟合？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Dropout%E7%BC%BA%E7%82%B9"><span class="nav-number">6.2.</span> <span class="nav-text">Dropout缺点</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">7.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#smooth-loss"><span class="nav-number">7.1.</span> <span class="nav-text">smooth loss</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-number">8.</span> <span class="nav-text">激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ReLU%E6%AF%94Sigmoid%E6%95%88%E6%9E%9C%E5%A5%BD%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F"><span class="nav-number">8.1.</span> <span class="nav-text">ReLU比Sigmoid效果好在哪里？</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="nav-number">9.</span> <span class="nav-text">优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#SGD"><span class="nav-number">9.1.</span> <span class="nav-text">SGD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SGDM"><span class="nav-number">9.2.</span> <span class="nav-text">SGDM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adagrad"><span class="nav-number">9.3.</span> <span class="nav-text">Adagrad</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RMSProp"><span class="nav-number">9.4.</span> <span class="nav-text">RMSProp</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adam"><span class="nav-number">9.5.</span> <span class="nav-text">Adam</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="nav-number">10.</span> <span class="nav-text">集成学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Bagging"><span class="nav-number">10.1.</span> <span class="nav-text">Bagging</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="nav-number">10.1.1.</span> <span class="nav-text">随机森林</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-number">10.1.1.1.</span> <span class="nav-text">决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%9E%84%E5%BB%BA%E7%9A%84%E7%BB%88%E6%AD%A2%E6%9D%A1%E4%BB%B6"><span class="nav-number">10.1.1.1.1.</span> <span class="nav-text">决策树构建的终止条件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E5%89%AA%E6%9E%9D"><span class="nav-number">10.1.1.1.2.</span> <span class="nav-text">决策树剪枝</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95"><span class="nav-number">10.1.1.1.3.</span> <span class="nav-text">决策树生成算法</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Boosting"><span class="nav-number">10.2.</span> <span class="nav-text">Boosting</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AdaBoost"><span class="nav-number">10.2.1.</span> <span class="nav-text">AdaBoost</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GBDT"><span class="nav-number">10.2.2.</span> <span class="nav-text">GBDT</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8F%90%E5%8D%87%E6%A0%91%E7%AE%97%E6%B3%95"><span class="nav-number">10.2.2.1.</span> <span class="nav-text">提升树算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gradient-Boosting-Decision-Tree%EF%BC%88%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%89"><span class="nav-number">10.2.2.2.</span> <span class="nav-text">Gradient Boosting Decision Tree（梯度提升决策树）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#XGBoost"><span class="nav-number">10.2.3.</span> <span class="nav-text">XGBoost</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0"><span class="nav-number">10.2.3.1.</span> <span class="nav-text">目标函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F%E5%B1%95%E5%BC%80"><span class="nav-number">10.2.3.2.</span> <span class="nav-text">泰勒公式展开</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%91%E7%9A%84%E5%8F%82%E6%95%B0%E5%8C%96"><span class="nav-number">10.2.3.3.</span> <span class="nav-text">树的参数化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%88%86%E8%A3%82"><span class="nav-number">10.2.3.4.</span> <span class="nav-text">特征分裂</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LightGBM"><span class="nav-number">10.2.4.</span> <span class="nav-text">LightGBM</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%B4%E6%96%B9%E5%9B%BEHistogram%E7%AE%97%E6%B3%95"><span class="nav-number">10.2.4.1.</span> <span class="nav-text">直方图Histogram算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%A6%E6%B7%B1%E5%BA%A6%E9%99%90%E5%88%B6%E7%9A%84Leaf-wise%E7%9A%84%E5%8F%B6%E5%AD%90%E7%94%9F%E9%95%BF%E7%AD%96%E7%95%A5"><span class="nav-number">10.2.4.2.</span> <span class="nav-text">带深度限制的Leaf-wise的叶子生长策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E7%B1%BB%E5%88%AB%E7%89%B9%E5%BE%81"><span class="nav-number">10.2.4.3.</span> <span class="nav-text">支持类别特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%A2%AF%E5%BA%A6%E7%9A%84%E5%8D%95%E8%BE%B9%E9%87%87%E6%A0%B7-GOSS"><span class="nav-number">10.2.4.4.</span> <span class="nav-text">基于梯度的单边采样(GOSS)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%92%E6%96%A5%E7%89%B9%E5%BE%81%E7%BB%91%E5%AE%9A"><span class="nav-number">10.2.4.5.</span> <span class="nav-text">互斥特征绑定</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CatBoost"><span class="nav-number">10.2.5.</span> <span class="nav-text">CatBoost</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%B1%BB%E5%88%AB%E7%89%B9%E5%BE%81%E7%9A%84Ordered-Target-Statistics%E6%95%B0%E5%80%BC%E7%BC%96%E7%A0%81%E6%96%B9%E6%B3%95"><span class="nav-number">10.2.5.1.</span> <span class="nav-text">基于类别特征的Ordered Target Statistics数值编码方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E8%B4%AA%E5%BF%83%E7%AD%96%E7%95%A5%E7%9A%84%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E6%96%B9%E6%B3%95"><span class="nav-number">10.2.5.2.</span> <span class="nav-text">基于贪心策略的特征交叉方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%81%BF%E5%85%8D%E9%A2%84%E6%B5%8B%E5%81%8F%E7%A7%BB%E7%9A%84Ordered-Boosting%E6%96%B9%E6%B3%95"><span class="nav-number">10.2.5.3.</span> <span class="nav-text">避免预测偏移的Ordered Boosting方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91%E4%BD%9C%E4%B8%BA%E5%9F%BA%E6%A8%A1%E5%9E%8B"><span class="nav-number">10.2.5.4.</span> <span class="nav-text">使用对称二叉树作为基模型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Stacking"><span class="nav-number">10.3.</span> <span class="nav-text">Stacking</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LableSmoothing"><span class="nav-number">11.</span> <span class="nav-text">LableSmoothing</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B8%AD%E5%B9%B3%E6%BB%91%E5%92%8C%E9%94%90%E5%8C%96%E6%93%8D%E4%BD%9C%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">12.</span> <span class="nav-text">图像处理中平滑和锐化操作是什么？</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E5%BF%B5-2"><span class="nav-number">12.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">12.2.</span> <span class="nav-text">使用场景</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#batchsize"><span class="nav-number">13.</span> <span class="nav-text">batchsize</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SVM"><span class="nav-number">14.</span> <span class="nav-text">SVM</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN"><span class="nav-number">15.</span> <span class="nav-text">CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">15.1.</span> <span class="nav-text">卷积层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%99%AE%E9%80%9A%E5%8D%B7%E7%A7%AF"><span class="nav-number">15.1.1.</span> <span class="nav-text">普通卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AF-group-convolution"><span class="nav-number">15.1.2.</span> <span class="nav-text">分组卷积(group convolution)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="nav-number">15.2.</span> <span class="nav-text">池化层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E6%9D%83%E5%80%BC%E5%85%B1%E4%BA%AB%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%9F"><span class="nav-number">15.3.</span> <span class="nav-text">神经网络中权值共享的理解？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E5%BE%AE%E8%B0%83-fine-tuning-%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BF%AE%E6%94%B9%E6%9C%80%E5%90%8E%E5%87%A0%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9D%83%E5%80%BC%EF%BC%9F"><span class="nav-number">15.4.</span> <span class="nav-text">对微调(fine-tuning)的理解，为什么要修改最后几层神经网络权值？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNet"><span class="nav-number">15.5.</span> <span class="nav-text">ResNet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ResNet%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%AE%E7%82%B9"><span class="nav-number">15.5.1.</span> <span class="nav-text">ResNet中的一些亮点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%87%E7%94%A8residual"><span class="nav-number">15.5.2.</span> <span class="nav-text">为什么采用residual?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#residual%E7%BB%93%E6%9E%84"><span class="nav-number">15.5.3.</span> <span class="nav-text">residual结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#residual%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F"><span class="nav-number">15.5.3.1.</span> <span class="nav-text">residual的计算方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ResNet%E4%B8%AD%E4%B8%A4%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84residual"><span class="nav-number">15.5.3.2.</span> <span class="nav-text">ResNet中两种不同的residual</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BatchNormalization"><span class="nav-number">15.5.4.</span> <span class="nav-text">BatchNormalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ResNet%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8Dropout%EF%BC%9F"><span class="nav-number">15.5.5.</span> <span class="nav-text">ResNet为什么不用Dropout？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RNN"><span class="nav-number">16.</span> <span class="nav-text">RNN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89"><span class="nav-number">16.1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81RNN%EF%BC%9F"><span class="nav-number">16.2.</span> <span class="nav-text">为什么需要RNN？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RNN%E7%9A%84%E4%B8%BB%E8%A6%81%E5%BA%94%E7%94%A8%E9%A2%86%E5%9F%9F"><span class="nav-number">16.3.</span> <span class="nav-text">RNN的主要应用领域</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RNN%E7%9A%84%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="nav-number">16.4.</span> <span class="nav-text">RNN的计算过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RNN%E7%9A%84%E5%BB%BA%E6%A8%A1%E6%96%B9%E5%BC%8F"><span class="nav-number">16.5.</span> <span class="nav-text">RNN的建模方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E5%AF%B9%E5%A4%9A-vector-to-sequence"><span class="nav-number">16.5.1.</span> <span class="nav-text">一对多(vector-to-sequence)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%AF%B9%E4%B8%80-sequence-to-vector"><span class="nav-number">16.5.2.</span> <span class="nav-text">多对一(sequence-to-vector)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%AF%B9%E5%A4%9A-Encoder-Decoder"><span class="nav-number">16.5.3.</span> <span class="nav-text">多对多(Encoder-Decoder)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RNN%E4%B8%AD%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E5%87%BA%E7%8E%B0%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%EF%BC%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%EF%BC%9F"><span class="nav-number">16.6.</span> <span class="nav-text">RNN中为什么会出现梯度消失？如何解决？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RNN%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-number">16.7.</span> <span class="nav-text">RNN的注意力机制</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Transformer"><span class="nav-number">17.</span> <span class="nav-text">Transformer</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">木霈玖</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/06/%E9%9D%A2%E7%BB%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="木霈玖">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="木霈玖的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          面经
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-03-06 22:04:43" itemprop="dateCreated datePublished" datetime="2023-03-06T22:04:43+08:00">2023-03-06</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2023-03-22 00:54:06" itemprop="dateModified" datetime="2023-03-22T00:54:06+08:00">2023-03-22</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%80%BB%E7%BB%93/" itemprop="url" rel="index"><span itemprop="name">总结</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>23k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>21 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>记录一下暑期实习面试经验。</p>
<a id="more"></a>
<h1 id="训练过程中模型不收敛，是否说明这个模型无效，致模型不收敛的原因有哪些"><a href="#训练过程中模型不收敛，是否说明这个模型无效，致模型不收敛的原因有哪些" class="headerlink" title="训练过程中模型不收敛，是否说明这个模型无效，致模型不收敛的原因有哪些?"></a>训练过程中模型不收敛，是否说明这个模型无效，致模型不收敛的原因有哪些?</h1><p>在训练过程中，如果模型不收敛并不能说明该模型时无效的。</p>
<p>导致模型不收敛的原因包括：</p>
<ol>
<li>没有对数据做归一化处理。</li>
<li>没有使用正则化。</li>
<li><code>Batch Size</code>设的太大。</li>
<li>学习率设置的太大容易产生震荡，太小会导致不收敛。</li>
<li>没有做数据预处理。</li>
<li>没有检查过预处理结果和最终的训练测试结果。</li>
<li>网络存在坏梯度，比如当<code>Relu</code>对负值的梯度为 $0$ ，反向传播时，梯度为 $0$ 表示不传播。</li>
<li>网络设定不合理，网络太浅或者太深。</li>
<li>最后一层的激活函数错误。</li>
<li>参数初始化错误。</li>
<li>隐藏层神经元数量错误。</li>
<li>数据集标签的设置有错误。</li>
</ol>
<h1 id="偏差和方差"><a href="#偏差和方差" class="headerlink" title="偏差和方差"></a>偏差和方差</h1><p>偏差：模型预测值的期望与真实值之间的差异，反应的是模型的拟合能力。<br>方差：反应的是训练集的变化所导致的学习性能的变化，即刻画了<strong>数据扰动</strong>所造成的影响，模型过拟合时会出现较大的方差。</p>
<h1 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>过拟合就是随着模型的训练，模型在训练集上的表现越来越好，但是在验证集上的表现却越来越差，也就是说对训练集的拟合程度过高，导致模型的泛化能力降低。<br>欠拟合就是模型在训练集上也无法达到满意的精度。</p>
<h2 id="过拟合的解决方案"><a href="#过拟合的解决方案" class="headerlink" title="过拟合的解决方案"></a>过拟合的解决方案</h2><p>过拟合通常是由于训练数据过少、模型复杂度过大等问题导致的，因此相应的解决方案也是从这两个角度考虑。</p>
<ul>
<li>使用更多的数据进行训练，并且数据集尽量均匀，做一些数据增强。</li>
<li>降低模型复杂度。并不是说模型越复杂越好，如果模型过于复杂，而训练集又较少，那么参数就很容易拟合到一个过于适配训练集的参数空间中，自然就会导致过拟合的出现。</li>
<li><code>Early Stopping</code>，简单来说就是减少迭代次数。随着训练次数的增加，模型对训练数据的拟合程度也会随之增高，所以也可以通过减少训练时间的方法避免过拟合，提高模型泛化能力。</li>
<li><code>L1</code>、<code>L2</code>正则化方法，限制模型权重。</li>
<li>在数据中增加一些噪声，从而通过影响损失函数的优化方向避免过拟合。</li>
<li><code>Dropout</code>，目的也是降低模型的复杂度。</li>
<li><code>ResNet</code>。是的，<code>ResNet</code>也可以解决过拟合问题，因为<code>ResNet</code>的跳线结构可以让部分参数权重归零，进而达到类似于<code>Dropout</code>的效果。</li>
</ul>
<h2 id="欠拟合的解决方案"><a href="#欠拟合的解决方案" class="headerlink" title="欠拟合的解决方案"></a>欠拟合的解决方案</h2><p>欠拟合通常是由于模型表征能力不足、数据量过大导致的，刚好和过拟合相反。</p>
<ul>
<li>使用更复杂的模型。</li>
<li>增加迭代次数。</li>
<li>减少数据中的噪声。</li>
</ul>
<h1 id="梯度消失和梯度爆炸"><a href="#梯度消失和梯度爆炸" class="headerlink" title="梯度消失和梯度爆炸"></a>梯度消失和梯度爆炸</h1><h2 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h2><p>梯度消失就是指在网络反向传播过程中由于链式求导法则不断的累积，如果每一层的梯度都小于 $1$ ，由于累乘效应，出现了某些参数的梯度非常小的现象。在使用这些梯度更新梯度的时候参数值基本没有发生变化，因此就出现了网络训练停滞、模型无法继续优化的问题。</p>
<p>梯度爆炸与之刚好相反，在网络反向传播过程中由于链式求导法则的累乘效应，在每一层梯度都大于 $1$ 的时候，就可能会出现某些参数的梯度非常大。在使用这些梯度更新参数的时候就会导致参数变化过大，就会出现损失函数震荡的现象。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol>
<li>预训练和<code>fine-tuning</code>就是将一些在公开训练集上训练好的模型参数加载到自己对应的模型中，这样损失函数通常就能稳定的优化。</li>
<li>梯度裁剪：梯度裁剪是一个针对梯度爆炸的解决方案，也就是说将梯度限制在某个阈值范围内，如果梯度超过的这个阈值，那么就将其设置为这个阈值。</li>
<li>正则化：正则化也是一种限制梯度爆炸的解决方案，同时也有限制过拟合的作用。</li>
<li>使用<code>ReLU</code>、<code>Leaky ReLU</code>、<code>ELU</code>等激活函数：梯度消失通常是因为损失函数选择 <code>Sigmoid</code> 导致的，而<code>ReLU</code>激活函数在正数部分梯度是恒等于 $1$ 的，由于 $1$ 不会累积加权的特性，自然就可以避免梯度消失或梯度爆炸现象。但是<code>ReLU</code>同样有缺点，作为分段函数，<code>ReLU</code>在负数部分恒为 $0$ ，导致一些神经元无法被激活。而<code>Leaky ReLU</code>、<code>ELU</code>就可以避免这个问题。</li>
<li><code>BN(Batch Normalization)</code>：<code>BN</code>可以加速网络收敛提升训练的稳定性，它把每一层神经网络的任意神经元输入值的分布规范为正态分布，如果采用<code>Sigmoid</code>激活函数，那么就可以使得激活函数的输入落在梯度较大的区域，因此就能一定程度解决梯度消失的问题。</li>
<li>使用类似<code>ResNet</code>的跳线结构：由于离输出近的层学习效果好，而由于链式求导法则的影响可能会导致梯度消失或者梯度爆炸，因此可以模仿<code>ResNet</code>在网络的中间增加跳线结构，这样对应层求导梯度时候由于跳线的连接可以增加一个让梯度无损传播的通路，从而避免梯度消失或者梯度爆炸。</li>
<li>采用<code>LSTM</code>等结构：在<code>NLP</code>领域中，<code>LSTM</code>有时也会被用于对抗梯度现象，这是由于其具有复杂的门结构来控制梯度更新。</li>
</ol>
<h1 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h1><p><code>2012</code>年，<code>Hinton</code>在其论文中提出<code>Dropout</code>。当一个复杂的前馈神经网络被训练在小的数据集时，容易造成过拟合。为了防止过拟合，可以通过阻止特征检测器的共同作用来提高神经网络的性能。<br><code>Droupout</code>是一种针对深度学习广泛应用的<strong>正则化技术</strong>。在每次迭代时随机关闭一些神经单元，随着迭代的进行，由于其他神经元可能在任何时候都被关闭，因此神经元对其他特定神经元的激活变得不那么敏感。</p>
<p>经过上面屏蔽掉某些神经元，使其激活值为 $0$ 以后，我们还需要对向量 $y_{1}\cdots y_{n}$ <strong>进行缩放</strong>，也就是乘以 $1/(1-p)$ ，此方法为<code>invert Dropout</code>；如果你在训练的时候，经过置 $0$ 后，没有对 $y_{1}\cdots y_{n}$ 进行<code>rescale</code>，那么在测试的时候，就需要对权重进行缩放，即对每个神经元的权重都乘以一个 $p$ ，这样在“总体上”使得测试数据和训练数据是大致一样的，此方法为<code>vanilla Dropout</code>。比如一个神经元的输出是 $x$ ，那么在训练的时候它有 $p$ 的概率参与训练， $(1-p)$ 的概率丢弃，那么它输出的期望是 $p\cdot x+ (1-p)\cdot 0=p\cdot x$。因此测试的时候把这个神经元 $d$ 的权重乘以 $p$ 可以得到同样的期望。</p>
<h2 id="为什么说Dropout可以解决过拟合？"><a href="#为什么说Dropout可以解决过拟合？" class="headerlink" title="为什么说Dropout可以解决过拟合？"></a>为什么说Dropout可以解决过拟合？</h2><ol>
<li>取平均的作用。<code>Dropout</code>掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个<code>Dropout</code>过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</li>
<li>减少神经元之间复杂的共适应关系：因为<code>Dropout</code>导致两个神经元不一定每次都在一个<code>Dropout</code>网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况 。迫使网络去学习更加鲁棒的特征，这些特征在其它的神经元的随机子集中也存在。换句话说假如我们的神经网络是在做出某种预测，它不应该对一些特定的线索片段太过敏感，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的特征。</li>
<li><code>Dropout</code>类似于性别在生物进化中的角色：物种为了生存往往会倾向于适应这种环境，环境突变则会导致物种难以做出及时反应，性别的出现可以繁衍出适应新环境的变种，有效的阻止过拟合，即避免环境改变时物种可能面临的灭绝。</li>
</ol>
<h2 id="Dropout缺点"><a href="#Dropout缺点" class="headerlink" title="Dropout缺点"></a>Dropout缺点</h2><p>明确定义的损失函数每一次迭代都会下降，而<code>Dropout</code>每一次都会随机删除节点，也就是说每一次训练的网络都是不同的，损失函数不再被明确地定义，在某种程度上很难计算，我们失去了调试工具。</p>
<h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><h2 id="smooth-loss"><a href="#smooth-loss" class="headerlink" title="smooth loss"></a>smooth loss</h2><h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><h2 id="ReLU比Sigmoid效果好在哪里？"><a href="#ReLU比Sigmoid效果好在哪里？" class="headerlink" title="ReLU比Sigmoid效果好在哪里？"></a>ReLU比Sigmoid效果好在哪里？</h2><p><code>ReLU</code>的输出要么是 $0$ , 要么是输入本身。虽然方程简单，但实际上效果更好。</p>
<ol>
<li><code>ReLU</code>函数计算简单，可以减少很多计算量。反向传播求误差梯度时，涉及除法，计算量相对较大，采用<code>ReLU</code>激活函数，可以节省很多计算量。</li>
<li>避免梯度消失问题。对于深层网络，<code>Sigmoid</code>函数反向传播时，很容易就会出现梯度消失问题（在<code>Sigmoid</code>接近饱和区时，变换太缓慢，导数趋于 $0$ ，这种情况会造成信息丢失），从而无法完成深层网络的训练。例如在<code>RNN</code>当中，随着时间序列的不断深入，小数的累乘就会导致梯度越来越小直到接近于 $0$ ，这就是“梯度消失“现象。此时采用<code>ReLU</code>激活函数就避免了“梯度消失“的发生。</li>
<li>可以缓解过拟合问题的发生，<code>ReLU</code>会使一部分神经元的输出为 $0$ ，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。</li>
</ol>
<h1 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h1><p>记号： $\theta_{t}$ 表示第 $t$ 轮的参数， $\eta$ 表示学习率， $g_{t}$ 表示第 $t$ 轮的梯度即 $\triangledown\hat{\mathcal{L}(\theta_{t})}$ ， $m_{t}$ 表示第 $t$ 轮的一阶动量， $v_{t}$ 表示第 $t$ 轮的二阶动量， $\hat{m}_{t}$ 为偏差纠正后的一阶矩估计， $\hat{v}_{t}$ 为偏差纠正后的二阶矩估计。</p>
<h2 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h2><p><code>SGD(Stochastic Gradient Descent)</code>，随机梯度下降。每次选择一个<code>mini-batch</code>，而不是全部样本，使用梯度下降来更新模型参数。它解决了随机小批量样本的问题，但仍然有自适应学习率、容易卡在梯度较小点等问题。</p>
<p>$m_{t}=g_{t}, \ v_{t}=1$</p>
<p>$\theta_{t+1}=\theta_{t}-\eta \frac{m_{t}}{\sqrt{v_{t}}}=\theta_{t}-\eta g_{t} $</p>
<p><strong>缺点：</strong>下降速度慢，而且可能会在沟壑的两边持续振荡，停留在一个局部最优点</p>
<h2 id="SGDM"><a href="#SGDM" class="headerlink" title="SGDM"></a>SGDM</h2><p><code>SGDM(SGD with momentum)</code>，在<code>SGD</code>基础上增加一阶动量。  参数更新时以上一个时刻的一阶动量为主。</p>
<p>$m_{t} = \beta m_{t-1} + (1-\beta)  g_{t}, \ v_{t} = 1$</p>
<p>$\theta_{t+1} = \theta_{t} - \eta \frac{m_{t}}{\sqrt{v_{t}}} = \theta_{t} - \eta (\beta m_{t-1} + (1-\beta) g_{t}) $</p>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><p>在<code>SGD</code>基础上增加二阶动量，可以对模型中的每个参数分配自适应学习率。</p>
<p>$m_{t}=g_{t}$</p>
<p>$v_{t}=\sum_{\tau=1}^{t}g_{\tau}^{2}$</p>
<p>$\theta_{t+1}=\theta_{t}-\eta \frac{g_{t}}{\sqrt{v_{t}+\epsilon}}=\theta_{t}-\eta \frac{g_{t}}{\sqrt{\sum_{\tau=1}^{t}g_{\tau}^{2}+\epsilon}}$</p>
<p><strong>优点：Adagrad在稀疏数据场景下表现最好</strong>，因为对于频繁出现的参数，学习率衰减快；对于稀疏的参数，学习率衰减的更慢</p>
<p><strong>缺点：</strong>在实际很多情况下，<strong>二阶动量呈单调递增，累积从训练开始的梯度，学习率会很快减至0，导致参数不再更新</strong>，训练过程提前结束</p>
<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p><code>SGD(Root Mean Square Prop)</code>在<code>SGD</code>基础上增加二阶动量，由于<code>Adagrad</code>的学习率衰减太过激进，改变二阶动量的计算策略：<strong>不累计全部梯度，只关注过去某一窗口内的梯度</strong>。<strong>指数移动平均值</strong>大约是过去一段时间的平均值，反映<strong>局部的</strong>参数信息，用这个方法来计算二阶累积动量。</p>
<p>$m_{t}=g_{t}$</p>
<p>$v_{t}=\beta v_{t-1}+(1-\beta)g_{t}^{2}$</p>
<p>$\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{v_{t}}}g_{t}=\theta_{t}-\frac{\eta}{\sqrt{\beta v_{t-1}+(1-\beta)g_{t}^{2}}}g_{t} $</p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p><code>Adam(Adaptive Moment Estimation)</code>，自适应矩估计。是2014年提出的一种万金油式的优化器，使用起来非常方便，梯度下降速度快，但是容易在最优值附近震荡。竞赛中性能会略逊于<code>SGD</code>，毕竟最简单的才是最有效的。但是超强的易用性使得<code>Adam</code>被广泛使用。是<code>SGDM</code>和<code>RMSProp</code>的结合。</p>
<p>$m_{t}=\beta_{1}m_{t-1}+(1-\beta_{1})g_{t}$</p>
<p>$v_{t}=\beta_{2}v_{t-1}+(1-\beta_{2})g_{t}^{2}$</p>
<p>$\hat{m}_{t}=\frac{m_{t}}{1-\beta_{1}^{t}}$</p>
<p>$\hat{v}_{t}=\frac{v_{t}}{1-\beta_{w}^{t}}$</p>
<p>$\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{\hat{v}_{t}}+\epsilon}\hat{m}_t$</p>
<p><strong>解释：</strong></p>
<p>第一项 $m_{t}$ 为t时刻，梯度在动量形式下的一阶矩估计。</p>
<p>第二项 $v_{t}$ 为梯度在动量形式下的二阶矩估计。</p>
<p>第三项 $\hat{m}_{t}$ 为偏差纠正后的一阶矩估计。</p>
<p>第四项 $\hat{v}_{t}$ 为偏差纠正后的二阶矩估计。</p>
<p>最后一项是更新公式，可以参考<code>RMSProp</code>以及之前的算法。</p>
<p><strong>为什么需要偏差纠正？</strong></p>
<p>拿梯度在动量形式下的二阶矩估计 $v_{t}$ 为例，各个 $v_{t}$ 的公式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071555276.png" alt=""></p>
<p>而我们实际上需要的是梯度的二阶矩估计，也就是 $E(g_{i}^{2})$ 。因此使用动量求出来的二阶矩估计是有偏的，需要纠正。我们对动量二阶矩估计 $v_{t}$ 求期望 $E(v_{t})$ ，可以通过等比数列公式得到 $E(v_{t})$ 与 $E(g_{i}^{2})$ 的关系：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071559636.png" alt=""></p>
<p>因此，要得到 $E(g_{i}^{2})$ ，就需要除掉前面的系数 $(1-\beta_{2}^{t})$ 是一个常数</p>
<h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p><code>Bagging(Bootstrap aggregating)</code>，引导聚集算法，又称装袋算法，是机器学习领域的一种团体学习算法。<code>Bagging</code>算法可与其他分类、回归算法结合，提高其准确率、稳定性的同时，通过降低结果的方差，避免过拟合的发生。</p>
<p><strong>随机采样（bootstrap sample）</strong>从 $n$ 个数据点中<strong>有放回地重复随机</strong>抽取一个样本（即同一个样本可被多次抽取），共抽取 $n$ 次。创建一个与原数据大小相同得数据集，但有些数据点会缺失（大约 $1/3$ ），有些会重复。</p>
<p><code>Bagging</code>对于弱学习器没有限制，这和<code>Adaboost</code>一样。但是最常用的一般也是<strong>决策树</strong>和<strong>神经网络</strong>。</p>
<p><code>Bagging</code>的集合策略也比较简单，对于分类问题，通常使用简单投票法，得到最多票数的类别或者类别之一为最终的模型输出。对于回归问题，通常使用简单平均法，对 $T$ 个弱学习器得到的回归结果进行算术平均得到最终的模型输出。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071107979.png" alt=""></p>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>随机森林以决策树为基本单元，通过集成大量的决策树，就构成了随机森林。其构造过程如下：</p>
<ol>
<li>T中共有 $N$ 个样本，有放回的随机选择 $N$ 个样本（因为有放回，所以虽然是 $N$ 但是不可能遍历所有样本）。这选择好了的 $N$ 个样本用来训练一个决策树，作为决策树根节点处的样本。</li>
<li>当每个样本有 $M$ 个属性时，在决策树的每个节点需要分裂时，随机从这 $M$ 个属性中选取出 $m$ 个属性，满足条件 $m &lt;&lt; M$ 。然后从这 $m$ 个属性中采用某种策略来选择某个属性作为该节点的分裂属性。</li>
<li>决策树形成过程中每个节点都要按照上述步骤来分裂，一直到不能够再分裂为止。注意整个决策树形成过程中没有进行剪枝。</li>
<li>重复建立大量的决策树，这样就构成了随机森林了。</li>
</ol>
<h4 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h4><h5 id="决策树构建的终止条件"><a href="#决策树构建的终止条件" class="headerlink" title="决策树构建的终止条件"></a>决策树构建的终止条件</h5><ol>
<li><p>样本进来属于同一个类别，直接输出结果是 $C$ 类返回。</p>
</li>
<li><p>没法划分了，特征向量中所有属性都用完了；或者 $D$ 样本中的属性 $A$ 都相同，然后将此节点标记为叶子节点，将样本 $D$ 中数目最多的类当做类别返回。</p>
</li>
<li>当对数据进行划分成多个分支，如果存在分支中没有数据（分支为空），将划分前类别数目多的当做类别返回。</li>
</ol>
<h5 id="决策树剪枝"><a href="#决策树剪枝" class="headerlink" title="决策树剪枝"></a>决策树剪枝</h5><p>各种准则虽然对决策树的尺寸有较大影响,但<strong>对泛化性能的影响很有限</strong>，<strong>剪枝方法和程度对决策树泛化性能的影响更为显著；剪枝是决策树防止过拟合的手段</strong>。</p>
<p><strong>预剪枝：</strong>在决策树构造时就进行剪枝。在决策树构造过程中，对节点进行评估，如果对其划分并不能再验证集中提高准确性，那么该节点就不要继续往下划分。这时就会把当前节点作为叶节点。</p>
<p><strong>后剪枝：</strong>在生成决策树之后再剪枝。通常会从决策树的叶节点开始，逐层向上对每个节点进行评估。如果剪掉该节点，带来的验证集中准确性差别不大或有明显提升，则可以对它进行剪枝，用叶子节点来代填该节点。</p>
<p><strong>预剪枝vs后剪枝</strong></p>
<p>时间开销：</p>
<ul>
<li>预剪枝：训练时间开销降低，测试时间开销降低</li>
<li>后剪枝：训练时间开销增加，测试时间开销降低</li>
</ul>
<p>过/欠拟合风险:</p>
<ul>
<li>预剪枝：过拟合风险降低，欠拟合风险增加</li>
<li>后剪枝：过拟合风险降低，欠拟合风险基本不变</li>
</ul>
<p>泛化性能：后剪枝通常优于预剪枝</p>
<h5 id="决策树生成算法"><a href="#决策树生成算法" class="headerlink" title="决策树生成算法"></a>决策树生成算法</h5><p><strong>ID3</strong></p>
<p>使用信息熵增益作为特征选择的标准。</p>
<p>数据集 $D$ 的经验熵定义为： $Ent(D)=-\sum_{k=1}^{K}\frac{|C_{k}|}{|D|}\log_{2}\frac{|C_{k}|}{|D|}$ ，其中 $|C_{k}|$ 为第 $k$ 类样本的数目， $|D|$ 为数据集 $D$ 中样本的数目。</p>
<p>计算特征 $A$ 对数据集 $D$ 的经验条件熵： $Ent(D|A)=\sum_{i=1}^{n}\frac{|D_{i}|}{|D|}Ent(D_{i})=-\sum_{i=1}^{n}\frac{|D_{i}|}{|D|}\sum_{k=1}^{K}\frac{|D_{ik}|}{|D_{i}|}\log_{2}\frac{|D_{ik}|}{|D_{i}|}$  。意思就是对划分后的新的 $n$ 个小数据集的经验熵加权，权重为每一个小数据集中的样本数目占未划分前的大数据集的比例。</p>
<p>计算信息熵增益： $gain(D,A)=Ent(D)-Ent(D|A)$ ，选择信息熵增益最大的特征。</p>
<p><strong>C4.5</strong></p>
<p>与<code>ID3</code>算法的最大不同在于使用信息熵增益率代替信息熵增益。</p>
<p>$gain_ratio(D,A)=\frac{gain(D,A)}{IV(A)}$ ，其中 $IV(A)=-\sum_{i=1}^{n}\frac{|D_{i}|}{|D|}\log_{2}\frac{|D_{i}|}{|D|}$ 称为数据集 $D$ 关于 $A$ 的取值熵。</p>
<p>这种方法对可能取值少的属性有所偏好，因此<code>C4.5</code>算法也不是直接使用增益率最大的来划分属性，而是使用了一种“启发式”的方法，先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。</p>
<p><strong>CART</strong></p>
<p><code>CART</code>决策树使用“基尼指数”来选择划分属性，选取那个使划分后基尼指数<strong>最小</strong>的属性。数据集 $D$ 的纯度可用基尼值来度量。 $Gini(D)$ 越小，则数据集的纯度越高。</p>
<p>$Gini(D)=\sum_{k=1}^{K}p_{k}(1-p_{k})=1-\sum_{k=1}^{K}p_{k}^{2}$ ，则属性 $A$ 的基尼指数： $Gini_index(D,A)=\sum_{v=1}^{V}\frac{|D^{v}|}{|D|}Gini(D^{v})$</p>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p><code>Bagging</code>在随机森林的构建过程中，各棵树之间是相互独立的，在构建第 $m$ 棵树的时候，不会考虑前面的 $m-1$ 棵树。<code>Boosting</code>在构建第 $m$ 棵子树的时候，会考虑到前 $m-1$ 棵子树的结果。</p>
<p><strong>提升学习(Boosting)</strong>是一种机器学习技术，通过从训练数据构建模型，然后创建第二个模型来尝试纠正第一个模型中的错误来完成的。添加模型直到完美预测训练集或添加最大数量的模型。提升学习的每一步产生弱预测模型（如决策树），并加权累加到总模型中；如果每一步的弱预测模型的生成都是依据损失函数的梯度方式，就称为梯度提升<code>(Gradient Boosting)</code>。</p>
<h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071138731.png" alt=""></p>
<p><code>Adaptive Boosting(AdaBoost)</code>是第一个为二进制分类开发的真正成功的提升算法。这是理解<code>Boosting</code>的最佳起点，现代提升方法建立在<code>AdaBoost</code>之上。</p>
<p><code>AdaBoost</code>流程：</p>
<ol>
<li><p>训练数据集中的每个实例都被加权。初始权重设置为： $Weight(X_{i})=\frac{1}{N_{}}$ </p>
</li>
<li><p>使用加权之后的样本作为训练数据，以弱分类器（决策树桩）进行训练。</p>
</li>
<li><p>为训练后的模型计算当前分类器的分类误差。传统的计算方式如下：</p>
<p>分类误差： $error_t = \sum_{i=1}^{N}(W_{t,i}\times terror_{i})$ 。其中 $terror_{i}=I(G_{t}(X_{i})\neq y_{i})$ 。</p>
<p>例如：如果我们有三个训练实例，权重分别为 $0.01$ 、 $0.5$ 和 $0.2$ 。预测值为 $-1$ 、 $-1$ 和 $-1$ ，实例中的真实输出变量为 $-1$ 、 $1$ 和 $-1$ ，则  $terror$ 为 $0$ 、 $1$ 和 $0$ 。误分类率将计算为：<strong>error = (0.01*0 + 0.5*1 + 0.2*0) or error = 0.5</strong>。</p>
</li>
<li><p>为经过训练的模型计算阶段权值，该值为模型做出的任何预测提供权重。训练模型的阶段值计算公式： $\alpha_{t}=\frac{1}{2}\times\ln\frac{1-error_{t}}{error_{t}}$</p>
</li>
<li><p>更新训练权重，为错误预测的实例提供更多的权重，为正确预测的实例提供更少权重。计算公式： $W_{t+1,i}=\frac{W_{t,i}}{Z_{t}}\exp(-\alpha_{t}G_{t}(X_{i})y_{i})$ ， $Z_{t}$ 是规范因子， $Z_{t}=\sum_{i=1}^{N}W_{t,i}\exp(-\alpha_{t}G_{t}(X_{i})y_{i})$</p>
</li>
<li><p>最终的分类器为： $G(X)=sign(\sum_{m=1}^{K}\alpha_{m}G_{m}(X))$</p>
</li>
</ol>
<h3 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h3><p><code>GBDT(Gradient Boosting Decision Tree)</code>在数据分析和预测中的效果很好。它是一种基于决策树的集成算法。其中<code>Gradient Boosting</code>是集成方法<code>Boosting</code>中的一种算法，通过梯度下降来对新的学习器进行迭代。将表现一般的数个模型（通常是深度固定的决策树）组合在一起来集成一个表现较好的模型。抽象地说，模型的训练过程是对一任意可导目标函数的优化过程。通过反复地选择一个指向负梯度方向的函数，该算法可被看做在函数空间里对目标函数进行优化。因此可以说<code>Gradient Boosting = Gradient Descent + Boosting</code>。</p>
<p>模型的结果是一组回归分类树组合<code>(CART Tree Ensemble)</code>： $T_{1},\cdots,T_{K}$ 。其中 $T_{j}$ 学习的是之前 $j-1$ 棵树预测结果的残差，这种思想就像准备考试前的复习，先做一遍习题册，然后把做错的题目挑出来，再做一次，然后把做错的题目挑出来再做一次，经过反复多轮训练，取得最好的成绩。而模型最后的输出，是一个样本在各个树中输出的结果的和： $\bar{y}=\sum_{k=1}^{K}f_{k}(x)$ 。</p>
<p>和<code>AdaBoost</code>一样，<code>Gradient Boosting</code>也是重复选择一个表现一般的模型并且每次基于先前模型的表现进行调整。不同的是，<code>AdaBoost</code>是通过提升错分数据点的权重来定位模型的不足而<code>Gradient Boosting</code>是通过算梯度<code>(gradient)</code>来定位模型的不足。因此相比<code>AdaBoost</code>，<code>Gradient Boosting</code>可以使用更多种类的目标函数。</p>
<h4 id="提升树算法"><a href="#提升树算法" class="headerlink" title="提升树算法"></a>提升树算法</h4><p>提升树是迭代多棵回归树来共同决策。当采用平方误差损失函数时，每一棵回归树学习的是之前所有树的结论和残差，拟合得到一个当前的残差回归树，残差的意义如公式：残差=真实值-预测值。提升树即是整个迭代过程生成的回归树的累加。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101613543.jpg" alt=""></p>
<p>具体的算法步骤：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101613198.png" alt=""></p>
<h4 id="Gradient-Boosting-Decision-Tree（梯度提升决策树）"><a href="#Gradient-Boosting-Decision-Tree（梯度提升决策树）" class="headerlink" title="Gradient Boosting Decision Tree（梯度提升决策树）"></a>Gradient Boosting Decision Tree（梯度提升决策树）</h4><p>提升树利用加法模型和前向分步算法实现学习的优化过程。当损失函数时平方损失和指数损失函数时，每一步的优化很简单，如平方损失函数学习残差回归树。</p>
<p>但对于一般的损失函数，往往每一步优化没那么容易，如上图中的绝对值损失函数和<code>Huber</code>损失函数。针对这一问题，<code>Freidman</code>提出了梯度提升算法：利用最速下降的近似方法，即利用损失函数的负梯度在当前模型的值，作为回归问题中提升树算法的残差的近似值，拟合一个回归树。</p>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><p><strong>原始目标函数</strong></p>
<p>目标函数，可以分为两个部分，一部分是损失函数，一部分是正则（用于控制模型的复杂度）。</p>
<p>对于第 $t$ 颗树，第 $i$ 个样本的，模型的预测值是这样的：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101650959.png" alt=""></p>
<p>进一步，我们可以得到我们的原始目标函数，如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101651061.png" alt=""></p>
<p><strong>损失函数化简</strong></p>
<p><code>XGBoost</code>是前向迭代，我们的重点在于第 $t$ 个树，所以涉及到前 $t-1$ 个树变量或者说参数我们是可以<strong>看做常数</strong>的。所以我们的损失函数进一步可以化为如下，其中一个变化是我们对正则项进行了拆分，变成可前 $t-1$ 项和第 $t$ 项：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101656177.png" alt=""></p>
<h4 id="泰勒公式展开"><a href="#泰勒公式展开" class="headerlink" title="泰勒公式展开"></a>泰勒公式展开</h4><p>使用泰勒公式进行近似展开的核心目标是就是对目标函数进行化简，将常数项抽离出来。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101658315.png" alt=""></p>
<p>这里 $\Delta x$ 对应的是第 $t$ 棵树的模型 $f_{t}(x_{i})$ ， $x$ 对应的是 $\hat{y}_{i}^{(t-1)}$ ，相应的 $f(x)$ 对应到损失函数应该是 $l(y_{i},\hat{y}_{i}^{(t-1)})+f_{t}(x_{i})$ 。</p>
<p>所以原有公式进行泰勒公式二阶展开，结果为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101704500.png" alt=""></p>
<p>进而我们可以得到目标函数展开公式为如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101704670.png" alt=""></p>
<h4 id="树的参数化"><a href="#树的参数化" class="headerlink" title="树的参数化"></a>树的参数化</h4><p><strong>树模型参数化</strong></p>
<ul>
<li>每棵树每个叶子节点的值（或者说每个叶子节点的权重） $w$ ：这是一个向量，因为每个树有很多叶子节点</li>
<li>样本到叶子节节点的映射关系 $q$ ：告诉每个样本落在当前这个树的哪一个叶子节点上</li>
<li>叶子节点样本归属集合 $I$ ：告诉每个叶子节点包含哪些样本</li>
</ul>
<p><strong>树复杂度参数化</strong></p>
<p>树的复杂度定义如下，其中 $T$ 参数表示当前这棵树叶子节点的个数； $w_{j}^{2}$ 是叶子节点值的 $L_{2}$ 范数：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101716405.png" alt=""></p>
<p>进而我们可以对树进行了参数化，带入到目标函数我们可以得到如下式子：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101727004.png" alt=""></p>
<p>最后一步的转化思路是从在这个树中，每个样本落在哪个节点转为了每个节点上有哪些样本。</p>
<p>叶子节点 $j$ 所包含的样本的一阶导数累加之和为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101743580.png" alt=""></p>
<p>叶子节点 $j$ 所包含的样本的二阶导数累加之和为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101744292.png" alt=""></p>
<p>进而我们可以进一步化简为：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101744829.png" alt=""></p>
<p>对目标函数对 $w_{j}$ 进行求导就能得出极值点：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303101746573.png" alt=""></p>
<h4 id="特征分裂"><a href="#特征分裂" class="headerlink" title="特征分裂"></a>特征分裂</h4><p>对于上述的目标函数，我们仍存在问题，即 $T$ 的取值，也就是如何做特征分裂。</p>
<p><strong>贪心算法</strong></p>
<p>本质上是做两次循环，第一个循环是针对每个特征的每个分割点做一次循环，计算收益，从而选择此特征的最佳分割点。分裂收益使用的是分裂之后的目标函数的变化差值。第二个循环是对样本所有特征的循环，从中挑选出收益最大的特征。</p>
<p>简单说就是首先找到基于每个特征找到收益最大的分割点，然后基于所有特征找到收益最大的特征。</p>
<p><strong>近似算法-分位数候选点</strong></p>
<p>对于每个特征，不去暴力搜索每个值，而是使用分位点</p>
<ul>
<li>根据样本数量选择三分位点或者四分位点等</li>
<li>或者根据二阶导数（也就是梯度）作为权重进行划分</li>
</ul>
<p>也就是说原来是某个特征的所有取值是候选点，现在是某个特征的分位点作为候选点。</p>
<h3 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h3><p><code>LightGBM(Light Gradient Boosting Machine)</code>是一种梯度提升框架，它使用决策树作为基学习器。<code>LightGBM</code>为高效并行计算而生，它的<code>Light</code>体现在以下几个点上：</p>
<ul>
<li>更快的训练速度</li>
<li>更低的内存使用</li>
<li>支持单机多线程，多机并行计算，以及<code>GPU</code>训练</li>
<li>能够处理大规模数据</li>
</ul>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102112494.png" alt=""></p>
<p>概括来说，<code>lightGBM</code>主要有以下特点：</p>
<ul>
<li>基于<code>Histogram</code>的决策树算法</li>
<li>带深度限制的<code>Leaf-wise</code>的叶子生长策略</li>
<li>直方图做差加速</li>
<li>直接支持类别特征<code>(Categorical Feature)</code></li>
<li><code>Cache</code>命中率优化</li>
<li>基于直方图的稀疏特征优化</li>
<li>多线程优化</li>
</ul>
<h4 id="直方图Histogram算法"><a href="#直方图Histogram算法" class="headerlink" title="直方图Histogram算法"></a>直方图Histogram算法</h4><p><strong>寻找最佳分类点</strong></p>
<p>将连续型特征值放入离散化的箱子<code>(bin)</code>中，然后用这些箱子构建特征直方图。然后模型基于特征直方图寻找最佳分裂点，构建直方图的时间复杂度是 $O(data \times feature)$ ，但寻找最佳分裂点的时间复杂度为 $O(bin \times feature)$ 。模型训练速度会因此而提高，而且因为不需要存储排序索引，内存压力也变小了。<code>LGBM</code>采用的就是直方图算法（现在<code>XGBoost</code>开源代码也支持直方图算法）。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102149708.png" alt=""></p>
<p><strong>直方图差加速</strong></p>
<p>直方图做差是指：”一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的 $k$ 个桶。利用这个方法，<code>LightGBM</code>可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。” 示意图如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102152516.png" alt=""></p>
<h4 id="带深度限制的Leaf-wise的叶子生长策略"><a href="#带深度限制的Leaf-wise的叶子生长策略" class="headerlink" title="带深度限制的Leaf-wise的叶子生长策略"></a>带深度限制的Leaf-wise的叶子生长策略</h4><p><code>GBDT</code>与<code>XGBoost</code>模型在叶子生长策略上均采用按层<code>level-wise</code>分裂的方式，这种方式在分裂时会针对同一层的每一个节点，即每次迭代都要遍历整个数据集中的全部数据，这种方式虽然可以使每一层的叶子节点并行完成，并控制模型的复杂度，但也会产生许多不必要搜索或分裂，从而消耗更多的运行内存，增加计算成本。</p>
<p>而<code>LightGBM</code>算法对其进行了改进，使用了按叶子节点<code>leaf-wise</code>分裂的生长方式，即每次是对所有叶子中<strong>分裂增益最大的叶子节点进行分裂</strong>，其他叶子节点则不会分裂。这种分裂方式比按层分裂会带来更小的误差，并且加快算法的学习速度，但由于没有对其他叶子进行分裂，会使得分裂结果不够细化，并且在每层中只对一个叶子不断进行分裂将增大树的深度，造成模型过拟合。因此，<code>LightGBM</code>算法在按叶子节点生长过程中会限制树的深度来避免过拟合。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102156269.png" alt=""></p>
<h4 id="支持类别特征"><a href="#支持类别特征" class="headerlink" title="支持类别特征"></a>支持类别特征</h4><p>实际上大多数机器学习工具都无法直接支持类别特征，一般需要把类别特征，转化<code>one-hotting</code>特征，降低了空间和时间的效率。而类别特征的使用是在实践中很常用的。基于这个考虑，<code>LightGBM</code>优化了对类别特征的支持，可以直接输入类别特征，不需要额外的 $0/1$ 展开。并在决策树算法上增加了类别特征的决策规则。决策树在学习节点分裂时，是一种<code>one-vs-rest</code>模式，每次只能根据一个类别做分类，如下图。这种模式效率比较低，而且不利于决策树学习。<code>LightGBM</code>对此进行了优化，采用<code>many-vs-many</code>模式分裂节点，如下图。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102208969.png" alt=""></p>
<h4 id="基于梯度的单边采样-GOSS"><a href="#基于梯度的单边采样-GOSS" class="headerlink" title="基于梯度的单边采样(GOSS)"></a>基于梯度的单边采样(GOSS)</h4><p>在<code>AdaBoost</code>中，样本权重指示了数据样本的重要性，而在GBDT上并没有样本权重这一说，可作者发现：在<code>GBDT</code>中，梯度对于每个样本是个很有用的信息，它可以用来帮助采样。为什么这么说呢？让我们打个比方，如果某样本得到的一个小的梯度值，那么说明该样本的训练误差也小，模型在该样本上表现得就很好，那这些小梯度的样本其实是不是不用参与训练了？就好像准备考试时刷题不刷简单题，这样可以吗？不可以！因为如果真的直接剔除它们，数据分布会改变，从而损害模型的准确率。为了处理这个问题，作者提出了<code>GOSS</code>，<code>GOSS</code>全称是<code>Gradient-based One-Side Sampling</code>单边梯度采样，它保留所有大梯度的样本，然后小梯度样本采用随机采样，在不改变原始数据分布的同时，减小了样本数量，提升了模型的训练速度。</p>
<h4 id="互斥特征绑定"><a href="#互斥特征绑定" class="headerlink" title="互斥特征绑定"></a>互斥特征绑定</h4><p>从特征角度来看，稀疏特征会包含很多 $0$ 元素；从样本角度来看，一个样本的多个稀疏特征经常同时为 $0$ 。<code>EFB(Exclusive Feature Bundling)</code>基于这种想法，对<strong>互斥特征</strong>进行了<strong>捆绑</strong>，整体过程有点类似于<code>One-Hot</code>逆过程。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303102216271.png" alt=""></p>
<p><strong>捆哪些特征</strong></p>
<p>尝试每种组合，是<code>NP</code>难问题，现有算力做不到。所以只能采用贪心算法找。具体过程如下：</p>
<ol>
<li>遍历特征，先把第一个特征拿出来作为一个组合</li>
<li>第二个特征往这个组合里放，冲突比例小就放进去合并成一个特征，冲突比例大就单拿出来作为另一个组合</li>
<li>第三个特征继续往已有的组合里放，能放就放，不能放就单成一个新组合</li>
<li>以此类推对所有特征做同样的操作。</li>
</ol>
<p><strong>如何捆绑特征</strong></p>
<p>因为不同特征下的值有不同的量纲，比如：特征<code>A</code>的值范围为 $[0, 10)$ ，特征<code>B</code>的值范围为 $[0, 20)$ ，将特征<code>A</code>和特征<code>B</code>的直方图加起来捆绑一起后，<code>bundle</code>的值范围变为 $[0, 20)$ ，但是我们无法从中辨别哪些是特征<code>A</code>，哪些是特征<code>B</code>。这样对模型是不利的，因为模型这样就没法根据<code>bundle</code>直方图的值范围去很好区分特征，对树生成会带来误差。对于该问题的解决办法就是加偏移量，如果我们对特征<code>B</code>加偏移量 $10$ ，特征<code>B</code>的值范围变为 $[10, 30)$ ，合并后的<code>bundle</code>值范围变为 $[0, 30)$ 。</p>
<h3 id="CatBoost"><a href="#CatBoost" class="headerlink" title="CatBoost"></a>CatBoost</h3><p><code>CatBoost</code>主要是在类别特征上的处理上做了很多的改进。从用户使用角度来看，相比<code>XGBoost</code>和<code>LightGBM</code>，<code>CatBoost</code>具有如下特点。</p>
<ul>
<li><strong>模型精度：</strong><code>XGBoost</code>和<code>LightGBM</code>相当，<code>CatBoost</code>往往略好一些，无需调参即可获取很好的结果。</li>
<li><strong>训练速度：</strong><code>LightGBM</code>远快于<code>XGBoost</code>，<code>CatBoost</code>快于<code>XGBoost</code>但比<code>LightGBM</code>慢。</li>
<li><strong>预测速度：</strong><code>LightGBM</code>与<code>XGBoost</code>相当，<code>CatBoost</code>远快于<code>LightGBM</code>与<code>XGBoost</code>，是它们的几十分之一。</li>
<li><strong>内存消耗：</strong><code>LightGBM</code>远小于<code>XGBoost</code>，<code>CatBoost</code>小于<code>XGBoost</code>，但大于<code>LightGBM</code>。</li>
<li><strong>类别特征：</strong><code>XGBoost</code>不支持类别特征，需要<code>One-Hot</code>编码预处理。<code>LightGBM</code>支持类别特征，需转换成整数编码。<code>CatBoost</code>提供更强大的对类别特征的支持，直接支持字符串类型的类别特征，无需预处理。</li>
<li><strong>缺失值特征：</strong><code>XGBoost</code>和<code>LightGBM</code>都可以自动处理特征缺失值，<code>CatBoost</code>不能自动处理缺失值（或者将缺失值视为最小值/最大值）。</li>
<li><strong>GPU支持：</strong><code>LightGBM</code>与<code>CatBoost</code>支持<code>GPU</code>训练，<code>XGBoost</code>也支持<code>GPU</code>训练。</li>
<li><strong>可视化：</strong><code>CatBoost</code>还自带一套可视化工具，可以在<code>Jupyter Notebook</code>或者<code>TensorBoard</code>中实时看到指标变化。</li>
</ul>
<h4 id="基于类别特征的Ordered-Target-Statistics数值编码方法"><a href="#基于类别特征的Ordered-Target-Statistics数值编码方法" class="headerlink" title="基于类别特征的Ordered Target Statistics数值编码方法"></a>基于类别特征的Ordered Target Statistics数值编码方法</h4><p>对于类别特征，如果类别数目不多，可以使用<code>One-Hot</code>编码。但如果类别数量成百上千，使用<code>One-Hot</code>编码会导致特征数量爆炸。<strong>CatBoost设计了一种基于预测目标统计值的方法可以将类别特征转化为数值特征。</strong>先将样本随机打乱，然后每个样本只使用它排序在它前面的样本来计算其类别特征的数值编码。这样就防止了<code>label</code>的泄露，并且能够较为合理地评估这个特征的真实有效性。具体公式表达为： $i \rightarrow \frac{Current\ Count+a\star P}{Max\ Count + a}$ 。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303111538347.png" alt=""></p>
<p>对上述例子来说，我们要计算第 $i$ 条数据的<code>label</code>，计算结果就为 $\frac{2+a \star P}{3+a}$ ，如果将第三行的<code>label</code>改为 $1$ ，那么结果就变成了 $\frac{3+a\star P}{3+a}$ 。</p>
<h4 id="基于贪心策略的特征交叉方法"><a href="#基于贪心策略的特征交叉方法" class="headerlink" title="基于贪心策略的特征交叉方法"></a>基于贪心策略的特征交叉方法</h4><p>使用<code>Ordered Target Statistics</code>方法将类别特征转化成为数值特征以后，会影响到特征交叉，因为数值特征无法有效地进行交叉。为了有效地利用特征交叉，<code>CatBoost</code>在将类别特征转换为数值编码的同时，会自动生成交叉特征。但如果让全部的类别特征之间都进行交叉，两两交叉，三三交叉，四四交叉，这个复杂度是指数级的，特征维度一定会爆炸。<code>CatBoost</code>使用一种贪心的策略来进行特征交叉。生成<code>tree</code>的第一次分裂，<code>CatBoost</code>不使用任何交叉特征。在后面的分裂中，<code>CatBoost</code>会使用生成<code>tree</code>所用到的全部原始特征和交叉特征跟数据集中的全部类别特征进行交叉。</p>
<h4 id="避免预测偏移的Ordered-Boosting方法"><a href="#避免预测偏移的Ordered-Boosting方法" class="headerlink" title="避免预测偏移的Ordered Boosting方法"></a>避免预测偏移的Ordered Boosting方法</h4><p>使用<code>XGBoost</code>或者<code>LightGBM</code>做模型时，我们可能经常会发现模型在训练集上拟合的很好，<code>train_auc</code>甚至达到了 $1.0$ ，但是在验证集上却差了很多，<code>val_auc</code>可能只有 $0.7$ 。这当然有可能是因为tree的数量太多了，或者是每棵<code>tree</code>的<code>leaves</code>太多了，总之模型太复杂了造成了过拟合。</p>
<p>但也有一些<code>XGBoost</code>和<code>LightGBM</code>自身算法的缺陷因素。我们知道<code>LightGBM</code>在训练下一棵<code>tree</code>的时候，需要计算前面这些<code>tree</code>构成的加法模型在所有样本上的一阶梯度和二阶梯度（<code>Loss</code>对模型预测结果的导数），然后用这些梯度来决定下一棵树的结构和叶子节点取值。</p>
<p>但是我们计算的这些一阶梯度和二阶梯度值是问题的。前面的这些<code>tree</code>都是在这些样本上训练的，现在我们又在这些样本上估计模型预测结果的一阶和二阶梯度。我们应该换一些新的样本才更合理。但是我们从哪里找这些新的样本呢？</p>
<p><code>CatBoost</code>的作者故伎重演。先将样本随机打乱，然后每个样本只使用<strong>排序在它前面的样本</strong>来训练模型。用这样的模型来估计这个样本预测结果的一阶和二阶梯度。然后用这些梯度构建一棵<code>tree</code>的结构，最终<code>tree</code>的每个叶子节点的取值，是使用全体样本进行计算的。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303111601603.png" alt=""></p>
<h4 id="使用对称二叉树作为基模型"><a href="#使用对称二叉树作为基模型" class="headerlink" title="使用对称二叉树作为基模型"></a>使用对称二叉树作为基模型</h4><p><code>XGBoost</code>和<code>LightGBM</code>采用的基模型是普通的二叉树，但是<code>CatBoost</code>采用的是对称的二叉树。这种对树结构上的约束有一定的<strong>正则作用</strong>。更为重要的是，它可以让<code>CatBoost</code>模型的推断过程极快。对于<code>CatBoost</code>的<code>tree</code>的预测过程来说，每个特征的分裂都是独立的，不分先后顺序，多个样本可以一起预测。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303111619137.jpg" alt=""></p>
<h2 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h2><p>待总结</p>
<h1 id="LableSmoothing"><a href="#LableSmoothing" class="headerlink" title="LableSmoothing"></a>LableSmoothing</h1><p>传统做图像分类采用的损失是交叉熵损失，具体形式是： $\mathcal{L}=-\sum_{i=1}^{m}t_{i}\log(y_{i})$ 。其中， $m$ 表示类别数， $y_{i}$ 表示<code>softmax</code>之后每个类的预测概率， $t_{i}$ 表示样本的真实标签值。然而，神经网络 有一个坏习惯，就是在训练过程中对预测变得”过于自信“，这可能会降低它们的泛化能力，从而在新的、看不见的未来数据上表现得同样出色。此外，大型数据集通常会包含标签错误的数据，这意味着神经网络在本质上应该对“正确答案”持怀疑态度，以减少一定程度上围绕错误答案的极端情况下的建模。</p>
<p>因此，标签平滑所做的就是通过训练网络向<code>1-adjustment</code>目标移动，然后在其余的类上除以这个<code>adjustment</code>，从而使它对自己的答案不那么自信，而不是简单的设为 $1$ 。新标签的表现形式为：$T^{\prime}=(1-\varepsilon)*T+\frac{\varepsilon}{N}$。其中， $N$ 表示类别的个数， $T$ 表示真实标签值， $T^{\prime}$ 表示平滑后的标签。</p>
<p>例如，原来的标签 $T$ 为 $[0,0,1,0,0]$ ， $\varepsilon=0.1$ ，经过<code>LabelSmoothing</code>之后的标签 $T^{\prime}$ 为 $[0.02,0.02,0.92,0.02,0.02]$ 。</p>
<h1 id="图像处理中平滑和锐化操作是什么？"><a href="#图像处理中平滑和锐化操作是什么？" class="headerlink" title="图像处理中平滑和锐化操作是什么？"></a>图像处理中平滑和锐化操作是什么？</h1><h2 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h2><p>锐化就是通过增强图像的高频信息，也就是纹理边缘来减少图像中的模糊细节，但是在增强纹理的时候也引入了图像噪声。</p>
<p>平滑处理<code>(smoothing)</code>也称模糊处理<code>(bluring)</code>，主要用于消除图像中的噪声部分，平滑处理常用的用途是用来减少图像上的噪点或失真，平滑主要使用图像滤波。在这里，我个人认为可以把图像平滑和图像滤波联系起来，因为图像平滑常用的方法就是图像滤波器。</p>
<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ul>
<li>在计算机视觉的一些任务中，涉及到图像重建的、如高精度的深度估计、医学图像分割、三维重建等任务，最终需要得到原始图像分辨率大小的输出，同时对图像的边缘清晰度也有较高的要求，这时候可以通过增强特征图中的高频分量，在计算损失函数的时候放大这些区域的损失，进而放大对应参数的梯度，使得网络往更突出边缘的方向上优化。</li>
<li>与上相反，如果是一些希望输出更加平滑的任务，则可以考虑对特征图进行平滑操作，进而减小高频区域的损失，减小对应参数的梯度，使得网络往更平滑的方向上优化，通常这种技术都会用在<code>smooth loss</code>中。</li>
</ul>
<h1 id="batchsize"><a href="#batchsize" class="headerlink" title="batchsize"></a>batchsize</h1><p>（1）<code>batchsize</code>：批大小。在深度学习中，一般采用<code>SGD</code>训练，即每次训练在训练集中取<code>batchsize</code>个样本训练。<br>（2）<code>iteration</code>：1个<code>iteration</code>等于使用<code>batchsize</code>个样本训练一次。<br>（3）<code>epoch</code>：1个<code>epoch</code>等于使用训练集中的全部样本训练一次。<br>如果数据集比较小，则完全可以采用全数据集的形式。这样做的好处有两点：</p>
<ol>
<li>全数据集的方向能够更好的代表样本总体，确定其极值所在。</li>
<li>由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。</li>
</ol>
<p>增大<code>batchsize</code>的好处有三点：</p>
<ol>
<li>内存的利用率提高了，大矩阵乘法的并行化效率提高。</li>
<li>跑完一次<code>epoch</code>（全数据集）所需迭代次数减少，对于相同的数据量的处理速度进一步加快。</li>
<li>一定范围内，<code>batchsize</code>越大，其确定的下降方向就越准，引起训练震荡越小。</li>
</ol>
<p>盲目增大<code>batchsize</code>的坏处有三点：</p>
<ol>
<li>当数据集太大时，内存撑不住。</li>
<li>跑完一次<code>epoch</code>（全数据集）所需迭代次数减少了，但要想达到相同的精度，时间开销太大，参数的修正更加缓慢。</li>
<li><code>batchsize</code>增大到一定的程度，其确定的下降方向已经基本不再变化。</li>
</ol>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><p>支持向量机<code>(support vector machines，SVM)</code>是一种二分类模型，它将实例的特征向量映射为空间中的一些点，<code>SVM</code>的目的就是想要画出一条线，以 “最好地” 区分这两类点，以至如果以后有了新的点，这条线也能做出很好的分类。<code>SVM</code>适合中小型数据样本、非线性、高维的分类问题。</p>
<p>将实例的特征向量（以二维为例）映射为空间中的一些点，如下图的实心点和空心点，它们属于不同的两类。<code>SVM</code>的目的就是想要画出一条线，以“最好地”区分这两类点，以至如果以后有了新的点，这条线也能做出很好的分类。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071255957.png" alt=""></p>
<p><strong>Q1：能够画出多少条线对样本点进行区分？</strong><br>答：线是有无数条可以画的，区别就在于效果好不好，每条线都可以叫做一个划分超平面。比如上面的绿线就不好，蓝线还凑合，红线看起来就比较好。我们所希望找到的这条效果最好的线就是具有 “最大间隔的划分超平面”。</p>
<p><strong>Q2：为什么要叫作“超平面”呢？</strong><br>答：因为样本的特征很可能是高维的，此时样本空间的划分就不是一条线了。</p>
<p><strong>Q3：画线的标准是什么？/ 什么才叫这条线的效果好？/ 哪里好？</strong><br>答：<code>SVM</code>将会寻找可以区分两个类别并且能使间隔<code>(margin)</code>最大的划分超平面。比较好的划分超平面，样本局部扰动时对它的影响最小、产生的分类结果最鲁棒、对未见示例的泛化能力最强。</p>
<p><strong>Q4：间隔margin是什么？</strong><br>答：对于任意一个超平面，其两侧数据点都距离它有一个最小距离（垂直距离），这两个最小距离的和就是间隔。比如下图中两条虚线构成的带状区域就是<code>margin</code>，虚线是由距离中央实线最近的两个点所确定出来的（也就是由支持向量决定）。但此<code>margin</code>比较小，如果用第二种方式画，<code>margin</code>明显变大也更接近我们的目标。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071300267.png" alt=""></p>
<p><strong>Q5：为什么要让margin尽量大？</strong><br>答：因为大<code>margin</code>犯错的几率比较小，也就是更鲁棒啦。</p>
<p><strong>Q6：支持向量是什么？</strong><br>答：从上图可以看出，虚线上的点到划分超平面的距离都是一样的，实际上只有这几个点共同确定了超平面的位置，因此被称作 “支持向量<code>(support vectors)</code>”，“支持向量机” 也是由此来的。</p>
<p><strong>Q7：SVM 算法特性</strong></p>
<ol>
<li>训练好的模型的算法复杂度是由支持向量的个数决定的，而不是由数据的维度决定的。所以<code>SVM</code>不太容易产生<code>overfitting</code>。</li>
<li><code>SVM</code>训练出来的模型完全依赖于支持向量，即使训练集里面所有非支持向量的点都被去除，重复训练过程，结果仍然会得到完全一样的模型。</li>
<li>一个<code>SVM</code>如果训练得出的支持向量个数比较少，那么<code>SVM</code>训练出的模型比较容易被泛化。</li>
</ol>
<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><h3 id="普通卷积"><a href="#普通卷积" class="headerlink" title="普通卷积"></a>普通卷积</h3><p>在卷积神经网络中我们通常需要输入<code>in_channels</code>和<code>out_channels</code>，即输入通道数和输出通道数。</p>
<p>对于最初输入图片样本的通道数<code>in_channels</code>取决于图片的类型，如果是彩色的，即<code>RGB</code>类型，这时候通道数固定为 $3$ ，如果是灰度图，通道数为 $1$ 。<br>卷积完成之后，输出的通道数<code>out_channels</code>取决于过滤器的数量。从这个方向理解，这里的<code>out_channels</code>设置的就是过滤器的数目。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/20230106231925.png" alt=""></p>
<p>如上图，输入的通道数为 $3$ ，所以卷积的时候每个需要对每个通道有个卷积核；输出的通道数为 $4$ ，输出的通道数就是我们设置的过滤器的数目。</p>
<h3 id="分组卷积-group-convolution"><a href="#分组卷积-group-convolution" class="headerlink" title="分组卷积(group convolution)"></a>分组卷积(group convolution)</h3><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303212301932.png" alt=""></p>
<p><strong>我们用同等的参数量运算量生成了g个feature map！！！</strong></p>
<p>所以<code>group convolution</code>常用在轻量型高效网络中，因为它用少量的参数量和运算量就能生成大量的<code>feature map</code>，大量的<code>feature map</code>意味着能够编码更多的信息！</p>
<p>从分组卷积的角度来看，分组数 $g$ 就像一个控制旋钮，最小值是 $1$ ，此时 $g=1$ 的卷积就是普通卷积；最大值是输入<code>feature map</code>的通道数 $C$ ，此时 $g=C$ 的卷积就是<strong>depthwise sepereable convolution</strong>，即深度分离卷积，又叫逐通道卷积。</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化层是当前卷积神经网络中常用组件之一，它最早见于<code>LeNet</code>一文，称之为<code>Subsample</code>。自<code>AlexNet</code>之后采用<code>Pooling</code>命名。池化层是模仿人的视觉系统对数据进行降维，用更高层次的特征表示图像。</p>
<p>实施池化的目的：(1) 降低信息冗余；(2) 提升模型的尺度不变性、旋转不变性；(3) 防止过拟合。</p>
<h2 id="神经网络中权值共享的理解？"><a href="#神经网络中权值共享的理解？" class="headerlink" title="神经网络中权值共享的理解？"></a>神经网络中权值共享的理解？</h2><p>所谓权值共享就是说给定一张输入图片，用一个卷积核来卷积这张图，卷积核里的值叫做权重，这张图的每个位置是被同一个卷积核扫的，即卷积的时候所用的权重是一样的。其实权值共享这个词说全了就是整张图片在使用同一个卷积核内的参数，比如一个 $3\times 3 \times 1$ 的卷积核，这个卷积核内 $9$ 个的参数被整张图共享，而不会因为图像内位置的不同而改变卷积核内的权系数。说的再直白一些，就是用一个卷积核不改变其内权系数的情况下卷积处理整张图片（当然<code>CNN</code>中每一层不会只有一个卷积核的，这样说只是为了方便解释而已）。<br>作用：大大减少网络训练参数的同时，还可以实现并行训练。</p>
<h2 id="对微调-fine-tuning-的理解，为什么要修改最后几层神经网络权值？"><a href="#对微调-fine-tuning-的理解，为什么要修改最后几层神经网络权值？" class="headerlink" title="对微调(fine-tuning)的理解，为什么要修改最后几层神经网络权值？"></a>对微调(fine-tuning)的理解，为什么要修改最后几层神经网络权值？</h2><p>使用预训练模型的好处，在于利用训练好的<code>SOTA</code>模型权重去做特征提取，可以节省我们训练模型和调参的时间。</p>
<p>为什么只微调最后几层神经网络权重，是因为：</p>
<ol>
<li><code>CNN</code>中更靠近底部的层（定义模型时先添加到模型中的层）编码的是更加通用的可复用特征，而更靠近顶部的层（最后添加到模型中的层）编码的是更专业化的特征。微调这些更专业化的特征更加有用，它更代表了新数据集上的有用特征。</li>
<li>训练的参数越多，过拟合的风险越大。很多<code>SOTA</code>模型拥有超过千万的参数，在一个不大的数据集上训练这么多参数是有过拟合风险的，除非你的数据集像<code>ImageNet</code>那样大。</li>
</ol>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><h3 id="ResNet中的一些亮点"><a href="#ResNet中的一些亮点" class="headerlink" title="ResNet中的一些亮点"></a>ResNet中的一些亮点</h3><ol>
<li>超深的网络结构（超过 $1000$ 层）。</li>
<li>提出<code>residual</code>（残差结构）模块。</li>
<li>使用<code>Batch Normalization</code>加速训练（丢弃<code>Dropout</code>）。</li>
</ol>
<h3 id="为什么采用residual"><a href="#为什么采用residual" class="headerlink" title="为什么采用residual?"></a>为什么采用residual?</h3><p>人们认为卷积层和池化层的层数越多，获取到的图片特征信息越全，学习效果也就越好。但是在实际的试验中发现，随着卷积层和池化层的叠加，不但没有出现学习效果越来越好的情况，反而两种问题：</p>
<ol>
<li>梯度消失和梯度爆炸<br>梯度消失：若每一层的误差梯度小于 $1$ ，反向传播时，网络越深，梯度越趋近于 $0$<br>梯度爆炸：若每一层的误差梯度大于 $1$ ，反向传播时，网络越深，梯度越来越大</li>
<li>退化问题<br>随着层数的增加，预测效果反而越来越差。</li>
</ol>
<ul>
<li>为了解决梯度消失或梯度爆炸问题，<code>ResNet</code>论文提出通过数据的预处理以及在网络中使用 <code>BN(Batch Normalization)</code>层来解决。</li>
<li>为了解决深层网络中的退化问题，可以人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为残差网络<code>(ResNets)</code>。<code>ResNet</code>论文提出了<code>residual</code>结构（残差结构）来减轻退化问题，随着网络的不断加深，效果并没有变差，而是变的更好了。</li>
</ul>
<h3 id="residual结构"><a href="#residual结构" class="headerlink" title="residual结构"></a>residual结构</h3><h4 id="residual的计算方式"><a href="#residual的计算方式" class="headerlink" title="residual的计算方式"></a>residual的计算方式</h4><p><code>residual</code>结构使用了一种<code>shortcut</code>的连接方式，也可理解为捷径。让特征矩阵隔层相加，注意 $\mathcal{F}(\mathbb{x})$ 和 $\mathbb{x}$ 形状要相同，所谓相加是特征矩阵相同位置上的数字进行相加。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071317819.png" alt=""></p>
<h4 id="ResNet中两种不同的residual"><a href="#ResNet中两种不同的residual" class="headerlink" title="ResNet中两种不同的residual"></a>ResNet中两种不同的residual</h4><p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071317983.png" alt=""></p>
<ol>
<li>左侧残差结构称为<code>BasicBlock</code></li>
<li>右侧残差结构称为<code>Bottleneck</code><ul>
<li>其中第一层的 $1\times1$ 的卷积核的作用是对特征矩阵进行降维操作，将特征矩阵的深度由 $256$ 降为 $64$ ；</li>
<li>第三层的 $1\times1$ 的卷积核是对特征矩阵进行升维操作，将特征矩阵的深度由 $64$ 升成 $256$ 。<br>降低特征矩阵的深度主要是为了减少参数的个数。<br>如果采用<code>BasicBlock</code>，参数的个数应该是： $256\times256\times3\times3\times2=1179648$<br>采用<code>Bottleneck</code>，参数的个数是： $1\times1\times256\times64+3\times3\times64\times64+1\times1\times256\times64=69632$</li>
<li>先降后升为了主分支上输出的特征矩阵和捷径分支上输出的特征矩阵形状相同，以便进行加法操作。</li>
</ul>
</li>
</ol>
<h3 id="BatchNormalization"><a href="#BatchNormalization" class="headerlink" title="BatchNormalization"></a>BatchNormalization</h3><p><strong>BatchNormalization就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布。</strong></p>
<p>在神经网络中, 数据分布对训练会产生影响。比如某个神经元 $x$ 的值为 $1$ ，某个 <code>Weights</code> 的初始值为 $0.1$ ，这样后一层神经元计算结果就是 $Wx = 0.1$ ；又或者 $x = 20$ ，这样 $Wx$ 的结果就为 $2$ 。现在还不能看出什么问题,，但是，当我们加上一层激活函数，激活这个  $Wx$ 值的时候，问题就来了。如果使用像 <code>tanh</code> 的激活函数， $Wx$ 的激活值就变成了 $\approx 0.1$ 和 $\approx 1$, 接近于 $1$ 的部已经处在了激活函数的饱和阶段, 也就是 $x$ 无论再怎么扩大， <code>tanh</code> 激励函数输出值也还是接近 $1$ 。</p>
<p>我们为了避免这种情况，就会对数据进行归一化，<strong>对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0​，方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。</strong>同时了为了恢复出原始的某一层所学到的特征，我们引入了这个可学习重构参数 $\gamma$ 、$\beta$ ，让我们的网络可以学习恢复出原始网络所要学习的特征分布。</p>
<h3 id="ResNet为什么不用Dropout？"><a href="#ResNet为什么不用Dropout？" class="headerlink" title="ResNet为什么不用Dropout？"></a>ResNet为什么不用Dropout？</h3><p><code>Dropout</code>与<code>BN</code>不兼容。<code>BN</code>在训练过程对每个单个样本的<code>forward</code>均引入多个样本的统计信息，相当于自带一定噪音，起到正则效果，所以也就基本消除了<code>Dropout</code>的必要。</p>
<h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>循环神经网络<code>(Recurrent Neural Network, RNN)</code>是一类以序列<code>(sequence)</code>数据为输入，在序列的演进方向进行递归<code>(recursion)</code>且所有节点（循环单元）按链式连接的递归神经网络<code>(recursive neural network)</code> 。</p>
<p>对循环神经网络的研究始于二十世纪八九十年代，并在二十一世纪初发展为深度学习算法之一 ，其中双向循环神经网络<code>(Bidirectional RNN, Bi-RNN)</code>和长短期记忆网络<code>(Long Short-Term Memory networks, LSTM)</code>是常见的循环神经网络。</p>
<h2 id="为什么需要RNN？"><a href="#为什么需要RNN？" class="headerlink" title="为什么需要RNN？"></a>为什么需要RNN？</h2><p>在<code>CNN</code>网络中的训练样本的数据为<code>IID</code>数据（独立同分布数据），所解决的问题也是分类问题或者回归问题或者是特征表达问题。<strong>但更多的数据是不满足IID的</strong>，如语言翻译，自动文本生成。它们是一个序列问题，包括时间序列和空间序列。比如时间序列数据，这类数据是在不同时间点上收集到的数据，反映了某一事物、现象等随时间的变化状态或程度。一般的神经网络，在训练数据足够、算法模型优越的情况下，给定特定的 $x$ ，就能得到期望 $y$ 。其一般处理单个的输入，前一个输入和后一个输入完全无关，但实际应用中，某些任务需要能够更好的处理序列的信息，即前面的输入和后面的输入是有关系的。 这时就要用到<code>RNN</code>网络，<code>RNN</code>的结构图如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071328562.png" alt=""></p>
<h2 id="RNN的主要应用领域"><a href="#RNN的主要应用领域" class="headerlink" title="RNN的主要应用领域"></a>RNN的主要应用领域</h2><p>可以说只要考虑时间先后顺序的问题都可以使用<code>RNN</code>来解决，这里主要说一下几个常见的应用领域：</p>
<ul>
<li>自然语言处理<code>(NLP)</code>：主要有视频处理，文本生成，语言模型，图像处理。</li>
<li>机器翻译，机器写文章。</li>
<li>语音识别。</li>
<li>图像描述生成。</li>
<li>文本相似度计算。</li>
<li>推荐系统。例如：音乐推荐、网易考拉商品推荐、<code>Youtube</code>视频推荐等新的应用领域。</li>
</ul>
<h2 id="RNN的计算过程"><a href="#RNN的计算过程" class="headerlink" title="RNN的计算过程"></a>RNN的计算过程</h2><p><code>RNN</code>引入了隐状态 $h$ ， $h$ 可对序列数据提取特征，接着再转换为输出。首先我们计算 $h_{1}$ ：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071332166.jpg" alt=""></p>
<p><code>RNN</code>中，每个步骤使用的参数 $U,W,b$ 相同， $h_{2},h_{3},h_{4}$ 的计算方式和 $h_{1}$ 类似，其计算结果如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071333924.jpg" alt=""></p>
<p>接下来，计算<code>RNN</code>的输出 $y_1$ ，采用<code>Softmax</code>作为激活函数，根据 $y_n=f(Wx+b)$ ，得到 $y_1$ :</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071335563.jpg" alt=""></p>
<p>使用和 $y_1$ 相同的参数 $V,c$ ，得到 $y_2,y_3,y_4$ 的输出结构：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071336003.jpg" alt=""></p>
<h2 id="RNN的建模方式"><a href="#RNN的建模方式" class="headerlink" title="RNN的建模方式"></a>RNN的建模方式</h2><h3 id="一对多-vector-to-sequence"><a href="#一对多-vector-to-sequence" class="headerlink" title="一对多(vector-to-sequence)"></a>一对多(vector-to-sequence)</h3><p>输入是一个单独的值，输出是一个序列。此时，有两种主要建模方式：</p>
<p>方式一：可只在其中的某一个序列进行计算，比如序列第一个进行输入计算，其建模方式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071339814.jpg" alt=""></p>
<p>方式二：把输入信息 $X$ 作为每个阶段的输入，其建模方式如下：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071339457.jpg" alt=""></p>
<h3 id="多对一-sequence-to-vector"><a href="#多对一-sequence-to-vector" class="headerlink" title="多对一(sequence-to-vector)"></a>多对一(sequence-to-vector)</h3><p>输入是一个序列，输出是一个单独的值，此时通常在最后的一个序列上进行输出变换，其建模如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071340668.jpg" alt=""></p>
<h3 id="多对多-Encoder-Decoder"><a href="#多对多-Encoder-Decoder" class="headerlink" title="多对多(Encoder-Decoder)"></a>多对多(Encoder-Decoder)</h3><p><strong>步骤一</strong>：将输入数据编码成一个上下文向量 $c$ ，这部分称为<code>Encoder</code>，得到 $c$ 有多种方式，最简单的方法就是把<code>Encoder</code>的最后一个隐状态赋值给 $c$ ，还可以对最后的隐状态做一个变换得到 $c$ ，也可以对所有的隐状态做变换。其示意如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071341013.jpg" alt=""></p>
<p><strong>步骤二</strong>：用另一个<code>RNN</code>网络（我们将其称为<code>Decoder</code>）对其进行编码。</p>
<p>方法一是将步骤一中的 $c$ 作为初始状态输入到<code>Decoder</code>，示意图如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071342703.jpg" alt=""></p>
<p>方法二是将 $c$ 作为<code>Decoder</code>的每一步输入，示意图如下所示：</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071343619.jpg" alt=""></p>
<h2 id="RNN中为什么会出现梯度消失？如何解决？"><a href="#RNN中为什么会出现梯度消失？如何解决？" class="headerlink" title="RNN中为什么会出现梯度消失？如何解决？"></a>RNN中为什么会出现梯度消失？如何解决？</h2><p><strong>梯度消失的原因：</strong><code>Sigmoid</code>函数的导数范围是 $(0,0.25]$，<code>tanh</code>函数的导数范围是 $(0,1]$ ，他们的导数最大都不大于 $1$ ，如果取<code>tanh</code>或<code>Sigmoid</code>函数作为激活函数嵌套到<code>RNN</code>中，那么必然是一堆小数在做乘法，结果就是越乘越小。随着时间序列的不断深入，小数的累乘就会导致梯度越来越小直到接近于 $0$ ，这就是“梯度消失“现象。实际使用中，会优先选择<code>tanh</code>函数，原因是<code>tanh</code>函数相对于<code>Sigmoid</code>函数来说梯度较大，收敛速度更快且引起梯度消失更慢。</p>
<p> <strong>解决RNN中的梯度消失方法主要有：</strong></p>
<ol>
<li>选取更好的激活函数，如<code>ReLU</code>激活函数。<code>ReLU</code>函数的左侧导数为 $0$ ，右侧导数恒为 $1$ ，这就避免了“梯度消失“的发生。但恒为 $1$ 的导数容易导致“梯度爆炸“，但设定合适的阈值可以解决这个问题。</li>
<li>加入<code>BN</code>层，其优点包括可加速收敛、控制过拟合，可以少用或不用<code>Dropout</code>和正则、降低网络对初始化权重不敏感，且能允许使用较大的学习率等。</li>
<li>改变传播结构，选择更高级的模型，例如：<code>LSTM</code>结构可以有效解决这个问题。</li>
</ol>
<h2 id="RNN的注意力机制"><a href="#RNN的注意力机制" class="headerlink" title="RNN的注意力机制"></a>RNN的注意力机制</h2><p>在上述的<code>Encoder-Decoder</code>结构中，<code>Encoder</code>把所有的输入序列都编码成一个统一的语义特征 $c$ 再解码。因此， $c$ 中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。如机器翻译问题，当要翻译的句子较长时，一个 $c$ 可能存不下那么多信息，就会造成翻译精度的下降。<code>Attention</code>机制通过在每个时间输入不同的 $c$ 来解决此问题。</p>
<p><img src="https://my-pic-storage-1305445540.cos.ap-nanjing.myqcloud.com/202303071356215.png" alt=""></p>
<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%80%BB%E7%BB%93/" rel="tag"># 总结</a>
              <a href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag"># 面试</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/11/22/%E7%AE%97%E6%B3%95Tricks/" rel="prev" title="算法Tricks">
                  <i class="fa fa-chevron-left"></i> 算法Tricks
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">木霈玖</span>
</div>

    </div>
  </footer>

  
  <script src="//unpkg.com/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'none'
      },
      options: {
        renderActions: {
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//unpkg.com/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



</body>
</html>
